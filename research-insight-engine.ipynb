{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"A100","mount_file_id":"1oyDdJlQuN7CzEVAWS85Z39B48ZNUFUq5","authorship_tag":"ABX9TyNd9I9d5LmkxfNvmB9fw6m4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"6dbe79b08f7c46fbab846335bddc93b1":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c5a8b9a2c0bd47acaae968c61e82f6e3","IPY_MODEL_ecb2fe9bed9d4512bd32f276079413d4","IPY_MODEL_8fdb7de8b1774884b7bfe09adb60db3c"],"layout":"IPY_MODEL_ac00711acad1428da67c177d8f973a39"}},"c5a8b9a2c0bd47acaae968c61e82f6e3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0f463feff196495783d0655db3b07900","placeholder":"​","style":"IPY_MODEL_ff574ef011444aaa9f04ad23e263c575","value":"Fetching papers: "}},"ecb2fe9bed9d4512bd32f276079413d4":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_17adee2299b640389d573b29d600fe95","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_89f7975d6f6e44299c7c94acc9c40806","value":1}},"8fdb7de8b1774884b7bfe09adb60db3c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ec4ea8b8e2f64ae8b121e06a2de0c02d","placeholder":"​","style":"IPY_MODEL_a57ffdddf90f44b58a6d36620842c1b5","value":" 1000/? [00:38&lt;00:00, 24.58it/s]"}},"ac00711acad1428da67c177d8f973a39":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0f463feff196495783d0655db3b07900":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ff574ef011444aaa9f04ad23e263c575":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"17adee2299b640389d573b29d600fe95":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"89f7975d6f6e44299c7c94acc9c40806":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ec4ea8b8e2f64ae8b121e06a2de0c02d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a57ffdddf90f44b58a6d36620842c1b5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4836eadb309d41d8b7d9fe4e723d6c8a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_352c2d68cd3946b0a8c147a5a9650ac6","IPY_MODEL_2447001413b24cbcb36eb40f6ae4e27e","IPY_MODEL_a94ddb49f31a45f7bfe2b99ace1285bb"],"layout":"IPY_MODEL_dce451b61c454ca69686d9b0b6b046ca"}},"352c2d68cd3946b0a8c147a5a9650ac6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0d053f43462f4878a0d65b7ea905522b","placeholder":"​","style":"IPY_MODEL_5feae43d39dc45da95d71f839617d1b5","value":"modules.json: 100%"}},"2447001413b24cbcb36eb40f6ae4e27e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_4e584f230dc6499da52f0511d4cd5b7a","max":349,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6cb07eb4367d483d80503736faac8a77","value":349}},"a94ddb49f31a45f7bfe2b99ace1285bb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6db939ca964b4444bd5fccca2974b9fe","placeholder":"​","style":"IPY_MODEL_5418312766a84a338706ac9c3674559d","value":" 349/349 [00:00&lt;00:00, 44.2kB/s]"}},"dce451b61c454ca69686d9b0b6b046ca":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0d053f43462f4878a0d65b7ea905522b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5feae43d39dc45da95d71f839617d1b5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4e584f230dc6499da52f0511d4cd5b7a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6cb07eb4367d483d80503736faac8a77":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6db939ca964b4444bd5fccca2974b9fe":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5418312766a84a338706ac9c3674559d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c3ce137ddd904724ac75a561e5dda321":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a5bfa781cba746b69ef2ef3e8ca3e345","IPY_MODEL_981d468334474425a53a046edff02e92","IPY_MODEL_9b7dda8e252b4600bce3bcc2ddea3d1a"],"layout":"IPY_MODEL_7ed860f521024ec5a7fb21df7247e780"}},"a5bfa781cba746b69ef2ef3e8ca3e345":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_62084156cd5e4f3ea0e6e461e366de00","placeholder":"​","style":"IPY_MODEL_228b2b06dcb54d0b9eae7973c13cc00c","value":"config_sentence_transformers.json: 100%"}},"981d468334474425a53a046edff02e92":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_3f81938bda0e4d9095be672fbe7bf565","max":116,"min":0,"orientation":"horizontal","style":"IPY_MODEL_af95b216915240109d1ed3d4fc354f28","value":116}},"9b7dda8e252b4600bce3bcc2ddea3d1a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c87f0faad32e4eb4abcdae41a681d6ba","placeholder":"​","style":"IPY_MODEL_15302f98b16b4364a30ab8c1981a1177","value":" 116/116 [00:00&lt;00:00, 13.7kB/s]"}},"7ed860f521024ec5a7fb21df7247e780":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"62084156cd5e4f3ea0e6e461e366de00":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"228b2b06dcb54d0b9eae7973c13cc00c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3f81938bda0e4d9095be672fbe7bf565":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"af95b216915240109d1ed3d4fc354f28":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c87f0faad32e4eb4abcdae41a681d6ba":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"15302f98b16b4364a30ab8c1981a1177":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"084b5d2844aa4545878f15c358b45558":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_692c71a00fee468ba6095ddcdab1094d","IPY_MODEL_5b0b06e12e90445e840f848250e71f35","IPY_MODEL_d54bc64250df4847834fb993f500580f"],"layout":"IPY_MODEL_5cb004602b4a4a858103e682e0e0a45d"}},"692c71a00fee468ba6095ddcdab1094d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_15eabe9dac8043088055f9e17b4592ac","placeholder":"​","style":"IPY_MODEL_ab022b02bb6e4e16b7b77410b6fb90b5","value":"README.md: 100%"}},"5b0b06e12e90445e840f848250e71f35":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f4f666afa39d41fc9849988b2b6dc957","max":10454,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7834f0b099974dc993c51cfd63ee39dc","value":10454}},"d54bc64250df4847834fb993f500580f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2618108599b84e1ba5cd13903a852d2e","placeholder":"​","style":"IPY_MODEL_50bbc895809f45c1a33d858e877b7fd7","value":" 10.5k/10.5k [00:00&lt;00:00, 1.28MB/s]"}},"5cb004602b4a4a858103e682e0e0a45d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"15eabe9dac8043088055f9e17b4592ac":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ab022b02bb6e4e16b7b77410b6fb90b5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f4f666afa39d41fc9849988b2b6dc957":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7834f0b099974dc993c51cfd63ee39dc":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2618108599b84e1ba5cd13903a852d2e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"50bbc895809f45c1a33d858e877b7fd7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"664bad2172d54cbab9ca6b9517ca7e68":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_45a1501c32474ba082880378925fb70e","IPY_MODEL_b3a7e2c3e3e04dfda76f2db27d5e73ba","IPY_MODEL_6d23374099ae4945a9b7a50188dc2002"],"layout":"IPY_MODEL_47c2709a24924bee977283d3be132c42"}},"45a1501c32474ba082880378925fb70e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_04a92370a6744189a924c4fda4557759","placeholder":"​","style":"IPY_MODEL_fd980a96a1994cb9a4ca4382adf9a7c4","value":"sentence_bert_config.json: 100%"}},"b3a7e2c3e3e04dfda76f2db27d5e73ba":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_329bd41cb9484158b3637a582a8b6730","max":53,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1b9297ff6e5744158ac334c845567b1a","value":53}},"6d23374099ae4945a9b7a50188dc2002":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_50820142bc45451bb6ce3203cb41c138","placeholder":"​","style":"IPY_MODEL_54642013260a4bb3b375ea3875922aeb","value":" 53.0/53.0 [00:00&lt;00:00, 6.62kB/s]"}},"47c2709a24924bee977283d3be132c42":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"04a92370a6744189a924c4fda4557759":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fd980a96a1994cb9a4ca4382adf9a7c4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"329bd41cb9484158b3637a582a8b6730":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1b9297ff6e5744158ac334c845567b1a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"50820142bc45451bb6ce3203cb41c138":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"54642013260a4bb3b375ea3875922aeb":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"dee5a7227e424d75bccd8b08c22b4c80":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4231491f7a2849c2b29e21d0aaa0edf7","IPY_MODEL_bd0162546c8740f68dc31c68603a57c5","IPY_MODEL_522bfbdf7b7e4520a5f807fd35362a5c"],"layout":"IPY_MODEL_6819e5fca0b247a19e07da68160d43a5"}},"4231491f7a2849c2b29e21d0aaa0edf7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_340bf8d54a9645d2b14e443d8951b9c5","placeholder":"​","style":"IPY_MODEL_6fc7afdb991b491483a46efef3577a8c","value":"config.json: 100%"}},"bd0162546c8740f68dc31c68603a57c5":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ba184642912244b08acb75ba99730c5a","max":612,"min":0,"orientation":"horizontal","style":"IPY_MODEL_adb031dd0892421a8d74358c1e3f9f08","value":612}},"522bfbdf7b7e4520a5f807fd35362a5c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_04b98679cc724266af61dc1501e0435e","placeholder":"​","style":"IPY_MODEL_92aeda1bdb6540b8b34f8986c1cc3c6b","value":" 612/612 [00:00&lt;00:00, 79.1kB/s]"}},"6819e5fca0b247a19e07da68160d43a5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"340bf8d54a9645d2b14e443d8951b9c5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6fc7afdb991b491483a46efef3577a8c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ba184642912244b08acb75ba99730c5a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"adb031dd0892421a8d74358c1e3f9f08":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"04b98679cc724266af61dc1501e0435e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"92aeda1bdb6540b8b34f8986c1cc3c6b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ed480a71184b474c9800cc6966196c32":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_54fe70b95570401692948e9ae8f9b5ef","IPY_MODEL_7a233c1c046d47e6bccc263436082ec2","IPY_MODEL_2c3f053e0c4c432c80494392c778e522"],"layout":"IPY_MODEL_d003b6aad20f4b91a314f6f231209072"}},"54fe70b95570401692948e9ae8f9b5ef":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9a8e24a9644d4624b2ce76d42288b284","placeholder":"​","style":"IPY_MODEL_9a04d2a280d246c58729eebd99ce5abd","value":"model.safetensors: 100%"}},"7a233c1c046d47e6bccc263436082ec2":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_1ef2d750f0f84ea79f9ca683d61e3e3d","max":90868376,"min":0,"orientation":"horizontal","style":"IPY_MODEL_26cb23297e30434bb5f35056b94f3755","value":90868376}},"2c3f053e0c4c432c80494392c778e522":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1647a435ca794c489e64df514d6eefe2","placeholder":"​","style":"IPY_MODEL_5487bb0f79964734880848f61da29728","value":" 90.9M/90.9M [00:00&lt;00:00, 205MB/s]"}},"d003b6aad20f4b91a314f6f231209072":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9a8e24a9644d4624b2ce76d42288b284":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9a04d2a280d246c58729eebd99ce5abd":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1ef2d750f0f84ea79f9ca683d61e3e3d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"26cb23297e30434bb5f35056b94f3755":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1647a435ca794c489e64df514d6eefe2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5487bb0f79964734880848f61da29728":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"abec9d3a40a144979cc015836901ccf3":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f5e660e16bf14c86bb2e1325679a5d7d","IPY_MODEL_438921975ad24d06b81db988f9356704","IPY_MODEL_a79ea0d3fe6a4d32bf4e4a87937fcb1b"],"layout":"IPY_MODEL_a499ce1a7f5a4d93a5f36774dc656e67"}},"f5e660e16bf14c86bb2e1325679a5d7d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_937cef85bbee45b6b693a28e2edd5213","placeholder":"​","style":"IPY_MODEL_30226c54a0b04c4b8449cafa9ca9e7c2","value":"tokenizer_config.json: 100%"}},"438921975ad24d06b81db988f9356704":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b7afd975d0674ebfa46cdf5579c871e5","max":350,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2d01fad7ad1643bdb8fcb539b7e93d29","value":350}},"a79ea0d3fe6a4d32bf4e4a87937fcb1b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f157046690d14dfbac852444c4077ffd","placeholder":"​","style":"IPY_MODEL_6347c502c2dc4275965ba9bf1ae50e72","value":" 350/350 [00:00&lt;00:00, 44.5kB/s]"}},"a499ce1a7f5a4d93a5f36774dc656e67":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"937cef85bbee45b6b693a28e2edd5213":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"30226c54a0b04c4b8449cafa9ca9e7c2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b7afd975d0674ebfa46cdf5579c871e5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2d01fad7ad1643bdb8fcb539b7e93d29":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f157046690d14dfbac852444c4077ffd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6347c502c2dc4275965ba9bf1ae50e72":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"08a586d8be014287827706b33e03e48b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5d618bb2572e4300a6a82b09220c5d81","IPY_MODEL_ec972992f9f14797bc60aab3eb20e575","IPY_MODEL_a659490f9e774e29adbf33c6db1be3fe"],"layout":"IPY_MODEL_0632e9899d074d8f92f5eef5bf4a24b2"}},"5d618bb2572e4300a6a82b09220c5d81":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_45931b7c12e9480dae2609b01056c60a","placeholder":"​","style":"IPY_MODEL_49de9884db2543eba07889378ee15cff","value":"vocab.txt: 100%"}},"ec972992f9f14797bc60aab3eb20e575":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_5893acdd3e29477eb3d2d39b4b3ac6a5","max":231508,"min":0,"orientation":"horizontal","style":"IPY_MODEL_afa311dc12e14bb3b8c88172a74b3041","value":231508}},"a659490f9e774e29adbf33c6db1be3fe":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_83e516f30dd047abafa626c45796f140","placeholder":"​","style":"IPY_MODEL_3a9673da20af41e7872489a0e6b1639d","value":" 232k/232k [00:00&lt;00:00, 24.4MB/s]"}},"0632e9899d074d8f92f5eef5bf4a24b2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"45931b7c12e9480dae2609b01056c60a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"49de9884db2543eba07889378ee15cff":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5893acdd3e29477eb3d2d39b4b3ac6a5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"afa311dc12e14bb3b8c88172a74b3041":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"83e516f30dd047abafa626c45796f140":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3a9673da20af41e7872489a0e6b1639d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"dd4aafb52f014626a69a4d48565037b1":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_79a4944d39fc4affa058fd67c0ef9a7f","IPY_MODEL_2bb88b3138f74a56a6571610cb084166","IPY_MODEL_d7e5647c394c4337bedec074c27dab98"],"layout":"IPY_MODEL_63017d6b5b7a461582f4cfffa459549e"}},"79a4944d39fc4affa058fd67c0ef9a7f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3ed3b5c8f04247d593d81c382659f729","placeholder":"​","style":"IPY_MODEL_9c83719524df45fbbb96ebcf0e59e5f3","value":"tokenizer.json: 100%"}},"2bb88b3138f74a56a6571610cb084166":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c4e47fdd0a5749f3821da938fde885a1","max":466247,"min":0,"orientation":"horizontal","style":"IPY_MODEL_28de84f5bc07427689c2f9a25e56ee61","value":466247}},"d7e5647c394c4337bedec074c27dab98":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2c75be1f7df74d63bda3f94c47a82c6e","placeholder":"​","style":"IPY_MODEL_16baa8e23ba543fbbbf60f25dfe31b2f","value":" 466k/466k [00:00&lt;00:00, 43.4MB/s]"}},"63017d6b5b7a461582f4cfffa459549e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3ed3b5c8f04247d593d81c382659f729":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9c83719524df45fbbb96ebcf0e59e5f3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c4e47fdd0a5749f3821da938fde885a1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"28de84f5bc07427689c2f9a25e56ee61":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2c75be1f7df74d63bda3f94c47a82c6e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"16baa8e23ba543fbbbf60f25dfe31b2f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"32e9f2542c344311944e0ab4af0ea2fc":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5724c506815247a1b68872af559130fc","IPY_MODEL_68c0fc1ef3534f18a0c7e82b601e37ad","IPY_MODEL_00bd1575dce84981be459e831b8f0f58"],"layout":"IPY_MODEL_1d1625d44f274b868b198d5117bfb3e3"}},"5724c506815247a1b68872af559130fc":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_de1c8e774c984574bd1f1be290e78d02","placeholder":"​","style":"IPY_MODEL_c5bec5a1b797433fb9ff8622fefd5638","value":"special_tokens_map.json: 100%"}},"68c0fc1ef3534f18a0c7e82b601e37ad":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c01a95869cf24b5fb0580aec7e9b439a","max":112,"min":0,"orientation":"horizontal","style":"IPY_MODEL_0542437707dd44ddb2f7487f85daaf02","value":112}},"00bd1575dce84981be459e831b8f0f58":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_99c29e8ec20148fa8bdcb4f253d9e03f","placeholder":"​","style":"IPY_MODEL_1751cc12365d4d538a7869fd20f0c0fa","value":" 112/112 [00:00&lt;00:00, 14.1kB/s]"}},"1d1625d44f274b868b198d5117bfb3e3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"de1c8e774c984574bd1f1be290e78d02":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c5bec5a1b797433fb9ff8622fefd5638":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c01a95869cf24b5fb0580aec7e9b439a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0542437707dd44ddb2f7487f85daaf02":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"99c29e8ec20148fa8bdcb4f253d9e03f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1751cc12365d4d538a7869fd20f0c0fa":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a14928b56cad4f1290190ae1f7fc350b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4f7d4b5bca51485b85e6b988d99fe00b","IPY_MODEL_25aa3683a4ad4aeb94f99d389ae966d0","IPY_MODEL_9ba5c8c5956d4db8a320b67ed12c4b97"],"layout":"IPY_MODEL_2005ad67d16e4fb0be7b25b32fb7e5e9"}},"4f7d4b5bca51485b85e6b988d99fe00b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5bd8d79a175449f68643a7384f7d5cd8","placeholder":"​","style":"IPY_MODEL_d5bdfab29ccd4d5b9270dc0a7c460035","value":"config.json: 100%"}},"25aa3683a4ad4aeb94f99d389ae966d0":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_484e660f55184a13bf6e92d66437e8be","max":190,"min":0,"orientation":"horizontal","style":"IPY_MODEL_eb93ce31eb1f4b21adaa14d6f1606e9d","value":190}},"9ba5c8c5956d4db8a320b67ed12c4b97":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1f183f733edd447abe1f87e4c6915f7d","placeholder":"​","style":"IPY_MODEL_62daae2f105c4c8c89f184a275a62c9b","value":" 190/190 [00:00&lt;00:00, 23.8kB/s]"}},"2005ad67d16e4fb0be7b25b32fb7e5e9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5bd8d79a175449f68643a7384f7d5cd8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d5bdfab29ccd4d5b9270dc0a7c460035":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"484e660f55184a13bf6e92d66437e8be":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"eb93ce31eb1f4b21adaa14d6f1606e9d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1f183f733edd447abe1f87e4c6915f7d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"62daae2f105c4c8c89f184a275a62c9b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c4479d08c34f4a2797477013c9e83d3a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2c1bf5c571b847dc80f8d92fdd4de150","IPY_MODEL_4b3c7005c12149189af1df3b70e24179","IPY_MODEL_374a8f5f43164cc496a99e8d8f950faf"],"layout":"IPY_MODEL_d49b4bfdf1144570bc643a700932ad07"}},"2c1bf5c571b847dc80f8d92fdd4de150":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_27905e3f821b44ae8af454b91f78e4b6","placeholder":"​","style":"IPY_MODEL_c9eb7c34786e41a18cc332b4e484076f","value":"Batches: 100%"}},"4b3c7005c12149189af1df3b70e24179":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_4d9085c8c695457bba2b7f22817774b5","max":16,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6a68921aa0154bdbaaeb7ccf40319f94","value":16}},"374a8f5f43164cc496a99e8d8f950faf":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_68026f81fe8d4b0785d9f946c476dc67","placeholder":"​","style":"IPY_MODEL_d027cb8f28024d729ea1a3855c1218e2","value":" 16/16 [00:01&lt;00:00, 17.75it/s]"}},"d49b4bfdf1144570bc643a700932ad07":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"27905e3f821b44ae8af454b91f78e4b6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c9eb7c34786e41a18cc332b4e484076f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4d9085c8c695457bba2b7f22817774b5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6a68921aa0154bdbaaeb7ccf40319f94":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"68026f81fe8d4b0785d9f946c476dc67":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d027cb8f28024d729ea1a3855c1218e2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1fa53bec8bf84ddb81f78f8b0e934152":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6eef0ccec7b2469dbfbdcc765770248d","IPY_MODEL_4925c502894f4c6a9ea9359a9f4cbed3","IPY_MODEL_f7a06ca0ecb1454683ff2cff868e1f63"],"layout":"IPY_MODEL_94602d9fc51c4b26a66409ce2485f803"}},"6eef0ccec7b2469dbfbdcc765770248d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_387635a5ffd24f899ea2393fe2f6daa7","placeholder":"​","style":"IPY_MODEL_4b1a7bd4ff6245af8d7542453fb971dd","value":"Loading checkpoint shards: 100%"}},"4925c502894f4c6a9ea9359a9f4cbed3":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_1bfa799f5e4c4868a18014f0755a409d","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8d7b335c0e8c46479ef962fb6366c3c5","value":2}},"f7a06ca0ecb1454683ff2cff868e1f63":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fcaee2b8d90a4a76a6c9fe6463d16a55","placeholder":"​","style":"IPY_MODEL_c70beee724cc478c8ee2c647f57a7313","value":" 2/2 [00:09&lt;00:00,  4.25s/it]"}},"94602d9fc51c4b26a66409ce2485f803":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"387635a5ffd24f899ea2393fe2f6daa7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4b1a7bd4ff6245af8d7542453fb971dd":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1bfa799f5e4c4868a18014f0755a409d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8d7b335c0e8c46479ef962fb6366c3c5":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"fcaee2b8d90a4a76a6c9fe6463d16a55":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c70beee724cc478c8ee2c647f57a7313":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"tKRtB60uYA-J"},"outputs":[],"source":["# Install dependencies\n","!pip install -q arxiv pandas numpy tqdm sentence-transformers umap-learn hdbscan plotly streamlit transformers torch scikit-learn\n","\n","# Mount Google Drive (optional - uncomment if you want to save results)\n"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mJ8edfRbbR9X","executionInfo":{"status":"ok","timestamp":1742741710220,"user_tz":360,"elapsed":9130,"user":{"displayName":"Alex Baret","userId":"10734557950216503149"}},"outputId":"6bfe5d0c-1bdf-4bec-c59b-fabd21efae23"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["import os\n","import sys\n","sys.path.append('src')  # relative path from current dir\n","\n","# Replace with the name of your folder\n","folder_path = '/content/drive/My Drive/research_insight_engine/src'\n","\n","os.chdir(folder_path)\n","!ls  # lists files in the current directory"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UumgExS5bgWR","executionInfo":{"status":"ok","timestamp":1742741729373,"user_tz":360,"elapsed":112,"user":{"displayName":"Alex Baret","userId":"10734557950216503149"}},"outputId":"a960fd90-a864-4b85-c6a8-78e244d67313"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["1_data_ingestion.py  2_embedding_clustering.py\t3_summarization_novelty.py  4_visualization.py\n"]}]},{"cell_type":"code","source":["import os\n","import sys\n","from IPython.display import HTML, display\n","import pandas as pd\n","import plotly.express as px\n","import json\n","from tqdm.notebook import tqdm\n","\n","\n","# Import our modules\n","from data_ingestion import fetch_papers, setup_directory\n","from embedding_clustering import create_embeddings, reduce_dimensions, cluster_papers\n","from summarization_novelty import setup_model, create_cluster_prompt, generate_summary, compute_novelty_score"],"metadata":{"id":"6MjT1SKJbrbk","executionInfo":{"status":"ok","timestamp":1742741837446,"user_tz":360,"elapsed":35005,"user":{"displayName":"Alex Baret","userId":"10734557950216503149"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["from datetime import datetime, timedelta\n","import arxiv\n","def setup_directory():\n","    \"\"\"Create and return the path to the data directory.\"\"\"\n","    base_path = \"data\"\n","    os.makedirs(base_path, exist_ok=True)\n","    return base_path\n","\n","def format_paper_title(title):\n","    \"\"\"Clean and format paper title.\"\"\"\n","    return title.strip().replace('\\n', ' ').replace('  ', ' ')\n","\n","# Create data directory\n","def fetch_papers(days=7, category='cs.LG'):\n","    \"\"\"Fetch papers from arXiv published in the last n days.\"\"\"\n","    # Calculate date range with timezone awareness\n","    from datetime import timezone\n","    end_date = datetime.now(timezone.utc)\n","    start_date = end_date - timedelta(days=days)\n","    print(f\"Fetching papers from {start_date.date()} to {end_date.date()}\")\n","\n","    # Create search query\n","    search = arxiv.Search(\n","        query=f\"cat:{category}\",\n","        max_results=1000,  # We'll filter by date later\n","        sort_by=arxiv.SortCriterion.SubmittedDate\n","    )\n","\n","    # Fetch and process papers\n","    papers = []\n","    for result in tqdm(search.results(), desc=\"Fetching papers\"):\n","        # The result.published is timezone-aware, so we can compare directly\n","        if start_date <= result.published <= end_date:\n","            paper = {\n","                'id': result.entry_id.split('/')[-1],\n","                'title': format_paper_title(result.title),\n","                'abstract': result.summary,\n","                'authors': [author.name for author in result.authors],\n","                'date': result.published.strftime('%Y-%m-%d'),\n","                'categories': result.categories,\n","                'comment': result.comment if result.comment else '',\n","                'pdf_url': result.pdf_url\n","            }\n","            papers.append(paper)\n","\n","    return papers\n","\n","data_path = \"data\"\n","os.makedirs(data_path, exist_ok=True)\n","\n","# Step 1: Data Ingestion\n","print(\"📚 Step 1: Fetching Papers\")\n","papers = fetch_papers(days=7, category='cs.LG')\n","df = pd.DataFrame(papers)\n","df.to_csv(os.path.join(data_path, 'recent_papers.csv'), index=False)\n","print(f\"Found {len(papers)} papers\\n\")\n","\n","# Display sample\n","display(df[['title', 'date', 'authors']].head())\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":342,"referenced_widgets":["6dbe79b08f7c46fbab846335bddc93b1","c5a8b9a2c0bd47acaae968c61e82f6e3","ecb2fe9bed9d4512bd32f276079413d4","8fdb7de8b1774884b7bfe09adb60db3c","ac00711acad1428da67c177d8f973a39","0f463feff196495783d0655db3b07900","ff574ef011444aaa9f04ad23e263c575","17adee2299b640389d573b29d600fe95","89f7975d6f6e44299c7c94acc9c40806","ec4ea8b8e2f64ae8b121e06a2de0c02d","a57ffdddf90f44b58a6d36620842c1b5"]},"id":"apZLdd7LfwuK","executionInfo":{"status":"ok","timestamp":1742742873669,"user_tz":360,"elapsed":38160,"user":{"displayName":"Alex Baret","userId":"10734557950216503149"}},"outputId":"ba5afc09-63de-488e-c97a-789784bf0528"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["📚 Step 1: Fetching Papers\n","Fetching papers from 2025-03-16 to 2025-03-23\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-17-85508d34a316>:31: DeprecationWarning: The 'Search.results' method is deprecated, use 'Client.results' instead\n","  for result in tqdm(search.results(), desc=\"Fetching papers\"):\n"]},{"output_type":"display_data","data":{"text/plain":["Fetching papers: 0it [00:00, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6dbe79b08f7c46fbab846335bddc93b1"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Found 483 papers\n","\n"]},{"output_type":"display_data","data":{"text/plain":["                                               title        date  \\\n","0     GAEA: A Geolocation Aware Conversational Model  2025-03-20   \n","1  MagicMotion: Controllable Video Generation wit...  2025-03-20   \n","2  InfiniteYou: Flexible Photo Recrafting While P...  2025-03-20   \n","3           Survey on Evaluation of LLM-based Agents  2025-03-20   \n","4  DreamTexture: Shape from Virtual Texture with ...  2025-03-20   \n","\n","                                             authors  \n","0  [Ron Campos, Ashmal Vayani, Parth Parag Kulkar...  \n","1  [Quanhao Li, Zhen Xing, Rui Wang, Hui Zhang, Q...  \n","2  [Liming Jiang, Qing Yan, Yumin Jia, Zichuan Li...  \n","3  [Asaf Yehudai, Lilach Eden, Alan Li, Guy Uziel...  \n","4  [Ananta R. Bhattarai, Xingzhe He, Alla Sheffer...  "],"text/html":["\n","  <div id=\"df-f7988a20-6edf-4ffc-a737-00f4b04a885d\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>title</th>\n","      <th>date</th>\n","      <th>authors</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>GAEA: A Geolocation Aware Conversational Model</td>\n","      <td>2025-03-20</td>\n","      <td>[Ron Campos, Ashmal Vayani, Parth Parag Kulkar...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>MagicMotion: Controllable Video Generation wit...</td>\n","      <td>2025-03-20</td>\n","      <td>[Quanhao Li, Zhen Xing, Rui Wang, Hui Zhang, Q...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>InfiniteYou: Flexible Photo Recrafting While P...</td>\n","      <td>2025-03-20</td>\n","      <td>[Liming Jiang, Qing Yan, Yumin Jia, Zichuan Li...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Survey on Evaluation of LLM-based Agents</td>\n","      <td>2025-03-20</td>\n","      <td>[Asaf Yehudai, Lilach Eden, Alan Li, Guy Uziel...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>DreamTexture: Shape from Virtual Texture with ...</td>\n","      <td>2025-03-20</td>\n","      <td>[Ananta R. Bhattarai, Xingzhe He, Alla Sheffer...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f7988a20-6edf-4ffc-a737-00f4b04a885d')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-f7988a20-6edf-4ffc-a737-00f4b04a885d button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-f7988a20-6edf-4ffc-a737-00f4b04a885d');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-9645aa9e-26d5-4017-b3d4-f4dd997884de\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9645aa9e-26d5-4017-b3d4-f4dd997884de')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-9645aa9e-26d5-4017-b3d4-f4dd997884de button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","summary":"{\n  \"name\": \"display(df[['title', 'date', 'authors']]\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"title\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"MagicMotion: Controllable Video Generation with Dense-to-Sparse Trajectory Guidance\",\n          \"DreamTexture: Shape from Virtual Texture with Analysis by Augmentation\",\n          \"InfiniteYou: Flexible Photo Recrafting While Preserving Your Identity\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"date\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"2025-03-20\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"authors\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{}}]},{"cell_type":"code","source":["# Step 2: Embedding & Clustering\n","print(\"\\n🧬 Step 2: Creating Embeddings & Clusters\")\n","# Create embeddings\n","texts = df['title'] + \" \" + df['abstract']\n","embeddings = create_embeddings(texts)\n","\n","# Reduce dimensions\n","embeddings_2d = reduce_dimensions(embeddings)\n","\n","# Cluster papers\n","cluster_labels = cluster_papers(embeddings)\n","\n","# Add results to dataframe\n","df['cluster'] = cluster_labels\n","df['x'] = embeddings_2d[:, 0]\n","df['y'] = embeddings_2d[:, 1]\n","\n","# Save intermediate results\n","df.to_csv(os.path.join(data_path, 'papers_with_clusters.csv'), index=False)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["4836eadb309d41d8b7d9fe4e723d6c8a","352c2d68cd3946b0a8c147a5a9650ac6","2447001413b24cbcb36eb40f6ae4e27e","a94ddb49f31a45f7bfe2b99ace1285bb","dce451b61c454ca69686d9b0b6b046ca","0d053f43462f4878a0d65b7ea905522b","5feae43d39dc45da95d71f839617d1b5","4e584f230dc6499da52f0511d4cd5b7a","6cb07eb4367d483d80503736faac8a77","6db939ca964b4444bd5fccca2974b9fe","5418312766a84a338706ac9c3674559d","c3ce137ddd904724ac75a561e5dda321","a5bfa781cba746b69ef2ef3e8ca3e345","981d468334474425a53a046edff02e92","9b7dda8e252b4600bce3bcc2ddea3d1a","7ed860f521024ec5a7fb21df7247e780","62084156cd5e4f3ea0e6e461e366de00","228b2b06dcb54d0b9eae7973c13cc00c","3f81938bda0e4d9095be672fbe7bf565","af95b216915240109d1ed3d4fc354f28","c87f0faad32e4eb4abcdae41a681d6ba","15302f98b16b4364a30ab8c1981a1177","084b5d2844aa4545878f15c358b45558","692c71a00fee468ba6095ddcdab1094d","5b0b06e12e90445e840f848250e71f35","d54bc64250df4847834fb993f500580f","5cb004602b4a4a858103e682e0e0a45d","15eabe9dac8043088055f9e17b4592ac","ab022b02bb6e4e16b7b77410b6fb90b5","f4f666afa39d41fc9849988b2b6dc957","7834f0b099974dc993c51cfd63ee39dc","2618108599b84e1ba5cd13903a852d2e","50bbc895809f45c1a33d858e877b7fd7","664bad2172d54cbab9ca6b9517ca7e68","45a1501c32474ba082880378925fb70e","b3a7e2c3e3e04dfda76f2db27d5e73ba","6d23374099ae4945a9b7a50188dc2002","47c2709a24924bee977283d3be132c42","04a92370a6744189a924c4fda4557759","fd980a96a1994cb9a4ca4382adf9a7c4","329bd41cb9484158b3637a582a8b6730","1b9297ff6e5744158ac334c845567b1a","50820142bc45451bb6ce3203cb41c138","54642013260a4bb3b375ea3875922aeb","dee5a7227e424d75bccd8b08c22b4c80","4231491f7a2849c2b29e21d0aaa0edf7","bd0162546c8740f68dc31c68603a57c5","522bfbdf7b7e4520a5f807fd35362a5c","6819e5fca0b247a19e07da68160d43a5","340bf8d54a9645d2b14e443d8951b9c5","6fc7afdb991b491483a46efef3577a8c","ba184642912244b08acb75ba99730c5a","adb031dd0892421a8d74358c1e3f9f08","04b98679cc724266af61dc1501e0435e","92aeda1bdb6540b8b34f8986c1cc3c6b","ed480a71184b474c9800cc6966196c32","54fe70b95570401692948e9ae8f9b5ef","7a233c1c046d47e6bccc263436082ec2","2c3f053e0c4c432c80494392c778e522","d003b6aad20f4b91a314f6f231209072","9a8e24a9644d4624b2ce76d42288b284","9a04d2a280d246c58729eebd99ce5abd","1ef2d750f0f84ea79f9ca683d61e3e3d","26cb23297e30434bb5f35056b94f3755","1647a435ca794c489e64df514d6eefe2","5487bb0f79964734880848f61da29728","abec9d3a40a144979cc015836901ccf3","f5e660e16bf14c86bb2e1325679a5d7d","438921975ad24d06b81db988f9356704","a79ea0d3fe6a4d32bf4e4a87937fcb1b","a499ce1a7f5a4d93a5f36774dc656e67","937cef85bbee45b6b693a28e2edd5213","30226c54a0b04c4b8449cafa9ca9e7c2","b7afd975d0674ebfa46cdf5579c871e5","2d01fad7ad1643bdb8fcb539b7e93d29","f157046690d14dfbac852444c4077ffd","6347c502c2dc4275965ba9bf1ae50e72","08a586d8be014287827706b33e03e48b","5d618bb2572e4300a6a82b09220c5d81","ec972992f9f14797bc60aab3eb20e575","a659490f9e774e29adbf33c6db1be3fe","0632e9899d074d8f92f5eef5bf4a24b2","45931b7c12e9480dae2609b01056c60a","49de9884db2543eba07889378ee15cff","5893acdd3e29477eb3d2d39b4b3ac6a5","afa311dc12e14bb3b8c88172a74b3041","83e516f30dd047abafa626c45796f140","3a9673da20af41e7872489a0e6b1639d","dd4aafb52f014626a69a4d48565037b1","79a4944d39fc4affa058fd67c0ef9a7f","2bb88b3138f74a56a6571610cb084166","d7e5647c394c4337bedec074c27dab98","63017d6b5b7a461582f4cfffa459549e","3ed3b5c8f04247d593d81c382659f729","9c83719524df45fbbb96ebcf0e59e5f3","c4e47fdd0a5749f3821da938fde885a1","28de84f5bc07427689c2f9a25e56ee61","2c75be1f7df74d63bda3f94c47a82c6e","16baa8e23ba543fbbbf60f25dfe31b2f","32e9f2542c344311944e0ab4af0ea2fc","5724c506815247a1b68872af559130fc","68c0fc1ef3534f18a0c7e82b601e37ad","00bd1575dce84981be459e831b8f0f58","1d1625d44f274b868b198d5117bfb3e3","de1c8e774c984574bd1f1be290e78d02","c5bec5a1b797433fb9ff8622fefd5638","c01a95869cf24b5fb0580aec7e9b439a","0542437707dd44ddb2f7487f85daaf02","99c29e8ec20148fa8bdcb4f253d9e03f","1751cc12365d4d538a7869fd20f0c0fa","a14928b56cad4f1290190ae1f7fc350b","4f7d4b5bca51485b85e6b988d99fe00b","25aa3683a4ad4aeb94f99d389ae966d0","9ba5c8c5956d4db8a320b67ed12c4b97","2005ad67d16e4fb0be7b25b32fb7e5e9","5bd8d79a175449f68643a7384f7d5cd8","d5bdfab29ccd4d5b9270dc0a7c460035","484e660f55184a13bf6e92d66437e8be","eb93ce31eb1f4b21adaa14d6f1606e9d","1f183f733edd447abe1f87e4c6915f7d","62daae2f105c4c8c89f184a275a62c9b","c4479d08c34f4a2797477013c9e83d3a","2c1bf5c571b847dc80f8d92fdd4de150","4b3c7005c12149189af1df3b70e24179","374a8f5f43164cc496a99e8d8f950faf","d49b4bfdf1144570bc643a700932ad07","27905e3f821b44ae8af454b91f78e4b6","c9eb7c34786e41a18cc332b4e484076f","4d9085c8c695457bba2b7f22817774b5","6a68921aa0154bdbaaeb7ccf40319f94","68026f81fe8d4b0785d9f946c476dc67","d027cb8f28024d729ea1a3855c1218e2"]},"id":"ZhJeO8kYfxz6","executionInfo":{"status":"ok","timestamp":1742742918289,"user_tz":360,"elapsed":29397,"user":{"displayName":"Alex Baret","userId":"10734557950216503149"}},"outputId":"922de1d6-3b1d-4dcc-d497-9bb437b218c6"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","🧬 Step 2: Creating Embeddings & Clusters\n","Loading model...\n"]},{"output_type":"display_data","data":{"text/plain":["modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4836eadb309d41d8b7d9fe4e723d6c8a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c3ce137ddd904724ac75a561e5dda321"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["README.md:   0%|          | 0.00/10.5k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"084b5d2844aa4545878f15c358b45558"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"664bad2172d54cbab9ca6b9517ca7e68"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dee5a7227e424d75bccd8b08c22b4c80"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ed480a71184b474c9800cc6966196c32"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"abec9d3a40a144979cc015836901ccf3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"08a586d8be014287827706b33e03e48b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dd4aafb52f014626a69a4d48565037b1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"32e9f2542c344311944e0ab4af0ea2fc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a14928b56cad4f1290190ae1f7fc350b"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Generating embeddings...\n"]},{"output_type":"display_data","data":{"text/plain":["Batches:   0%|          | 0/16 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c4479d08c34f4a2797477013c9e83d3a"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Reducing dimensions...\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n","  warn(\n"]},{"output_type":"stream","name":"stdout","text":["Clustering papers...\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/html":["<html>\n","<head><meta charset=\"utf-8\" /></head>\n","<body>\n","    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n","        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"709de2cd-a32f-4cbb-a59f-e265110a5c0d\" class=\"plotly-graph-div\" style=\"height:600px; width:1000px;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"709de2cd-a32f-4cbb-a59f-e265110a5c0d\")) {                    Plotly.newPlot(                        \"709de2cd-a32f-4cbb-a59f-e265110a5c0d\",                        [{\"customdata\":[[\"GAEA: A Geolocation Aware Conversational Model\"],[\"MagicMotion: Controllable Video Generation with Dense-to-Sparse Trajectory Guidance\"],[\"InfiniteYou: Flexible Photo Recrafting While Preserving Your Identity\"],[\"Survey on Evaluation of LLM-based Agents\"],[\"DreamTexture: Shape from Virtual Texture with Analysis by Augmentation\"],[\"RoboFactory: Exploring Embodied Agent Collaboration with Compositional Constraints\"],[\"The Emperor's New Clothes in Benchmarking? A Rigorous Examination of Mitigation Strategies for LLM Benchmark Data Contamination\"],[\"Exploring the Hidden Reasoning Process of Large Language Models by Misleading Them\"],[\"ScalingNoise: Scaling Inference-Time Search for Generating Infinite Videos\"],[\"The global convergence time of stochastic gradient descent in non-convex landscapes: Sharp estimates via large deviations\"],[\"Truthful Elicitation of Imprecise Forecasts\"],[\"Sparse Nonparametric Contextual Bandits\"],[\"Reinforcement Learning-based Heuristics to Guide Domain-Independent Dynamic Programming\"],[\"Neural Networks: According to the Principles of Grassmann Algebra\"],[\"Probabilistic Quantum SVM Training on Ising Machine\"],[\"Enhancing variational quantum algorithms by balancing training on classical and quantum hardware\"],[\"CaKE: Circuit-aware Editing Enables Generalizable Knowledge Learners\"],[\"Lyra: An Efficient and Expressive Subquadratic Architecture for Modeling Biological Sequences\"],[\"HiQ-Lip: The First Quantum-Classical Hierarchical Method for Global Lipschitz Constant Estimation of ReLU Networks\"],[\"Nonlinear action prediction models reveal multi-timescale locomotor control\"],[\"Optimal Complexity in Byzantine-Robust Distributed Stochastic Optimization with Data Heterogeneity\"],[\"Knowledge-guided machine learning model with soil moisture for corn yield prediction under drought conditions\"],[\"NeuralFoil: An Airfoil Aerodynamics Analysis Tool Using Physics-Informed Machine Learning\"],[\"On the Cone Effect in the Learning Dynamics\"],[\"Active Learning For Repairable Hardware Systems With Partial Coverage\"],[\"Structured-Noise Masked Modeling for Video, Audio and Beyond\"],[\"Explainable Graph-theoretical Machine Learning: with Application to Alzheimer's Disease Prediction\"],[\"Uni-3DAR: Unified 3D Generation and Understanding via Autoregression on Compressed Spatial Tokens\"],[\"Rethinking Robustness in Machine Learning: A Posterior Agreement Approach\"],[\"RESFL: An Uncertainty-Aware Framework for Responsible Federated Learning by Balancing Privacy, Fairness and Utility in Autonomous Vehicles\"],[\"OpenMIBOOD: Open Medical Imaging Benchmarks for Out-Of-Distribution Detection\"],[\"Machine learning identifies nullclines in oscillatory dynamical systems\"],[\"Empirical Analysis of Privacy-Fairness-Accuracy Trade-offs in Federated Learning: A Step Towards Responsible AI\"],[\"Flight Testing an Optionally Piloted Aircraft: a Case Study on Trust Dynamics in Human-Autonomy Teaming\"],[\"Reinforcement Learning for Reasoning in Small LLMs: What Works and What Doesn't\"],[\"Neural Variable-Order Fractional Differential Equation Networks\"],[\"Interpretable Neural Causal Models with TRAM-DAGs\"],[\"Deferring Concept Bottleneck Models: Learning to Defer Interventions to Inaccurate Experts\"],[\"VP-NTK: Exploring the Benefits of Visual Prompting in Differentially Private Data Synthesis\"],[\"Nonparametric Bellman Mappings for Value Iteration in Distributed Reinforcement Learning\"],[\"Large Language Models for Water Distribution Systems Modeling and Decision-Making\"],[\"Manifold learning in metric spaces\"],[\"Variance-Aware Noisy Training: Hardening DNNs against Unstable Analog Computations\"],[\"Narrowing Class-Wise Robustness Gaps in Adversarial Training\"],[\"Neural Combinatorial Optimization for Real-World Routing\"],[\"Distributed Learning over Arbitrary Topology: Linear Speed-Up with Polynomial Transient Time\"],[\"Improving Discriminator Guidance in Diffusion Models\"],[\"Learn to Bid as a Price-Maker Wind Power Producer\"],[\"AIMI: Leveraging Future Knowledge and Personalization in Sparse Event Forecasting for Treatment Adherence\"],[\"Hyperspectral Imaging for Identifying Foreign Objects on Pork Belly\"],[\"OThink-MR1: Stimulating multimodal generalized reasoning capabilities through dynamic reinforcement learning\"],[\"Redefining Toxicity: An Objective and Context-Aware Approach for Stress-Level-Based Detection\"],[\"Expert Race: A Flexible Routing Strategy for Scaling Diffusion Transformer with Mixture of Experts\"],[\"Patch-based learning of adaptive Total Variation parameter maps for blind image denoising\"],[\"InhibiDistilbert: Knowledge Distillation for a ReLU and Addition-based Transformer\"],[\"TVineSynth: A Truncated C-Vine Copula Generator of Synthetic Tabular Data to Balance Privacy and Utility\"],[\"Information maximization for a broad variety of multi-armed bandit games\"],[\"Multivariate Time Series Anomaly Detection in Industry 5.0\"],[\"Sample-Efficient Bayesian Transfer Learning for Online Machine Parameter Optimization\"],[\"Denoising-based Contractive Imitation Learning\"],[\"On the Limits of Applying Graph Transformers for Brain Connectome Classification\"],[\"A multi-model approach using XAI and anomaly detection to predict asteroid hazards\"],[\"Learning 3D Scene Analogies with Neural Contextual Scene Maps\"],[\"Time After Time: Deep-Q Effect Estimation for Interventions on When and What to do\"],[\"LeanTTA: A Backpropagation-Free and Stateless Approach to Quantized Test-Time Adaptation on Edge Devices\"],[\"Enhancing Zero-Shot Image Recognition in Vision-Language Models through Human-like Concept Guidance\"],[\"InCo-DPO: Balancing Distribution Shift and Data Quality for Enhanced Preference Optimization\"],[\"FedSAF: A Federated Learning Framework for Enhanced Gastric Cancer Detection and Privacy Preservation\"],[\"Active management of battery degradation in wireless sensor network using deep reinforcement learning for group battery replacement\"],[\"Network Embedding Exploration Tool (NEExT)\"],[\"Network-wide Freeway Traffic Estimation Using Sparse Sensor Data: A Dirichlet Graph Auto-Encoder Approach\"],[\"FedAWA: Adaptive Optimization of Aggregation Weights in Federated Learning Using Client Vectors\"],[\"Energy-Efficient Federated Learning and Migration in Digital Twin Edge Networks\"],[\"Control Pneumatic Soft Bending Actuator with Online Learning Pneumatic Physical Reservoir Computing\"],[\"Big data comparison of quantum invariants\"],[\"Communication Efficient Federated Learning with Linear Convergence on Heterogeneous Data\"],[\"Disentangling Uncertainties by Learning Compressed Data Representation\"],[\"Mixture of Lookup Experts\"],[\"Blend the Separated: Mixture of Synergistic Experts for Data-Scarcity Drug-Target Interaction Prediction\"],[\"DNA Bench: When Silence is Smarter -- Benchmarking Over-Reasoning in Reasoning LLMs\"],[\"MobiFuse: Learning Universal Human Mobility Patterns through Cross-domain Data Fusion\"],[\"Line Space Clustering (LSC): Feature-Based Clustering using K-medians and Dynamic Time Warping for Versatility\"],[\"Prediction of Permissioned Blockchain Performance for Resource Scaling Configurations\"],[\"Accelerating Transient CFD through Machine Learning-Based Flow Initialization\"],[\"ATTENTION2D: Communication Efficient Distributed Self-Attention Mechanism\"],[\"PARQ: Piecewise-Affine Regularized Quantization\"],[\"Using machine learning to map simulated noisy and laser-limited multidimensional spectra to molecular electronic couplings\"],[\"Tuning Sequential Monte Carlo Samplers via Greedy Incremental Divergence Minimization\"],[\"Approximation properties of neural ODEs\"],[\"Good Actions Succeed, Bad Actions Generalize: A Case Study on Why RL Generalizes Better\"],[\"Robotic Paper Wrapping by Learning Force Control\"],[\"Sequential learning based PINNs to overcome temporal domain complexities in unsteady flow past flapping wings\"],[\"Model Risk Management for Generative AI In Financial Institutions\"],[\"Survey on Generalization Theory for Graph Neural Networks\"],[\"Multi-Modal Gesture Recognition from Video and Surgical Tool Pose Information via Motion Invariants\"],[\"Using machine learning to measure evidence of students' sensemaking in physics courses\"],[\"Neural Lyapunov Function Approximation with Self-Supervised Reinforcement Learning\"],[\"Does Context Matter? ContextualJudgeBench for Evaluating LLM-based Judges in Contextual Settings\"],[\"PEnGUiN: Partially Equivariant Graph NeUral Networks for Sample Efficient MARL\"],[\"TULIP: Towards Unified Language-Image Pretraining\"],[\"Value Profiles for Encoding Human Variation\"],[\"Natural Quantization of Neural Networks\"],[\"Learning to Play Piano in the Real World\"],[\"SWEET-RL: Training Multi-Turn LLM Agents on Collaborative Reasoning Tasks\"],[\"What Makes a Reward Model a Good Teacher? An Optimization Perspective\"],[\"Di$\\\\mathtt{[M]}$O: Distilling Masked Diffusion Models into One-step Generator\"],[\"Temporal Encoding Strategies for Energy Time Series Prediction\"],[\"Reducing Communication Overhead in Federated Learning for Network Anomaly Detection with Adaptive Client Selection\"],[\"A discontinuity-capturing neural network with categorical embedding and its application to anisotropic elliptic interface problems\"],[\"Accurate, transferable, and verifiable machine-learned interatomic potentials for layered materials\"],[\"LIFT: Latent Implicit Functions for Task- and Data-Agnostic Encoding\"],[\"Exploiting Prior Knowledge in Preferential Learning of Individualized Autonomous Vehicle Driving Styles\"],[\"Efficient Post-Hoc Uncertainty Calibration via Variance-Based Smoothing\"],[\"HQNN-FSP: A Hybrid Classical-Quantum Neural Network for Regression-Based Financial Stock Market Prediction\"],[\"Geometrically-Aware One-Shot Skill Transfer of Category-Level Objects\"],[\"Online Imitation Learning for Manipulation via Decaying Relative Correction through Teleoperation\"],[\"FedBEns: One-Shot Federated Learning based on Bayesian Ensemble\"],[\"Robustness of Nonlinear Representation Learning\"],[\"Leveraging Perfect Multimodal Alignment and Gaussian Assumptions for Cross-modal Transfer\"],[\"Hierarchical clustering with maximum density paths and mixture models\"],[\"Borsuk-Ulam and Replicable Learning of Large-Margin Halfspaces\"],[\"Beacon2Science: Enhancing STEREO\\u002fHI beacon data1 with machine learning for efficient CME tracking\"],[\"Performance-bounded Online Ensemble Learning Method Based on Multi-armed bandits and Its Applications in Real-time Safety Assessment\"],[\"Learning to quantify graph nodes\"],[\"Fast MLE and MAPE-Based Device Activity Detection for Grant-Free Access via PSCA and PSCA-Net\"],[\"ImputeGAP: A Comprehensive Library for Time Series Imputation\"],[\"A Personalized Data-Driven Generative Model of Human Motion\"],[\"A Foundation Model for Patient Behavior Monitoring and Suicide Detection\"],[\"Online federated learning framework for classification\"],[\"Kolmogorov-Arnold Network for Transistor Compact Modeling\"],[\"Understanding the Generalization of In-Context Learning in Transformers: An Empirical Study\"],[\"Partially Observable Reinforcement Learning with Memory Traces\"],[\"Sparseformer: a Transferable Transformer with Multi-granularity Token Sparsification for Medical Time Series Classification\"],[\"Learning Topology Actions for Power Grid Control: A Graph-Based Soft-Label Imitation Learning Approach\"],[\"A Bird Song Detector for improving bird identification through Deep Learning: a case study from Doñana\"],[\"Food Delivery Time Prediction in Indian Cities Using Machine Learning Models\"],[\"Multi-Agent Actor-Critic with Harmonic Annealing Pruning for Dynamic Spectrum Access Systems\"],[\"World Models in Artificial Intelligence: Sensing, Learning, and Reasoning Like a Child\"],[\"Machine Unlearning in Hyperbolic vs. Euclidean Multimodal Contrastive Learning: Adapting Alignment Calibration to MERU\"],[\"Global Group Fairness in Federated Learning via Function Tracking\"],[\"Preference Construction: A Bayesian Interactive Preference Elicitation Framework Based on Monte Carlo Tree Search\"],[\"Machine learning surrogate models of many-body dispersion interactions in polymer melts\"],[\"Machine Learning Techniques for Multifactor Analysis of National Carbon Dioxide Emissions\"],[\"Neuronal Activation States as Sample Embeddings for Data Selection in Task-Specific Instruction Tuning\"],[\"DeCaFlow: A Deconfounding Causal Generative Model\"],[\"FedLWS: Federated Learning with Adaptive Layer-wise Weight Shrinking\"],[\"VIPER: Visual Perception and Explainable Reasoning for Sequential Decision-Making\"],[\"Interpretability of Graph Neural Networks to Assert Effects of Global Change Drivers on Ecological Networks\"],[\"Control, Optimal Transport and Neural Differential Equations in Supervised Learning\"],[\"LLM-Aided Customizable Profiling of Code Data Based On Programming Language Concepts\"],[\"Diffusion-Based Forecasting for Uncertainty-Aware Model Predictive Control\"],[\"Continual Contrastive Learning on Tabular Data with Out of Distribution\"],[\"RAG-based User Profiling for Precision Planning in Mixed-precision Over-the-Air Federated Learning\"],[\"Multivariate Gaussian Topic Modelling: A novel approach to discover topics with greater semantic coherence\"],[\"Mixed precision accumulation for neural network inference guided by componentwise forward error analysis\"],[\"Manifold Learning for Hyperspectral Images\"],[\"Ambient Noise Full Waveform Inversion with Neural Operators\"],[\"A Novel Channel Boosted Residual CNN-Transformer with Regional-Boundary Learning for Breast Cancer Detection\"],[\"Towards Unified Latent Space for 3D Molecular Latent Diffusion Modeling\"],[\"Scalable Trajectory-User Linking with Dual-Stream Representation Networks\"],[\"Embedding spatial context in urban traffic forecasting with contrastive pre-training\"],[\"Application of linear regression method to the deep reinforcement learning in continuous action cases\"],[\"Continual Multimodal Contrastive Learning\"],[\"Proceedings of the 3rd Italian Conference on Big Data and Data Science (ITADATA2024)\"],[\"Enhancing Code LLM Training with Programmer Attention\"],[\"Prada: Black-Box LLM Adaptation with Private Data on Resource-Constrained Devices\"],[\"Enforcing Consistency and Fairness in Multi-level Hierarchical Classification with a Mask-based Output Layer\"],[\"ACE: A Cardinality Estimator for Set-Valued Queries\"],[\"Semi-Gradient SARSA Routing with Theoretical Guarantee on Traffic Stability and Weight Convergence\"],[\"pFedFair: Towards Optimal Group Fairness-Accuracy Trade-off in Heterogeneous Federated Learning\"],[\"A Semantic and Clean-label Backdoor Attack against Graph Convolutional Networks\"],[\"Pseudo-Relevance Feedback Can Improve Zero-Shot LLM-Based Dense Retrieval\"],[\"Exploring the Limits of KV Cache Compression in Visual Autoregressive Transformers\"],[\"GReaTER: Generate Realistic Tabular data after data Enhancement and Reduction\"],[\"Robust Support Vector Machines for Imbalanced and Noisy Data via Benders Decomposition\"],[\"Evaluating Time Series Models with Knowledge Discovery\"],[\"Global Renewables Watch: A Temporal Dataset of Solar and Wind Energy Derived from Satellite Imagery\"],[\"1000 Layer Networks for Self-Supervised RL: Scaling Depth Can Enable New Goal-Reaching Capabilities\"],[\"Dynamic Power Flow Analysis and Fault Characteristics: A Graph Attention Neural Network\"],[\"LogLLaMA: Transformer-based log anomaly detection with LLaMA\"],[\"On the Robustness Tradeoff in Fine-Tuning\"],[\"Curiosity-Diffuser: Curiosity Guide Diffusion Models for Reliability\"],[\"H2ST: Hierarchical Two-Sample Tests for Continual Out-of-Distribution Detection\"],[\"Robust Transmission of Punctured Text with Large Language Model-based Recovery\"],[\"Scaled Supervision is an Implicit Lipschitz Regularizer\"],[\"Learning with Expert Abstractions for Efficient Multi-Task Continuous Control\"],[\"Long Context Modeling with Ranked Memory-Augmented Retrieval\"],[\"Pruning-Based TinyML Optimization of Machine Learning Models for Anomaly Detection in Electric Vehicle Charging Infrastructure\"],[\"A New Benchmark for Online Learning with Budget-Balancing Constraints\"],[\"The Hardness of Validating Observational Studies with Experimental Data\"],[\"SEEK: Self-adaptive Explainable Kernel For Nonstationary Gaussian Processes\"],[\"RAT: Boosting Misclassification Detection Ability without Extra Data\"],[\"Fake Runs, Real Fixes -- Analyzing xPU Performance Through Simulation\"],[\"Localized Physics-informed Gaussian Processes with Curriculum Training for Topology Optimization\"],[\"Temporal Context Awareness: A Defense Framework Against Multi-turn Manipulation Attacks on Large Language Models\"],[\"Advanced Relay-Based Collaborative Framework for Optimizing Synchronization in Split Federated Learning over Wireless Networks\"],[\"Cosmos-Reason1: From Physical Common Sense To Embodied Reasoning\"],[\"RETHINED: A New Benchmark and Baseline for Real-Time High-Resolution Image Inpainting On Edge Devices\"],[\"Bayesian Modeling of Zero-Shot Classifications for Urban Flood Detection\"],[\"LipShiFT: A Certifiably Robust Shift-based Vision Transformer\"],[\"Uncertainty Distillation: Teaching Language Models to Express Semantic Confidence\"],[\"GR00T N1: An Open Foundation Model for Generalist Humanoid Robots\"],[\"Variational Autoencoded Multivariate Spatial Fay-Herriot Models\"],[\"Better Private Distribution Testing by Leveraging Unverified Auxiliary Data\"],[\"A Comprehensive Study of LLM Secure Code Generation\"],[\"Sepsyn-OLCP: An Online Learning-based Framework for Early Sepsis Prediction with Uncertainty Quantification using Conformal Prediction\"],[\"Reinforcement learning-based motion imitation for physiologically plausible musculoskeletal motor control\"],[\"Assessing Large Language Models for Automated Feedback Generation in Learning Programming Problem Solving\"],[\"Reducing False Ventricular Tachycardia Alarms in ICU Settings: A Machine Learning Approach\"],[\"Anomaly-Flow: A Multi-domain Federated Generative Adversarial Network for Distributed Denial-of-Service Detection\"],[\"Unique Hard Attention: A Tale of Two Sides\"],[\"Command R7B Arabic: A Small, Enterprise Focused, Multilingual, and Culturally Aware Arabic LLM\"],[\"MusicInfuser: Making Video Diffusion Listen and Dance\"],[\"The Power of Context: How Multimodality Improves Image Super-Resolution\"],[\"Utilization of Neighbor Information for Image Classification with Different Levels of Supervision\"],[\"Measuring AI Ability to Complete Long Tasks\"],[\"Temporal Consistency for LLM Reasoning Process Error Identification\"],[\"Cosmos-Transfer1: Conditional World Generation with Adaptive Multimodal Control\"],[\"Don't lie to your friends: Learning what you know from collaborative self-play\"],[\"DAPO: An Open-Source LLM Reinforcement Learning System at Scale\"],[\"EnQode: Fast Amplitude Embedding for Quantum Machine Learning Using Classical Data\"],[\"Doubly robust identification of treatment effects from multiple environments\"],[\"RWKV-7 \\\"Goose\\\" with Expressive Dynamic State Evolution\"],[\"Online Conformal Probabilistic Numerics via Adaptive Edge-Cloud Offloading\"],[\"EnvBench: A Benchmark for Automated Environment Setup\"],[\"Inducing Causal Structure for Interpretable Neural Networks Applied to Glucose Prediction for T1DM Patients\"],[\"Graph-CNNs for RF Imaging: Learning the Electric Field Integral Equations\"],[\"LLM-FE: Automated Feature Engineering for Tabular Data with LLMs as Evolutionary Optimizers\"],[\"PLAY2PROMPT: Zero-shot Tool Instruction Optimization for LLM Agents via Tool Play\"],[\"ExDDV: A New Dataset for Explainable Deepfake Detection in Video\"],[\"DUNE: Distilling a Universal Encoder from Heterogeneous 2D and 3D Teachers\"],[\"Landscape Complexity for the Empirical Risk of Generalized Linear Models: Discrimination between Structured Data\"],[\"Technical Report: Aggregation on Learnable Manifolds for Asynchronous Federated Optimization\"],[\"On the clustering behavior of sliding windows\"],[\"Optimizing High-Dimensional Oblique Splits\"],[\"PHGNN: A Novel Prompted Hypergraph Neural Network to Diagnose Alzheimer's Disease\"],[\"Advancing Medical Representation Learning Through High-Quality Data\"],[\"Tiled Flash Linear Attention: More Efficient Linear RNN and xLSTM Kernels\"],[\"Evaluating Machine Learning Approaches for ASCII Art Generation\"],[\"SocialJax: An Evaluation Suite for Multi-agent Reinforcement Learning in Sequential Social Dilemmas\"],[\"C(NN)FD -- Deep Learning Modelling of Multi-Stage Axial Compressors Aerodynamics\"],[\"The Exoplanet Citizen Science Pipeline: Human Factors and Machine Learning\"],[\"RFMI: Estimating Mutual Information on Rectified Flow for Text-to-Image Alignment\"],[\"Wasserstein-based Kernels for Clustering: Application to Power Distribution Graphs\"],[\"Sequence Analysis Using the Bezier Curve\"],[\"Benchmarking community drug response prediction models: datasets, models, tools, and metrics for cross-dataset generalization analysis\"],[\"Unified Analysis of Decentralized Gradient Descent: a Contraction Mapping Framework\"],[\"MoonCast: High-Quality Zero-Shot Podcast Generation\"],[\"End-to-End Optimal Detector Design with Mutual Information Surrogates\"],[\"Efficient but Vulnerable: Benchmarking and Defending LLM Batch Prompting Attack\"],[\"Higher-Order Graphon Neural Networks: Approximation and Cut Distance\"],[\"PENCIL: Long Thoughts with Short Memory\"],[\"Revealing higher-order neural representations with generative artificial intelligence\"],[\"Consumer-grade EEG-based Eye Tracking\"],[\"COPA: Comparing the Incomparable to Explore the Pareto Front\"],[\"FeNeC: Enhancing Continual Learning via Feature Clustering with Neighbor- or Logit-Based Classification\"],[\"Unveiling the Role of Randomization in Multiclass Adversarial Classification: Insights from Graph Theory\"],[\"Improved Scalable Lipschitz Bounds for Deep Neural Networks\"],[\"Robust Weight Imprinting: Insights from Neural Collapse and Proxy-Based Aggregation\"],[\"Tapered Off-Policy REINFORCE: Stable and efficient reinforcement learning for LLMs\"],[\"XOXO: Stealthy Cross-Origin Context Poisoning Attacks against AI Coding Assistants\"],[\"Automating Experimental Optics with Sample Efficient Machine Learning Methods\"],[\"Quantization-Free Autoregressive Action Transformer\"],[\"CINNAMON: A hybrid approach to change point detection and parameter estimation in single-particle tracking data\"],[\"Trading-off Accuracy and Communication Cost in Federated Learning\"],[\"Persistent Homology-induced Graph Ensembles for Time Series Regressions\"],[\"Predicting Cardiopulmonary Exercise Testing Outcomes in Congenital Heart Disease Through Multi-modal Data Integration and Geometric Learning\"],[\"CRCE: Coreference-Retention Concept Erasure in Text-to-Image Diffusion Models\"],[\"Multi-task Learning for Identification of Porcelain in Song and Yuan Dynasties\"],[\"Decision Tree Induction Through LLMs via Semantically-Aware Evolution\"],[\"Efficient Data Selection for Training Genomic Perturbation Models\"],[\"Rolling Forward: Enhancing LightGCN with Causal Graph Convolution for Credit Bond Recommendation\"],[\"Layer-wise Adaptive Gradient Norm Penalizing Method for Efficient and Accurate Deep Learning\"],[\"Strategic White Paper on AI Infrastructure for Particle, Nuclear, and Astroparticle Physics: Insights from JENA and EuCAIF\"],[\"Potential Score Matching: Debiasing Molecular Structure Sampling with Potential Energy Guidance\"],[\"Speculative Decoding for Verilog: Speed and Quality, All in One\"],[\"Teaching Artificial Intelligence to Perform Rapid, Resolution-Invariant Grain Growth Modeling via Fourier Neural Operator\"],[\"SpecReX: Explainable AI for Raman Spectroscopy\"],[\"Frac-Connections: Fractional Extension of Hyper-Connections\"],[\"Fundamental Limits of Matrix Sensing: Exact Asymptotics, Universality, and Applications\"],[\"PET-MAD, a universal interatomic potential for advanced materials modeling\"],[\"Towards Location-Specific Precipitation Projections Using Deep Neural Networks\"],[\"Semantic Communication in Dynamic Channel Scenarios: Collaborative Optimization of Dual-Pipeline Joint Source-Channel Coding and Personalized Federated Learning\"],[\"Theoretical Foundation of Flow-Based Time Series Generation: Provable Approximation, Generalization, and Efficiency\"],[\"Modular Distributed Nonconvex Learning with Error Feedback\"],[\"ON-Traffic: An Operator Learning Framework for Online Traffic Flow Estimation and Uncertainty Quantification from Lagrangian Sensors\"],[\"Empirical risk minimization algorithm for multiclass classification of S.D.E. paths\"],[\"Learning on LLM Output Signatures for gray-box LLM Behavior Analysis\"],[\"Uncertainty-Aware Global-View Reconstruction for Multi-View Multi-Label Feature Selection\"],[\"Predicting Human Choice Between Textually Described Lotteries\"],[\"MeshFleet: Filtered and Annotated 3D Vehicle Dataset for Domain Specific Generative Modeling\"],[\"Effortless Active Labeling for Long-Term Test-Time Adaptation\"],[\"DefectFill: Realistic Defect Generation with Inpainting Diffusion Model for Visual Inspection\"],[\"Empowering LLMs in Decision Games through Algorithmic Data Synthesis\"],[\"Identifying Critical Phases for Disease Onset with Sparse Haematological Biomarkers\"],[\"A CNN-based End-to-End Learning for RIS-assisted Communication System\"],[\"MDocAgent: A Multi-Modal Multi-Agent Framework for Document Understanding\"],[\"Enhanced High-Dimensional Data Visualization through Adaptive Multi-Scale Manifold Embedding\"],[\"Structured Knowledge Accumulation: An Autonomous Framework for Layer-Wise Entropy Reduction in Neural Learning\"],[\"Reconstructing Cell Lineage Trees from Phenotypic Features with Metric Learning\"],[\"Learning Accurate Models on Incomplete Data with Minimal Imputation\"],[\"Robust Machine Unlearning for Quantized Neural Networks via Adaptive Gradient Reweighting with Similar Labels\"],[\"KANITE: Kolmogorov-Arnold Networks for ITE estimation\"],[\"Incorporating Attributes and Multi-Scale Structures for Heterogeneous Graph Contrastive Learning\"],[\"Quantification of Uncertainties in Probabilistic Deep Neural Network by Implementing Boosting of Variational Inference\"],[\"Learning local neighborhoods of non-Gaussian graphical models: A measure transport approach\"],[\"MoK-RAG: Mixture of Knowledge Paths Enhanced Retrieval-Augmented Generation for Embodied AI Environments\"],[\"Squeeze Out Tokens from Sample for Finer-Grained Data Governance\"],[\"Multi-label feature selection based on binary hashing learning and dynamic graph constraints\"],[\"Empirical Calibration and Metric Differential Privacy in Language Models\"],[\"Out-of-Distribution Generalization in Time Series: A Survey\"],[\"HySurvPred: Multimodal Hyperbolic Embedding with Angle-Aware Hierarchical Contrastive Learning and Uncertainty Constraints for Survival Prediction\"],[\"MamBEV: Enabling State Space Models to Learn Birds-Eye-View Representations\"],[\"Spotting Persuasion: A Low-cost Model for Persuasion Detection in Political Ads on Social Media\"],[\"Counterfactual experience augmented off-policy reinforcement learning\"],[\"Self-Vocabularizing Training for Neural Machine Translation\"],[\"SALAD: Skeleton-aware Latent Diffusion for Text-driven Motion Generation and Editing\"],[\"Causal Discovery from Data Assisted by Large Language Models\"],[\"VARP: Reinforcement Learning from Vision-Language Model Feedback with Agent Regularized Preferences\"],[\"Text-Guided Image Invariant Feature Learning for Robust Image Watermarking\"],[\"AI-Powered Prediction of Nanoparticle Pharmacokinetics: A Multi-View Learning Approach\"],[\"BurTorch: Revisiting Training from First Principles by Coupling Autodiff, Math Optimization, and Systems\"],[\"Designing and Deploying AI Models for Sustainable Logistics Optimization: A Case Study on Eco-Efficient Supply Chains in the USA\"],[\"ROCK: A variational formulation for occupation kernel methods in Reproducing Kernel Hilbert Spaces\"],[\"Evaluating the Application of SOLID Principles in Modern AI Framework Architectures\"],[\"A finite-sample bound for identifying partially observed linear switched systems from a single trajectory\"],[\"Effective Dimension Aware Fractional-Order Stochastic Gradient Descent for Convex Optimization Problems\"],[\"Neural Edge Histogram Descriptors for Underwater Acoustic Target Recognition\"],[\"Synchronous vs Asynchronous Reinforcement Learning in a Real World Robot\"],[\"Optimizing ML Training with Metagradient Descent\"],[\"Redefining non-IID Data in Federated Learning for Computer Vision Tasks: Migrating from Labels to Embeddings for Task-Specific Data Distributions\"],[\"Multi-modal Time Series Analysis: A Tutorial and Survey\"],[\"Mitigating Spectral Bias in Neural Operators via High-Frequency Scaling for Physical Systems\"],[\"Atyaephyra at SemEval-2025 Task 4: Low-Rank NPO\"],[\"Novel AI-Based Quantification of Breast Arterial Calcification to Predict Cardiovascular Risk\"],[\"PrETi: Predicting Execution Time in Early Stage with LLVM and Machine Learning\"],[\"Sampling Decisions\"],[\"Bayesian Kernel Regression for Functional Data\"],[\"SRBB-Based Quantum State Preparation\"],[\"Quantum EigenGame for excited state calculation\"],[\"Matching Skeleton-based Activity Representations with Heterogeneous Signals for HAR\"],[\"A Convex formulation for linear discriminant analysis\"],[\"MetaScale: Test-Time Scaling with Evolving Meta-Thoughts\"],[\"Deep Belief Markov Models for POMDP Inference\"],[\"Unified Autoregressive Visual Generation and Understanding with Continuous Tokens\"],[\"Uncovering Utility Functions from Observed Outcomes\"],[\"Measuring In-Context Computation Complexity via Hidden State Prediction\"],[\"AugMapNet: Improving Spatial Latent Structure via BEV Grid Augmentation for Enhanced Vectorized Online HD Map Construction\"],[\"xLSTM 7B: A Recurrent LLM for Fast and Efficient Inference\"],[\"SuperBPE: Space Travel for Language Models\"],[\"The Impact of Artificial Intelligence on Emergency Medicine: A Review of Recent Advances\"],[\"Reward Adaptation Via Q-Manipulation\"],[\"Fed-Joint: Joint Modeling of Nonlinear Degradation Signals and Failure Events for Remaining Useful Life Prediction using Federated Learning\"],[\"MicroVQA: A Multimodal Reasoning Benchmark for Microscopy-Based Scientific Research\"],[\"PANDORA: Diffusion Policy Learning for Dexterous Robotic Piano Playing\"],[\"Investigating the effect of CPT in lateral spreading prediction using Explainable AI\"],[\"Spectrally-Corrected and Regularized QDA Classifier for Spiked Covariance Model\"],[\"Scale Efficient Training for Large Datasets\"],[\"Cream of the Crop: Harvesting Rich, Scalable and Transferable Multi-Modal Data for Instruction Fine-Tuning\"],[\"SyncDiff: Diffusion-based Talking Head Synthesis with Bottlenecked Temporal Visual Prior for Improved Synchronization\"],[\"Follow-the-Regularized-Leader with Adversarial Constraints\"],[\"Mitigating Visual Forgetting via Take-along Visual Conditioning for Multi-modal Long CoT Reasoning\"],[\"Agents Play Thousands of 3D Video Games\"],[\"Strain Problems got you in a Twist? Try StrainRelief: A Quantum-Accurate Tool for Ligand Strain Calculations\"],[\"Reliable and Efficient Amortized Model-based Evaluation\"],[\"PERC: a suite of software tools for the curation of cryoEM data with application to simulation, modelling and machine learning\"],[\"SMPR: A structure-enhanced multimodal drug-disease prediction model for drug repositioning and cold start\"],[\"ASMR: Adaptive Skeleton-Mesh Rigging and Skinning via 2D Generative Prior\"],[\"Do you understand epistemic uncertainty? Think again! Rigorous frequentist epistemic uncertainty estimation in regression\"],[\"RainScaleGAN: a Conditional Generative Adversarial Network for Rainfall Downscaling\"],[\"GFSNetwork: Differentiable Feature Selection via Gumbel-Sigmoid Relaxation\"],[\"On Local Posterior Structure in Deep Ensembles\"],[\"$φ$-Decoding: Adaptive Foresight Sampling for Balanced Inference-Time Exploration and Exploitation\"],[\"LLM-Match: An Open-Sourced Patient Matching Model Based on Large Language Models and Retrieval-Augmented Generation\"],[\"Graph Generative Models Evaluation with Masked Autoencoder\"],[\"Convolutional neural network for early detection of lameness and irregularity in horses using an IMU sensor\"],[\"AI-Driven Rapid Identification of Bacterial and Fungal Pathogens in Blood Smears of Septic Patients\"],[\"Neural network-based Godunov corrections for approximate Riemann solvers using bi-fidelity learning\"],[\"Highly Efficient Direct Analytics on Semantic-aware Time Series Data Compression\"],[\"Gradient Extrapolation for Debiased Representation Learning\"],[\"Mind the Gap: Confidence Discrepancy Can Guide Federated Semi-Supervised Learning Across Pseudo-Mismatch\"],[\"ProDiF: Protecting Domain-Invariant Features to Secure Pre-Trained Models Against Extraction\"],[\"Dense Policy: Bidirectional Autoregressive Learning of Actions\"],[\"When Should We Orchestrate Multiple Agents?\"],[\"MAME: Multidimensional Adaptive Metamer Exploration with Human Perceptual Feedback\"],[\"Vision-Language Models for Acute Tuberculosis Diagnosis: A Multimodal Approach Combining Imaging and Clinical Data\"],[\"Timing the Match: A Deep Reinforcement Learning Approach for Ride-Hailing and Ride-Pooling Services\"],[\"Deep Learning Advancements in Anomaly Detection: A Comprehensive Survey\"],[\"A representational framework for learning and encoding structurally enriched trajectories in complex agent environments\"],[\"GC-Fed: Gradient Centralized Federated Learning with Partial Client Participation\"],[\"Rapfi: Distilling Efficient Neural Network for the Game of Gomoku\"],[\"PAUSE: Low-Latency and Privacy-Aware Active User Selection for Federated Learning\"],[\"Advancing Chronic Tuberculosis Diagnostics Using Vision-Language Models: A Multi modal Framework for Precision Analysis\"],[\"Analytic Subspace Routing: How Recursive Least Squares Works in Continual Learning of Large Language Model\"],[\"Efficient Imitation Under Misspecification\"],[\"Laplace-Net: Learning Dynamical Systems with External Forcing\"],[\"High-entropy Advantage in Neural Networks' Generalizability\"],[\"Online Signature Verification based on the Lagrange formulation with 2D and 3D robotic models\"],[\"VeriLeaky: Navigating IP Protection vs Utility in Fine-Tuning for LLM-Driven Verilog Coding\"],[\"Beyond Propagation of Chaos: A Stochastic Algorithm for Mean Field Optimization\"],[\"Exploring the Potential of Bilevel Optimization for Calibrating Neural Networks\"],[\"MM-Spatial: Exploring 3D Spatial Understanding in Multimodal LLMs\"],[\"VeriContaminated: Assessing LLM-Driven Verilog Coding for Data Contamination\"],[\"ExChanGeAI: An End-to-End Platform and Efficient Foundation Model for Electrocardiogram Analysis and Fine-tuning\"],[\"Towards Better Sample Efficiency in Multi-Agent Reinforcement Learning via Exploration\"],[\"MaskSDM with Shapley values to improve flexibility, robustness, and explainability in species distribution modeling\"],[\"Deep Hedging of Green PPAs in Electricity Markets\"],[\"Permutation Learning with Only N Parameters: From SoftSort to Self-Organizing Gaussians\"],[\"E-Values Expand the Scope of Conformal Prediction\"],[\"WMINet: A Wheel-Mounted Inertial Learning Approach For Mobile-Robot Positioning\"],[\"Knowledge Distillation: Enhancing Neural Network Compression with Integrated Gradients\"],[\"Linear-Size Neural Network Representation of Piecewise Affine Functions in $\\\\mathbb{R}^2$\"],[\"Robot Policy Transfer with Online Demonstrations: An Active Reinforcement Learning Approach\"],[\"Enhancing Job Salary Prediction with Disentangled Composition Effect Modeling: A Neural Prototyping Approach\"],[\"Optimal Denoising in Score-Based Generative Models: The Role of Data Regularity\"],[\"Training Video Foundation Models with NVIDIA NeMo\"],[\"Classification of power quality events in the transmission grid: comparative evaluation of different machine learning models\"],[\"HiDe-LLaVA: Hierarchical Decoupling for Continual Instruction Tuning of Multimodal Large Language Model\"],[\"R1-VL: Learning to Reason with Multimodal Large Language Models via Step-wise Group Relative Policy Optimization\"],[\"Efficient Action-Constrained Reinforcement Learning via Acceptance-Rejection Method and Augmented MDPs\"],[\"Augmented Invertible Koopman Autoencoder for long-term time series forecasting\"],[\"ML-SpecQD: Multi-Level Speculative Decoding with Quantized Drafts\"],[\"Lifelong Reinforcement Learning with Similarity-Driven Weighting by Large Models\"],[\"COSMOS: Continuous Simplicial Neural Networks\"],[\"Pose as a Modality: A Psychology-Inspired Network for Personality Recognition with a New Multimodal Dataset\"],[\"Experiments with Optimal Model Trees\"],[\"A Semantic-based Optimization Approach for Repairing LLMs: Case Study on Code Generation\"],[\"Federated Continual Instruction Tuning\"],[\"Edgeworth Expansion for Semi-hard Triplet Loss\"],[\"Micro Text Classification Based on Balanced Positive-Unlabeled Learning\"],[\"Early Detection of Forest Calamities in Homogeneous Stands -- Deep Learning Applied to Bark-Beetle Outbreaks\"],[\"DAPI: Domain Adaptive Toxicity Probe Vector Intervention for Fine-Grained Detoxification\"],[\"Harnessing Test-time Adaptation for NLU tasks Involving Dialects of English\"],[\"Island-Based Evolutionary Computation with Diverse Surrogates and Adaptive Knowledge Transfer for High-Dimensional Data-Driven Optimization\"],[\"Adaptive Transformer Attention and Multi-Scale Fusion for Spine 3D Segmentation\"],[\"An Optimization Framework for Differentially Private Sparse Fine-Tuning\"],[\"Epidemic Forecasting with a Hybrid Deep Learning Method Using CNN-LSTM With WOA-GWO Parameter Optimization: Global COVID-19 Case Study\"],[\"A Multi-Power Law for Loss Curve Prediction Across Learning Rate Schedules\"],[\"Estimating stationary mass, frequency by frequency\"],[\"Leveraging Deep Neural Networks for Aspect-Based Sentiment Classification\"],[\"BLIA: Detect model memorization in binary classification model through passive Label Inference attack\"],[\"A Reinforcement Learning-Driven Transformer GAN for Molecular Generation\"],[\"Improving Generalization of Universal Adversarial Perturbation via Dynamic Maximin Optimization\"],[\"Causal Feature Learning in the Social Sciences\"],[\"LangDA: Building Context-Awareness via Language for Domain Adaptive Semantic Segmentation\"],[\"Asynchronous Predictive Counterfactual Regret Minimization$^+$ Algorithm in Solving Extensive-Form Games\"],[\"Stabilization Analysis and Mode Recognition of Kerosene Supersonic Combustion: A Deep Learning Approach Based on Res-CNN-beta-VAE\"],[\"A Survey on Human Interaction Motion Generation\"],[\"Dynamical Mode Recognition of Turbulent Flames in a Swirl-stabilized Annular Combustor by a Time-series Learning Approach\"],[\"SNPL: Simultaneous Policy Learning and Evaluation for Safe Multi-Objective Policy Improvement\"],[\"Cohort-attention Evaluation Metric against Tied Data: Studying Performance of Classification Models in Cancer Detection\"],[\"Survival Analysis with Machine Learning for Predicting Li-ion Battery Remaining Useful Life\"],[\"SafeSlice: Enabling SLA-Compliant O-RAN Slicing via Safe Deep Reinforcement Learning\"],[\"Finite Samples for Shallow Neural Networks\"],[\"Enhancing Circuit Trainability with Selective Gate Activation Strategy\"],[\"In-Context Linear Regression Demystified: Training Dynamics and Mechanistic Interpretability of Multi-Head Softmax Attention\"],[\"A Linearized Alternating Direction Multiplier Method for Federated Matrix Completion Problems\"],[\"APF+: Boosting adaptive-potential function reinforcement learning methods with a W-shaped network for high-dimensional games\"],[\"TinySQL: A Progressive Text-to-SQL Dataset for Mechanistic Interpretability Research\"],[\"Dynamic Angle Selection in X-Ray CT: A Reinforcement Learning Approach to Optimal Stopping\"],[\"Can LLMs Formally Reason as Abstract Interpreters for Program Analysis?\"],[\"Algebraic Adversarial Attacks on Explainability Models\"],[\"Discovering uncertainty: Gaussian constitutive neural networks with correlated weights\"],[\"RL-TIME: Reinforcement Learning-based Task Replication in Multicore Embedded Systems\"],[\"ZO2: Scalable Zeroth-Order Fine-Tuning for Extremely Large Language Models with Limited GPU Memory\"],[\"Logic-RAG: Augmenting Large Multimodal Models with Visual-Spatial Knowledge for Road Scene Understanding\"],[\"TuneNSearch: a hybrid transfer learning and local search approach for solving vehicle routing problems\"],[\"FW-Merging: Scaling Model Merging with Frank-Wolfe Optimization\"],[\"Realized Volatility Forecasting for New Issues and Spin-Offs using Multi-Source Transfer Learning\"],[\"Understanding Gradient Orthogonalization for Deep Learning via Non-Euclidean Trust-Region Optimization\"],[\"Hybrid Learners Do Not Forget: A Brain-Inspired Neuro-Symbolic Approach to Continual Learning\"],[\"Fast filtering of non-Gaussian models using Amortized Optimal Transport Maps\"],[\"MAVEN: Multi-modal Attention for Valence-Arousal Emotion Network\"],[\"Real-Time Cell Sorting with Scalable In Situ FPGA-Accelerated Deep Learning\"],[\"Scaling Semantic Categories: Investigating the Impact on Vision Transformer Labeling Performance\"],[\"LATINO-PRO: LAtent consisTency INverse sOlver with PRompt Optimization\"],[\"SynLlama: Generating Synthesizable Molecules and Their Analogs with Large Language Models\"],[\"GraphEval: A Lightweight Graph-Based LLM Framework for Idea Evaluation\"],[\"Fourier-Based 3D Multistage Transformer for Aberration Correction in Multicellular Specimens\"],[\"MoECollab: Democratizing LLM Development Through Collaborative Mixture of Experts\"],[\"Focusing Robot Open-Ended Reinforcement Learning Through Users' Purposes\"],[\"Deblur Gaussian Splatting SLAM\"],[\"Diffusion on Graph: Augmentation of Graph Structure for Node Classification\"]],\"hovertemplate\":\"x=%{x}\\u003cbr\\u003ey=%{y}\\u003cbr\\u003etitle=%{customdata[0]}\\u003cbr\\u003ecluster=%{marker.color}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"\",\"marker\":{\"color\":[0,0,0,0,0,0,0,0,0,0,-1,0,0,-1,0,0,0,0,0,0,-1,-1,1,-1,-1,-1,0,0,-1,0,0,-1,0,-1,0,-1,0,0,0,-1,-1,-1,0,0,-1,0,-1,0,-1,-1,0,-1,-1,-1,-1,0,0,0,-1,0,0,0,0,-1,0,0,-1,0,-1,0,-1,0,0,-1,-1,0,0,0,0,0,-1,-1,-1,1,0,0,0,0,0,0,-1,-1,-1,0,-1,-1,0,0,0,0,0,0,0,0,0,0,-1,0,0,0,0,-1,0,0,0,0,0,-1,0,-1,-1,-1,0,0,-1,-1,0,-1,0,-1,0,0,0,0,-1,-1,0,-1,0,0,-1,0,-1,0,0,0,0,-1,-1,0,-1,0,0,-1,0,-1,-1,-1,-1,-1,-1,0,0,-1,0,0,-1,-1,-1,0,0,-1,0,0,-1,0,-1,0,-1,-1,0,0,0,-1,-1,0,-1,-1,0,-1,0,-1,0,1,0,0,0,-1,-1,0,0,0,-1,-1,0,-1,0,0,0,0,-1,0,0,0,-1,-1,0,0,0,0,0,0,0,-1,-1,-1,-1,0,0,0,0,-1,0,-1,-1,0,0,0,0,-1,1,-1,0,-1,-1,0,0,-1,-1,0,-1,0,0,-1,-1,0,0,0,-1,0,0,-1,0,-1,0,-1,-1,-1,-1,-1,0,-1,0,-1,0,0,-1,-1,-1,-1,0,-1,0,-1,0,-1,-1,0,-1,-1,0,0,-1,0,0,-1,0,-1,-1,0,-1,0,-1,0,0,-1,0,0,-1,0,0,-1,0,-1,0,0,0,-1,0,-1,0,-1,-1,-1,-1,-1,0,-1,0,0,0,0,-1,-1,-1,-1,0,-1,0,-1,0,-1,0,-1,0,-1,0,0,0,-1,0,0,-1,0,0,-1,-1,0,0,-1,0,0,0,0,0,-1,-1,-1,-1,-1,0,0,0,-1,0,-1,-1,-1,-1,0,0,-1,0,-1,0,-1,-1,0,0,0,-1,0,-1,0,0,-1,1,-1,-1,-1,-1,0,0,0,0,0,-1,-1,-1,-1,0,-1,0,-1,-1,0,-1,0,0,0,-1,0,0,0,-1,-1,-1,0,-1,-1,0,-1,0,-1,-1,0,0,0,-1,-1,0,0,0,-1,0,-1,-1,0,-1,0,0,0,0,-1,0,0,0,0,0,-1,0,0,0,-1,0,0,0,0,-1,0,0,-1,-1,-1,-1,0,0,0,-1,-1,0,-1,0],\"coloraxis\":\"coloraxis\",\"symbol\":\"circle\"},\"mode\":\"markers\",\"name\":\"\",\"orientation\":\"v\",\"showlegend\":false,\"x\":[9.605637,10.183499,9.595906,11.85868,9.776608,10.660749,10.664802,10.917786,10.083787,6.8142357,8.100864,8.941665,9.81522,4.7410274,4.6363974,4.588753,11.240451,6.5874314,4.60878,10.470416,6.9371395,8.03875,5.4005384,6.1007624,8.105491,9.582596,7.0139675,9.821754,8.289776,7.8428082,8.487536,6.099417,7.715434,11.951793,11.348261,6.1223755,6.3785844,8.867576,8.480375,6.7202196,11.310509,7.21759,8.080635,8.440142,9.342316,6.9108195,7.9439545,8.786603,7.753238,8.65596,10.814277,6.963507,9.929504,7.7598104,9.393696,8.225685,9.144522,7.6100726,8.924503,10.439448,6.9829574,7.8463244,10.147258,8.147569,8.254787,10.41236,10.121151,7.482444,9.540675,6.867851,9.008858,7.42478,7.2540846,10.719008,4.784133,7.1554356,8.008466,10.7379,6.618797,11.268011,9.028115,7.301508,7.7200065,5.4224052,10.451529,8.045861,5.909983,8.704163,5.927677,10.305966,10.638704,5.4699297,7.872022,6.9509916,10.320557,10.835984,10.618621,10.642978,9.514599,9.432523,10.246475,4.742183,10.670567,11.539505,11.021008,10.027651,7.5916977,7.38402,5.8462133,5.832825,9.813819,8.981143,7.634457,4.631597,10.672004,10.582214,7.19864,7.3168683,9.531057,7.543521,7.132023,8.400863,8.746248,6.988598,6.8224316,7.3303475,10.446046,7.848225,7.5720987,5.8798323,10.829591,9.83925,7.6676116,9.558093,8.390105,8.082013,9.689618,10.965312,9.964129,7.548744,10.31557,5.9263673,7.9830995,10.274405,6.4445176,7.4743457,11.005279,8.376985,6.0605874,11.4449215,8.364271,9.307483,10.416603,7.744636,6.4204426,7.1087894,5.9542646,8.783607,5.8617506,9.520951,9.133895,9.708343,9.64883,7.9027224,11.092867,8.260699,8.862365,10.398969,9.549572,7.62737,7.4487553,10.270194,10.447527,10.878051,8.682736,7.554811,8.1364,10.567147,7.276247,10.88046,8.745136,10.430802,9.591781,9.050563,10.039756,9.918929,10.329011,7.670104,8.901019,6.5030427,7.935744,8.430456,11.582647,5.717758,10.968711,7.2399173,11.08045,9.163564,9.5220995,8.447197,10.774986,10.453993,8.671799,8.186086,11.353741,8.085524,10.512627,11.267981,8.2344265,7.700457,10.314401,10.682294,10.205043,9.663011,8.112701,11.663909,11.525943,10.157354,11.899335,11.40223,4.6588564,6.4816594,11.123026,7.968997,11.652148,6.57341,8.791034,11.190426,11.6869755,9.640304,9.790685,7.2903943,7.177434,7.37048,7.3402715,7.1191263,8.888752,10.85899,8.919409,11.741455,5.459473,7.9260206,9.736211,7.283407,6.638668,6.932449,6.788138,10.1209,6.1100793,11.047037,6.8026037,11.385736,7.965722,10.177571,10.4997835,8.291816,8.10097,6.70543,7.910689,11.179539,11.069041,9.694613,10.252502,6.369373,7.0083723,6.5159063,8.116649,10.052653,8.898937,10.990263,6.9992633,7.218366,7.299049,7.899882,5.9728174,11.487574,5.7548885,6.7886047,6.700339,7.2744465,5.7821336,8.383862,7.1185446,7.2629976,6.9806747,9.02824,7.556968,11.019449,7.829168,10.2511425,9.851483,9.319418,9.085692,11.409754,7.1592555,8.778152,10.542012,7.2889924,6.358027,6.833432,7.2957435,8.093578,6.461166,7.186614,7.72124,7.305065,10.584966,9.053982,7.6411753,8.290814,7.3913617,9.315041,9.773605,10.05996,9.868212,10.680001,10.096052,6.046383,10.755472,9.273012,6.73438,11.553844,7.937136,7.103738,11.835194,8.973368,6.7091007,8.569618,10.721335,8.422717,8.071876,7.536749,5.6596017,9.920256,8.264313,11.648827,8.657157,7.6860723,4.6678157,4.563841,10.33185,7.504776,11.3879175,8.03436,9.833579,6.551287,11.442274,9.721181,11.266088,11.251654,8.343042,9.9071455,7.779742,10.875358,10.51441,7.956048,7.6495786,8.368639,10.502804,10.223134,8.873621,10.502408,11.4849,5.948078,10.58746,6.4428267,6.4037642,10.380518,8.025463,8.892306,8.020122,7.591901,11.483506,10.305763,7.105991,8.466282,8.385439,5.8087435,7.6526847,8.628085,7.9564443,8.498336,10.202983,11.848545,9.691647,8.7709255,9.455479,7.707464,10.8289385,7.310744,11.523851,7.401642,8.767626,10.34501,10.319958,6.039827,6.18509,10.387929,11.4685955,6.7291455,7.6998158,9.864614,11.50876,8.191453,10.257655,8.256591,7.9069,10.676323,8.0423765,10.748493,8.931973,5.951113,10.204712,9.678734,7.575213,10.193043,7.6684375,10.085965,11.217447,10.020114,5.764166,11.513113,10.639223,5.840633,9.427066,8.7597275,11.384766,10.095427,7.2660823,8.9291525,8.1092,6.9961047,10.405931,10.893826,8.934713,8.212598,8.007316,9.512038,8.749467,8.939962,8.399882,6.0462666,8.350499,6.334461,9.555769,8.988556,5.5511317,10.316374,5.5777597,9.681082,8.464249,7.661218,9.747089,5.9667025,4.596109,10.156967,7.064365,10.041579,11.114764,10.17031,11.561113,8.332902,7.692542,9.860473,11.012971,10.704998,9.487479,10.252892,7.372369,6.8728776,10.768976,8.545781,9.456544,8.259312,8.775592,9.78418,6.2778764,9.4607935,8.481462,11.232045,10.867614,10.030415,7.039593],\"xaxis\":\"x\",\"y\":[7.3723297,7.159702,8.258823,8.4794035,7.328652,6.256365,9.918319,8.740373,7.7416883,10.226469,5.7743235,5.223871,5.346754,9.672871,9.731551,9.782365,8.40073,7.89636,9.772995,6.366925,10.849834,7.1489234,8.776329,9.417931,7.394075,7.924862,8.55346,7.1829524,10.088012,11.216755,8.300302,8.564456,11.345105,8.029746,8.552141,8.880279,6.722129,9.81481,10.988901,10.550206,9.078833,9.261935,9.838558,10.1572075,6.6428714,10.879687,10.021051,5.439168,8.024268,7.9705772,8.320852,7.5073195,7.90098,9.509889,9.108132,11.197445,5.2460246,7.7960153,5.834613,5.763468,8.749813,7.6894135,7.0918617,5.811127,9.691415,8.240551,9.516554,11.145771,5.5865746,8.734368,6.7679176,11.329757,11.245417,5.846257,9.727827,11.239155,5.769998,8.979272,7.3904743,8.5143175,6.7814198,8.617325,6.789542,8.759732,8.505413,9.646883,7.5079947,6.033548,9.243809,5.6039467,5.7836175,8.7914295,6.5383754,8.934293,6.758662,9.305594,5.793284,9.816459,6.0584517,8.077292,9.790719,9.6557,5.9827967,8.355231,6.4427176,8.186153,7.18299,11.34869,9.151627,7.417114,8.452946,5.9073744,5.879442,9.73746,6.0216928,5.78056,11.290755,9.771467,8.384096,8.955701,10.00238,7.5547996,5.3505697,8.848211,10.285759,8.024141,6.525986,8.463701,11.149917,7.920917,9.433954,5.93481,8.082046,5.850825,7.69305,7.2152114,5.381572,7.7800546,8.540346,11.406751,9.554653,7.4816656,7.103045,9.191202,6.7096405,11.295199,7.9056315,7.1798377,9.030049,9.775978,5.98605,8.928835,9.321085,9.026289,9.6676855,9.244643,8.621756,8.158984,7.372773,6.975492,6.732968,5.490464,8.5988,11.310798,9.559995,11.195535,10.258577,9.479095,6.2084312,11.289322,9.154189,9.557044,8.596795,9.270912,9.606026,7.866867,7.1197557,5.557319,8.548425,10.023159,9.966644,5.5881143,9.419642,8.966876,9.590348,5.643592,9.532171,7.487489,5.1953964,6.671328,6.1464777,9.954358,9.52636,8.778928,10.290384,11.391704,7.779663,8.121697,7.6291127,9.427606,9.56407,6.180059,7.245075,11.2438,10.111074,5.9150124,6.3732305,9.327856,8.02079,10.920892,8.9516325,9.677766,7.6723657,7.910141,9.544544,8.326848,9.096581,7.2404194,8.0671625,8.515929,9.709814,6.749397,9.268887,6.1773167,9.377926,6.862063,8.555865,9.104274,9.026225,7.907492,7.422733,9.984132,11.468512,8.489135,10.184569,8.515255,8.476775,8.8532505,8.635864,8.221157,8.614059,7.723008,8.219213,9.051863,7.957791,7.5955772,10.607845,7.791225,8.098544,10.395191,9.144205,8.73456,5.685543,8.986687,9.435144,9.382583,10.282206,10.015119,10.788839,8.69801,10.307766,5.5910153,5.7505455,8.56359,11.039679,8.56603,8.183225,8.20404,8.530196,8.938709,8.721385,8.487089,9.91354,7.8153286,7.4079165,9.707673,7.990553,7.420069,9.420686,9.900743,7.3410163,7.227097,11.382196,7.6912417,10.941084,6.564842,10.347198,9.79278,9.882884,9.608498,7.276966,9.862629,7.9707074,8.156605,8.182601,8.810536,8.147232,8.88689,9.234086,8.202366,8.033198,10.063525,6.629513,8.997607,5.873299,9.084496,7.2415714,9.331825,9.56583,11.172791,7.9831433,8.625156,7.6052556,9.812283,5.7668657,9.516872,7.708904,6.9789076,5.730372,8.228631,7.643791,8.914992,7.0381536,9.53126,8.589775,6.0472417,9.633581,8.087678,5.711292,10.1060095,10.236277,8.139248,8.626249,9.559894,8.283902,9.495454,5.9212065,6.21905,9.676223,9.840193,6.819335,9.939567,8.557789,5.7441974,8.0701885,6.5480604,9.002041,7.362466,8.881634,9.609837,8.215023,5.258826,7.3968835,8.202616,6.0220146,7.2874036,9.902133,9.68575,9.671797,7.679961,5.213753,8.274746,7.8359237,7.428439,9.732533,7.785681,7.623366,6.792634,5.7533665,7.402877,8.351088,5.9801526,8.770868,9.919852,9.045647,7.722456,8.112726,8.982431,8.003313,10.013718,10.4084,10.740307,5.824948,8.144302,8.440228,8.190109,6.1982245,7.9278235,7.1482744,11.296189,7.9578433,11.443443,8.339049,8.898973,5.68869,8.4432335,9.214321,6.6628933,9.9553995,10.11101,5.861969,7.241239,9.800541,8.16098,5.35883,7.471728,6.600375,8.928012,5.969573,6.132316,8.895937,9.308453,5.888455,9.342703,9.644915,7.35496,7.3236523,9.021548,8.155184,5.5723677,8.484876,9.191419,8.118012,8.789744,8.552422,9.764452,9.814396,9.154291,10.011135,9.451561,7.481365,7.6009912,9.945856,8.777083,8.038003,11.228718,7.676175,9.757792,6.040301,9.082148,10.87573,7.4846067,10.361844,6.707887,7.5364137,5.2508335,8.61204,6.8490424,8.577832,5.8027787,8.34856,7.3137584,5.458064,9.338972,9.754086,8.903142,11.080338,5.210889,8.9563265,5.7156034,9.842694,10.452744,5.8531213,5.5244813,9.0877075,7.5821543,6.615688,8.917293,7.7661953,10.184523,8.1911955,6.370125,8.584763,8.295605,9.097639,8.16404,7.499674,9.609486,8.320643,8.826875,6.0042033,7.2699494,8.89086],\"yaxis\":\"y\",\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"x\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"y\"}},\"coloraxis\":{\"colorbar\":{\"title\":{\"text\":\"cluster\"}},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"legend\":{\"tracegroupgap\":0},\"title\":{\"text\":\"Paper Clusters\"},\"height\":600,\"width\":1000},                        {\"responsive\": true}                    ).then(function(){\n","                            \n","var gd = document.getElementById('709de2cd-a32f-4cbb-a59f-e265110a5c0d');\n","var x = new MutationObserver(function (mutations, observer) {{\n","        var display = window.getComputedStyle(gd).display;\n","        if (!display || display === 'none') {{\n","            console.log([gd, 'removed!']);\n","            Plotly.purge(gd);\n","            observer.disconnect();\n","        }}\n","}});\n","\n","// Listen for the removal of the full notebook cells\n","var notebookContainer = gd.closest('#notebook-container');\n","if (notebookContainer) {{\n","    x.observe(notebookContainer, {childList: true});\n","}}\n","\n","// Listen for the clearing of the current output cell\n","var outputEl = gd.closest('.output');\n","if (outputEl) {{\n","    x.observe(outputEl, {childList: true});\n","}}\n","\n","                        })                };                            </script>        </div>\n","</body>\n","</html>"]},"metadata":{}}]},{"cell_type":"code","source":["# Visualize clusters\n","fig = px.scatter(\n","    df,\n","    x='x',\n","    y='y',\n","    color='cluster',\n","    hover_data=['title'],\n","    title='Paper Clusters',\n","    width=1000,\n","    height=600\n",")\n","fig.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":617},"id":"XJER2QulkuBU","executionInfo":{"status":"ok","timestamp":1742742939770,"user_tz":360,"elapsed":218,"user":{"displayName":"Alex Baret","userId":"10734557950216503149"}},"outputId":"e18e6ca0-9b75-463f-8b54-1cd2ea1b1aef"},"execution_count":19,"outputs":[{"output_type":"display_data","data":{"text/html":["<html>\n","<head><meta charset=\"utf-8\" /></head>\n","<body>\n","    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n","        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"9cb5b036-0c2b-489c-88c2-c1e0ddeaca5a\" class=\"plotly-graph-div\" style=\"height:600px; width:1000px;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"9cb5b036-0c2b-489c-88c2-c1e0ddeaca5a\")) {                    Plotly.newPlot(                        \"9cb5b036-0c2b-489c-88c2-c1e0ddeaca5a\",                        [{\"customdata\":[[\"GAEA: A Geolocation Aware Conversational Model\"],[\"MagicMotion: Controllable Video Generation with Dense-to-Sparse Trajectory Guidance\"],[\"InfiniteYou: Flexible Photo Recrafting While Preserving Your Identity\"],[\"Survey on Evaluation of LLM-based Agents\"],[\"DreamTexture: Shape from Virtual Texture with Analysis by Augmentation\"],[\"RoboFactory: Exploring Embodied Agent Collaboration with Compositional Constraints\"],[\"The Emperor's New Clothes in Benchmarking? A Rigorous Examination of Mitigation Strategies for LLM Benchmark Data Contamination\"],[\"Exploring the Hidden Reasoning Process of Large Language Models by Misleading Them\"],[\"ScalingNoise: Scaling Inference-Time Search for Generating Infinite Videos\"],[\"The global convergence time of stochastic gradient descent in non-convex landscapes: Sharp estimates via large deviations\"],[\"Truthful Elicitation of Imprecise Forecasts\"],[\"Sparse Nonparametric Contextual Bandits\"],[\"Reinforcement Learning-based Heuristics to Guide Domain-Independent Dynamic Programming\"],[\"Neural Networks: According to the Principles of Grassmann Algebra\"],[\"Probabilistic Quantum SVM Training on Ising Machine\"],[\"Enhancing variational quantum algorithms by balancing training on classical and quantum hardware\"],[\"CaKE: Circuit-aware Editing Enables Generalizable Knowledge Learners\"],[\"Lyra: An Efficient and Expressive Subquadratic Architecture for Modeling Biological Sequences\"],[\"HiQ-Lip: The First Quantum-Classical Hierarchical Method for Global Lipschitz Constant Estimation of ReLU Networks\"],[\"Nonlinear action prediction models reveal multi-timescale locomotor control\"],[\"Optimal Complexity in Byzantine-Robust Distributed Stochastic Optimization with Data Heterogeneity\"],[\"Knowledge-guided machine learning model with soil moisture for corn yield prediction under drought conditions\"],[\"NeuralFoil: An Airfoil Aerodynamics Analysis Tool Using Physics-Informed Machine Learning\"],[\"On the Cone Effect in the Learning Dynamics\"],[\"Active Learning For Repairable Hardware Systems With Partial Coverage\"],[\"Structured-Noise Masked Modeling for Video, Audio and Beyond\"],[\"Explainable Graph-theoretical Machine Learning: with Application to Alzheimer's Disease Prediction\"],[\"Uni-3DAR: Unified 3D Generation and Understanding via Autoregression on Compressed Spatial Tokens\"],[\"Rethinking Robustness in Machine Learning: A Posterior Agreement Approach\"],[\"RESFL: An Uncertainty-Aware Framework for Responsible Federated Learning by Balancing Privacy, Fairness and Utility in Autonomous Vehicles\"],[\"OpenMIBOOD: Open Medical Imaging Benchmarks for Out-Of-Distribution Detection\"],[\"Machine learning identifies nullclines in oscillatory dynamical systems\"],[\"Empirical Analysis of Privacy-Fairness-Accuracy Trade-offs in Federated Learning: A Step Towards Responsible AI\"],[\"Flight Testing an Optionally Piloted Aircraft: a Case Study on Trust Dynamics in Human-Autonomy Teaming\"],[\"Reinforcement Learning for Reasoning in Small LLMs: What Works and What Doesn't\"],[\"Neural Variable-Order Fractional Differential Equation Networks\"],[\"Interpretable Neural Causal Models with TRAM-DAGs\"],[\"Deferring Concept Bottleneck Models: Learning to Defer Interventions to Inaccurate Experts\"],[\"VP-NTK: Exploring the Benefits of Visual Prompting in Differentially Private Data Synthesis\"],[\"Nonparametric Bellman Mappings for Value Iteration in Distributed Reinforcement Learning\"],[\"Large Language Models for Water Distribution Systems Modeling and Decision-Making\"],[\"Manifold learning in metric spaces\"],[\"Variance-Aware Noisy Training: Hardening DNNs against Unstable Analog Computations\"],[\"Narrowing Class-Wise Robustness Gaps in Adversarial Training\"],[\"Neural Combinatorial Optimization for Real-World Routing\"],[\"Distributed Learning over Arbitrary Topology: Linear Speed-Up with Polynomial Transient Time\"],[\"Improving Discriminator Guidance in Diffusion Models\"],[\"Learn to Bid as a Price-Maker Wind Power Producer\"],[\"AIMI: Leveraging Future Knowledge and Personalization in Sparse Event Forecasting for Treatment Adherence\"],[\"Hyperspectral Imaging for Identifying Foreign Objects on Pork Belly\"],[\"OThink-MR1: Stimulating multimodal generalized reasoning capabilities through dynamic reinforcement learning\"],[\"Redefining Toxicity: An Objective and Context-Aware Approach for Stress-Level-Based Detection\"],[\"Expert Race: A Flexible Routing Strategy for Scaling Diffusion Transformer with Mixture of Experts\"],[\"Patch-based learning of adaptive Total Variation parameter maps for blind image denoising\"],[\"InhibiDistilbert: Knowledge Distillation for a ReLU and Addition-based Transformer\"],[\"TVineSynth: A Truncated C-Vine Copula Generator of Synthetic Tabular Data to Balance Privacy and Utility\"],[\"Information maximization for a broad variety of multi-armed bandit games\"],[\"Multivariate Time Series Anomaly Detection in Industry 5.0\"],[\"Sample-Efficient Bayesian Transfer Learning for Online Machine Parameter Optimization\"],[\"Denoising-based Contractive Imitation Learning\"],[\"On the Limits of Applying Graph Transformers for Brain Connectome Classification\"],[\"A multi-model approach using XAI and anomaly detection to predict asteroid hazards\"],[\"Learning 3D Scene Analogies with Neural Contextual Scene Maps\"],[\"Time After Time: Deep-Q Effect Estimation for Interventions on When and What to do\"],[\"LeanTTA: A Backpropagation-Free and Stateless Approach to Quantized Test-Time Adaptation on Edge Devices\"],[\"Enhancing Zero-Shot Image Recognition in Vision-Language Models through Human-like Concept Guidance\"],[\"InCo-DPO: Balancing Distribution Shift and Data Quality for Enhanced Preference Optimization\"],[\"FedSAF: A Federated Learning Framework for Enhanced Gastric Cancer Detection and Privacy Preservation\"],[\"Active management of battery degradation in wireless sensor network using deep reinforcement learning for group battery replacement\"],[\"Network Embedding Exploration Tool (NEExT)\"],[\"Network-wide Freeway Traffic Estimation Using Sparse Sensor Data: A Dirichlet Graph Auto-Encoder Approach\"],[\"FedAWA: Adaptive Optimization of Aggregation Weights in Federated Learning Using Client Vectors\"],[\"Energy-Efficient Federated Learning and Migration in Digital Twin Edge Networks\"],[\"Control Pneumatic Soft Bending Actuator with Online Learning Pneumatic Physical Reservoir Computing\"],[\"Big data comparison of quantum invariants\"],[\"Communication Efficient Federated Learning with Linear Convergence on Heterogeneous Data\"],[\"Disentangling Uncertainties by Learning Compressed Data Representation\"],[\"Mixture of Lookup Experts\"],[\"Blend the Separated: Mixture of Synergistic Experts for Data-Scarcity Drug-Target Interaction Prediction\"],[\"DNA Bench: When Silence is Smarter -- Benchmarking Over-Reasoning in Reasoning LLMs\"],[\"MobiFuse: Learning Universal Human Mobility Patterns through Cross-domain Data Fusion\"],[\"Line Space Clustering (LSC): Feature-Based Clustering using K-medians and Dynamic Time Warping for Versatility\"],[\"Prediction of Permissioned Blockchain Performance for Resource Scaling Configurations\"],[\"Accelerating Transient CFD through Machine Learning-Based Flow Initialization\"],[\"ATTENTION2D: Communication Efficient Distributed Self-Attention Mechanism\"],[\"PARQ: Piecewise-Affine Regularized Quantization\"],[\"Using machine learning to map simulated noisy and laser-limited multidimensional spectra to molecular electronic couplings\"],[\"Tuning Sequential Monte Carlo Samplers via Greedy Incremental Divergence Minimization\"],[\"Approximation properties of neural ODEs\"],[\"Good Actions Succeed, Bad Actions Generalize: A Case Study on Why RL Generalizes Better\"],[\"Robotic Paper Wrapping by Learning Force Control\"],[\"Sequential learning based PINNs to overcome temporal domain complexities in unsteady flow past flapping wings\"],[\"Model Risk Management for Generative AI In Financial Institutions\"],[\"Survey on Generalization Theory for Graph Neural Networks\"],[\"Multi-Modal Gesture Recognition from Video and Surgical Tool Pose Information via Motion Invariants\"],[\"Using machine learning to measure evidence of students' sensemaking in physics courses\"],[\"Neural Lyapunov Function Approximation with Self-Supervised Reinforcement Learning\"],[\"Does Context Matter? ContextualJudgeBench for Evaluating LLM-based Judges in Contextual Settings\"],[\"PEnGUiN: Partially Equivariant Graph NeUral Networks for Sample Efficient MARL\"],[\"TULIP: Towards Unified Language-Image Pretraining\"],[\"Value Profiles for Encoding Human Variation\"],[\"Natural Quantization of Neural Networks\"],[\"Learning to Play Piano in the Real World\"],[\"SWEET-RL: Training Multi-Turn LLM Agents on Collaborative Reasoning Tasks\"],[\"What Makes a Reward Model a Good Teacher? An Optimization Perspective\"],[\"Di$\\\\mathtt{[M]}$O: Distilling Masked Diffusion Models into One-step Generator\"],[\"Temporal Encoding Strategies for Energy Time Series Prediction\"],[\"Reducing Communication Overhead in Federated Learning for Network Anomaly Detection with Adaptive Client Selection\"],[\"A discontinuity-capturing neural network with categorical embedding and its application to anisotropic elliptic interface problems\"],[\"Accurate, transferable, and verifiable machine-learned interatomic potentials for layered materials\"],[\"LIFT: Latent Implicit Functions for Task- and Data-Agnostic Encoding\"],[\"Exploiting Prior Knowledge in Preferential Learning of Individualized Autonomous Vehicle Driving Styles\"],[\"Efficient Post-Hoc Uncertainty Calibration via Variance-Based Smoothing\"],[\"HQNN-FSP: A Hybrid Classical-Quantum Neural Network for Regression-Based Financial Stock Market Prediction\"],[\"Geometrically-Aware One-Shot Skill Transfer of Category-Level Objects\"],[\"Online Imitation Learning for Manipulation via Decaying Relative Correction through Teleoperation\"],[\"FedBEns: One-Shot Federated Learning based on Bayesian Ensemble\"],[\"Robustness of Nonlinear Representation Learning\"],[\"Leveraging Perfect Multimodal Alignment and Gaussian Assumptions for Cross-modal Transfer\"],[\"Hierarchical clustering with maximum density paths and mixture models\"],[\"Borsuk-Ulam and Replicable Learning of Large-Margin Halfspaces\"],[\"Beacon2Science: Enhancing STEREO\\u002fHI beacon data1 with machine learning for efficient CME tracking\"],[\"Performance-bounded Online Ensemble Learning Method Based on Multi-armed bandits and Its Applications in Real-time Safety Assessment\"],[\"Learning to quantify graph nodes\"],[\"Fast MLE and MAPE-Based Device Activity Detection for Grant-Free Access via PSCA and PSCA-Net\"],[\"ImputeGAP: A Comprehensive Library for Time Series Imputation\"],[\"A Personalized Data-Driven Generative Model of Human Motion\"],[\"A Foundation Model for Patient Behavior Monitoring and Suicide Detection\"],[\"Online federated learning framework for classification\"],[\"Kolmogorov-Arnold Network for Transistor Compact Modeling\"],[\"Understanding the Generalization of In-Context Learning in Transformers: An Empirical Study\"],[\"Partially Observable Reinforcement Learning with Memory Traces\"],[\"Sparseformer: a Transferable Transformer with Multi-granularity Token Sparsification for Medical Time Series Classification\"],[\"Learning Topology Actions for Power Grid Control: A Graph-Based Soft-Label Imitation Learning Approach\"],[\"A Bird Song Detector for improving bird identification through Deep Learning: a case study from Doñana\"],[\"Food Delivery Time Prediction in Indian Cities Using Machine Learning Models\"],[\"Multi-Agent Actor-Critic with Harmonic Annealing Pruning for Dynamic Spectrum Access Systems\"],[\"World Models in Artificial Intelligence: Sensing, Learning, and Reasoning Like a Child\"],[\"Machine Unlearning in Hyperbolic vs. Euclidean Multimodal Contrastive Learning: Adapting Alignment Calibration to MERU\"],[\"Global Group Fairness in Federated Learning via Function Tracking\"],[\"Preference Construction: A Bayesian Interactive Preference Elicitation Framework Based on Monte Carlo Tree Search\"],[\"Machine learning surrogate models of many-body dispersion interactions in polymer melts\"],[\"Machine Learning Techniques for Multifactor Analysis of National Carbon Dioxide Emissions\"],[\"Neuronal Activation States as Sample Embeddings for Data Selection in Task-Specific Instruction Tuning\"],[\"DeCaFlow: A Deconfounding Causal Generative Model\"],[\"FedLWS: Federated Learning with Adaptive Layer-wise Weight Shrinking\"],[\"VIPER: Visual Perception and Explainable Reasoning for Sequential Decision-Making\"],[\"Interpretability of Graph Neural Networks to Assert Effects of Global Change Drivers on Ecological Networks\"],[\"Control, Optimal Transport and Neural Differential Equations in Supervised Learning\"],[\"LLM-Aided Customizable Profiling of Code Data Based On Programming Language Concepts\"],[\"Diffusion-Based Forecasting for Uncertainty-Aware Model Predictive Control\"],[\"Continual Contrastive Learning on Tabular Data with Out of Distribution\"],[\"RAG-based User Profiling for Precision Planning in Mixed-precision Over-the-Air Federated Learning\"],[\"Multivariate Gaussian Topic Modelling: A novel approach to discover topics with greater semantic coherence\"],[\"Mixed precision accumulation for neural network inference guided by componentwise forward error analysis\"],[\"Manifold Learning for Hyperspectral Images\"],[\"Ambient Noise Full Waveform Inversion with Neural Operators\"],[\"A Novel Channel Boosted Residual CNN-Transformer with Regional-Boundary Learning for Breast Cancer Detection\"],[\"Towards Unified Latent Space for 3D Molecular Latent Diffusion Modeling\"],[\"Scalable Trajectory-User Linking with Dual-Stream Representation Networks\"],[\"Embedding spatial context in urban traffic forecasting with contrastive pre-training\"],[\"Application of linear regression method to the deep reinforcement learning in continuous action cases\"],[\"Continual Multimodal Contrastive Learning\"],[\"Proceedings of the 3rd Italian Conference on Big Data and Data Science (ITADATA2024)\"],[\"Enhancing Code LLM Training with Programmer Attention\"],[\"Prada: Black-Box LLM Adaptation with Private Data on Resource-Constrained Devices\"],[\"Enforcing Consistency and Fairness in Multi-level Hierarchical Classification with a Mask-based Output Layer\"],[\"ACE: A Cardinality Estimator for Set-Valued Queries\"],[\"Semi-Gradient SARSA Routing with Theoretical Guarantee on Traffic Stability and Weight Convergence\"],[\"pFedFair: Towards Optimal Group Fairness-Accuracy Trade-off in Heterogeneous Federated Learning\"],[\"A Semantic and Clean-label Backdoor Attack against Graph Convolutional Networks\"],[\"Pseudo-Relevance Feedback Can Improve Zero-Shot LLM-Based Dense Retrieval\"],[\"Exploring the Limits of KV Cache Compression in Visual Autoregressive Transformers\"],[\"GReaTER: Generate Realistic Tabular data after data Enhancement and Reduction\"],[\"Robust Support Vector Machines for Imbalanced and Noisy Data via Benders Decomposition\"],[\"Evaluating Time Series Models with Knowledge Discovery\"],[\"Global Renewables Watch: A Temporal Dataset of Solar and Wind Energy Derived from Satellite Imagery\"],[\"1000 Layer Networks for Self-Supervised RL: Scaling Depth Can Enable New Goal-Reaching Capabilities\"],[\"Dynamic Power Flow Analysis and Fault Characteristics: A Graph Attention Neural Network\"],[\"LogLLaMA: Transformer-based log anomaly detection with LLaMA\"],[\"On the Robustness Tradeoff in Fine-Tuning\"],[\"Curiosity-Diffuser: Curiosity Guide Diffusion Models for Reliability\"],[\"H2ST: Hierarchical Two-Sample Tests for Continual Out-of-Distribution Detection\"],[\"Robust Transmission of Punctured Text with Large Language Model-based Recovery\"],[\"Scaled Supervision is an Implicit Lipschitz Regularizer\"],[\"Learning with Expert Abstractions for Efficient Multi-Task Continuous Control\"],[\"Long Context Modeling with Ranked Memory-Augmented Retrieval\"],[\"Pruning-Based TinyML Optimization of Machine Learning Models for Anomaly Detection in Electric Vehicle Charging Infrastructure\"],[\"A New Benchmark for Online Learning with Budget-Balancing Constraints\"],[\"The Hardness of Validating Observational Studies with Experimental Data\"],[\"SEEK: Self-adaptive Explainable Kernel For Nonstationary Gaussian Processes\"],[\"RAT: Boosting Misclassification Detection Ability without Extra Data\"],[\"Fake Runs, Real Fixes -- Analyzing xPU Performance Through Simulation\"],[\"Localized Physics-informed Gaussian Processes with Curriculum Training for Topology Optimization\"],[\"Temporal Context Awareness: A Defense Framework Against Multi-turn Manipulation Attacks on Large Language Models\"],[\"Advanced Relay-Based Collaborative Framework for Optimizing Synchronization in Split Federated Learning over Wireless Networks\"],[\"Cosmos-Reason1: From Physical Common Sense To Embodied Reasoning\"],[\"RETHINED: A New Benchmark and Baseline for Real-Time High-Resolution Image Inpainting On Edge Devices\"],[\"Bayesian Modeling of Zero-Shot Classifications for Urban Flood Detection\"],[\"LipShiFT: A Certifiably Robust Shift-based Vision Transformer\"],[\"Uncertainty Distillation: Teaching Language Models to Express Semantic Confidence\"],[\"GR00T N1: An Open Foundation Model for Generalist Humanoid Robots\"],[\"Variational Autoencoded Multivariate Spatial Fay-Herriot Models\"],[\"Better Private Distribution Testing by Leveraging Unverified Auxiliary Data\"],[\"A Comprehensive Study of LLM Secure Code Generation\"],[\"Sepsyn-OLCP: An Online Learning-based Framework for Early Sepsis Prediction with Uncertainty Quantification using Conformal Prediction\"],[\"Reinforcement learning-based motion imitation for physiologically plausible musculoskeletal motor control\"],[\"Assessing Large Language Models for Automated Feedback Generation in Learning Programming Problem Solving\"],[\"Reducing False Ventricular Tachycardia Alarms in ICU Settings: A Machine Learning Approach\"],[\"Anomaly-Flow: A Multi-domain Federated Generative Adversarial Network for Distributed Denial-of-Service Detection\"],[\"Unique Hard Attention: A Tale of Two Sides\"],[\"Command R7B Arabic: A Small, Enterprise Focused, Multilingual, and Culturally Aware Arabic LLM\"],[\"MusicInfuser: Making Video Diffusion Listen and Dance\"],[\"The Power of Context: How Multimodality Improves Image Super-Resolution\"],[\"Utilization of Neighbor Information for Image Classification with Different Levels of Supervision\"],[\"Measuring AI Ability to Complete Long Tasks\"],[\"Temporal Consistency for LLM Reasoning Process Error Identification\"],[\"Cosmos-Transfer1: Conditional World Generation with Adaptive Multimodal Control\"],[\"Don't lie to your friends: Learning what you know from collaborative self-play\"],[\"DAPO: An Open-Source LLM Reinforcement Learning System at Scale\"],[\"EnQode: Fast Amplitude Embedding for Quantum Machine Learning Using Classical Data\"],[\"Doubly robust identification of treatment effects from multiple environments\"],[\"RWKV-7 \\\"Goose\\\" with Expressive Dynamic State Evolution\"],[\"Online Conformal Probabilistic Numerics via Adaptive Edge-Cloud Offloading\"],[\"EnvBench: A Benchmark for Automated Environment Setup\"],[\"Inducing Causal Structure for Interpretable Neural Networks Applied to Glucose Prediction for T1DM Patients\"],[\"Graph-CNNs for RF Imaging: Learning the Electric Field Integral Equations\"],[\"LLM-FE: Automated Feature Engineering for Tabular Data with LLMs as Evolutionary Optimizers\"],[\"PLAY2PROMPT: Zero-shot Tool Instruction Optimization for LLM Agents via Tool Play\"],[\"ExDDV: A New Dataset for Explainable Deepfake Detection in Video\"],[\"DUNE: Distilling a Universal Encoder from Heterogeneous 2D and 3D Teachers\"],[\"Landscape Complexity for the Empirical Risk of Generalized Linear Models: Discrimination between Structured Data\"],[\"Technical Report: Aggregation on Learnable Manifolds for Asynchronous Federated Optimization\"],[\"On the clustering behavior of sliding windows\"],[\"Optimizing High-Dimensional Oblique Splits\"],[\"PHGNN: A Novel Prompted Hypergraph Neural Network to Diagnose Alzheimer's Disease\"],[\"Advancing Medical Representation Learning Through High-Quality Data\"],[\"Tiled Flash Linear Attention: More Efficient Linear RNN and xLSTM Kernels\"],[\"Evaluating Machine Learning Approaches for ASCII Art Generation\"],[\"SocialJax: An Evaluation Suite for Multi-agent Reinforcement Learning in Sequential Social Dilemmas\"],[\"C(NN)FD -- Deep Learning Modelling of Multi-Stage Axial Compressors Aerodynamics\"],[\"The Exoplanet Citizen Science Pipeline: Human Factors and Machine Learning\"],[\"RFMI: Estimating Mutual Information on Rectified Flow for Text-to-Image Alignment\"],[\"Wasserstein-based Kernels for Clustering: Application to Power Distribution Graphs\"],[\"Sequence Analysis Using the Bezier Curve\"],[\"Benchmarking community drug response prediction models: datasets, models, tools, and metrics for cross-dataset generalization analysis\"],[\"Unified Analysis of Decentralized Gradient Descent: a Contraction Mapping Framework\"],[\"MoonCast: High-Quality Zero-Shot Podcast Generation\"],[\"End-to-End Optimal Detector Design with Mutual Information Surrogates\"],[\"Efficient but Vulnerable: Benchmarking and Defending LLM Batch Prompting Attack\"],[\"Higher-Order Graphon Neural Networks: Approximation and Cut Distance\"],[\"PENCIL: Long Thoughts with Short Memory\"],[\"Revealing higher-order neural representations with generative artificial intelligence\"],[\"Consumer-grade EEG-based Eye Tracking\"],[\"COPA: Comparing the Incomparable to Explore the Pareto Front\"],[\"FeNeC: Enhancing Continual Learning via Feature Clustering with Neighbor- or Logit-Based Classification\"],[\"Unveiling the Role of Randomization in Multiclass Adversarial Classification: Insights from Graph Theory\"],[\"Improved Scalable Lipschitz Bounds for Deep Neural Networks\"],[\"Robust Weight Imprinting: Insights from Neural Collapse and Proxy-Based Aggregation\"],[\"Tapered Off-Policy REINFORCE: Stable and efficient reinforcement learning for LLMs\"],[\"XOXO: Stealthy Cross-Origin Context Poisoning Attacks against AI Coding Assistants\"],[\"Automating Experimental Optics with Sample Efficient Machine Learning Methods\"],[\"Quantization-Free Autoregressive Action Transformer\"],[\"CINNAMON: A hybrid approach to change point detection and parameter estimation in single-particle tracking data\"],[\"Trading-off Accuracy and Communication Cost in Federated Learning\"],[\"Persistent Homology-induced Graph Ensembles for Time Series Regressions\"],[\"Predicting Cardiopulmonary Exercise Testing Outcomes in Congenital Heart Disease Through Multi-modal Data Integration and Geometric Learning\"],[\"CRCE: Coreference-Retention Concept Erasure in Text-to-Image Diffusion Models\"],[\"Multi-task Learning for Identification of Porcelain in Song and Yuan Dynasties\"],[\"Decision Tree Induction Through LLMs via Semantically-Aware Evolution\"],[\"Efficient Data Selection for Training Genomic Perturbation Models\"],[\"Rolling Forward: Enhancing LightGCN with Causal Graph Convolution for Credit Bond Recommendation\"],[\"Layer-wise Adaptive Gradient Norm Penalizing Method for Efficient and Accurate Deep Learning\"],[\"Strategic White Paper on AI Infrastructure for Particle, Nuclear, and Astroparticle Physics: Insights from JENA and EuCAIF\"],[\"Potential Score Matching: Debiasing Molecular Structure Sampling with Potential Energy Guidance\"],[\"Speculative Decoding for Verilog: Speed and Quality, All in One\"],[\"Teaching Artificial Intelligence to Perform Rapid, Resolution-Invariant Grain Growth Modeling via Fourier Neural Operator\"],[\"SpecReX: Explainable AI for Raman Spectroscopy\"],[\"Frac-Connections: Fractional Extension of Hyper-Connections\"],[\"Fundamental Limits of Matrix Sensing: Exact Asymptotics, Universality, and Applications\"],[\"PET-MAD, a universal interatomic potential for advanced materials modeling\"],[\"Towards Location-Specific Precipitation Projections Using Deep Neural Networks\"],[\"Semantic Communication in Dynamic Channel Scenarios: Collaborative Optimization of Dual-Pipeline Joint Source-Channel Coding and Personalized Federated Learning\"],[\"Theoretical Foundation of Flow-Based Time Series Generation: Provable Approximation, Generalization, and Efficiency\"],[\"Modular Distributed Nonconvex Learning with Error Feedback\"],[\"ON-Traffic: An Operator Learning Framework for Online Traffic Flow Estimation and Uncertainty Quantification from Lagrangian Sensors\"],[\"Empirical risk minimization algorithm for multiclass classification of S.D.E. paths\"],[\"Learning on LLM Output Signatures for gray-box LLM Behavior Analysis\"],[\"Uncertainty-Aware Global-View Reconstruction for Multi-View Multi-Label Feature Selection\"],[\"Predicting Human Choice Between Textually Described Lotteries\"],[\"MeshFleet: Filtered and Annotated 3D Vehicle Dataset for Domain Specific Generative Modeling\"],[\"Effortless Active Labeling for Long-Term Test-Time Adaptation\"],[\"DefectFill: Realistic Defect Generation with Inpainting Diffusion Model for Visual Inspection\"],[\"Empowering LLMs in Decision Games through Algorithmic Data Synthesis\"],[\"Identifying Critical Phases for Disease Onset with Sparse Haematological Biomarkers\"],[\"A CNN-based End-to-End Learning for RIS-assisted Communication System\"],[\"MDocAgent: A Multi-Modal Multi-Agent Framework for Document Understanding\"],[\"Enhanced High-Dimensional Data Visualization through Adaptive Multi-Scale Manifold Embedding\"],[\"Structured Knowledge Accumulation: An Autonomous Framework for Layer-Wise Entropy Reduction in Neural Learning\"],[\"Reconstructing Cell Lineage Trees from Phenotypic Features with Metric Learning\"],[\"Learning Accurate Models on Incomplete Data with Minimal Imputation\"],[\"Robust Machine Unlearning for Quantized Neural Networks via Adaptive Gradient Reweighting with Similar Labels\"],[\"KANITE: Kolmogorov-Arnold Networks for ITE estimation\"],[\"Incorporating Attributes and Multi-Scale Structures for Heterogeneous Graph Contrastive Learning\"],[\"Quantification of Uncertainties in Probabilistic Deep Neural Network by Implementing Boosting of Variational Inference\"],[\"Learning local neighborhoods of non-Gaussian graphical models: A measure transport approach\"],[\"MoK-RAG: Mixture of Knowledge Paths Enhanced Retrieval-Augmented Generation for Embodied AI Environments\"],[\"Squeeze Out Tokens from Sample for Finer-Grained Data Governance\"],[\"Multi-label feature selection based on binary hashing learning and dynamic graph constraints\"],[\"Empirical Calibration and Metric Differential Privacy in Language Models\"],[\"Out-of-Distribution Generalization in Time Series: A Survey\"],[\"HySurvPred: Multimodal Hyperbolic Embedding with Angle-Aware Hierarchical Contrastive Learning and Uncertainty Constraints for Survival Prediction\"],[\"MamBEV: Enabling State Space Models to Learn Birds-Eye-View Representations\"],[\"Spotting Persuasion: A Low-cost Model for Persuasion Detection in Political Ads on Social Media\"],[\"Counterfactual experience augmented off-policy reinforcement learning\"],[\"Self-Vocabularizing Training for Neural Machine Translation\"],[\"SALAD: Skeleton-aware Latent Diffusion for Text-driven Motion Generation and Editing\"],[\"Causal Discovery from Data Assisted by Large Language Models\"],[\"VARP: Reinforcement Learning from Vision-Language Model Feedback with Agent Regularized Preferences\"],[\"Text-Guided Image Invariant Feature Learning for Robust Image Watermarking\"],[\"AI-Powered Prediction of Nanoparticle Pharmacokinetics: A Multi-View Learning Approach\"],[\"BurTorch: Revisiting Training from First Principles by Coupling Autodiff, Math Optimization, and Systems\"],[\"Designing and Deploying AI Models for Sustainable Logistics Optimization: A Case Study on Eco-Efficient Supply Chains in the USA\"],[\"ROCK: A variational formulation for occupation kernel methods in Reproducing Kernel Hilbert Spaces\"],[\"Evaluating the Application of SOLID Principles in Modern AI Framework Architectures\"],[\"A finite-sample bound for identifying partially observed linear switched systems from a single trajectory\"],[\"Effective Dimension Aware Fractional-Order Stochastic Gradient Descent for Convex Optimization Problems\"],[\"Neural Edge Histogram Descriptors for Underwater Acoustic Target Recognition\"],[\"Synchronous vs Asynchronous Reinforcement Learning in a Real World Robot\"],[\"Optimizing ML Training with Metagradient Descent\"],[\"Redefining non-IID Data in Federated Learning for Computer Vision Tasks: Migrating from Labels to Embeddings for Task-Specific Data Distributions\"],[\"Multi-modal Time Series Analysis: A Tutorial and Survey\"],[\"Mitigating Spectral Bias in Neural Operators via High-Frequency Scaling for Physical Systems\"],[\"Atyaephyra at SemEval-2025 Task 4: Low-Rank NPO\"],[\"Novel AI-Based Quantification of Breast Arterial Calcification to Predict Cardiovascular Risk\"],[\"PrETi: Predicting Execution Time in Early Stage with LLVM and Machine Learning\"],[\"Sampling Decisions\"],[\"Bayesian Kernel Regression for Functional Data\"],[\"SRBB-Based Quantum State Preparation\"],[\"Quantum EigenGame for excited state calculation\"],[\"Matching Skeleton-based Activity Representations with Heterogeneous Signals for HAR\"],[\"A Convex formulation for linear discriminant analysis\"],[\"MetaScale: Test-Time Scaling with Evolving Meta-Thoughts\"],[\"Deep Belief Markov Models for POMDP Inference\"],[\"Unified Autoregressive Visual Generation and Understanding with Continuous Tokens\"],[\"Uncovering Utility Functions from Observed Outcomes\"],[\"Measuring In-Context Computation Complexity via Hidden State Prediction\"],[\"AugMapNet: Improving Spatial Latent Structure via BEV Grid Augmentation for Enhanced Vectorized Online HD Map Construction\"],[\"xLSTM 7B: A Recurrent LLM for Fast and Efficient Inference\"],[\"SuperBPE: Space Travel for Language Models\"],[\"The Impact of Artificial Intelligence on Emergency Medicine: A Review of Recent Advances\"],[\"Reward Adaptation Via Q-Manipulation\"],[\"Fed-Joint: Joint Modeling of Nonlinear Degradation Signals and Failure Events for Remaining Useful Life Prediction using Federated Learning\"],[\"MicroVQA: A Multimodal Reasoning Benchmark for Microscopy-Based Scientific Research\"],[\"PANDORA: Diffusion Policy Learning for Dexterous Robotic Piano Playing\"],[\"Investigating the effect of CPT in lateral spreading prediction using Explainable AI\"],[\"Spectrally-Corrected and Regularized QDA Classifier for Spiked Covariance Model\"],[\"Scale Efficient Training for Large Datasets\"],[\"Cream of the Crop: Harvesting Rich, Scalable and Transferable Multi-Modal Data for Instruction Fine-Tuning\"],[\"SyncDiff: Diffusion-based Talking Head Synthesis with Bottlenecked Temporal Visual Prior for Improved Synchronization\"],[\"Follow-the-Regularized-Leader with Adversarial Constraints\"],[\"Mitigating Visual Forgetting via Take-along Visual Conditioning for Multi-modal Long CoT Reasoning\"],[\"Agents Play Thousands of 3D Video Games\"],[\"Strain Problems got you in a Twist? Try StrainRelief: A Quantum-Accurate Tool for Ligand Strain Calculations\"],[\"Reliable and Efficient Amortized Model-based Evaluation\"],[\"PERC: a suite of software tools for the curation of cryoEM data with application to simulation, modelling and machine learning\"],[\"SMPR: A structure-enhanced multimodal drug-disease prediction model for drug repositioning and cold start\"],[\"ASMR: Adaptive Skeleton-Mesh Rigging and Skinning via 2D Generative Prior\"],[\"Do you understand epistemic uncertainty? Think again! Rigorous frequentist epistemic uncertainty estimation in regression\"],[\"RainScaleGAN: a Conditional Generative Adversarial Network for Rainfall Downscaling\"],[\"GFSNetwork: Differentiable Feature Selection via Gumbel-Sigmoid Relaxation\"],[\"On Local Posterior Structure in Deep Ensembles\"],[\"$φ$-Decoding: Adaptive Foresight Sampling for Balanced Inference-Time Exploration and Exploitation\"],[\"LLM-Match: An Open-Sourced Patient Matching Model Based on Large Language Models and Retrieval-Augmented Generation\"],[\"Graph Generative Models Evaluation with Masked Autoencoder\"],[\"Convolutional neural network for early detection of lameness and irregularity in horses using an IMU sensor\"],[\"AI-Driven Rapid Identification of Bacterial and Fungal Pathogens in Blood Smears of Septic Patients\"],[\"Neural network-based Godunov corrections for approximate Riemann solvers using bi-fidelity learning\"],[\"Highly Efficient Direct Analytics on Semantic-aware Time Series Data Compression\"],[\"Gradient Extrapolation for Debiased Representation Learning\"],[\"Mind the Gap: Confidence Discrepancy Can Guide Federated Semi-Supervised Learning Across Pseudo-Mismatch\"],[\"ProDiF: Protecting Domain-Invariant Features to Secure Pre-Trained Models Against Extraction\"],[\"Dense Policy: Bidirectional Autoregressive Learning of Actions\"],[\"When Should We Orchestrate Multiple Agents?\"],[\"MAME: Multidimensional Adaptive Metamer Exploration with Human Perceptual Feedback\"],[\"Vision-Language Models for Acute Tuberculosis Diagnosis: A Multimodal Approach Combining Imaging and Clinical Data\"],[\"Timing the Match: A Deep Reinforcement Learning Approach for Ride-Hailing and Ride-Pooling Services\"],[\"Deep Learning Advancements in Anomaly Detection: A Comprehensive Survey\"],[\"A representational framework for learning and encoding structurally enriched trajectories in complex agent environments\"],[\"GC-Fed: Gradient Centralized Federated Learning with Partial Client Participation\"],[\"Rapfi: Distilling Efficient Neural Network for the Game of Gomoku\"],[\"PAUSE: Low-Latency and Privacy-Aware Active User Selection for Federated Learning\"],[\"Advancing Chronic Tuberculosis Diagnostics Using Vision-Language Models: A Multi modal Framework for Precision Analysis\"],[\"Analytic Subspace Routing: How Recursive Least Squares Works in Continual Learning of Large Language Model\"],[\"Efficient Imitation Under Misspecification\"],[\"Laplace-Net: Learning Dynamical Systems with External Forcing\"],[\"High-entropy Advantage in Neural Networks' Generalizability\"],[\"Online Signature Verification based on the Lagrange formulation with 2D and 3D robotic models\"],[\"VeriLeaky: Navigating IP Protection vs Utility in Fine-Tuning for LLM-Driven Verilog Coding\"],[\"Beyond Propagation of Chaos: A Stochastic Algorithm for Mean Field Optimization\"],[\"Exploring the Potential of Bilevel Optimization for Calibrating Neural Networks\"],[\"MM-Spatial: Exploring 3D Spatial Understanding in Multimodal LLMs\"],[\"VeriContaminated: Assessing LLM-Driven Verilog Coding for Data Contamination\"],[\"ExChanGeAI: An End-to-End Platform and Efficient Foundation Model for Electrocardiogram Analysis and Fine-tuning\"],[\"Towards Better Sample Efficiency in Multi-Agent Reinforcement Learning via Exploration\"],[\"MaskSDM with Shapley values to improve flexibility, robustness, and explainability in species distribution modeling\"],[\"Deep Hedging of Green PPAs in Electricity Markets\"],[\"Permutation Learning with Only N Parameters: From SoftSort to Self-Organizing Gaussians\"],[\"E-Values Expand the Scope of Conformal Prediction\"],[\"WMINet: A Wheel-Mounted Inertial Learning Approach For Mobile-Robot Positioning\"],[\"Knowledge Distillation: Enhancing Neural Network Compression with Integrated Gradients\"],[\"Linear-Size Neural Network Representation of Piecewise Affine Functions in $\\\\mathbb{R}^2$\"],[\"Robot Policy Transfer with Online Demonstrations: An Active Reinforcement Learning Approach\"],[\"Enhancing Job Salary Prediction with Disentangled Composition Effect Modeling: A Neural Prototyping Approach\"],[\"Optimal Denoising in Score-Based Generative Models: The Role of Data Regularity\"],[\"Training Video Foundation Models with NVIDIA NeMo\"],[\"Classification of power quality events in the transmission grid: comparative evaluation of different machine learning models\"],[\"HiDe-LLaVA: Hierarchical Decoupling for Continual Instruction Tuning of Multimodal Large Language Model\"],[\"R1-VL: Learning to Reason with Multimodal Large Language Models via Step-wise Group Relative Policy Optimization\"],[\"Efficient Action-Constrained Reinforcement Learning via Acceptance-Rejection Method and Augmented MDPs\"],[\"Augmented Invertible Koopman Autoencoder for long-term time series forecasting\"],[\"ML-SpecQD: Multi-Level Speculative Decoding with Quantized Drafts\"],[\"Lifelong Reinforcement Learning with Similarity-Driven Weighting by Large Models\"],[\"COSMOS: Continuous Simplicial Neural Networks\"],[\"Pose as a Modality: A Psychology-Inspired Network for Personality Recognition with a New Multimodal Dataset\"],[\"Experiments with Optimal Model Trees\"],[\"A Semantic-based Optimization Approach for Repairing LLMs: Case Study on Code Generation\"],[\"Federated Continual Instruction Tuning\"],[\"Edgeworth Expansion for Semi-hard Triplet Loss\"],[\"Micro Text Classification Based on Balanced Positive-Unlabeled Learning\"],[\"Early Detection of Forest Calamities in Homogeneous Stands -- Deep Learning Applied to Bark-Beetle Outbreaks\"],[\"DAPI: Domain Adaptive Toxicity Probe Vector Intervention for Fine-Grained Detoxification\"],[\"Harnessing Test-time Adaptation for NLU tasks Involving Dialects of English\"],[\"Island-Based Evolutionary Computation with Diverse Surrogates and Adaptive Knowledge Transfer for High-Dimensional Data-Driven Optimization\"],[\"Adaptive Transformer Attention and Multi-Scale Fusion for Spine 3D Segmentation\"],[\"An Optimization Framework for Differentially Private Sparse Fine-Tuning\"],[\"Epidemic Forecasting with a Hybrid Deep Learning Method Using CNN-LSTM With WOA-GWO Parameter Optimization: Global COVID-19 Case Study\"],[\"A Multi-Power Law for Loss Curve Prediction Across Learning Rate Schedules\"],[\"Estimating stationary mass, frequency by frequency\"],[\"Leveraging Deep Neural Networks for Aspect-Based Sentiment Classification\"],[\"BLIA: Detect model memorization in binary classification model through passive Label Inference attack\"],[\"A Reinforcement Learning-Driven Transformer GAN for Molecular Generation\"],[\"Improving Generalization of Universal Adversarial Perturbation via Dynamic Maximin Optimization\"],[\"Causal Feature Learning in the Social Sciences\"],[\"LangDA: Building Context-Awareness via Language for Domain Adaptive Semantic Segmentation\"],[\"Asynchronous Predictive Counterfactual Regret Minimization$^+$ Algorithm in Solving Extensive-Form Games\"],[\"Stabilization Analysis and Mode Recognition of Kerosene Supersonic Combustion: A Deep Learning Approach Based on Res-CNN-beta-VAE\"],[\"A Survey on Human Interaction Motion Generation\"],[\"Dynamical Mode Recognition of Turbulent Flames in a Swirl-stabilized Annular Combustor by a Time-series Learning Approach\"],[\"SNPL: Simultaneous Policy Learning and Evaluation for Safe Multi-Objective Policy Improvement\"],[\"Cohort-attention Evaluation Metric against Tied Data: Studying Performance of Classification Models in Cancer Detection\"],[\"Survival Analysis with Machine Learning for Predicting Li-ion Battery Remaining Useful Life\"],[\"SafeSlice: Enabling SLA-Compliant O-RAN Slicing via Safe Deep Reinforcement Learning\"],[\"Finite Samples for Shallow Neural Networks\"],[\"Enhancing Circuit Trainability with Selective Gate Activation Strategy\"],[\"In-Context Linear Regression Demystified: Training Dynamics and Mechanistic Interpretability of Multi-Head Softmax Attention\"],[\"A Linearized Alternating Direction Multiplier Method for Federated Matrix Completion Problems\"],[\"APF+: Boosting adaptive-potential function reinforcement learning methods with a W-shaped network for high-dimensional games\"],[\"TinySQL: A Progressive Text-to-SQL Dataset for Mechanistic Interpretability Research\"],[\"Dynamic Angle Selection in X-Ray CT: A Reinforcement Learning Approach to Optimal Stopping\"],[\"Can LLMs Formally Reason as Abstract Interpreters for Program Analysis?\"],[\"Algebraic Adversarial Attacks on Explainability Models\"],[\"Discovering uncertainty: Gaussian constitutive neural networks with correlated weights\"],[\"RL-TIME: Reinforcement Learning-based Task Replication in Multicore Embedded Systems\"],[\"ZO2: Scalable Zeroth-Order Fine-Tuning for Extremely Large Language Models with Limited GPU Memory\"],[\"Logic-RAG: Augmenting Large Multimodal Models with Visual-Spatial Knowledge for Road Scene Understanding\"],[\"TuneNSearch: a hybrid transfer learning and local search approach for solving vehicle routing problems\"],[\"FW-Merging: Scaling Model Merging with Frank-Wolfe Optimization\"],[\"Realized Volatility Forecasting for New Issues and Spin-Offs using Multi-Source Transfer Learning\"],[\"Understanding Gradient Orthogonalization for Deep Learning via Non-Euclidean Trust-Region Optimization\"],[\"Hybrid Learners Do Not Forget: A Brain-Inspired Neuro-Symbolic Approach to Continual Learning\"],[\"Fast filtering of non-Gaussian models using Amortized Optimal Transport Maps\"],[\"MAVEN: Multi-modal Attention for Valence-Arousal Emotion Network\"],[\"Real-Time Cell Sorting with Scalable In Situ FPGA-Accelerated Deep Learning\"],[\"Scaling Semantic Categories: Investigating the Impact on Vision Transformer Labeling Performance\"],[\"LATINO-PRO: LAtent consisTency INverse sOlver with PRompt Optimization\"],[\"SynLlama: Generating Synthesizable Molecules and Their Analogs with Large Language Models\"],[\"GraphEval: A Lightweight Graph-Based LLM Framework for Idea Evaluation\"],[\"Fourier-Based 3D Multistage Transformer for Aberration Correction in Multicellular Specimens\"],[\"MoECollab: Democratizing LLM Development Through Collaborative Mixture of Experts\"],[\"Focusing Robot Open-Ended Reinforcement Learning Through Users' Purposes\"],[\"Deblur Gaussian Splatting SLAM\"],[\"Diffusion on Graph: Augmentation of Graph Structure for Node Classification\"]],\"hovertemplate\":\"x=%{x}\\u003cbr\\u003ey=%{y}\\u003cbr\\u003etitle=%{customdata[0]}\\u003cbr\\u003ecluster=%{marker.color}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"\",\"marker\":{\"color\":[0,0,0,0,0,0,0,0,0,0,-1,0,0,-1,0,0,0,0,0,0,-1,-1,1,-1,-1,-1,0,0,-1,0,0,-1,0,-1,0,-1,0,0,0,-1,-1,-1,0,0,-1,0,-1,0,-1,-1,0,-1,-1,-1,-1,0,0,0,-1,0,0,0,0,-1,0,0,-1,0,-1,0,-1,0,0,-1,-1,0,0,0,0,0,-1,-1,-1,1,0,0,0,0,0,0,-1,-1,-1,0,-1,-1,0,0,0,0,0,0,0,0,0,0,-1,0,0,0,0,-1,0,0,0,0,0,-1,0,-1,-1,-1,0,0,-1,-1,0,-1,0,-1,0,0,0,0,-1,-1,0,-1,0,0,-1,0,-1,0,0,0,0,-1,-1,0,-1,0,0,-1,0,-1,-1,-1,-1,-1,-1,0,0,-1,0,0,-1,-1,-1,0,0,-1,0,0,-1,0,-1,0,-1,-1,0,0,0,-1,-1,0,-1,-1,0,-1,0,-1,0,1,0,0,0,-1,-1,0,0,0,-1,-1,0,-1,0,0,0,0,-1,0,0,0,-1,-1,0,0,0,0,0,0,0,-1,-1,-1,-1,0,0,0,0,-1,0,-1,-1,0,0,0,0,-1,1,-1,0,-1,-1,0,0,-1,-1,0,-1,0,0,-1,-1,0,0,0,-1,0,0,-1,0,-1,0,-1,-1,-1,-1,-1,0,-1,0,-1,0,0,-1,-1,-1,-1,0,-1,0,-1,0,-1,-1,0,-1,-1,0,0,-1,0,0,-1,0,-1,-1,0,-1,0,-1,0,0,-1,0,0,-1,0,0,-1,0,-1,0,0,0,-1,0,-1,0,-1,-1,-1,-1,-1,0,-1,0,0,0,0,-1,-1,-1,-1,0,-1,0,-1,0,-1,0,-1,0,-1,0,0,0,-1,0,0,-1,0,0,-1,-1,0,0,-1,0,0,0,0,0,-1,-1,-1,-1,-1,0,0,0,-1,0,-1,-1,-1,-1,0,0,-1,0,-1,0,-1,-1,0,0,0,-1,0,-1,0,0,-1,1,-1,-1,-1,-1,0,0,0,0,0,-1,-1,-1,-1,0,-1,0,-1,-1,0,-1,0,0,0,-1,0,0,0,-1,-1,-1,0,-1,-1,0,-1,0,-1,-1,0,0,0,-1,-1,0,0,0,-1,0,-1,-1,0,-1,0,0,0,0,-1,0,0,0,0,0,-1,0,0,0,-1,0,0,0,0,-1,0,0,-1,-1,-1,-1,0,0,0,-1,-1,0,-1,0],\"coloraxis\":\"coloraxis\",\"symbol\":\"circle\"},\"mode\":\"markers\",\"name\":\"\",\"orientation\":\"v\",\"showlegend\":false,\"x\":[9.605637,10.183499,9.595906,11.85868,9.776608,10.660749,10.664802,10.917786,10.083787,6.8142357,8.100864,8.941665,9.81522,4.7410274,4.6363974,4.588753,11.240451,6.5874314,4.60878,10.470416,6.9371395,8.03875,5.4005384,6.1007624,8.105491,9.582596,7.0139675,9.821754,8.289776,7.8428082,8.487536,6.099417,7.715434,11.951793,11.348261,6.1223755,6.3785844,8.867576,8.480375,6.7202196,11.310509,7.21759,8.080635,8.440142,9.342316,6.9108195,7.9439545,8.786603,7.753238,8.65596,10.814277,6.963507,9.929504,7.7598104,9.393696,8.225685,9.144522,7.6100726,8.924503,10.439448,6.9829574,7.8463244,10.147258,8.147569,8.254787,10.41236,10.121151,7.482444,9.540675,6.867851,9.008858,7.42478,7.2540846,10.719008,4.784133,7.1554356,8.008466,10.7379,6.618797,11.268011,9.028115,7.301508,7.7200065,5.4224052,10.451529,8.045861,5.909983,8.704163,5.927677,10.305966,10.638704,5.4699297,7.872022,6.9509916,10.320557,10.835984,10.618621,10.642978,9.514599,9.432523,10.246475,4.742183,10.670567,11.539505,11.021008,10.027651,7.5916977,7.38402,5.8462133,5.832825,9.813819,8.981143,7.634457,4.631597,10.672004,10.582214,7.19864,7.3168683,9.531057,7.543521,7.132023,8.400863,8.746248,6.988598,6.8224316,7.3303475,10.446046,7.848225,7.5720987,5.8798323,10.829591,9.83925,7.6676116,9.558093,8.390105,8.082013,9.689618,10.965312,9.964129,7.548744,10.31557,5.9263673,7.9830995,10.274405,6.4445176,7.4743457,11.005279,8.376985,6.0605874,11.4449215,8.364271,9.307483,10.416603,7.744636,6.4204426,7.1087894,5.9542646,8.783607,5.8617506,9.520951,9.133895,9.708343,9.64883,7.9027224,11.092867,8.260699,8.862365,10.398969,9.549572,7.62737,7.4487553,10.270194,10.447527,10.878051,8.682736,7.554811,8.1364,10.567147,7.276247,10.88046,8.745136,10.430802,9.591781,9.050563,10.039756,9.918929,10.329011,7.670104,8.901019,6.5030427,7.935744,8.430456,11.582647,5.717758,10.968711,7.2399173,11.08045,9.163564,9.5220995,8.447197,10.774986,10.453993,8.671799,8.186086,11.353741,8.085524,10.512627,11.267981,8.2344265,7.700457,10.314401,10.682294,10.205043,9.663011,8.112701,11.663909,11.525943,10.157354,11.899335,11.40223,4.6588564,6.4816594,11.123026,7.968997,11.652148,6.57341,8.791034,11.190426,11.6869755,9.640304,9.790685,7.2903943,7.177434,7.37048,7.3402715,7.1191263,8.888752,10.85899,8.919409,11.741455,5.459473,7.9260206,9.736211,7.283407,6.638668,6.932449,6.788138,10.1209,6.1100793,11.047037,6.8026037,11.385736,7.965722,10.177571,10.4997835,8.291816,8.10097,6.70543,7.910689,11.179539,11.069041,9.694613,10.252502,6.369373,7.0083723,6.5159063,8.116649,10.052653,8.898937,10.990263,6.9992633,7.218366,7.299049,7.899882,5.9728174,11.487574,5.7548885,6.7886047,6.700339,7.2744465,5.7821336,8.383862,7.1185446,7.2629976,6.9806747,9.02824,7.556968,11.019449,7.829168,10.2511425,9.851483,9.319418,9.085692,11.409754,7.1592555,8.778152,10.542012,7.2889924,6.358027,6.833432,7.2957435,8.093578,6.461166,7.186614,7.72124,7.305065,10.584966,9.053982,7.6411753,8.290814,7.3913617,9.315041,9.773605,10.05996,9.868212,10.680001,10.096052,6.046383,10.755472,9.273012,6.73438,11.553844,7.937136,7.103738,11.835194,8.973368,6.7091007,8.569618,10.721335,8.422717,8.071876,7.536749,5.6596017,9.920256,8.264313,11.648827,8.657157,7.6860723,4.6678157,4.563841,10.33185,7.504776,11.3879175,8.03436,9.833579,6.551287,11.442274,9.721181,11.266088,11.251654,8.343042,9.9071455,7.779742,10.875358,10.51441,7.956048,7.6495786,8.368639,10.502804,10.223134,8.873621,10.502408,11.4849,5.948078,10.58746,6.4428267,6.4037642,10.380518,8.025463,8.892306,8.020122,7.591901,11.483506,10.305763,7.105991,8.466282,8.385439,5.8087435,7.6526847,8.628085,7.9564443,8.498336,10.202983,11.848545,9.691647,8.7709255,9.455479,7.707464,10.8289385,7.310744,11.523851,7.401642,8.767626,10.34501,10.319958,6.039827,6.18509,10.387929,11.4685955,6.7291455,7.6998158,9.864614,11.50876,8.191453,10.257655,8.256591,7.9069,10.676323,8.0423765,10.748493,8.931973,5.951113,10.204712,9.678734,7.575213,10.193043,7.6684375,10.085965,11.217447,10.020114,5.764166,11.513113,10.639223,5.840633,9.427066,8.7597275,11.384766,10.095427,7.2660823,8.9291525,8.1092,6.9961047,10.405931,10.893826,8.934713,8.212598,8.007316,9.512038,8.749467,8.939962,8.399882,6.0462666,8.350499,6.334461,9.555769,8.988556,5.5511317,10.316374,5.5777597,9.681082,8.464249,7.661218,9.747089,5.9667025,4.596109,10.156967,7.064365,10.041579,11.114764,10.17031,11.561113,8.332902,7.692542,9.860473,11.012971,10.704998,9.487479,10.252892,7.372369,6.8728776,10.768976,8.545781,9.456544,8.259312,8.775592,9.78418,6.2778764,9.4607935,8.481462,11.232045,10.867614,10.030415,7.039593],\"xaxis\":\"x\",\"y\":[7.3723297,7.159702,8.258823,8.4794035,7.328652,6.256365,9.918319,8.740373,7.7416883,10.226469,5.7743235,5.223871,5.346754,9.672871,9.731551,9.782365,8.40073,7.89636,9.772995,6.366925,10.849834,7.1489234,8.776329,9.417931,7.394075,7.924862,8.55346,7.1829524,10.088012,11.216755,8.300302,8.564456,11.345105,8.029746,8.552141,8.880279,6.722129,9.81481,10.988901,10.550206,9.078833,9.261935,9.838558,10.1572075,6.6428714,10.879687,10.021051,5.439168,8.024268,7.9705772,8.320852,7.5073195,7.90098,9.509889,9.108132,11.197445,5.2460246,7.7960153,5.834613,5.763468,8.749813,7.6894135,7.0918617,5.811127,9.691415,8.240551,9.516554,11.145771,5.5865746,8.734368,6.7679176,11.329757,11.245417,5.846257,9.727827,11.239155,5.769998,8.979272,7.3904743,8.5143175,6.7814198,8.617325,6.789542,8.759732,8.505413,9.646883,7.5079947,6.033548,9.243809,5.6039467,5.7836175,8.7914295,6.5383754,8.934293,6.758662,9.305594,5.793284,9.816459,6.0584517,8.077292,9.790719,9.6557,5.9827967,8.355231,6.4427176,8.186153,7.18299,11.34869,9.151627,7.417114,8.452946,5.9073744,5.879442,9.73746,6.0216928,5.78056,11.290755,9.771467,8.384096,8.955701,10.00238,7.5547996,5.3505697,8.848211,10.285759,8.024141,6.525986,8.463701,11.149917,7.920917,9.433954,5.93481,8.082046,5.850825,7.69305,7.2152114,5.381572,7.7800546,8.540346,11.406751,9.554653,7.4816656,7.103045,9.191202,6.7096405,11.295199,7.9056315,7.1798377,9.030049,9.775978,5.98605,8.928835,9.321085,9.026289,9.6676855,9.244643,8.621756,8.158984,7.372773,6.975492,6.732968,5.490464,8.5988,11.310798,9.559995,11.195535,10.258577,9.479095,6.2084312,11.289322,9.154189,9.557044,8.596795,9.270912,9.606026,7.866867,7.1197557,5.557319,8.548425,10.023159,9.966644,5.5881143,9.419642,8.966876,9.590348,5.643592,9.532171,7.487489,5.1953964,6.671328,6.1464777,9.954358,9.52636,8.778928,10.290384,11.391704,7.779663,8.121697,7.6291127,9.427606,9.56407,6.180059,7.245075,11.2438,10.111074,5.9150124,6.3732305,9.327856,8.02079,10.920892,8.9516325,9.677766,7.6723657,7.910141,9.544544,8.326848,9.096581,7.2404194,8.0671625,8.515929,9.709814,6.749397,9.268887,6.1773167,9.377926,6.862063,8.555865,9.104274,9.026225,7.907492,7.422733,9.984132,11.468512,8.489135,10.184569,8.515255,8.476775,8.8532505,8.635864,8.221157,8.614059,7.723008,8.219213,9.051863,7.957791,7.5955772,10.607845,7.791225,8.098544,10.395191,9.144205,8.73456,5.685543,8.986687,9.435144,9.382583,10.282206,10.015119,10.788839,8.69801,10.307766,5.5910153,5.7505455,8.56359,11.039679,8.56603,8.183225,8.20404,8.530196,8.938709,8.721385,8.487089,9.91354,7.8153286,7.4079165,9.707673,7.990553,7.420069,9.420686,9.900743,7.3410163,7.227097,11.382196,7.6912417,10.941084,6.564842,10.347198,9.79278,9.882884,9.608498,7.276966,9.862629,7.9707074,8.156605,8.182601,8.810536,8.147232,8.88689,9.234086,8.202366,8.033198,10.063525,6.629513,8.997607,5.873299,9.084496,7.2415714,9.331825,9.56583,11.172791,7.9831433,8.625156,7.6052556,9.812283,5.7668657,9.516872,7.708904,6.9789076,5.730372,8.228631,7.643791,8.914992,7.0381536,9.53126,8.589775,6.0472417,9.633581,8.087678,5.711292,10.1060095,10.236277,8.139248,8.626249,9.559894,8.283902,9.495454,5.9212065,6.21905,9.676223,9.840193,6.819335,9.939567,8.557789,5.7441974,8.0701885,6.5480604,9.002041,7.362466,8.881634,9.609837,8.215023,5.258826,7.3968835,8.202616,6.0220146,7.2874036,9.902133,9.68575,9.671797,7.679961,5.213753,8.274746,7.8359237,7.428439,9.732533,7.785681,7.623366,6.792634,5.7533665,7.402877,8.351088,5.9801526,8.770868,9.919852,9.045647,7.722456,8.112726,8.982431,8.003313,10.013718,10.4084,10.740307,5.824948,8.144302,8.440228,8.190109,6.1982245,7.9278235,7.1482744,11.296189,7.9578433,11.443443,8.339049,8.898973,5.68869,8.4432335,9.214321,6.6628933,9.9553995,10.11101,5.861969,7.241239,9.800541,8.16098,5.35883,7.471728,6.600375,8.928012,5.969573,6.132316,8.895937,9.308453,5.888455,9.342703,9.644915,7.35496,7.3236523,9.021548,8.155184,5.5723677,8.484876,9.191419,8.118012,8.789744,8.552422,9.764452,9.814396,9.154291,10.011135,9.451561,7.481365,7.6009912,9.945856,8.777083,8.038003,11.228718,7.676175,9.757792,6.040301,9.082148,10.87573,7.4846067,10.361844,6.707887,7.5364137,5.2508335,8.61204,6.8490424,8.577832,5.8027787,8.34856,7.3137584,5.458064,9.338972,9.754086,8.903142,11.080338,5.210889,8.9563265,5.7156034,9.842694,10.452744,5.8531213,5.5244813,9.0877075,7.5821543,6.615688,8.917293,7.7661953,10.184523,8.1911955,6.370125,8.584763,8.295605,9.097639,8.16404,7.499674,9.609486,8.320643,8.826875,6.0042033,7.2699494,8.89086],\"yaxis\":\"y\",\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"x\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"y\"}},\"coloraxis\":{\"colorbar\":{\"title\":{\"text\":\"cluster\"}},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"legend\":{\"tracegroupgap\":0},\"title\":{\"text\":\"Paper Clusters\"},\"height\":600,\"width\":1000},                        {\"responsive\": true}                    ).then(function(){\n","                            \n","var gd = document.getElementById('9cb5b036-0c2b-489c-88c2-c1e0ddeaca5a');\n","var x = new MutationObserver(function (mutations, observer) {{\n","        var display = window.getComputedStyle(gd).display;\n","        if (!display || display === 'none') {{\n","            console.log([gd, 'removed!']);\n","            Plotly.purge(gd);\n","            observer.disconnect();\n","        }}\n","}});\n","\n","// Listen for the removal of the full notebook cells\n","var notebookContainer = gd.closest('#notebook-container');\n","if (notebookContainer) {{\n","    x.observe(notebookContainer, {childList: true});\n","}}\n","\n","// Listen for the clearing of the current output cell\n","var outputEl = gd.closest('.output');\n","if (outputEl) {{\n","    x.observe(outputEl, {childList: true});\n","}}\n","\n","                        })                };                            </script>        </div>\n","</body>\n","</html>"]},"metadata":{}}]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","from transformers import AutoTokenizer, AutoModelForCausalLM\n","import torch\n","import os\n","from tqdm import tqdm\n","from sklearn.metrics.pairwise import euclidean_distances\n","import json\n","\n","# Step 3: Summarization & Novelty\n","print(\"\\n🎯 Step 3: Generating Summaries & Computing Novelty\")\n","\n","def setup_model():\n","    \"\"\"Setup Deepseek model for inference.\"\"\"\n","    print(\"Loading Deepseek model...\")\n","    model_name = \"deepseek-ai/deepseek-coder-6.7b-instruct\"\n","\n","    tokenizer = AutoTokenizer.from_pretrained(model_name)\n","    model = AutoModelForCausalLM.from_pretrained(\n","        model_name,\n","        torch_dtype=torch.float16,\n","        device_map=\"auto\"\n","    )\n","    return model, tokenizer\n","\n","def create_cluster_prompt(titles):\n","    \"\"\"Create prompt for cluster summarization.\"\"\"\n","    # Limit number of titles if there are too many\n","    if len(titles) > 20:\n","        titles = titles[:20]  # Take first 20 titles\n","        titles.append(\"... and more papers\")\n","\n","    titles_str = '\\n'.join([f\"- {title}\" for title in titles])\n","    return f\"\"\"You are a research assistant helping to analyze machine learning papers.\n","    Below are titles of related research papers. Please provide:\n","    1. A short theme that connects these papers (1 sentence)\n","    2. Key research directions or trends (2-3 bullet points)\n","\n","    Papers:\n","    {titles_str}\n","\n","    Response:\"\"\"\n","\n","def generate_summary(model, tokenizer, prompt):\n","    \"\"\"Generate summary using Deepseek model.\"\"\"\n","    # Truncate input if too long\n","    inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True, max_length=3072)\n","    inputs = {k: v.to(model.device) for k, v in inputs.items()}\n","\n","    with torch.no_grad():\n","        outputs = model.generate(\n","            **inputs,\n","            max_new_tokens=512,  # Control length of generated summary\n","            temperature=0.7,\n","            num_return_sequences=1,\n","            pad_token_id=tokenizer.eos_token_id,\n","            do_sample=True,\n","            top_p=0.9,\n","        )\n","\n","    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n","\n","def compute_novelty_score(embedding, cluster_embeddings):\n","    \"\"\"Compute novelty score as average distance to other papers in cluster.\"\"\"\n","    distances = euclidean_distances([embedding], cluster_embeddings)[0]\n","    return float(np.mean(distances))\n","\n","def generate_summary(model, tokenizer, prompt):\n","    \"\"\"Generate summary using Deepseek model.\"\"\"\n","    # Truncate input if too long\n","    inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True, max_length=3072)\n","    inputs = {k: v.to(model.device) for k, v in inputs.items()}\n","\n","    with torch.no_grad():\n","        outputs = model.generate(\n","            **inputs,\n","            max_new_tokens=512,  # Control length of generated summary\n","            temperature=0.7,\n","            num_return_sequences=1,\n","            pad_token_id=tokenizer.eos_token_id,\n","            do_sample=True,\n","            top_p=0.9,\n","        )\n","\n","    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n","\n","# Setup model\n","model, tokenizer = setup_model()\n","\n","# Generate summaries for each cluster\n","cluster_summaries = {}\n","for cluster in tqdm(df['cluster'].unique(), desc=\"Summarizing clusters\"):\n","    if cluster >= 0:  # Skip noise cluster (-1)\n","        cluster_papers = df[df['cluster'] == cluster]\n","        prompt = create_cluster_prompt(cluster_papers['title'].tolist())\n","        summary = generate_summary(model, tokenizer, prompt)\n","        cluster_summaries[str(cluster)] = summary\n","\n","        # Display summary as we go\n","        print(f\"\\nCluster {cluster} Summary:\")\n","        print(summary)\n","\n","# Compute novelty scores\n","print(\"\\nComputing novelty scores...\")\n","novelty_scores = []\n","for idx, row in tqdm(df.iterrows(), total=len(df)):\n","    cluster = row['cluster']\n","    if cluster >= 0:\n","        cluster_papers = df[df['cluster'] == cluster]\n","        cluster_embeddings = embeddings[cluster_papers.index]\n","        score = compute_novelty_score(embeddings[idx], cluster_embeddings)\n","    else:\n","        score = 1.0  # High novelty for outliers\n","    novelty_scores.append(score)\n","\n","df['novelty_score'] = novelty_scores\n","\n","# Flag standout papers\n","df['is_novel'] = False\n","for cluster in df['cluster'].unique():\n","    if cluster >= 0:\n","        cluster_mask = df['cluster'] == cluster\n","        threshold = df[cluster_mask]['novelty_score'].quantile(0.9)\n","        df.loc[cluster_mask & (df['novelty_score'] >= threshold), 'is_novel'] = True\n","\n","# Save final results\n","df.to_csv(os.path.join(data_path, 'papers_analyzed.csv'), index=False)\n","with open(os.path.join(data_path, 'cluster_summaries.json'), 'w') as f:\n","    json.dump(cluster_summaries, f, indent=2)\n","\n","# Display novel papers\n","novel_papers = df[df['is_novel']].sort_values('novelty_score', ascending=False)\n","print(f\"\\nFound {len(novel_papers)} novel papers\")\n","print(\"\\nTop 5 most novel papers:\")\n","display(novel_papers[['title', 'cluster', 'novelty_score']].head())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["1fa53bec8bf84ddb81f78f8b0e934152","6eef0ccec7b2469dbfbdcc765770248d","4925c502894f4c6a9ea9359a9f4cbed3","f7a06ca0ecb1454683ff2cff868e1f63","94602d9fc51c4b26a66409ce2485f803","387635a5ffd24f899ea2393fe2f6daa7","4b1a7bd4ff6245af8d7542453fb971dd","1bfa799f5e4c4868a18014f0755a409d","8d7b335c0e8c46479ef962fb6366c3c5","fcaee2b8d90a4a76a6c9fe6463d16a55","c70beee724cc478c8ee2c647f57a7313"]},"id":"z1PKNKhCf220","executionInfo":{"status":"ok","timestamp":1742743244805,"user_tz":360,"elapsed":44898,"user":{"displayName":"Alex Baret","userId":"10734557950216503149"}},"outputId":"e36f5160-7e15-4ab4-88f4-873f311cb4ad"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","🎯 Step 3: Generating Summaries & Computing Novelty\n","Loading Deepseek model...\n"]},{"output_type":"display_data","data":{"text/plain":["Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1fa53bec8bf84ddb81f78f8b0e934152"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Summarizing clusters:  33%|███▎      | 1/3 [00:20<00:41, 20.78s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","Cluster 0 Summary:\n","You are a research assistant helping to analyze machine learning papers.\n","    Below are titles of related research papers. Please provide:\n","    1. A short theme that connects these papers (1 sentence)\n","    2. Key research directions or trends (2-3 bullet points)\n","    \n","    Papers:\n","    - GAEA: A Geolocation Aware Conversational Model\n","- MagicMotion: Controllable Video Generation with Dense-to-Sparse Trajectory Guidance\n","- InfiniteYou: Flexible Photo Recrafting While Preserving Your Identity\n","- Survey on Evaluation of LLM-based Agents\n","- DreamTexture: Shape from Virtual Texture with Analysis by Augmentation\n","- RoboFactory: Exploring Embodied Agent Collaboration with Compositional Constraints\n","- The Emperor's New Clothes in Benchmarking? A Rigorous Examination of Mitigation Strategies for LLM Benchmark Data Contamination\n","- Exploring the Hidden Reasoning Process of Large Language Models by Misleading Them\n","- ScalingNoise: Scaling Inference-Time Search for Generating Infinite Videos\n","- The global convergence time of stochastic gradient descent in non-convex landscapes: Sharp estimates via large deviations\n","- Sparse Nonparametric Contextual Bandits\n","- Reinforcement Learning-based Heuristics to Guide Domain-Independent Dynamic Programming\n","- Probabilistic Quantum SVM Training on Ising Machine\n","- Enhancing variational quantum algorithms by balancing training on classical and quantum hardware\n","- CaKE: Circuit-aware Editing Enables Generalizable Knowledge Learners\n","- Lyra: An Efficient and Expressive Subquadratic Architecture for Modeling Biological Sequences\n","- HiQ-Lip: The First Quantum-Classical Hierarchical Method for Global Lipschitz Constant Estimation of ReLU Networks\n","- Nonlinear action prediction models reveal multi-timescale locomotor control\n","- Explainable Graph-theoretical Machine Learning: with Application to Alzheimer's Disease Prediction\n","- Uni-3DAR: Unified 3D Generation and Understanding via Autoregression on Compressed Spatial Tokens\n","- ... and more papers\n","    \n","    Response:\n","1. The theme that connects these papers is the application of machine learning techniques to various aspects of digital media, particularly in the context of geolocation, video generation, and photo recrafting.\n","\n","2. Key research directions or trends include:\n","   - Exploring diverse approaches to controllable video generation, with a focus on dense-to-sparse trajectory guidance.\n","   - Investigating the potential of LLM-based agents for tasks that require reasoning and decision-making, especially in the context of large language models.\n","   - Enhancing the performance of LLM-based agents by investigating ways to mitigate data contamination in benchmarking.\n","   - Investigating ways to make LLM-based agents more understandable and interpretable.\n","   - Exploring ways to scale up inference-time search for generating infinite videos.\n","   - Investigating ways to enhance the performance of variational quantum algorithms by balancing training on classical and quantum hardware.\n","   - Investigating ways to make quantum-based machine learning algorithms more explainable.\n","   - Investigating ways to make quantum-based machine learning algorithms more efficient and expressive.\n","   - Investigating ways to make quantum-based machine learning algorithms more robust and versatile.\n","   - Investigating ways to improve the performance of probabilistic quantum SVM training on Ising machines.\n","   - Investigating ways to enhance the performance of variational quantum algorithms by balancing training on classical and quantum hardware.\n","   - Investigating ways to make quantum-based machine learning algorithms more explainable.\n","   - Investigating ways to make quantum-based machine learning algorithms more efficient and expressive.\n","   - Investigating ways to make quantum-based machine learning algorithms more robust and versatile.\n","   - Investigating ways to improve the performance of probabilistic quantum SVM training on Ising machines.\n","   - Investigating ways to enhance the performance of variational quantum algorithms by balancing training on classical and quantum hardware.\n","   - Investigating ways to make quantum-based machine learning algorithms more explainable.\n","   - Investigating ways to make quantum-based machine learning algorithms more efficient and expressive.\n","   - Investigating ways to make quantum-based machine learning algorithms more robust and versatile.\n","   \n","   Note: The above points are a summary of the research topics and may not be exhaustive. The actual research topics\n"]},{"output_type":"stream","name":"stderr","text":["Summarizing clusters: 100%|██████████| 3/3 [00:33<00:00, 11.10s/it]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Cluster 1 Summary:\n","You are a research assistant helping to analyze machine learning papers.\n","    Below are titles of related research papers. Please provide:\n","    1. A short theme that connects these papers (1 sentence)\n","    2. Key research directions or trends (2-3 bullet points)\n","    \n","    Papers:\n","    - NeuralFoil: An Airfoil Aerodynamics Analysis Tool Using Physics-Informed Machine Learning\n","- Accelerating Transient CFD through Machine Learning-Based Flow Initialization\n","- Localized Physics-informed Gaussian Processes with Curriculum Training for Topology Optimization\n","- C(NN)FD -- Deep Learning Modelling of Multi-Stage Axial Compressors Aerodynamics\n","- High-entropy Advantage in Neural Networks' Generalizability\n","    \n","    Response:\n","1. The theme that connects these papers is the integration of machine learning (ML) and computational fluid dynamics (CFD) to improve the efficiency and accuracy of aerodynamic analysis.\n","2. Key research directions or trends include:\n","   - Exploring the use of ML in CFD simulations for the initialization of simulations, which can speed up the process and potentially improve the accuracy of the results.\n","   - Investigating the integration of physics-informed ML methods in aerodynamic analysis, which can help to understand complex phenomena and improve the accuracy of the results.\n","   - Developing methods for ML-based flow initialization that can be more accurate and efficient, particularly for transient CFD simulations.\n","   - Exploring the use of Gaussian processes with curriculum training for topology optimization, which can improve the generalization of ML models and the accuracy of the results.\n","   - Investigating the use of ML in CFD simulations for multi-stage axial compressors aerodynamics, which can provide insights into the behavior of these systems and improve the accuracy of the results.\n","   - Investigating the impact of high-entropy (complex) data on the generalizability of neural networks, which can provide insights into the trade-off between complexity and generalizability in ML models.\n","   \n","    This information is related to the field of aerodynamics, computational fluid dynamics, machine learning, and physics-informed machine learning. The research papers discussed here are all related to improving the efficiency and accuracy of aerodynamic analysis through the use of ML and CFD.\n","\n","\n","Computing novelty scores...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 483/483 [00:00<00:00, 1376.25it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Found 28 novel papers\n","\n","Top 5 most novel papers:\n"]},{"output_type":"display_data","data":{"text/plain":["                                                 title  cluster  novelty_score\n","204  A Comprehensive Study of LLM Secure Code Gener...        0       1.312210\n","363  Strain Problems got you in a Twist? Try Strain...        0       1.264747\n","338               SRBB-Based Quantum State Preparation        0       1.261714\n","212  MusicInfuser: Making Video Diffusion Listen an...        0       1.251776\n","88             Approximation properties of neural ODEs        0       1.251656"],"text/html":["\n","  <div id=\"df-f8147a69-7676-40d0-af3e-f3628d30f89f\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>title</th>\n","      <th>cluster</th>\n","      <th>novelty_score</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>204</th>\n","      <td>A Comprehensive Study of LLM Secure Code Gener...</td>\n","      <td>0</td>\n","      <td>1.312210</td>\n","    </tr>\n","    <tr>\n","      <th>363</th>\n","      <td>Strain Problems got you in a Twist? Try Strain...</td>\n","      <td>0</td>\n","      <td>1.264747</td>\n","    </tr>\n","    <tr>\n","      <th>338</th>\n","      <td>SRBB-Based Quantum State Preparation</td>\n","      <td>0</td>\n","      <td>1.261714</td>\n","    </tr>\n","    <tr>\n","      <th>212</th>\n","      <td>MusicInfuser: Making Video Diffusion Listen an...</td>\n","      <td>0</td>\n","      <td>1.251776</td>\n","    </tr>\n","    <tr>\n","      <th>88</th>\n","      <td>Approximation properties of neural ODEs</td>\n","      <td>0</td>\n","      <td>1.251656</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f8147a69-7676-40d0-af3e-f3628d30f89f')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-f8147a69-7676-40d0-af3e-f3628d30f89f button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-f8147a69-7676-40d0-af3e-f3628d30f89f');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-9a414398-c249-4d3f-ae45-75256fe8e659\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9a414398-c249-4d3f-ae45-75256fe8e659')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-9a414398-c249-4d3f-ae45-75256fe8e659 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","summary":"{\n  \"name\": \"display(novel_papers[['title', 'cluster', 'novelty_score']]\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"title\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Strain Problems got you in a Twist? Try StrainRelief: A Quantum-Accurate Tool for Ligand Strain Calculations\",\n          \"Approximation properties of neural ODEs\",\n          \"SRBB-Based Quantum State Preparation\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"cluster\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"novelty_score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.025169646204097954,\n        \"min\": 1.2516560554504395,\n        \"max\": 1.3122097253799438,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          1.2647470235824585\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{}}]},{"cell_type":"code","source":["\n","\n","# Step 4: Interactive Exploration\n","print(\"\\n📊 Step 4: Interactive Exploration\")\n","\n","def explore_cluster(cluster_id):\n","    \"\"\"Display information about a specific cluster.\"\"\"\n","    cluster_papers = df[df['cluster'] == cluster_id].sort_values('novelty_score', ascending=False)\n","\n","    print(f\"\\nCluster {cluster_id} Summary:\")\n","    print(cluster_summaries[str(cluster_id)])\n","\n","    print(f\"\\nPapers in Cluster {cluster_id}:\")\n","    for _, paper in cluster_papers.iterrows():\n","        print(f\"\\n{'🌟 ' if paper['is_novel'] else ''}Title: {paper['title']}\")\n","        print(f\"Authors: {paper['authors']}\")\n","        print(f\"Novelty Score: {paper['novelty_score']:.3f}\")\n","        print(f\"Abstract: {paper['abstract'][:200]}...\")\n","\n","def search_papers(query):\n","    \"\"\"Search papers by title or abstract.\"\"\"\n","    mask = df['title'].str.contains(query, case=False) | \\\n","           df['abstract'].str.contains(query, case=False)\n","    results = df[mask].sort_values('novelty_score', ascending=False)\n","\n","    print(f\"\\nFound {len(results)} papers matching '{query}':\")\n","    for _, paper in results.iterrows():\n","        print(f\"\\n{'🌟 ' if paper['is_novel'] else ''}Title: {paper['title']}\")\n","        print(f\"Cluster: {paper['cluster']}\")\n","        print(f\"Novelty Score: {paper['novelty_score']:.3f}\")\n","        print(f\"Abstract: {paper['abstract'][:200]}...\")\n","\n","# Example usage:\n","print(\"To explore a cluster:\")\n","print(\"explore_cluster(0)  # Replace 0 with any cluster number\")\n","print(\"\\nTo search papers:\")\n","print(\"search_papers('reinforcement learning')\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kHU3zz66ZLRB","executionInfo":{"status":"ok","timestamp":1742743292016,"user_tz":360,"elapsed":205,"user":{"displayName":"Alex Baret","userId":"10734557950216503149"}},"outputId":"db78cefe-7682-4df6-8ace-a8f3aab62893"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","📊 Step 4: Interactive Exploration\n","To explore a cluster:\n","explore_cluster(0)  # Replace 0 with any cluster number\n","\n","To search papers:\n","search_papers('reinforcement learning')\n"]}]},{"cell_type":"code","source":["explore_cluster(0)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":297},"id":"9z98ka_6mkpG","executionInfo":{"status":"error","timestamp":1742743955803,"user_tz":360,"elapsed":64,"user":{"displayName":"Alex Baret","userId":"10734557950216503149"}},"outputId":"73ab541b-a7eb-4a98-8a3b-ea0d0748b4e9"},"execution_count":30,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Cluster 2 Summary:\n"]},{"output_type":"error","ename":"KeyError","evalue":"'2'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m<ipython-input-30-20e76bd67165>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mexplore_cluster\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-23-5c5d0cbabc3c>\u001b[0m in \u001b[0;36mexplore_cluster\u001b[0;34m(cluster_id)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\\nCluster {cluster_id} Summary:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcluster_summaries\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcluster_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\\nPapers in Cluster {cluster_id}:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyError\u001b[0m: '2'"]}]}]}