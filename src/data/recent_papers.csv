id,title,abstract,authors,date,categories,comment,pdf_url
2503.16423v1,GAEA: A Geolocation Aware Conversational Model,"Image geolocalization, in which, traditionally, an AI model predicts the
precise GPS coordinates of an image is a challenging task with many downstream
applications. However, the user cannot utilize the model to further their
knowledge other than the GPS coordinate; the model lacks an understanding of
the location and the conversational ability to communicate with the user. In
recent days, with tremendous progress of large multimodal models (LMMs)
proprietary and open-source researchers have attempted to geolocalize images
via LMMs. However, the issues remain unaddressed; beyond general tasks, for
more specialized downstream tasks, one of which is geolocalization, LMMs
struggle. In this work, we propose to solve this problem by introducing a
conversational model GAEA that can provide information regarding the location
of an image, as required by a user. No large-scale dataset enabling the
training of such a model exists. Thus we propose a comprehensive dataset GAEA
with 800K images and around 1.6M question answer pairs constructed by
leveraging OpenStreetMap (OSM) attributes and geographical context clues. For
quantitative evaluation, we propose a diverse benchmark comprising 4K
image-text pairs to evaluate conversational capabilities equipped with diverse
question types. We consider 11 state-of-the-art open-source and proprietary
LMMs and demonstrate that GAEA significantly outperforms the best open-source
model, LLaVA-OneVision by 25.69% and the best proprietary model, GPT-4o by
8.28%. Our dataset, model and codes are available","['Ron Campos', 'Ashmal Vayani', 'Parth Parag Kulkarni', 'Rohit Gupta', 'Aritra Dutta', 'Mubarak Shah']",2025-03-20,"['cs.CV', 'cs.LG', 'I.4; I.2.7; I.5']","The dataset and code used in this submission is available at:
  https://ucf-crcv.github.io/GAEA/",http://arxiv.org/pdf/2503.16423v1
2503.16421v1,MagicMotion: Controllable Video Generation with Dense-to-Sparse Trajectory Guidance,"Recent advances in video generation have led to remarkable improvements in
visual quality and temporal coherence. Upon this, trajectory-controllable video
generation has emerged to enable precise object motion control through
explicitly defined spatial paths. However, existing methods struggle with
complex object movements and multi-object motion control, resulting in
imprecise trajectory adherence, poor object consistency, and compromised visual
quality. Furthermore, these methods only support trajectory control in a single
format, limiting their applicability in diverse scenarios. Additionally, there
is no publicly available dataset or benchmark specifically tailored for
trajectory-controllable video generation, hindering robust training and
systematic evaluation. To address these challenges, we introduce MagicMotion, a
novel image-to-video generation framework that enables trajectory control
through three levels of conditions from dense to sparse: masks, bounding boxes,
and sparse boxes. Given an input image and trajectories, MagicMotion seamlessly
animates objects along defined trajectories while maintaining object
consistency and visual quality. Furthermore, we present MagicData, a
large-scale trajectory-controlled video dataset, along with an automated
pipeline for annotation and filtering. We also introduce MagicBench, a
comprehensive benchmark that assesses both video quality and trajectory control
accuracy across different numbers of objects. Extensive experiments demonstrate
that MagicMotion outperforms previous methods across various metrics. Our
project page are publicly available at
https://quanhaol.github.io/magicmotion-site.","['Quanhao Li', 'Zhen Xing', 'Rui Wang', 'Hui Zhang', 'Qi Dai', 'Zuxuan Wu']",2025-03-20,"['cs.CV', 'cs.AI', 'cs.LG', 'cs.MM']",,http://arxiv.org/pdf/2503.16421v1
2503.16418v1,InfiniteYou: Flexible Photo Recrafting While Preserving Your Identity,"Achieving flexible and high-fidelity identity-preserved image generation
remains formidable, particularly with advanced Diffusion Transformers (DiTs)
like FLUX. We introduce InfiniteYou (InfU), one of the earliest robust
frameworks leveraging DiTs for this task. InfU addresses significant issues of
existing methods, such as insufficient identity similarity, poor text-image
alignment, and low generation quality and aesthetics. Central to InfU is
InfuseNet, a component that injects identity features into the DiT base model
via residual connections, enhancing identity similarity while maintaining
generation capabilities. A multi-stage training strategy, including pretraining
and supervised fine-tuning (SFT) with synthetic single-person-multiple-sample
(SPMS) data, further improves text-image alignment, ameliorates image quality,
and alleviates face copy-pasting. Extensive experiments demonstrate that InfU
achieves state-of-the-art performance, surpassing existing baselines. In
addition, the plug-and-play design of InfU ensures compatibility with various
existing methods, offering a valuable contribution to the broader community.","['Liming Jiang', 'Qing Yan', 'Yumin Jia', 'Zichuan Liu', 'Hao Kang', 'Xin Lu']",2025-03-20,"['cs.CV', 'cs.LG']","Project page: https://bytedance.github.io/InfiniteYou/ Code and
  model: https://github.com/bytedance/InfiniteYou",http://arxiv.org/pdf/2503.16418v1
2503.16416v1,Survey on Evaluation of LLM-based Agents,"The emergence of LLM-based agents represents a paradigm shift in AI, enabling
autonomous systems to plan, reason, use tools, and maintain memory while
interacting with dynamic environments. This paper provides the first
comprehensive survey of evaluation methodologies for these increasingly capable
agents. We systematically analyze evaluation benchmarks and frameworks across
four critical dimensions: (1) fundamental agent capabilities, including
planning, tool use, self-reflection, and memory; (2) application-specific
benchmarks for web, software engineering, scientific, and conversational
agents; (3) benchmarks for generalist agents; and (4) frameworks for evaluating
agents. Our analysis reveals emerging trends, including a shift toward more
realistic, challenging evaluations with continuously updated benchmarks. We
also identify critical gaps that future research must address-particularly in
assessing cost-efficiency, safety, and robustness, and in developing
fine-grained, and scalable evaluation methods. This survey maps the rapidly
evolving landscape of agent evaluation, reveals the emerging trends in the
field, identifies current limitations, and proposes directions for future
research.","['Asaf Yehudai', 'Lilach Eden', 'Alan Li', 'Guy Uziel', 'Yilun Zhao', 'Roy Bar-Haim', 'Arman Cohan', 'Michal Shmueli-Scheuer']",2025-03-20,"['cs.AI', 'cs.CL', 'cs.LG']",,http://arxiv.org/pdf/2503.16416v1
2503.16412v1,DreamTexture: Shape from Virtual Texture with Analysis by Augmentation,"DreamFusion established a new paradigm for unsupervised 3D reconstruction
from virtual views by combining advances in generative models and
differentiable rendering. However, the underlying multi-view rendering, along
with supervision from large-scale generative models, is computationally
expensive and under-constrained. We propose DreamTexture, a novel
Shape-from-Virtual-Texture approach that leverages monocular depth cues to
reconstruct 3D objects. Our method textures an input image by aligning a
virtual texture with the real depth cues in the input, exploiting the inherent
understanding of monocular geometry encoded in modern diffusion models. We then
reconstruct depth from the virtual texture deformation with a new conformal map
optimization, which alleviates memory-intensive volumetric representations. Our
experiments reveal that generative models possess an understanding of monocular
shape cues, which can be extracted by augmenting and aligning texture cues -- a
novel monocular reconstruction paradigm that we call Analysis by Augmentation.","['Ananta R. Bhattarai', 'Xingzhe He', 'Alla Sheffer', 'Helge Rhodin']",2025-03-20,"['cs.CV', 'cs.AI', 'cs.LG']",Project page: https://anantarb.github.io/dreamtexture/,http://arxiv.org/pdf/2503.16412v1
2503.16408v1,RoboFactory: Exploring Embodied Agent Collaboration with Compositional Constraints,"Designing effective embodied multi-agent systems is critical for solving
complex real-world tasks across domains. Due to the complexity of multi-agent
embodied systems, existing methods fail to automatically generate safe and
efficient training data for such systems. To this end, we propose the concept
of compositional constraints for embodied multi-agent systems, addressing the
challenges arising from collaboration among embodied agents. We design various
interfaces tailored to different types of constraints, enabling seamless
interaction with the physical world. Leveraging compositional constraints and
specifically designed interfaces, we develop an automated data collection
framework for embodied multi-agent systems and introduce the first benchmark
for embodied multi-agent manipulation, RoboFactory. Based on RoboFactory
benchmark, we adapt and evaluate the method of imitation learning and analyzed
its performance in different difficulty agent tasks. Furthermore, we explore
the architectures and training strategies for multi-agent imitation learning,
aiming to build safe and efficient embodied multi-agent systems.","['Yiran Qin', 'Li Kang', 'Xiufeng Song', 'Zhenfei Yin', 'Xiaohong Liu', 'Xihui Liu', 'Ruimao Zhang', 'Lei Bai']",2025-03-20,"['cs.RO', 'cs.AI', 'cs.CV', 'cs.LG']",Project page: https://iranqin.github.io/robofactory/,http://arxiv.org/pdf/2503.16408v1
2503.16402v1,The Emperor's New Clothes in Benchmarking? A Rigorous Examination of Mitigation Strategies for LLM Benchmark Data Contamination,"Benchmark Data Contamination (BDC)-the inclusion of benchmark testing samples
in the training set-has raised increasing concerns in Large Language Model
(LLM) evaluation, leading to falsely inflated performance estimates and
undermining evaluation reliability. To address this, researchers have proposed
various mitigation strategies to update existing benchmarks, including
modifying original questions or generating new ones based on them. However, a
rigorous examination of the effectiveness of these mitigation strategies
remains lacking. In this paper, we design a systematic and controlled pipeline
along with two novel metrics-fidelity and contamination resistance-to provide a
fine-grained and comprehensive assessment of existing BDC mitigation
strategies. Previous assessment methods, such as accuracy drop and accuracy
matching, focus solely on aggregate accuracy, often leading to incomplete or
misleading conclusions. Our metrics address this limitation by emphasizing
question-level evaluation result matching. Extensive experiments with 10 LLMs,
5 benchmarks, 20 BDC mitigation strategies, and 2 contamination scenarios
reveal that no existing strategy significantly improves resistance over the
vanilla case (i.e., no benchmark update) across all benchmarks, and none
effectively balances fidelity and contamination resistance. These findings
underscore the urgent need for designing more effective BDC mitigation
strategies. Our code repository is available at
https://github.com/ASTRAL-Group/BDC_mitigation_assessment.","['Yifan Sun', 'Han Wang', 'Dongbai Li', 'Gang Wang', 'Huan Zhang']",2025-03-20,"['cs.AI', 'cs.CL', 'cs.LG']",23 pages,http://arxiv.org/pdf/2503.16402v1
2503.16401v1,Exploring the Hidden Reasoning Process of Large Language Models by Misleading Them,"Large language models (LLMs) and Vision language models (VLMs) have been able
to perform various forms of reasoning tasks in a wide range of scenarios, but
are they truly engaging in task abstraction and rule-based reasoning beyond
mere memorization and pattern matching? To answer this question, we propose a
novel experimental approach, Misleading Fine-Tuning (MisFT), to examine whether
LLMs/VLMs perform abstract reasoning by altering their original understanding
of fundamental rules. In particular, by constructing a dataset with math
expressions that contradict correct operation principles, we fine-tune the
model to learn those contradictory rules and assess its generalization ability
on different test domains. Through a series of experiments, we find that
current LLMs/VLMs are capable of effectively applying contradictory rules to
solve practical math word problems and math expressions represented by images,
implying the presence of an internal mechanism that abstracts before reasoning.","['Guanyu Chen', 'Peiyang Wang', 'Tianren Zhang', 'Feng Chen']",2025-03-20,['cs.LG'],,http://arxiv.org/pdf/2503.16401v1
2503.16400v1,ScalingNoise: Scaling Inference-Time Search for Generating Infinite Videos,"Video diffusion models (VDMs) facilitate the generation of high-quality
videos, with current research predominantly concentrated on scaling efforts
during training through improvements in data quality, computational resources,
and model complexity. However, inference-time scaling has received less
attention, with most approaches restricting models to a single generation
attempt. Recent studies have uncovered the existence of ""golden noises"" that
can enhance video quality during generation. Building on this, we find that
guiding the scaling inference-time search of VDMs to identify better noise
candidates not only evaluates the quality of the frames generated in the
current step but also preserves the high-level object features by referencing
the anchor frame from previous multi-chunks, thereby delivering long-term
value. Our analysis reveals that diffusion models inherently possess flexible
adjustments of computation by varying denoising steps, and even a one-step
denoising approach, when guided by a reward signal, yields significant
long-term benefits. Based on the observation, we proposeScalingNoise, a
plug-and-play inference-time search strategy that identifies golden initial
noises for the diffusion sampling process to improve global content consistency
and visual diversity. Specifically, we perform one-step denoising to convert
initial noises into a clip and subsequently evaluate its long-term value,
leveraging a reward model anchored by previously generated content. Moreover,
to preserve diversity, we sample candidates from a tilted noise distribution
that up-weights promising noises. In this way, ScalingNoise significantly
reduces noise-induced errors, ensuring more coherent and spatiotemporally
consistent video generation. Extensive experiments on benchmark datasets
demonstrate that the proposed ScalingNoise effectively improves long video
generation.","['Haolin Yang', 'Feilong Tang', 'Ming Hu', 'Yulong Li', 'Junjie Guo', 'Yexin Liu', 'Zelin Peng', 'Junjun He', 'Zongyuan Ge', 'Imran Razzak']",2025-03-20,['cs.LG'],,http://arxiv.org/pdf/2503.16400v1
2503.16398v1,The global convergence time of stochastic gradient descent in non-convex landscapes: Sharp estimates via large deviations,"In this paper, we examine the time it takes for stochastic gradient descent
(SGD) to reach the global minimum of a general, non-convex loss function. We
approach this question through the lens of randomly perturbed dynamical systems
and large deviations theory, and we provide a tight characterization of the
global convergence time of SGD via matching upper and lower bounds. These
bounds are dominated by the most ""costly"" set of obstacles that the algorithm
may need to overcome to reach a global minimizer from a given initialization,
coupling in this way the global geometry of the underlying loss landscape with
the statistics of the noise entering the process. Finally, motivated by
applications to the training of deep neural networks, we also provide a series
of refinements and extensions of our analysis for loss functions with shallow
local minima.","['Waïss Azizian', 'Franck Iutzeler', 'Jérôme Malick', 'Panayotis Mertikopoulos']",2025-03-20,"['math.OC', 'cs.LG', 'Primary 90C15, 90C26, 60F10, secondary 90C30, 68Q32']","62 pages, 5 figures",http://arxiv.org/pdf/2503.16398v1
2503.16395v1,Truthful Elicitation of Imprecise Forecasts,"The quality of probabilistic forecasts is crucial for decision-making under
uncertainty. While proper scoring rules incentivize truthful reporting of
precise forecasts, they fall short when forecasters face epistemic uncertainty
about their beliefs, limiting their use in safety-critical domains where
decision-makers (DMs) prioritize proper uncertainty management. To address
this, we propose a framework for scoring imprecise forecasts -- forecasts given
as a set of beliefs. Despite existing impossibility results for deterministic
scoring rules, we enable truthful elicitation by drawing connection to social
choice theory and introducing a two-way communication framework where DMs first
share their aggregation rules (e.g., averaging or min-max) used in downstream
decisions for resolving forecast ambiguity. This, in turn, helps forecasters
resolve indecision during elicitation. We further show that truthful
elicitation of imprecise forecasts is achievable using proper scoring rules
randomized over the aggregation procedure. Our approach allows DM to elicit and
integrate the forecaster's epistemic uncertainty into their decision-making
process, thus improving credibility.","['Anurag Singh', 'Siu Lun Chau', 'Krikamol Muandet']",2025-03-20,['cs.LG'],"32 pages, 3 figures",http://arxiv.org/pdf/2503.16395v1
2503.16382v1,Sparse Nonparametric Contextual Bandits,"This paper studies the problem of simultaneously learning relevant features
and minimising regret in contextual bandit problems. We introduce and analyse a
new class of contextual bandit problems, called sparse nonparametric contextual
bandits, in which the expected reward function lies in the linear span of a
small unknown set of features that belongs to a known infinite set of candidate
features. We consider two notions of sparsity, for which the set of candidate
features is either countable or uncountable. Our contribution is two-fold.
First, we provide lower bounds on the minimax regret, which show that
polynomial dependence on the number of actions is generally unavoidable in this
setting. Second, we show that a variant of the Feel-Good Thompson Sampling
algorithm enjoys regret bounds that match our lower bounds up to logarithmic
factors of the horizon, and have logarithmic dependence on the effective number
of candidate features. When we apply our results to kernelised and neural
contextual bandits, we find that sparsity always enables better regret bounds,
as long as the horizon is large enough relative to the sparsity and the number
of actions.","['Hamish Flynn', 'Julia Olkhovskaya', 'Paul Rognon-Vael']",2025-03-20,"['stat.ML', 'cs.LG']",45 pages,http://arxiv.org/pdf/2503.16382v1
2503.16371v1,Reinforcement Learning-based Heuristics to Guide Domain-Independent Dynamic Programming,"Domain-Independent Dynamic Programming (DIDP) is a state-space search
paradigm based on dynamic programming for combinatorial optimization. In its
current implementation, DIDP guides the search using user-defined dual bounds.
Reinforcement learning (RL) is increasingly being applied to combinatorial
optimization problems and shares several key structures with DP, being
represented by the Bellman equation and state-based transition systems. We
propose using reinforcement learning to obtain a heuristic function to guide
the search in DIDP. We develop two RL-based guidance approaches: value-based
guidance using Deep Q-Networks and policy-based guidance using Proximal Policy
Optimization. Our experiments indicate that RL-based guidance significantly
outperforms standard DIDP and problem-specific greedy heuristics with the same
number of node expansions. Further, despite longer node evaluation times, RL
guidance achieves better run-time performance than standard DIDP on three of
four benchmark domains.","['Minori Narita', 'Ryo Kuroiwa', 'J. Christopher Beck']",2025-03-20,"['cs.AI', 'cs.LG']","24 pages, 4 figures, to be published in CPAIOR 2025
  (https://sites.google.com/view/cpaior2025)",http://arxiv.org/pdf/2503.16371v1
2503.16364v1,Neural Networks: According to the Principles of Grassmann Algebra,"In this paper, we explore the algebra of quantum idempotents and the
quantization of fermions which gives rise to a Hilbert space equal to the
Grassmann algebra associated with the Lie algebra. Since idempotents carry
representations of the algebra under consideration, they form algebraic
varieties and smooth manifolds in the natural topology. In addition to the
motivation of linking up mathematical physics with machine learning, it is also
shown that by using idempotents and invariant subspace of the corresponding
algebras, these representations encode and perhaps provide a probabilistic
interpretation of reasoning and relational paths in geometrical terms.","['Z. Zarezadeh', 'N. Zarezadeh']",2025-03-20,"['cs.LG', 'cs.AI']",,http://arxiv.org/pdf/2503.16364v1
2503.16363v1,Probabilistic Quantum SVM Training on Ising Machine,"Quantum computing holds significant potential to accelerate machine learning
algorithms, especially in solving optimization problems like those encountered
in Support Vector Machine (SVM) training. However, current QUBO-based Quantum
SVM (QSVM) methods rely solely on binary optimal solutions, limiting their
ability to identify fuzzy boundaries in data. Additionally, the limited qubit
count in contemporary quantum devices constrains training on larger datasets.
In this paper, we propose a probabilistic quantum SVM training framework
suitable for Coherent Ising Machines (CIMs). By formulating the SVM training
problem as a QUBO model, we leverage CIMs' energy minimization capabilities and
introduce a Boltzmann distribution-based probabilistic approach to better
approximate optimal SVM solutions, enhancing robustness. To address qubit
limitations, we employ batch processing and multi-batch ensemble strategies,
enabling small-scale quantum devices to train SVMs on larger datasets and
support multi-class classification tasks via a one-vs-one approach. Our method
is validated through simulations and real-machine experiments on binary and
multi-class datasets. On the banknote binary classification dataset, our
CIM-based QSVM, utilizing an energy-based probabilistic approach, achieved up
to 20% higher accuracy compared to the original QSVM, while training up to
$10^4$ times faster than simulated annealing methods. Compared with classical
SVM, our approach either matched or reduced training time. On the IRIS
three-class dataset, our improved QSVM outperformed existing QSVM models in all
key metrics. As quantum technology advances, increased qubit counts are
expected to further enhance QSVM performance relative to classical SVM.","['Haoqi He', 'Yan Xiao']",2025-03-20,"['cs.LG', 'quant-ph']",,http://arxiv.org/pdf/2503.16363v1
2503.16361v1,Enhancing variational quantum algorithms by balancing training on classical and quantum hardware,"Quantum computers offer a promising route to tackling problems that are
classically intractable such as in prime-factorization, solving large-scale
linear algebra and simulating complex quantum systems, but require
fault-tolerant quantum hardware. On the other hand, variational quantum
algorithms (VQAs) have the potential to provide a near-term route to quantum
utility or advantage, and is usually constructed by using parametrized quantum
circuits (PQCs) in combination with a classical optimizer for training.
Although VQAs have been proposed for a multitude of tasks such as ground-state
estimation, combinatorial optimization and unitary compilation, there remain
major challenges in its trainability and resource costs on quantum hardware.
Here we address these challenges by adopting Hardware Efficient and dynamical
LIe algebra Supported Ansatz (HELIA), and propose two training schemes that
combine an existing g-sim method (that uses the underlying group structure of
the operators) and the Parameter-Shift Rule (PSR). Our improvement comes from
distributing the resources required for gradient estimation and training to
both classical and quantum hardware. We numerically test our proposal for
ground-state estimation using Variational Quantum Eigensolver (VQE) and
classification of quantum phases using quantum neural networks. Our methods
show better accuracy and success of trials, and also need fewer calls to the
quantum hardware on an average than using only PSR (upto 60% reduction), that
runs exclusively on quantum hardware. We also numerically demonstrate the
capability of HELIA in mitigating barren plateaus, paving the way for training
large-scale quantum models.","['Rahul Bhowmick', 'Harsh Wadhwa', 'Avinash Singh', 'Tania Sidana', 'Quoc Hoan Tran', 'Krishna Kumar Sabapathy']",2025-03-20,"['quant-ph', 'cs.LG']","28 pages, 13 figures, 5 tables, 4 algorithms",http://arxiv.org/pdf/2503.16361v1
2503.16356v1,CaKE: Circuit-aware Editing Enables Generalizable Knowledge Learners,"Knowledge Editing (KE) enables the modification of outdated or incorrect
information in large language models (LLMs). While existing KE methods can
update isolated facts, they struggle to generalize these updates to multi-hop
reasoning tasks that depend on the modified knowledge. Through an analysis of
reasoning circuits -- the neural pathways LLMs use for knowledge-based
inference, we observe that current layer-localized KE approaches, such as MEMIT
and WISE, which edit only single or a few model layers, struggle to effectively
incorporate updated information into these reasoning pathways. To address this
limitation, we propose CaKE (Circuit-aware Knowledge Editing), a novel method
that enables more effective integration of updated knowledge in LLMs. CaKE
leverages strategically curated data, guided by our circuits-based analysis,
that enforces the model to utilize the modified knowledge, stimulating the
model to develop appropriate reasoning circuits for newly integrated knowledge.
Experimental results show that CaKE enables more accurate and consistent use of
updated knowledge across related reasoning tasks, leading to an average of 20%
improvement in multi-hop reasoning accuracy on MQuAKE dataset compared to
existing KE methods. We release the code and data in
https://github.com/zjunlp/CaKE.","['Yunzhi Yao', 'Jizhan Fang', 'Jia-Chen Gu', 'Ningyu Zhang', 'Shumin Deng', 'Huajun Chen', 'Nanyun Peng']",2025-03-20,"['cs.CL', 'cs.AI', 'cs.CV', 'cs.IR', 'cs.LG']",Work in progress,http://arxiv.org/pdf/2503.16356v1
2503.16351v1,Lyra: An Efficient and Expressive Subquadratic Architecture for Modeling Biological Sequences,"Deep learning architectures such as convolutional neural networks and
Transformers have revolutionized biological sequence modeling, with recent
advances driven by scaling up foundation and task-specific models. The
computational resources and large datasets required, however, limit their
applicability in biological contexts. We introduce Lyra, a subquadratic
architecture for sequence modeling, grounded in the biological framework of
epistasis for understanding sequence-to-function relationships. Mathematically,
we demonstrate that state space models efficiently capture global epistatic
interactions and combine them with projected gated convolutions for modeling
local relationships. We demonstrate that Lyra is performant across over 100
wide-ranging biological tasks, achieving state-of-the-art (SOTA) performance in
many key areas, including protein fitness landscape prediction, biophysical
property prediction (e.g. disordered protein region functions) peptide
engineering applications (e.g. antibody binding, cell-penetrating peptide
prediction), RNA structure analysis, RNA function prediction, and CRISPR guide
design. It achieves this with orders-of-magnitude improvements in inference
speed and reduction in parameters (up to 120,000-fold in our tests) compared to
recent biology foundation models. Using Lyra, we were able to train and run
every task in this study on two or fewer GPUs in under two hours, democratizing
access to biological sequence modeling at SOTA performance, with potential
applications to many fields.","['Krithik Ramesh', 'Sameed M. Siddiqui', 'Albert Gu', 'Michael D. Mitzenmacher', 'Pardis C. Sabeti']",2025-03-20,"['cs.LG', 'q-bio.GN']","53 pages, 5 figures",http://arxiv.org/pdf/2503.16351v1
2503.16342v1,HiQ-Lip: The First Quantum-Classical Hierarchical Method for Global Lipschitz Constant Estimation of ReLU Networks,"Estimating the global Lipschitz constant of neural networks is crucial for
understanding and improving their robustness and generalization capabilities.
However, precise calculations are NP-hard, and current semidefinite programming
(SDP) methods face challenges such as high memory usage and slow processing
speeds. In this paper, we propose \textbf{HiQ-Lip}, a hybrid quantum-classical
hierarchical method that leverages Coherent Ising Machines (CIMs) to estimate
the global Lipschitz constant. We tackle the estimation by converting it into a
Quadratic Unconstrained Binary Optimization (QUBO) problem and implement a
multilevel graph coarsening and refinement strategy to adapt to the constraints
of contemporary quantum hardware. Our experimental evaluations on fully
connected neural networks demonstrate that HiQ-Lip not only provides estimates
comparable to state-of-the-art methods but also significantly accelerates the
computation process. In specific tests involving two-layer neural networks with
256 hidden neurons, HiQ-Lip doubles the solving speed and offers more accurate
upper bounds than the existing best method, LiPopt. These findings highlight
the promising utility of small-scale quantum devices in advancing the
estimation of neural network robustness.","['Haoqi He', 'Yan Xiao']",2025-03-20,"['cs.LG', 'cs.AI', 'quant-ph']",,http://arxiv.org/pdf/2503.16342v1
2503.16340v1,Nonlinear action prediction models reveal multi-timescale locomotor control,"Modeling movement in real-world tasks is a fundamental scientific goal.
However, it is unclear whether existing models and their assumptions,
overwhelmingly tested in laboratory-constrained settings, generalize to the
real world. For example, data-driven models of foot placement control -- a
crucial action for stable locomotion -- assume linear and single timescale
mappings. We develop nonlinear foot placement prediction models, finding that
neural network architectures with flexible input history-dependence like GRU
and Transformer perform best across multiple contexts (walking and running,
treadmill and overground, varying terrains) and input modalities (multiple body
states, gaze), outperforming traditional models. These models reveal context-
and modality-dependent timescales: there is more reliance on fast-timescale
predictions in complex terrain, gaze predictions precede body state
predictions, and full-body state predictions precede center-of-mass-relevant
predictions. Thus, nonlinear action prediction models provide quantifiable
insights into real-world motor control and can be extended to other actions,
contexts, and populations.","['Wei-Chen Wang', 'Antoine De Comite', 'Monica Daley', 'Alexandra Voloshina', 'Nidhi Seethapathi']",2025-03-20,"['cs.LG', 'cs.RO']",,http://arxiv.org/pdf/2503.16340v1
2503.16337v1,Optimal Complexity in Byzantine-Robust Distributed Stochastic Optimization with Data Heterogeneity,"In this paper, we establish tight lower bounds for Byzantine-robust
distributed first-order stochastic optimization methods in both strongly convex
and non-convex stochastic optimization. We reveal that when the distributed
nodes have heterogeneous data, the convergence error comprises two components:
a non-vanishing Byzantine error and a vanishing optimization error. We
establish the lower bounds on the Byzantine error and on the minimum number of
queries to a stochastic gradient oracle required to achieve an arbitrarily
small optimization error. Nevertheless, we identify significant discrepancies
between our established lower bounds and the existing upper bounds. To fill
this gap, we leverage the techniques of Nesterov's acceleration and variance
reduction to develop novel Byzantine-robust distributed stochastic optimization
methods that provably match these lower bounds, up to logarithmic factors,
implying that our established lower bounds are tight.","['Qiankun Shi', 'Jie Peng', 'Kun Yuan', 'Xiao Wang', 'Qing Ling']",2025-03-20,"['math.OC', 'cs.LG']",,http://arxiv.org/pdf/2503.16337v1
2503.16328v1,Knowledge-guided machine learning model with soil moisture for corn yield prediction under drought conditions,"Remote sensing (RS) techniques, by enabling non-contact acquisition of
extensive ground observations, have become a valuable tool for corn yield
prediction. Traditional process-based (PB) models are limited by fixed input
features and struggle to incorporate large volumes of RS data. In contrast,
machine learning (ML) models are often criticized for being ``black boxes''
with limited interpretability. To address these limitations, we used
Knowledge-Guided Machine Learning (KGML), which combined the strengths of both
approaches and fully used RS data. However, previous KGML methods overlooked
the crucial role of soil moisture in plant growth. To bridge this gap, we
proposed the Knowledge-Guided Machine Learning with Soil Moisture (KGML-SM)
framework, using soil moisture as an intermediate variable to emphasize its key
role in plant development. Additionally, based on the prior knowledge that the
model may overestimate under drought conditions, we designed a drought-aware
loss function that penalizes predicted yield in drought-affected areas. Our
experiments showed that the KGML-SM model outperformed other ML models.
Finally, we explored the relationships between drought, soil moisture, and corn
yield prediction, assessing the importance of various features and analyzing
how soil moisture impacts corn yield predictions across different regions and
time periods.","['Xiaoyu Wang', 'Yijia Xu', 'Jingyi Huang', 'Zhengwei Yang', 'Zhou Zhang']",2025-03-20,"['cs.LG', 'cs.AI']",,http://arxiv.org/pdf/2503.16328v1
2503.16323v1,NeuralFoil: An Airfoil Aerodynamics Analysis Tool Using Physics-Informed Machine Learning,"NeuralFoil is an open-source Python-based tool for rapid aerodynamics
analysis of airfoils, similar in purpose to XFoil. Speedups ranging from 8x to
1,000x over XFoil are demonstrated, after controlling for equivalent accuracy.
NeuralFoil computes both global and local quantities (lift, drag, velocity
distribution, etc.) over a broad input space, including: an 18-dimensional
space of airfoil shapes, possibly including control deflections; a 360 degree
range of angles of attack; Reynolds numbers from $10^2$ to $10^{10}$; subsonic
flows up to the transonic drag rise; and with varying turbulence parameters.
Results match those of XFoil closely: the mean relative error of drag is 0.37%
on simple cases, and remains as low as 2.0% on a test dataset with numerous
post-stall and transitional cases. NeuralFoil facilitates gradient-based design
optimization, due to its $C^\infty$-continuous solutions,
automatic-differentiation-compatibility, and bounded computational cost without
non-convergence issues.
  NeuralFoil is a hybrid of physics-informed machine learning techniques and
analytical models. Here, physics information includes symmetries that are
structurally embedded into the model architecture, feature engineering using
domain knowledge, and guaranteed extrapolation to known limit cases. This work
also introduces a new approach for surrogate model uncertainty quantification
that enables robust design optimization.
  This work discusses the methodology and performance of NeuralFoil with
several case studies, including a practical airfoil design optimization study
including both aerodynamic and non-aerodynamic constraints. Here, NeuralFoil
optimization is able to produce airfoils nearly identical in performance and
shape to expert-designed airfoils within seconds; these
computationally-optimized airfoils provide a useful starting point for further
expert refinement.","['Peter Sharpe', 'R. John Hansman']",2025-03-20,"['physics.flu-dyn', 'cs.LG']","42 pages, 14 figures",http://arxiv.org/pdf/2503.16323v1
2503.16316v1,On the Cone Effect in the Learning Dynamics,"Understanding the learning dynamics of neural networks is a central topic in
the deep learning community. In this paper, we take an empirical perspective to
study the learning dynamics of neural networks in real-world settings.
Specifically, we investigate the evolution process of the empirical Neural
Tangent Kernel (eNTK) during training. Our key findings reveal a two-phase
learning process: i) in Phase I, the eNTK evolves significantly, signaling the
rich regime, and ii) in Phase II, the eNTK keeps evolving but is constrained in
a narrow space, a phenomenon we term the cone effect. This two-phase framework
builds on the hypothesis proposed by Fort et al. (2020), but we uniquely
identify the cone effect in Phase II, demonstrating its significant performance
advantages over fully linearized training.","['Zhanpeng Zhou', 'Yongyi Yang', 'Jie Ren', 'Mahito Sugiyama', 'Junchi Yan']",2025-03-20,['cs.LG'],Accepted by ICLR 2025 workshop DeLTa,http://arxiv.org/pdf/2503.16316v1
2503.16315v1,Active Learning For Repairable Hardware Systems With Partial Coverage,"Identifying the optimal diagnostic test and hardware system instance to infer
reliability characteristics using field data is challenging, especially when
constrained by fixed budgets and minimal maintenance cycles. Active Learning
(AL) has shown promise for parameter inference with limited data and budget
constraints in machine learning/deep learning tasks. However, AL for
reliability model parameter inference remains underexplored for repairable
hardware systems. It requires specialized AL Acquisition Functions (AFs) that
consider hardware aging and the fact that a hardware system consists of
multiple sub-systems, which may undergo only partial testing during a given
diagnostic test. To address these challenges, we propose a relaxed Mixed
Integer Semidefinite Program (MISDP) AL AF that incorporates Diagnostic
Coverage (DC), Fisher Information Matrices (FIMs), and diagnostic testing
budgets. Furthermore, we design empirical-based simulation experiments focusing
on two diagnostic testing scenarios: (1) partial tests of a hardware system
with overlapping subsystem coverage, and (2) partial tests where one diagnostic
test fully subsumes the subsystem coverage of another. We evaluate our proposed
approach against the most widely used AL AF in the literature (entropy), as
well as several intuitive AL AFs tailored for reliability model parameter
inference. Our proposed AF ranked best on average among the alternative AFs
across 6,000 experimental configurations, with respect to Area Under the Curve
(AUC) of the Absolute Total Expected Event Error (ATEER) and Mean Squared Error
(MSE) curves, with statistical significance calculated at a 0.05 alpha level
using a Friedman hypothesis test.","['Michael Potter', 'Beyza Kalkanlı', 'Deniz Erdoğmuş', 'Michael Everett']",2025-03-20,"['stat.AP', 'cs.LG']","Submitted to IEEE Reliability and Maintainability Symposium - Europe
  2025",http://arxiv.org/pdf/2503.16315v1
2503.16311v1,"Structured-Noise Masked Modeling for Video, Audio and Beyond","Masked modeling has emerged as a powerful self-supervised learning framework,
but existing methods largely rely on random masking, disregarding the
structural properties of different modalities. In this work, we introduce
structured noise-based masking, a simple yet effective approach that naturally
aligns with the spatial, temporal, and spectral characteristics of video and
audio data. By filtering white noise into distinct color noise distributions,
we generate structured masks that preserve modality-specific patterns without
requiring handcrafted heuristics or access to the data. Our approach improves
the performance of masked video and audio modeling frameworks without any
computational overhead. Extensive experiments demonstrate that structured noise
masking achieves consistent improvement over random masking for standard and
advanced masked modeling methods, highlighting the importance of modality-aware
masking strategies for representation learning.","['Aritra Bhowmik', 'Fida Mohammad Thoker', 'Carlos Hinojosa', 'Bernard Ghanem', 'Cees G. M. Snoek']",2025-03-20,"['cs.LG', 'cs.AI', 'cs.SD']",,http://arxiv.org/pdf/2503.16311v1
2503.16286v1,Explainable Graph-theoretical Machine Learning: with Application to Alzheimer's Disease Prediction,"Alzheimer's disease (AD) affects 50 million people worldwide and is projected
to overwhelm 152 million by 2050. AD is characterized by cognitive decline due
partly to disruptions in metabolic brain connectivity. Thus, early and accurate
detection of metabolic brain network impairments is crucial for AD management.
Chief to identifying such impairments is FDG-PET data. Despite advancements,
most graph-based studies using FDG-PET data rely on group-level analysis or
thresholding. Yet, group-level analysis can veil individual differences and
thresholding may overlook weaker but biologically critical brain connections.
Additionally, machine learning-based AD prediction largely focuses on
univariate outcomes, such as disease status. Here, we introduce explainable
graph-theoretical machine learning (XGML), a framework employing kernel density
estimation and dynamic time warping to construct individual metabolic brain
graphs that capture the distance between pair-wise brain regions and identify
subgraphs most predictive of multivariate AD-related outcomes. Using FDG-PET
data from the Alzheimer's Disease Neuroimaging Initiative, XGML builds
metabolic brain graphs and uncovers subgraphs predictive of eight AD-related
cognitive scores in new subjects. XGML shows robust performance, particularly
for predicting scores measuring learning, memory, language, praxis, and
orientation, such as CDRSB ($r = 0.74$), ADAS11 ($r = 0.73$), and ADAS13 ($r =
0.71$). Moreover, XGML unveils key edges jointly but differentially predictive
of several AD-related outcomes; they may serve as potential network biomarkers
for assessing overall cognitive decline. Together, we show the promise of
graph-theoretical machine learning in biomarker discovery and disease
prediction and its potential to improve our understanding of network neural
mechanisms underlying AD.","['Narmina Baghirova', 'Duy-Thanh Vũ', 'Duy-Cat Can', 'Christelle Schneuwly Diaz', 'Julien Bodlet', 'Guillaume Blanc', 'Georgi Hrusanov', 'Bernard Ries', 'Oliver Y. Chén']",2025-03-20,['cs.LG'],,http://arxiv.org/pdf/2503.16286v1
2503.16278v1,Uni-3DAR: Unified 3D Generation and Understanding via Autoregression on Compressed Spatial Tokens,"Recent advancements in large language models and their multi-modal extensions
have demonstrated the effectiveness of unifying generation and understanding
through autoregressive next-token prediction. However, despite the critical
role of 3D structural generation and understanding ({3D GU}) in AI for science,
these tasks have largely evolved independently, with autoregressive methods
remaining underexplored. To bridge this gap, we introduce Uni-3DAR, a unified
framework that seamlessly integrates {3D GU} tasks via autoregressive
prediction. At its core, Uni-3DAR employs a novel hierarchical tokenization
that compresses 3D space using an octree, leveraging the inherent sparsity of
3D structures. It then applies an additional tokenization for fine-grained
structural details, capturing key attributes such as atom types and precise
spatial coordinates in microscopic 3D structures. We further propose two
optimizations to enhance efficiency and effectiveness. The first is a two-level
subtree compression strategy, which reduces the octree token sequence by up to
8x. The second is a masked next-token prediction mechanism tailored for
dynamically varying token positions, significantly boosting model performance.
By combining these strategies, Uni-3DAR successfully unifies diverse {3D GU}
tasks within a single autoregressive framework. Extensive experiments across
multiple microscopic {3D GU} tasks, including molecules, proteins, polymers,
and crystals, validate its effectiveness and versatility. Notably, Uni-3DAR
surpasses previous state-of-the-art diffusion models by a substantial margin,
achieving up to 256\% relative improvement while delivering inference speeds up
to 21.8x faster. The code is publicly available at
https://github.com/dptech-corp/Uni-3DAR.","['Shuqi Lu', 'Haowei Lin', 'Lin Yao', 'Zhifeng Gao', 'Xiaohong Ji', 'Weinan E', 'Linfeng Zhang', 'Guolin Ke']",2025-03-20,"['cs.LG', 'cond-mat.mtrl-sci', 'q-bio.BM']",,http://arxiv.org/pdf/2503.16278v1
2503.16271v1,Rethinking Robustness in Machine Learning: A Posterior Agreement Approach,"The robustness of algorithms against covariate shifts is a fundamental
problem with critical implications for the deployment of machine learning
algorithms in the real world. Current evaluation methods predominantly match
the robustness definition to that of standard generalization, relying on
standard metrics like accuracy-based scores, which, while designed for
performance assessment, lack a theoretical foundation encompassing their
application in estimating robustness to distribution shifts. In this work, we
set the desiderata for a robustness metric, and we propose a novel principled
framework for the robustness assessment problem that directly follows the
Posterior Agreement (PA) theory of model validation. Specifically, we extend
the PA framework to the covariate shift setting by proposing a PA metric for
robustness evaluation in supervised classification tasks. We assess the
soundness of our metric in controlled environments and through an empirical
robustness analysis in two different covariate shift scenarios: adversarial
learning and domain generalization. We illustrate the suitability of PA by
evaluating several models under different nature and magnitudes of shift, and
proportion of affected observations. The results show that the PA metric
provides a sensible and consistent analysis of the vulnerabilities in learning
algorithms, even in the presence of few perturbed observations.","['João Borges S. Carvalho', 'Alessandro Torcinovich', 'Victor Jimenez Rodriguez', 'Antonio E. Cinà', 'Carlos Cotrini', 'Lea Schönherr', 'Joachim M. Buhmann']",2025-03-20,['cs.LG'],"Preprint submitted to TMLR. 29 pages, 13 figures",http://arxiv.org/pdf/2503.16271v1
2503.16251v1,"RESFL: An Uncertainty-Aware Framework for Responsible Federated Learning by Balancing Privacy, Fairness and Utility in Autonomous Vehicles","Autonomous vehicles (AVs) increasingly rely on Federated Learning (FL) to
enhance perception models while preserving privacy. However, existing FL
frameworks struggle to balance privacy, fairness, and robustness, leading to
performance disparities across demographic groups. Privacy-preserving
techniques like differential privacy mitigate data leakage risks but worsen
fairness by restricting access to sensitive attributes needed for bias
correction. This work explores the trade-off between privacy and fairness in
FL-based object detection for AVs and introduces RESFL, an integrated solution
optimizing both. RESFL incorporates adversarial privacy disentanglement and
uncertainty-guided fairness-aware aggregation. The adversarial component uses a
gradient reversal layer to remove sensitive attributes, reducing privacy risks
while maintaining fairness. The uncertainty-aware aggregation employs an
evidential neural network to weight client updates adaptively, prioritizing
contributions with lower fairness disparities and higher confidence. This
ensures robust and equitable FL model updates. We evaluate RESFL on the FACET
dataset and CARLA simulator, assessing accuracy, fairness, privacy resilience,
and robustness under varying conditions. RESFL improves detection accuracy,
reduces fairness disparities, and lowers privacy attack success rates while
demonstrating superior robustness to adversarial conditions compared to other
approaches.","['Dawood Wasif', 'Terrence J. Moore', 'Jin-Hee Cho']",2025-03-20,"['cs.LG', 'cs.CV', 'cs.DC', 'cs.ET']",Submitted to PETS 2025 (under review),http://arxiv.org/pdf/2503.16251v1
2503.16247v1,OpenMIBOOD: Open Medical Imaging Benchmarks for Out-Of-Distribution Detection,"The growing reliance on Artificial Intelligence (AI) in critical domains such
as healthcare demands robust mechanisms to ensure the trustworthiness of these
systems, especially when faced with unexpected or anomalous inputs. This paper
introduces the Open Medical Imaging Benchmarks for Out-Of-Distribution
Detection (OpenMIBOOD), a comprehensive framework for evaluating
out-of-distribution (OOD) detection methods specifically in medical imaging
contexts. OpenMIBOOD includes three benchmarks from diverse medical domains,
encompassing 14 datasets divided into covariate-shifted in-distribution,
near-OOD, and far-OOD categories. We evaluate 24 post-hoc methods across these
benchmarks, providing a standardized reference to advance the development and
fair comparison of OOD detection methods. Results reveal that findings from
broad-scale OOD benchmarks in natural image domains do not translate to medical
applications, underscoring the critical need for such benchmarks in the medical
field. By mitigating the risk of exposing AI models to inputs outside their
training distribution, OpenMIBOOD aims to support the advancement of reliable
and trustworthy AI systems in healthcare. The repository is available at
https://github.com/remic-othr/OpenMIBOOD.","['Max Gutbrod', 'David Rauber', 'Danilo Weber Nunes', 'Christoph Palm']",2025-03-20,"['cs.CV', 'cs.LG']",,http://arxiv.org/pdf/2503.16247v1
2503.16240v1,Machine learning identifies nullclines in oscillatory dynamical systems,"We introduce CLINE (Computational Learning and Identification of Nullclines),
a neural network-based method that uncovers the hidden structure of nullclines
from oscillatory time series data. Unlike traditional approaches aiming at
direct prediction of system dynamics, CLINE identifies static geometric
features of the phase space that encode the (non)linear relationships between
state variables. It overcomes challenges such as multiple time scales and
strong nonlinearities while producing interpretable results convertible into
symbolic differential equations. We validate CLINE on various oscillatory
systems, showcasing its effectiveness.","['Bartosz Prokop', 'Jimmy Billen', 'Nikita Frolov', 'Lendert Gelens']",2025-03-20,"['cs.LG', 'math.DS', 'nlin.AO', 'physics.comp-ph']","7 pages, 4 figures",http://arxiv.org/pdf/2503.16240v1
2503.16233v1,Empirical Analysis of Privacy-Fairness-Accuracy Trade-offs in Federated Learning: A Step Towards Responsible AI,"Federated Learning (FL) enables collaborative machine learning while
preserving data privacy but struggles to balance privacy preservation (PP) and
fairness. Techniques like Differential Privacy (DP), Homomorphic Encryption
(HE), and Secure Multi-Party Computation (SMC) protect sensitive data but
introduce trade-offs. DP enhances privacy but can disproportionately impact
underrepresented groups, while HE and SMC mitigate fairness concerns at the
cost of computational overhead. This work explores the privacy-fairness
trade-offs in FL under IID (Independent and Identically Distributed) and
non-IID data distributions, benchmarking q-FedAvg, q-MAML, and Ditto on diverse
datasets. Our findings highlight context-dependent trade-offs and offer
guidelines for designing FL systems that uphold responsible AI principles,
ensuring fairness, privacy, and equitable real-world applications.","['Dawood Wasif', 'Dian Chen', 'Sindhuja Madabushi', 'Nithin Alluru', 'Terrence J. Moore', 'Jin-Hee Cho']",2025-03-20,"['cs.LG', 'cs.CR', 'cs.DC', 'cs.ET']",Submitted to IJCAI 2025 (under review),http://arxiv.org/pdf/2503.16233v1
2503.16227v1,Flight Testing an Optionally Piloted Aircraft: a Case Study on Trust Dynamics in Human-Autonomy Teaming,"This paper examines how trust is formed, maintained, or diminished over time
in the context of human-autonomy teaming with an optionally piloted aircraft.
Whereas traditional factor-based trust models offer a static representation of
human confidence in technology, here we discuss how variations in the
underlying factors lead to variations in trust, trust thresholds, and human
behaviours. Over 200 hours of flight test data collected over a multi-year test
campaign from 2021 to 2023 were reviewed. The
dispositional-situational-learned, process-performance-purpose, and IMPACTS
homeostasis trust models are applied to illuminate trust trends during nominal
autonomous flight operations. The results offer promising directions for future
studies on trust dynamics and design-for-trust in human-autonomy teaming.","['Jeremy C. -H. Wang', 'Ming Hou', 'David Dunwoody', 'Marko Ilievski', 'Justin Tomasi', 'Edward Chao', 'Carl Pigeon']",2025-03-20,"['cs.HC', 'cs.AI', 'cs.ET', 'cs.LG', 'cs.SY', 'eess.SY']","IEEE International Conference on Human-Machine Systems 2025,
  keywords: trust, human factors, aviation, safety-critical, human-autonomy
  teaming",http://arxiv.org/pdf/2503.16227v1
2503.16219v1,Reinforcement Learning for Reasoning in Small LLMs: What Works and What Doesn't,"Enhancing the reasoning capabilities of large language models (LLMs)
typically relies on massive computational resources and extensive datasets,
limiting accessibility for resource-constrained settings. Our study
investigates the potential of reinforcement learning (RL) to improve reasoning
in small LLMs, focusing on a 1.5-billion-parameter model,
DeepSeek-R1-Distill-Qwen-1.5B, under strict constraints: training on 4 NVIDIA
A40 GPUs (48 GB VRAM each) within 24 hours. Adapting the Group Relative Policy
Optimization (GRPO) algorithm and curating a compact, high-quality mathematical
reasoning dataset, we conducted three experiments to explore model behavior and
performance. Our results demonstrate rapid reasoning gains - e.g., AMC23
accuracy rising from 63% to 80% and AIME24 reaching 46.7%, surpassing
o1-preview - using only 7,000 samples and a $42 training cost, compared to
thousands of dollars for baseline models. However, challenges such as
optimization instability and length constraints emerged with prolonged
training. These findings highlight the efficacy of RL-based fine-tuning for
small LLMs, offering a cost-effective alternative to large-scale approaches. We
release our code and datasets as open-source resources, providing insights into
trade-offs and laying a foundation for scalable, reasoning-capable LLMs in
resource-limited environments. All are available at
https://github.com/knoveleng/open-rs.","['Quy-Anh Dang', 'Chris Ngo']",2025-03-20,"['cs.LG', 'cs.CL']",,http://arxiv.org/pdf/2503.16219v1
2503.16207v1,Neural Variable-Order Fractional Differential Equation Networks,"Neural differential equation models have garnered significant attention in
recent years for their effectiveness in machine learning applications.Among
these, fractional differential equations (FDEs) have emerged as a promising
tool due to their ability to capture memory-dependent dynamics, which are often
challenging to model with traditional integer-order approaches.While existing
models have primarily focused on constant-order fractional derivatives,
variable-order fractional operators offer a more flexible and expressive
framework for modeling complex memory patterns. In this work, we introduce the
Neural Variable-Order Fractional Differential Equation network (NvoFDE), a
novel neural network framework that integrates variable-order fractional
derivatives with learnable neural networks.Our framework allows for the
modeling of adaptive derivative orders dependent on hidden features, capturing
more complex feature-updating dynamics and providing enhanced flexibility. We
conduct extensive experiments across multiple graph datasets to validate the
effectiveness of our approach.Our results demonstrate that NvoFDE outperforms
traditional constant-order fractional and integer models across a range of
tasks, showcasing its superior adaptability and performance.","['Wenjun Cui', 'Qiyu Kang', 'Xuhao Li', 'Kai Zhao', 'Wee Peng Tay', 'Weihua Deng', 'Yidong Li']",2025-03-20,['cs.LG'],AAAI 2025,http://arxiv.org/pdf/2503.16207v1
2503.16206v1,Interpretable Neural Causal Models with TRAM-DAGs,"The ultimate goal of most scientific studies is to understand the underlying
causal mechanism between the involved variables. Structural causal models
(SCMs) are widely used to represent such causal mechanisms. Given an SCM,
causal queries on all three levels of Pearl's causal hierarchy can be answered:
$L_1$ observational, $L_2$ interventional, and $L_3$ counterfactual. An
essential aspect of modeling the SCM is to model the dependency of each
variable on its causal parents. Traditionally this is done by parametric
statistical models, such as linear or logistic regression models. This allows
to handle all kinds of data types and fit interpretable models but bears the
risk of introducing a bias. More recently neural causal models came up using
neural networks (NNs) to model the causal relationships, allowing the
estimation of nearly any underlying functional form without bias. However,
current neural causal models are generally restricted to continuous variables
and do not yield an interpretable form of the causal relationships.
Transformation models range from simple statistical regressions to complex
networks and can handle continuous, ordinal, and binary data. Here, we propose
to use TRAMs to model the functional relationships in SCMs allowing us to
bridge the gap between interpretability and flexibility in causal modeling. We
call this method TRAM-DAG and assume currently that the underlying directed
acyclic graph is known. For the fully observed case, we benchmark TRAM-DAGs
against state-of-the-art statistical and NN-based causal models. We show that
TRAM-DAGs are interpretable but also achieve equal or superior performance in
queries ranging from $L_1$ to $L_3$ in the causal hierarchy. For the continuous
case, TRAM-DAGs allow for counterfactual queries for three common causal
structures, including unobserved confounding.","['Beate Sick', 'Oliver Dürr']",2025-03-20,"['stat.ML', 'cs.LG']",Accepted at the CLeaR 2025 Conference,http://arxiv.org/pdf/2503.16206v1
2503.16199v1,Deferring Concept Bottleneck Models: Learning to Defer Interventions to Inaccurate Experts,"Concept Bottleneck Models (CBMs) are machine learning models that improve
interpretability by grounding their predictions on human-understandable
concepts, allowing for targeted interventions in their decision-making process.
However, when intervened on, CBMs assume the availability of humans that can
identify the need to intervene and always provide correct interventions. Both
assumptions are unrealistic and impractical, considering labor costs and human
error-proneness. In contrast, Learning to Defer (L2D) extends supervised
learning by allowing machine learning models to identify cases where a human is
more likely to be correct than the model, thus leading to deferring systems
with improved performance. In this work, we gain inspiration from L2D and
propose Deferring CBMs (DCBMs), a novel framework that allows CBMs to learn
when an intervention is needed. To this end, we model DCBMs as a composition of
deferring systems and derive a consistent L2D loss to train them. Moreover, by
relying on a CBM architecture, DCBMs can explain why defer occurs on the final
task. Our results show that DCBMs achieve high predictive performance and
interpretability at the cost of deferring more to humans.","['Andrea Pugnana', 'Riccardo Massidda', 'Francesco Giannini', 'Pietro Barbiero', 'Mateo Espinosa Zarlenga', 'Roberto Pellungrini', 'Gabriele Dominici', 'Fosca Giannotti', 'Davide Bacciu']",2025-03-20,['cs.LG'],,http://arxiv.org/pdf/2503.16199v1
2503.16195v1,VP-NTK: Exploring the Benefits of Visual Prompting in Differentially Private Data Synthesis,"Differentially private (DP) synthetic data has become the de facto standard
for releasing sensitive data. However, many DP generative models suffer from
the low utility of synthetic data, especially for high-resolution images. On
the other hand, one of the emerging techniques in parameter efficient
fine-tuning (PEFT) is visual prompting (VP), which allows well-trained existing
models to be reused for the purpose of adapting to subsequent downstream tasks.
In this work, we explore such a phenomenon in constructing captivating
generative models with DP constraints. We show that VP in conjunction with
DP-NTK, a DP generator that exploits the power of the neural tangent kernel
(NTK) in training DP generative models, achieves a significant performance
boost, particularly for high-resolution image datasets, with accuracy improving
from 0.644$\pm$0.044 to 0.769. Lastly, we perform ablation studies on the
effect of different parameters that influence the overall performance of
VP-NTK. Our work demonstrates a promising step forward in improving the utility
of DP synthetic data, particularly for high-resolution images.","['Chia-Yi Hsu', 'Jia-You Chen', 'Yu-Lin Tsai', 'Chih-Hsun Lin', 'Pin-Yu Chen', 'Chia-Mu Yu', 'Chun-Ying Huang']",2025-03-20,"['cs.CV', 'cs.LG']",Accepted by ICASSP 2025,http://arxiv.org/pdf/2503.16195v1
2503.16192v1,Nonparametric Bellman Mappings for Value Iteration in Distributed Reinforcement Learning,"This paper introduces novel Bellman mappings (B-Maps) for value iteration
(VI) in distributed reinforcement learning (DRL), where multiple agents operate
over a network without a centralized fusion node. Each agent constructs its own
nonparametric B-Map for VI while communicating only with direct neighbors to
achieve consensus. These B-Maps operate on Q-functions represented in a
reproducing kernel Hilbert space, enabling a nonparametric formulation that
allows for flexible, agent-specific basis function design. Unlike existing DRL
methods that restrict information exchange to Q-function estimates, the
proposed framework also enables agents to share basis information in the form
of covariance matrices, capturing additional structural details. A theoretical
analysis establishes linear convergence rates for both Q-function and
covariance-matrix estimates toward their consensus values. The optimal learning
rates for consensus-based updates are dictated by the ratio of the smallest
positive eigenvalue to the largest one of the network's Laplacian matrix.
Furthermore, each nodal Q-function estimate is shown to lie very close to the
fixed point of a centralized nonparametric B-Map, effectively allowing the
proposed DRL design to approximate the performance of a centralized fusion
center. Numerical experiments on two well-known control problems demonstrate
the superior performance of the proposed nonparametric B-Maps compared to prior
methods. Notably, the results reveal a counter-intuitive finding: although the
proposed approach involves greater information exchange -- specifically through
the sharing of covariance matrices -- it achieves the desired performance with
lower cumulative communication cost than existing DRL schemes, highlighting the
crucial role of basis information in accelerating the learning process.","['Yuki Akiyama', 'Konstantinos Slavakis']",2025-03-20,"['cs.LG', 'eess.SP']",,http://arxiv.org/pdf/2503.16192v1
2503.16191v1,Large Language Models for Water Distribution Systems Modeling and Decision-Making,"The design, operations, and management of water distribution systems (WDS)
involve complex mathematical models. These models are continually improving due
to computational advancements, leading to better decision-making and more
efficient WDS management. However, the significant time and effort required for
modeling, programming, and analyzing results remain substantial challenges.
Another issue is the professional burden, which confines the interaction with
models, databases, and other sophisticated tools to a small group of experts,
thereby causing non-technical stakeholders to depend on these experts or make
decisions without modeling support. Furthermore, explaining model results is
challenging even for experts, as it is often unclear which conditions cause the
model to reach a certain state or recommend a specific policy. The recent
advancements in Large Language Models (LLMs) open doors for a new stage in
human-model interaction. This study proposes a framework of plain language
interactions with hydraulic and water quality models based on LLM-EPANET
architecture. This framework is tested with increasing levels of complexity of
queries to study the ability of LLMs to interact with WDS models, run complex
simulations, and report simulation results. The performance of the proposed
framework is evaluated across several categories of queries and hyper-parameter
configurations, demonstrating its potential to enhance decision-making
processes in WDS management.","['Yinon Goldshtein', 'Gal Perelman', 'Assaf Schuster', 'Avi Ostfeld']",2025-03-20,"['cs.AI', 'cs.HC', 'cs.LG']",Accepted to EWRI Congress 2025,http://arxiv.org/pdf/2503.16191v1
2503.16187v1,Manifold learning in metric spaces,"Laplacian-based methods are popular for dimensionality reduction of data
lying in $\mathbb{R}^N$. Several theoretical results for these algorithms
depend on the fact that the Euclidean distance approximates the geodesic
distance on the underlying submanifold which the data are assumed to lie on.
However, for some applications, other metrics, such as the Wasserstein
distance, may provide a more appropriate notion of distance than the Euclidean
distance. We provide a framework that generalizes the problem of manifold
learning to metric spaces and study when a metric satisfies sufficient
conditions for the pointwise convergence of the graph Laplacian.","['Liane Xu', 'Amit Singer']",2025-03-20,"['cs.LG', 'stat.ML']",,http://arxiv.org/pdf/2503.16187v1
2503.16183v1,Variance-Aware Noisy Training: Hardening DNNs against Unstable Analog Computations,"The disparity between the computational demands of deep learning and the
capabilities of compute hardware is expanding drastically. Although deep
learning achieves remarkable performance in countless tasks, its escalating
requirements for computational power and energy consumption surpass the
sustainable limits of even specialized neural processing units, including the
Apple Neural Engine and NVIDIA TensorCores. This challenge is intensified by
the slowdown in CMOS scaling.
  Analog computing presents a promising alternative, offering substantial
improvements in energy efficiency by directly manipulating physical quantities
such as current, voltage, charge, or photons. However, it is inherently
vulnerable to manufacturing variations, nonlinearities, and noise, leading to
degraded prediction accuracy. One of the most effective techniques for
enhancing robustness, Noisy Training, introduces noise during the training
phase to reinforce the model against disturbances encountered during inference.
Although highly effective, its performance degrades in real-world environments
where noise characteristics fluctuate due to external factors such as
temperature variations and temporal drift.
  This study underscores the necessity of Noisy Training while revealing its
fundamental limitations in the presence of dynamic noise. To address these
challenges, we propose Variance-Aware Noisy Training, a novel approach that
mitigates performance degradation by incorporating noise schedules which
emulate the evolving noise conditions encountered during inference. Our method
substantially improves model robustness, without training overhead. We
demonstrate a significant increase in robustness, from 72.3\% with conventional
Noisy Training to 97.3\% with Variance-Aware Noisy Training on CIFAR-10 and
from 38.5\% to 89.9\% on Tiny ImageNet.","['Xiao Wang', 'Hendrik Borras', 'Bernhard Klein', 'Holger Fröning']",2025-03-20,['cs.LG'],,http://arxiv.org/pdf/2503.16183v1
2503.16179v1,Narrowing Class-Wise Robustness Gaps in Adversarial Training,"Efforts to address declining accuracy as a result of data shifts often
involve various data-augmentation strategies. Adversarial training is one such
method, designed to improve robustness to worst-case distribution shifts caused
by adversarial examples. While this method can improve robustness, it may also
hinder generalization to clean examples and exacerbate performance imbalances
across different classes. This paper explores the impact of adversarial
training on both overall and class-specific performance, as well as its
spill-over effects. We observe that enhanced labeling during training boosts
adversarial robustness by 53.50% and mitigates class imbalances by 5.73%,
leading to improved accuracy in both clean and adversarial settings compared to
standard adversarial training.","['Fatemeh Amerehi', 'Patrick Healy']",2025-03-20,"['cs.CV', 'cs.LG']","4 figures, ICLR 2025 Workshop on Foundation Models in the Wild",http://arxiv.org/pdf/2503.16179v1
2503.16159v1,Neural Combinatorial Optimization for Real-World Routing,"Vehicle Routing Problems (VRPs) are a class of NP-hard problems ubiquitous in
several real-world logistics scenarios that pose significant challenges for
optimization. Neural Combinatorial Optimization (NCO) has emerged as a
promising alternative to classical approaches, as it can learn fast heuristics
to solve VRPs. However, most research works in NCO for VRPs focus on simplified
settings, which do not account for asymmetric distances and travel durations
that cannot be derived by simple Euclidean distances and unrealistic data
distributions, hindering real-world deployment. This work introduces RRNCO
(Real Routing NCO) to bridge the gap of NCO between synthetic and real-world
VRPs in the critical aspects of both data and modeling. First, we introduce a
new, openly available dataset with real-world data containing a diverse dataset
of locations, distances, and duration matrices from 100 cities, considering
realistic settings with actual routing distances and durations obtained from
Open Source Routing Machine (OSRM). Second, we propose a novel approach that
efficiently processes both node and edge features through contextual gating,
enabling the construction of more informed node embedding, and we finally
incorporate an Adaptation Attention Free Module (AAFM) with neural adaptive
bias mechanisms that effectively integrates not only distance matrices but also
angular relationships between nodes, allowing our model to capture rich
structural information. RRNCO achieves state-of-the-art results in real-world
VRPs among NCO methods. We make our dataset and code publicly available at
https://github.com/ai4co/real-routing-nco.","['Jiwoo Son', 'Zhikai Zhao', 'Federico Berto', 'Chuanbo Hua', 'Changhyun Kwon', 'Jinkyoo Park']",2025-03-20,"['cs.LG', 'cs.AI']",,http://arxiv.org/pdf/2503.16159v1
2503.16123v1,Distributed Learning over Arbitrary Topology: Linear Speed-Up with Polynomial Transient Time,"We study a distributed learning problem in which $n$ agents, each with
potentially heterogeneous local data, collaboratively minimize the sum of their
local cost functions via peer-to-peer communication. We propose a novel
algorithm, Spanning Tree Push-Pull (STPP), which employs two spanning trees
extracted from a general communication graph to distribute both model
parameters and stochastic gradients. Unlike prior approaches that rely heavily
on spectral gap properties, STPP leverages a more flexible topological
characterization, enabling robust information flow and efficient updates.
Theoretically, we prove that STPP achieves linear speedup and polynomial
transient iteration complexity, up to $O(n^7)$ for smooth nonconvex objectives
and $\tilde{O}(n^3)$ for smooth strongly convex objectives, under arbitrary
network topologies. Moreover, compared with the existing methods, STPP achieves
faster convergence rates on sparse and non-regular topologies (e.g., directed
ring) and reduces communication overhead on dense networks (e.g., static
exponential graph). These results significantly advance the state of the art,
especially when $n$ is large. Numerical experiments further demonstrate the
strong performance of STPP and confirm the practical relevance of its
theoretical convergence rates across various common graph architectures. Our
code is available at
https://anonymous.4open.science/r/SpanningTreePushPull-5D3E.","['Runze You', 'Shi Pu']",2025-03-20,"['math.OC', 'cs.LG']",,http://arxiv.org/pdf/2503.16123v1
2503.16117v1,Improving Discriminator Guidance in Diffusion Models,"Discriminator Guidance has become a popular method for efficiently refining
pre-trained Score-Matching Diffusion models. However, in this paper, we
demonstrate that the standard implementation of this technique does not
necessarily lead to a distribution closer to the real data distribution.
Specifically, we show that training the discriminator using Cross-Entropy loss,
as commonly done, can in fact increase the Kullback-Leibler divergence between
the model and target distributions, particularly when the discriminator
overfits. To address this, we propose a theoretically sound training objective
for discriminator guidance that properly minimizes the KL divergence. We
analyze its properties and demonstrate empirically across multiple datasets
that our proposed method consistently improves over the conventional method by
producing samples of higher quality.","['Alexandre Verine', 'Mehdi Inane', 'Florian Le Bronnec', 'Benjamin Negrevergne', 'Yann Chevaleyre']",2025-03-20,['cs.LG'],,http://arxiv.org/pdf/2503.16117v1
2503.16107v1,Learn to Bid as a Price-Maker Wind Power Producer,"Wind power producers (WPPs) participating in short-term power markets face
significant imbalance costs due to their non-dispatchable and variable
production. While some WPPs have a large enough market share to influence
prices with their bidding decisions, existing optimal bidding methods rarely
account for this aspect. Price-maker approaches typically model bidding as a
bilevel optimization problem, but these methods require complex market models,
estimating other participants' actions, and are computationally demanding. To
address these challenges, we propose an online learning algorithm that
leverages contextual information to optimize WPP bids in the price-maker
setting. We formulate the strategic bidding problem as a contextual multi-armed
bandit, ensuring provable regret minimization. The algorithm's performance is
evaluated against various benchmark strategies using a numerical simulation of
the German day-ahead and real-time markets.","['Shobhit Singhal', 'Marta Fochesato', 'Liviu Aolaritei', 'Florian Dörfler']",2025-03-20,"['cs.LG', 'cs.SY', 'eess.SY']",,http://arxiv.org/pdf/2503.16107v1
2503.16091v1,AIMI: Leveraging Future Knowledge and Personalization in Sparse Event Forecasting for Treatment Adherence,"Adherence to prescribed treatments is crucial for individuals with chronic
conditions to avoid costly or adverse health outcomes. For certain patient
groups, intensive lifestyle interventions are vital for enhancing medication
adherence. Accurate forecasting of treatment adherence can open pathways to
developing an on-demand intervention tool, enabling timely and personalized
support. With the increasing popularity of smartphones and wearables, it is now
easier than ever to develop and deploy smart activity monitoring systems.
However, effective forecasting systems for treatment adherence based on
wearable sensors are still not widely available. We close this gap by proposing
Adherence Forecasting and Intervention with Machine Intelligence (AIMI). AIMI
is a knowledge-guided adherence forecasting system that leverages smartphone
sensors and previous medication history to estimate the likelihood of
forgetting to take a prescribed medication. A user study was conducted with 27
participants who took daily medications to manage their cardiovascular
diseases. We designed and developed CNN and LSTM-based forecasting models with
various combinations of input features and found that LSTM models can forecast
medication adherence with an accuracy of 0.932 and an F-1 score of 0.936.
Moreover, through a series of ablation studies involving convolutional and
recurrent neural network architectures, we demonstrate that leveraging known
knowledge about future and personalized training enhances the accuracy of
medication adherence forecasting. Code available:
https://github.com/ab9mamun/AIMI.","['Abdullah Mamun', 'Diane J. Cook', 'Hassan Ghasemzadeh']",2025-03-20,"['cs.LG', 'cs.AI']","15 pages, 5 figures",http://arxiv.org/pdf/2503.16091v1
2503.16086v1,Hyperspectral Imaging for Identifying Foreign Objects on Pork Belly,"Ensuring food safety and quality is critical in the food processing industry,
where the detection of contaminants remains a persistent challenge. This study
presents an automated solution for detecting foreign objects on pork belly meat
using hyperspectral imaging (HSI). A hyperspectral camera was used to capture
data across various bands in the near-infrared (NIR) spectrum (900-1700 nm),
enabling accurate identification of contaminants that are often undetectable
through traditional visual inspection methods. The proposed solution combines
pre-processing techniques with a segmentation approach based on a lightweight
Vision Transformer (ViT) to distinguish contaminants from meat, fat, and
conveyor belt materials. The adopted strategy demonstrates high detection
accuracy and training efficiency, while also addressing key industrial
challenges such as inherent noise, temperature variations, and spectral
similarity between contaminants and pork belly. Experimental results validate
the effectiveness of hyperspectral imaging in enhancing food safety,
highlighting its potential for broad real-time applications in automated
quality control processes.","['Gabriela Ghimpeteanu', 'Hayat Rajani', 'Josep Quintana', 'Rafael Garcia']",2025-03-20,"['cs.CV', 'cs.LG', 'I.2.6; I.2.10; J.7']","Article under review by Computers in Industry, Elsevier",http://arxiv.org/pdf/2503.16086v1
2503.16081v1,OThink-MR1: Stimulating multimodal generalized reasoning capabilities through dynamic reinforcement learning,"Multimodal Language Models have gained significant traction for their ability
to process diverse input data types and generate coherent, contextually
relevant outputs across various applications. While supervised fine-tuning
(SFT) has been the predominant approach to enhance MLLM capabilities in
task-specific optimization, it often falls short in fostering crucial
generalized reasoning abilities. Despite the potential of reinforcement
learning (RL) to address these limitations, it faces two issues: (1) its
generalized capabilities in multimodal tasks remain underexplored. (2) its
training constraints such as constant Kullback-Leibler or clamp strategy easily
lead to suboptimal bottleneck. To adress these issues, we introduce OThink-MR1,
a framework that extends RL to MLLMs, enabling them to achieve deeper
understanding and reasoning across multimodal tasks. We design a dynamic
Kullback-Leibler strategy that significantly enhances RL performance,
surpassing SFT in same-task evaluations. Also, we are the first to reveal that
RL exhibits remarkable cross-task generalization capabilities, which shows that
models post-trained with RL on one multimodal task can be effectively
transfered to another tasks. Finally, extensive experiments demonstrate the
great reasoning ability of our proposed OThink-MR1.","['Zhiyuan Liu', 'Yuting Zhang', 'Feng Liu', 'Changwang Zhang', 'Ying Sun', 'Jun Wang']",2025-03-20,"['cs.LG', 'cs.IR']",,http://arxiv.org/pdf/2503.16081v1
2503.16072v1,Redefining Toxicity: An Objective and Context-Aware Approach for Stress-Level-Based Detection,"The fundamental problem of toxicity detection lies in the fact that the term
""toxicity"" is ill-defined. Such uncertainty causes researchers to rely on
subjective and vague data during model training, which leads to non-robust and
inaccurate results, following the 'garbage in - garbage out' paradigm. This
study introduces a novel, objective, and context-aware framework for toxicity
detection, leveraging stress levels as a key determinant of toxicity. We
propose new definition, metric and training approach as a parts of our
framework and demonstrate it's effectiveness using a dataset we collected.","['Sergey Berezin', 'Reza Farahbakhsh', 'Noel Crespi']",2025-03-20,"['cs.LG', 'cs.AI', 'cs.CL']",,http://arxiv.org/pdf/2503.16072v1
2503.16057v1,Expert Race: A Flexible Routing Strategy for Scaling Diffusion Transformer with Mixture of Experts,"Diffusion models have emerged as mainstream framework in visual generation.
Building upon this success, the integration of Mixture of Experts (MoE) methods
has shown promise in enhancing model scalability and performance. In this
paper, we introduce Race-DiT, a novel MoE model for diffusion transformers with
a flexible routing strategy, Expert Race. By allowing tokens and experts to
compete together and select the top candidates, the model learns to dynamically
assign experts to critical tokens. Additionally, we propose per-layer
regularization to address challenges in shallow layer learning, and router
similarity loss to prevent mode collapse, ensuring better expert utilization.
Extensive experiments on ImageNet validate the effectiveness of our approach,
showcasing significant performance gains while promising scaling properties.","['Yike Yuan', 'Ziyu Wang', 'Zihao Huang', 'Defa Zhu', 'Xun Zhou', 'Jingyi Yu', 'Qiyang Min']",2025-03-20,"['cs.CV', 'cs.AI', 'cs.LG']",,http://arxiv.org/pdf/2503.16057v1
2503.16010v1,Patch-based learning of adaptive Total Variation parameter maps for blind image denoising,"We consider a patch-based learning approach defined in terms of neural
networks to estimate spatially adaptive regularisation parameter maps for image
denoising with weighted Total Variation and test it to situations when the
noise distribution is unknown. As an example, we consider situations where
noise could be either Gaussian or Poisson and perform preliminary model
selection by a standard binary classification network. Then, we define a
patch-based approach where at each image pixel an optimal weighting between TV
regularisation and the corresponding data fidelity is learned in a supervised
way using reference natural image patches upon optimisation of SSIM and in a
sliding window fashion. Extensive numerical results are reported for both noise
models, showing significant improvement w.r.t. results obtained by means of
optimal scalar regularisation.","['Claudio Fantasia', 'Luca Calatroni', 'Xavier Descombes', 'Rim Rekik']",2025-03-20,"['eess.IV', 'cs.LG', 'cs.NA', 'math.NA']",,http://arxiv.org/pdf/2503.16010v1
2503.15983v1,InhibiDistilbert: Knowledge Distillation for a ReLU and Addition-based Transformer,"This work explores optimizing transformer-based language models by
integrating model compression techniques with inhibitor attention, a novel
alternative attention mechanism. Inhibitor attention employs Manhattan
distances and ReLU activations instead of the matrix multiplications and
softmax activation of the conventional scaled dot-product attention. This shift
offers potential computational and energy savings while maintaining model
effectiveness. We propose further adjustments to improve the inhibitor
mechanism's training efficiency and evaluate its performance on the DistilBERT
architecture. Our knowledge distillation experiments indicate that the modified
inhibitor transformer model can achieve competitive performance on standard NLP
benchmarks, including General Language Understanding Evaluation (GLUE) and
sentiment analysis tasks.","['Tony Zhang', 'Rickard Brännvall']",2025-03-20,"['cs.CL', 'cs.AI', 'cs.LG', '68T50 (Primary) 68T07, 68Q32 (Secondary)', 'I.2.6; I.2.7; I.5.1']","7 pages, 2 tables",http://arxiv.org/pdf/2503.15983v1
2503.15972v1,TVineSynth: A Truncated C-Vine Copula Generator of Synthetic Tabular Data to Balance Privacy and Utility,"We propose TVineSynth, a vine copula based synthetic tabular data generator,
which is designed to balance privacy and utility, using the vine tree structure
and its truncation to do the trade-off. Contrary to synthetic data generators
that achieve DP by globally adding noise, TVineSynth performs a controlled
approximation of the estimated data generating distribution, so that it does
not suffer from poor utility of the resulting synthetic data for downstream
prediction tasks. TVineSynth introduces a targeted bias into the vine copula
model that, combined with the specific tree structure of the vine, causes the
model to zero out privacy-leaking dependencies while relying on those that are
beneficial for utility. Privacy is here measured with membership (MIA) and
attribute inference attacks (AIA). Further, we theoretically justify how the
construction of TVineSynth ensures AIA privacy under a natural privacy measure
for continuous sensitive attributes. When compared to competitor models, with
and without DP, on simulated and on real-world data, TVineSynth achieves a
superior privacy-utility balance.","['Elisabeth Griesbauer', 'Claudia Czado', 'Arnoldo Frigessi', 'Ingrid Hobæk Haff']",2025-03-20,"['cs.LG', 'stat.ML']","Accepted at the 28th International Conference on Artificial
  Intelligence and Statistics (AISTATS 2025)",http://arxiv.org/pdf/2503.15972v1
2503.15962v1,Information maximization for a broad variety of multi-armed bandit games,"Information and free-energy maximization are physics principles that provide
general rules for an agent to optimize actions in line with specific goals and
policies. These principles are the building blocks for designing
decision-making policies capable of efficient performance with only partial
information. Notably, the information maximization principle has shown
remarkable success in the classical bandit problem and has recently been shown
to yield optimal algorithms for Gaussian and sub-Gaussian reward distributions.
This article explores a broad extension of physics-based approaches to more
complex and structured bandit problems. To this end, we cover three distinct
types of bandit problems, where information maximization is adapted and leads
to strong performance. Since the main challenge of information maximization
lies in avoiding over-exploration, we highlight how information is tailored at
various levels to mitigate this issue, paving the way for more efficient and
robust decision-making strategies.","['Alex Barbier-Chebbah', 'Christian L. Vestergaard', 'Jean-Baptiste Masson']",2025-03-20,"['cs.LG', 'cond-mat.stat-mech', 'stat.ML']",,http://arxiv.org/pdf/2503.15962v1
2503.15946v1,Multivariate Time Series Anomaly Detection in Industry 5.0,"Industry5.0 environments present a critical need for effective anomaly
detection methods that can indicate equipment malfunctions, process
inefficiencies, or potential safety hazards. The ever-increasing sensorization
of manufacturing lines makes processes more observable, but also poses the
challenge of continuously analyzing vast amounts of multivariate time series
data. These challenges include data quality since data may contain noise, be
unlabeled or even mislabeled. A promising approach consists of combining an
embedding model with other Machine Learning algorithms to enhance the overall
performance in detecting anomalies. Moreover, representing time series as
vectors brings many advantages like higher flexibility and improved ability to
capture complex temporal dependencies. We tested our solution in a real
industrial use case, using data collected from a Bonfiglioli plant. The results
demonstrate that, unlike traditional reconstruction-based autoencoders, which
often struggle in the presence of sporadic noise, our embedding-based framework
maintains high performance across various noise conditions.","['Lorenzo Colombi', 'Michela Vespa', 'Nicolas Belletti', 'Matteo Brina', 'Simon Dahdal', 'Filippo Tabanelli', 'Elena Bellodi', 'Mauro Tortonesi', 'Cesare Stefanelli', 'Massimiliano Vignoli']",2025-03-20,['cs.LG'],,http://arxiv.org/pdf/2503.15946v1
2503.15928v1,Sample-Efficient Bayesian Transfer Learning for Online Machine Parameter Optimization,"Correctly setting the parameters of a production machine is essential to
improve product quality, increase efficiency, and reduce production costs while
also supporting sustainability goals. Identifying optimal parameters involves
an iterative process of producing an object and evaluating its quality.
Minimizing the number of iterations is, therefore, desirable to reduce the
costs associated with unsuccessful attempts. This work introduces a method to
optimize the machine parameters in the system itself using a \ac{BO} algorithm.
By leveraging existing machine data, we use a transfer learning approach in
order to identify an optimum with minimal iterations, resulting in a
cost-effective transfer learning algorithm. We validate our approach on a laser
machine for cutting sheet metal in the real world.","['Philipp Wagner', 'Tobias Nagel', 'Philipp Leube', 'Marco F. Huber']",2025-03-20,['cs.LG'],"Accepted in IEEE Conference on Artificial Intelligence, 2025",http://arxiv.org/pdf/2503.15928v1
2503.15918v1,Denoising-based Contractive Imitation Learning,"A fundamental challenge in imitation learning is the \emph{covariate shift}
problem. Existing methods to mitigate covariate shift often require additional
expert interactions, access to environment dynamics, or complex adversarial
training, which may not be practical in real-world applications. In this paper,
we propose a simple yet effective method (DeCIL) to mitigate covariate shift by
incorporating a denoising mechanism that enhances the contraction properties of
the state transition mapping. Our approach involves training two neural
networks: a dynamics model ( f ) that predicts the next state from the current
state, and a joint state-action denoising policy network ( d ) that refines
this state prediction via denoising and outputs the corresponding action. We
provide theoretical analysis showing that the denoising network acts as a local
contraction mapping, reducing the error propagation of the state transition and
improving stability. Our method is straightforward to implement and can be
easily integrated with existing imitation learning frameworks without requiring
additional expert data or complex modifications to the training procedure.
Empirical results demonstrate that our approach effectively improves success
rate of various imitation learning tasks under noise perturbation.","['Macheng Shen', 'Jishen Peng', 'Zefang Huang']",2025-03-20,"['cs.LG', 'cs.AI']",,http://arxiv.org/pdf/2503.15918v1
2503.15902v1,On the Limits of Applying Graph Transformers for Brain Connectome Classification,"Brain connectomes offer detailed maps of neural connections within the brain.
Recent studies have proposed novel connectome graph datasets and attempted to
improve connectome classification by using graph deep learning. With recent
advances demonstrating transformers' ability to model intricate relationships
and outperform in various domains, this work explores their performance on the
novel NeuroGraph benchmark datasets and synthetic variants derived from
probabilistically removing edges to simulate noisy data. Our findings suggest
that graph transformers offer no major advantage over traditional GNNs on this
dataset. Furthermore, both traditional and transformer GNN models maintain
accuracy even with all edges removed, suggesting that the dataset's graph
structures may not significantly impact predictions. We propose further
assessing NeuroGraph as a brain connectome benchmark, emphasizing the need for
well-curated datasets and improved preprocessing strategies to obtain
meaningful edge connections.","['Jose Lara-Rangel', 'Clare Heinbaugh']",2025-03-20,['cs.LG'],,http://arxiv.org/pdf/2503.15902v1
2503.15901v1,A multi-model approach using XAI and anomaly detection to predict asteroid hazards,"The potential for catastrophic collision makes near-Earth asteroids (NEAs) a
serious concern. Planetary defense depends on accurately classifying
potentially hazardous asteroids (PHAs), however the complexity of the data
hampers conventional techniques. This work offers a sophisticated method for
accurately predicting hazards by combining machine learning, deep learning,
explainable AI (XAI), and anomaly detection. Our approach extracts essential
parameters like size, velocity, and trajectory from historical and real-time
asteroid data. A hybrid algorithm improves prediction accuracy by combining
several cutting-edge models. A forecasting module predicts future asteroid
behavior, and Monte Carlo simulations evaluate the likelihood of collisions.
Timely mitigation is made possible by a real-time alarm system that notifies
worldwide monitoring stations. This technique enhances planetary defense
efforts by combining real-time alarms with sophisticated predictive modeling.","['Amit Kumar Mondal', 'Nafisha Aslam', 'Prasenjit Maji', 'Hemanta Kumar Mondal']",2025-03-20,"['astro-ph.EP', 'astro-ph.IM', 'cs.AI', 'cs.LG']","17 pages, 12 figures",http://arxiv.org/pdf/2503.15901v1
2503.15897v1,Learning 3D Scene Analogies with Neural Contextual Scene Maps,"Understanding scene contexts is crucial for machines to perform tasks and
adapt prior knowledge in unseen or noisy 3D environments. As data-driven
learning is intractable to comprehensively encapsulate diverse ranges of
layouts and open spaces, we propose teaching machines to identify relational
commonalities in 3D spaces. Instead of focusing on point-wise or object-wise
representations, we introduce 3D scene analogies, which are smooth maps between
3D scene regions that align spatial relationships. Unlike well-studied single
instance-level maps, these scene-level maps smoothly link large scene regions,
potentially enabling unique applications in trajectory transfer in AR/VR, long
demonstration transfer for imitation learning, and context-aware object
rearrangement. To find 3D scene analogies, we propose neural contextual scene
maps, which extract descriptor fields summarizing semantic and geometric
contexts, and holistically align them in a coarse-to-fine manner for map
estimation. This approach reduces reliance on individual feature points, making
it robust to input noise or shape variations. Experiments demonstrate the
effectiveness of our approach in identifying scene analogies and transferring
trajectories or object placements in diverse indoor scenes, indicating its
potential for robotics and AR/VR applications.","['Junho Kim', 'Gwangtak Bae', 'Eun Sun Lee', 'Young Min Kim']",2025-03-20,"['cs.CV', 'cs.LG']",,http://arxiv.org/pdf/2503.15897v1
2503.15890v1,Time After Time: Deep-Q Effect Estimation for Interventions on When and What to do,"Problems in fields such as healthcare, robotics, and finance requires
reasoning about the value both of what decision or action to take and when to
take it. The prevailing hope is that artificial intelligence will support such
decisions by estimating the causal effect of policies such as how to treat
patients or how to allocate resources over time. However, existing methods for
estimating the effect of a policy struggle with \emph{irregular time}. They
either discretize time, or disregard the effect of timing policies. We present
a new deep-Q algorithm that estimates the effect of both when and what to do
called Earliest Disagreement Q-Evaluation (EDQ). EDQ makes use of recursion for
the Q-function that is compatible with flexible sequence models, such as
transformers. EDQ provides accurate estimates under standard assumptions. We
validate the approach through experiments on survival time and tumor growth
tasks.","['Yoav Wald', 'Mark Goldstein', 'Yonathan Efroni', 'Wouter A. C. van Amsterdam', 'Rajesh Ranganath']",2025-03-20,"['cs.LG', 'cs.AI']",,http://arxiv.org/pdf/2503.15890v1
2503.15889v1,LeanTTA: A Backpropagation-Free and Stateless Approach to Quantized Test-Time Adaptation on Edge Devices,"While there are many advantages to deploying machine learning models on edge
devices, the resource constraints of mobile platforms, the dynamic nature of
the environment, and differences between the distribution of training versus
in-the-wild data make such deployments challenging. Current test-time
adaptation methods are often memory-intensive and not designed to be
quantization-compatible or deployed on low-resource devices. To address these
challenges, we present LeanTTA, a novel backpropagation-free and stateless
framework for quantized test-time adaptation tailored to edge devices. Our
approach minimizes computational costs by dynamically updating normalization
statistics without backpropagation, which frees LeanTTA from the common pitfall
of relying on large batches and historical data, making our method robust to
realistic deployment scenarios. Our approach is the first to enable further
computational gains by combining partial adaptation with quantized module
fusion. We validate our framework across sensor modalities, demonstrating
significant improvements over state-of-the-art TTA methods, including a 15.7%
error reduction, peak memory usage of only 11.2MB for ResNet18, and fast
adaptation within an order-of-magnitude of normal inference speeds on-device.
LeanTTA provides a robust solution for achieving the right trade offs between
accuracy and system efficiency in edge deployments, addressing the unique
challenges posed by limited data and varied operational conditions.","['Cynthia Dong', 'Hong Jia', 'Young D. Kwon', 'Georgios Rizos', 'Cecilia Mascolo']",2025-03-20,"['cs.LG', 'cs.AI']","8 pages, 5 figures",http://arxiv.org/pdf/2503.15889v1
2503.15886v1,Enhancing Zero-Shot Image Recognition in Vision-Language Models through Human-like Concept Guidance,"In zero-shot image recognition tasks, humans demonstrate remarkable
flexibility in classifying unseen categories by composing known simpler
concepts. However, existing vision-language models (VLMs), despite achieving
significant progress through large-scale natural language supervision, often
underperform in real-world applications because of sub-optimal prompt
engineering and the inability to adapt effectively to target classes. To
address these issues, we propose a Concept-guided Human-like Bayesian Reasoning
(CHBR) framework. Grounded in Bayes' theorem, CHBR models the concept used in
human image recognition as latent variables and formulates this task by summing
across potential concepts, weighted by a prior distribution and a likelihood
function. To tackle the intractable computation over an infinite concept space,
we introduce an importance sampling algorithm that iteratively prompts large
language models (LLMs) to generate discriminative concepts, emphasizing
inter-class differences. We further propose three heuristic approaches
involving Average Likelihood, Confidence Likelihood, and Test Time Augmentation
(TTA) Likelihood, which dynamically refine the combination of concepts based on
the test image. Extensive evaluations across fifteen datasets demonstrate that
CHBR consistently outperforms existing state-of-the-art zero-shot
generalization methods.","['Hui Liu', 'Wenya Wang', 'Kecheng Chen', 'Jie Liu', 'Yibing Liu', 'Tiexin Qin', 'Peisong He', 'Xinghao Jiang', 'Haoliang Li']",2025-03-20,"['cs.CV', 'cs.LG']","21 pages, 7 figures 7 tables",http://arxiv.org/pdf/2503.15886v1
2503.15880v1,InCo-DPO: Balancing Distribution Shift and Data Quality for Enhanced Preference Optimization,"Direct Preference Optimization (DPO) optimizes language models to align with
human preferences. Utilizing on-policy samples, generated directly by the
policy model, typically results in better performance due to its distribution
consistency with the model compared to off-policy samples. This paper
identifies the quality of candidate preference samples as another critical
factor. While the quality of on-policy data is inherently constrained by the
capabilities of the policy model, off-policy data, which can be derived from
diverse sources, offers greater potential for quality despite experiencing
distribution shifts. However, current research mostly relies on on-policy data
and neglects the value of off-policy data in terms of data quality, due to the
challenge posed by distribution shift. In this paper, we propose InCo-DPO, an
efficient method for synthesizing preference data by integrating on-policy and
off-policy data, allowing dynamic adjustments to balance distribution shifts
and data quality, thus finding an optimal trade-off. Consequently, InCo-DPO
overcomes the limitations of distribution shifts in off-policy data and the
quality constraints of on-policy data. We evaluated InCo-DPO with the
Alpaca-Eval 2.0 and Arena-Hard benchmarks. Experimental results demonstrate
that our approach not only outperforms both on-policy and off-policy data but
also achieves a state-of-the-art win rate of 60.8 on Arena-Hard with the
vanilla DPO using Gemma-2 model.","['Yunan Wang', 'Jijie Li', 'Bo-Wen Zhang', 'Liangdong Wang', 'Guang Liu']",2025-03-20,"['cs.LG', 'cs.CL']",,http://arxiv.org/pdf/2503.15880v1
2503.15870v1,FedSAF: A Federated Learning Framework for Enhanced Gastric Cancer Detection and Privacy Preservation,"Gastric cancer is one of the most commonly diagnosed cancers and has a high
mortality rate. Due to limited medical resources, developing machine learning
models for gastric cancer recognition provides an efficient solution for
medical institutions. However, such models typically require large sample sizes
for training and testing, which can challenge patient privacy. Federated
learning offers an effective alternative by enabling model training across
multiple institutions without sharing sensitive patient data. This paper
addresses the limited sample size of publicly available gastric cancer data
with a modified data processing method. This paper introduces FedSAF, a novel
federated learning algorithm designed to improve the performance of existing
methods, particularly in non-independent and identically distributed (non-IID)
data scenarios. FedSAF incorporates attention-based message passing and the
Fisher Information Matrix to enhance model accuracy, while a model splitting
function reduces computation and transmission costs. Hyperparameter tuning and
ablation studies demonstrate the effectiveness of this new algorithm, showing
improvements in test accuracy on gastric cancer datasets, with FedSAF
outperforming existing federated learning methods like FedAMP, FedAvg, and
FedProx. The framework's robustness and generalization ability were further
validated across additional datasets (SEED, BOT, FashionMNIST, and CIFAR-10),
achieving high performance in diverse environments.","['Yuxin Miao', 'Xinyuan Yang', 'Hongda Fan', 'Yichun Li', 'Yishu Hong', 'Xiechen Guo', 'Ali Braytee', 'Weidong Huang', 'Ali Anaissi']",2025-03-20,['cs.LG'],,http://arxiv.org/pdf/2503.15870v1
2503.15865v1,Active management of battery degradation in wireless sensor network using deep reinforcement learning for group battery replacement,"Wireless sensor networks (WSNs) have become a promising solution for
structural health monitoring (SHM), especially in hard-to-reach or remote
locations. Battery-powered WSNs offer various advantages over wired systems,
however limited battery life has always been one of the biggest obstacles in
practical use of the WSNs, regardless of energy harvesting methods. While
various methods have been studied for battery health management, existing
methods exclusively aim to extend lifetime of individual batteries, lacking a
system level view. A consequence of applying such methods is that batteries in
a WSN tend to fail at different times, posing significant difficulty on
planning and scheduling of battery replacement trip. This study investigate a
deep reinforcement learning (DRL) method for active battery degradation
management by optimizing duty cycle of WSNs at the system level. This active
management strategy effectively reduces earlier failure of battery individuals
which enable group replacement without sacrificing WSN performances. A
simulated environment based on a real-world WSN setup was developed to train a
DRL agent and learn optimal duty cycle strategies. The performance of the
strategy was validated in a long-term setup with various network sizes,
demonstrating its efficiency and scalability.","['Jong-Hyun Jeonga', 'Hongki Jo', 'Qiang Zhou', 'Tahsin Afroz Hoque Nishat', 'Lang Wu']",2025-03-20,"['cs.LG', 'cs.AI']",,http://arxiv.org/pdf/2503.15865v1
2503.15853v1,Network Embedding Exploration Tool (NEExT),"Many real-world and artificial systems and processes can be represented as
graphs. Some examples of such systems include social networks, financial
transactions, supply chains, and molecular structures. In many of these cases,
one needs to consider a collection of graphs, rather than a single network.
This could be a collection of distinct but related graphs, such as different
protein structures or graphs resulting from dynamic processes on the same
network. Examples of the latter include the evolution of social networks,
community-induced graphs, or ego-nets around various nodes. A significant
challenge commonly encountered is the absence of ground-truth labels for graphs
or nodes, necessitating the use of unsupervised techniques to analyze such
systems. Moreover, even when ground-truth labels are available, many existing
graph machine learning methods depend on complex deep learning models,
complicating model explainability and interpretability. To address some of
these challenges, we have introduced NEExT (Network Embedding Exploration Tool)
for embedding collections of graphs via user-defined node features. The
advantages of the framework are twofold: (i) the ability to easily define your
own interpretable node-based features in view of the task at hand, and (ii)
fast embedding of graphs provided by the Vectorizers library. In this paper, we
demonstrate the usefulness of NEExT on collections of synthetic and real-world
graphs. For supervised tasks, we demonstrate that performance in graph
classification tasks could be achieved similarly to other state-of-the-art
techniques while maintaining model interpretability. Furthermore, our framework
can also be used to generate high-quality embeddings in an unsupervised way,
where target variables are not available.","['Ashkan Dehghan', 'Paweł Prałat', 'François Théberge']",2025-03-20,['cs.LG'],"24 pages, 10 figures",http://arxiv.org/pdf/2503.15853v1
2503.15845v1,Network-wide Freeway Traffic Estimation Using Sparse Sensor Data: A Dirichlet Graph Auto-Encoder Approach,"Network-wide Traffic State Estimation (TSE), which aims to infer a complete
image of network traffic states with sparsely deployed sensors, plays a vital
role in intelligent transportation systems. With the development of data-driven
methods, traffic dynamics modeling has advanced significantly. However, TSE
poses fundamental challenges for data-driven approaches, since historical
patterns cannot be learned locally at sensor-free segments. Although inductive
graph learning shows promise in estimating states at locations without sensor,
existing methods typically handle unobserved locations by filling them with
zeros, introducing bias to the sensitive graph message propagation. The
recently proposed Dirichlet Energy-based Feature Propagation (DEFP) method
achieves State-Of-The-Art (SOTA) performance in unobserved node classification
by eliminating the need for zero-filling. However, applying it to TSE faces
three key challenges: inability to handle directed traffic networks, strong
assumptions in traffic spatial correlation modeling, and overlooks distinct
propagation rules of different patterns (e.g., congestion and free flow). We
propose DGAE, a novel inductive graph representation model that addresses these
challenges through theoretically derived DEFP for Directed graph (DEFP4D),
enhanced spatial representation learning via DEFP4D-guided latent space
encoding, and physics-guided propagation mechanisms that separately handles
congested and free-flow patterns. Experiments on three traffic datasets
demonstrate that DGAE outperforms existing SOTA methods and exhibits strong
cross-city transferability. Furthermore, DEFP4D can serve as a standalone
lightweight solution, showing superior performance under extremely sparse
sensor conditions.","['Qishen Zhou', 'Yifan Zhang', 'Michail A. Makridis', 'Anastasios Kouvelas', 'Yibing Wang', 'Simon Hu']",2025-03-20,['cs.LG'],This work has been submitted to the IEEE for possible publication,http://arxiv.org/pdf/2503.15845v1
2503.15842v1,FedAWA: Adaptive Optimization of Aggregation Weights in Federated Learning Using Client Vectors,"Federated Learning (FL) has emerged as a promising framework for distributed
machine learning, enabling collaborative model training without sharing local
data, thereby preserving privacy and enhancing security. However, data
heterogeneity resulting from differences across user behaviors, preferences,
and device characteristics poses a significant challenge for federated
learning. Most previous works overlook the adjustment of aggregation weights,
relying solely on dataset size for weight assignment, which often leads to
unstable convergence and reduced model performance. Recently, several studies
have sought to refine aggregation strategies by incorporating dataset
characteristics and model alignment. However, adaptively adjusting aggregation
weights while ensuring data security-without requiring additional proxy
data-remains a significant challenge. In this work, we propose Federated
learning with Adaptive Weight Aggregation (FedAWA), a novel method that
adaptively adjusts aggregation weights based on client vectors during the
learning process. The client vector captures the direction of model updates,
reflecting local data variations, and is used to optimize the aggregation
weight without requiring additional datasets or violating privacy. By assigning
higher aggregation weights to local models whose updates align closely with the
global optimization direction, FedAWA enhances the stability and generalization
of the global model. Extensive experiments under diverse scenarios demonstrate
the superiority of our method, providing a promising solution to the challenges
of data heterogeneity in federated learning.","['Changlong Shi', 'He Zhao', 'Bingjie Zhang', 'Mingyuan Zhou', 'Dandan Guo', 'Yi Chang']",2025-03-20,['cs.LG'],Accepted in CVPR 2025,http://arxiv.org/pdf/2503.15842v1
2503.15822v1,Energy-Efficient Federated Learning and Migration in Digital Twin Edge Networks,"The digital twin edge network (DITEN) is a significant paradigm in the
sixth-generation wireless system (6G) that aims to organize well-developed
infrastructures to meet the requirements of evolving application scenarios.
However, the impact of the interaction between the long-term DITEN maintenance
and detailed digital twin tasks, which often entail privacy considerations, is
commonly overlooked in current research. This paper addresses this issue by
introducing a problem of digital twin association and historical data
allocation for a federated learning (FL) task within DITEN. To achieve this
goal, we start by introducing a closed-form function to predict the training
accuracy of the FL task, referring to it as the data utility. Subsequently, we
carry out comprehensive convergence analyses on the proposed FL methodology.
Our objective is to jointly optimize the data utility of the digital
twin-empowered FL task and the energy costs incurred by the long-term DITEN
maintenance, encompassing FL model training, data synchronization, and twin
migration. To tackle the aforementioned challenge, we present an
optimization-driven learning algorithm that effectively identifies optimized
solutions for the formulated problem. Numerical results demonstrate that our
proposed algorithm outperforms various baseline approaches.","['Yuzhi Zhou', 'Yaru Fu', 'Zheng Shi', 'Howard H. Yang', 'Kevin Hung', 'Yan Zhang']",2025-03-20,"['cs.NI', 'cs.LG']",,http://arxiv.org/pdf/2503.15822v1
2503.15819v1,Control Pneumatic Soft Bending Actuator with Online Learning Pneumatic Physical Reservoir Computing,"The intrinsic nonlinearities of soft robots present significant control but
simultaneously provide them with rich computational potential. Reservoir
computing (RC) has shown effectiveness in online learning systems for
controlling nonlinear systems such as soft actuators. Conventional RC can be
extended into physical reservoir computing (PRC) by leveraging the nonlinear
dynamics of soft actuators for computation. This paper introduces a PRC-based
online learning framework to control the motion of a pneumatic soft bending
actuator, utilizing another pneumatic soft actuator as the PRC model. Unlike
conventional designs requiring two RC models, the proposed control system
employs a more compact architecture with a single RC model. Additionally, the
framework enables zero-shot online learning, addressing limitations of previous
PRC-based control systems reliant on offline training. Simulations and
experiments validated the performance of the proposed system. Experimental
results indicate that the PRC model achieved superior control performance
compared to a linear model, reducing the root-mean-square error (RMSE) by an
average of over 37% in bending motion control tasks. The proposed PRC-based
online learning control framework provides a novel approach for harnessing
physical systems' inherent nonlinearities to enhance the control of soft
actuators.","['Junyi Shen', 'Tetsuro Miyazaki', 'Kenji Kawashima']",2025-03-20,"['cs.RO', 'cs.LG', 'cs.SY', 'eess.SY']","8 pages, 13 figures, IEEE-RAS International Conference on Soft
  Robotics (RoboSoft 2025)",http://arxiv.org/pdf/2503.15819v1
2503.15810v1,Big data comparison of quantum invariants,"We apply big data techniques, including exploratory and topological data
analysis, to investigate quantum invariants. More precisely, our study explores
the Jones polynomial's structural properties and contrasts its behavior under
four principal methods of enhancement: coloring, rank increase,
categorification, and leaving the realm of Lie algebras.","['Daniel Tubbenhauer', 'Victor Zhang']",2025-03-20,"['math.GT', 'cs.LG', 'math.QA', 'Primary: 57K16, 62R07, secondary: 57K18, 68P05']","26 pages, many figures, comments welcome",http://arxiv.org/pdf/2503.15810v1
2503.15804v1,Communication Efficient Federated Learning with Linear Convergence on Heterogeneous Data,"By letting local clients perform multiple local updates before communicating
with a parameter server, modern federated learning algorithms such as FedAvg
tackle the communication bottleneck problem in distributed learning and have
found many successful applications. However, this asynchrony between local
updates and communication also leads to a ''client-drift'' problem when the
data is heterogeneous (not independent and identically distributed), resulting
in errors in the final learning result. In this paper, we propose a federated
learning algorithm, which is called FedCET, to ensure accurate convergence even
under heterogeneous distributions of data across clients. Inspired by the
distributed optimization algorithm NIDS, we use learning rates to weight
information received from local clients to eliminate the ''client-drift''. We
prove that under appropriate learning rates, FedCET can ensure linear
convergence to the exact solution. Different from existing algorithms which
have to share both gradients and a drift-correction term to ensure accurate
convergence under heterogeneous data distributions, FedCET only shares one
variable, which significantly reduces communication overhead. Numerical
comparison with existing counterpart algorithms confirms the effectiveness of
FedCET.","['Jie Liu', 'Yongqiang Wang']",2025-03-20,"['cs.LG', 'math.OC']",,http://arxiv.org/pdf/2503.15804v1
2503.15801v1,Disentangling Uncertainties by Learning Compressed Data Representation,"We study aleatoric and epistemic uncertainty estimation in a learned
regressive system dynamics model. Disentangling aleatoric uncertainty (the
inherent randomness of the system) from epistemic uncertainty (the lack of
data) is crucial for downstream tasks such as risk-aware control and
reinforcement learning, efficient exploration, and robust policy transfer.
While existing approaches like Gaussian Processes, Bayesian networks, and model
ensembles are widely adopted, they suffer from either high computational
complexity or inaccurate uncertainty estimation. To address these limitations,
we propose the Compressed Data Representation Model (CDRM), a framework that
learns a neural network encoding of the data distribution and enables direct
sampling from the output distribution. Our approach incorporates a novel
inference procedure based on Langevin dynamics sampling, allowing CDRM to
predict arbitrary output distributions rather than being constrained to a
Gaussian prior. Theoretical analysis provides the conditions where CDRM
achieves better memory and computational complexity compared to bin-based
compression methods. Empirical evaluations show that CDRM demonstrates a
superior capability to identify aleatoric and epistemic uncertainties
separately, achieving AUROCs of 0.8876 and 0.9981 on a single test set
containing a mixture of both uncertainties. Qualitative results further show
that CDRM's capability extends to datasets with multimodal output
distributions, a challenging scenario where existing methods consistently fail.
Code and supplementary materials are available at
https://github.com/ryeii/CDRM.","['Zhiyu An', 'Zhibo Hou', 'Wan Du']",2025-03-20,['cs.LG'],"Accepted by the 7th Annual Learning for Dynamics & Control Conference
  (L4DC) 2025",http://arxiv.org/pdf/2503.15801v1
2503.15798v1,Mixture of Lookup Experts,"Mixture-of-Experts (MoE) activates only a subset of experts during inference,
allowing the model to maintain low inference FLOPs and latency even as the
parameter count scales up. However, since MoE dynamically selects the experts,
all the experts need to be loaded into VRAM. Their large parameter size still
limits deployment, and offloading, which load experts into VRAM only when
needed, significantly increase inference latency. To address this, we propose
Mixture of Lookup Experts (MoLE), a new MoE architecture that is efficient in
both communication and VRAM usage. In MoLE, the experts are Feed-Forward
Networks (FFNs) during training, taking the output of the embedding layer as
input. Before inference, these experts can be re-parameterized as lookup tables
(LUTs) that retrieves expert outputs based on input ids, and offloaded to
storage devices. Therefore, we do not need to perform expert computations
during inference. Instead, we directly retrieve the expert's computation
results based on input ids and load them into VRAM, and thus the resulting
communication overhead is negligible. Experiments show that, with the same
FLOPs and VRAM usage, MoLE achieves inference speeds comparable to dense models
and significantly faster than MoE with experts offloading, while maintaining
performance on par with MoE.","['Shibo Jie', 'Yehui Tang', 'Kai Han', 'Yitong Li', 'Duyu Tang', 'Zhi-Hong Deng', 'Yunhe Wang']",2025-03-20,"['cs.LG', 'cs.CL']",,http://arxiv.org/pdf/2503.15798v1
2503.15796v1,Blend the Separated: Mixture of Synergistic Experts for Data-Scarcity Drug-Target Interaction Prediction,"Drug-target interaction prediction (DTI) is essential in various applications
including drug discovery and clinical application. There are two perspectives
of input data widely used in DTI prediction: Intrinsic data represents how
drugs or targets are constructed, and extrinsic data represents how drugs or
targets are related to other biological entities. However, any of the two
perspectives of input data can be scarce for some drugs or targets, especially
for those unpopular or newly discovered. Furthermore, ground-truth labels for
specific interaction types can also be scarce. Therefore, we propose the first
method to tackle DTI prediction under input data and/or label scarcity. To make
our model functional when only one perspective of input data is available, we
design two separate experts to process intrinsic and extrinsic data
respectively and fuse them adaptively according to different samples.
Furthermore, to make the two perspectives complement each other and remedy
label scarcity, two experts synergize with each other in a mutually supervised
way to exploit the enormous unlabeled data. Extensive experiments on 3
real-world datasets under different extents of input data scarcity and/or label
scarcity demonstrate our model outperforms states of the art significantly and
steadily, with a maximum improvement of 53.53%. We also test our model without
any data scarcity and it still outperforms current methods.","['Xinlong Zhai', 'Chunchen Wang', 'Ruijia Wang', 'Jiazheng Kang', 'Shujie Li', 'Boyu Chen', 'Tengfei Ma', 'Zikai Zhou', 'Cheng Yang', 'Chuan Shi']",2025-03-20,"['cs.LG', 'cs.AI']",,http://arxiv.org/pdf/2503.15796v1
2503.15793v1,DNA Bench: When Silence is Smarter -- Benchmarking Over-Reasoning in Reasoning LLMs,"Test-time scaling has significantly improved large language model
performance, enabling deeper reasoning to solve complex problems. However, this
increased reasoning capability also leads to excessive token generation and
unnecessary problem-solving attempts. We introduce Don\'t Answer Bench (DNA
Bench), a new benchmark designed to evaluate LLMs ability to robustly
understand the tricky reasoning triggers and avoiding unnecessary generation.
DNA Bench consists of 150 adversarially designed prompts that are easy for
humans to understand and respond to, but surprisingly not for many of the
recent prominent LLMs. DNA Bench tests models abilities across different
capabilities, such as instruction adherence, hallucination avoidance,
redundancy filtering, and unanswerable question recognition. We evaluate
reasoning LLMs (RLMs), including DeepSeek-R1, OpenAI O3-mini, Claude-3.7-sonnet
and compare them against a powerful non-reasoning model, e.g., GPT-4o. Our
experiments reveal that RLMs generate up to 70x more tokens than necessary,
often failing at tasks that simpler non-reasoning models handle efficiently
with higher accuracy. Our findings underscore the need for more effective
training and inference strategies in RLMs.","['Masoud Hashemi', 'Oluwanifemi Bamgbose', 'Sathwik Tejaswi Madhusudhan', 'Jishnu Sethumadhavan Nair', 'Aman Tiwari', 'Vikas Yadav']",2025-03-20,['cs.LG'],,http://arxiv.org/pdf/2503.15793v1
2503.15779v1,MobiFuse: Learning Universal Human Mobility Patterns through Cross-domain Data Fusion,"Human mobility modeling is critical for urban planning and transportation
management, yet existing datasets often lack the resolution and semantic
richness required for comprehensive analysis. To address this, we proposed a
cross-domain data fusion framework that integrates multi-modal data of distinct
nature and spatio-temporal resolution, including geographical, mobility,
socio-demographic, and traffic information, to construct a privacy-preserving
and semantically enriched human travel trajectory dataset. This framework is
demonstrated through two case studies in Los Angeles (LA) and Egypt, where a
domain adaptation algorithm ensures its transferability across diverse urban
contexts. Quantitative evaluation shows that the generated synthetic dataset
accurately reproduces mobility patterns observed in empirical data. Moreover,
large-scale traffic simulations for LA County based on the generated synthetic
demand align well with observed traffic. On California's I-405 corridor, the
simulation yields a Mean Absolute Percentage Error of 5.85% for traffic volume
and 4.36% for speed compared to Caltrans PeMS observations.","['Haoxuan Ma', 'Xishun Liao', 'Yifan Liu', 'Qinhua Jiang', 'Chris Stanford', 'Shangqing Cao', 'Jiaqi Ma']",2025-03-20,"['cs.LG', 'cs.AI']",,http://arxiv.org/pdf/2503.15779v1
2503.15777v1,Line Space Clustering (LSC): Feature-Based Clustering using K-medians and Dynamic Time Warping for Versatility,"Clustering high-dimensional data is a critical challenge in machine learning
due to the curse of dimensionality and the presence of noise. Traditional
clustering algorithms often fail to capture the intrinsic structures in such
data. This paper explores a combination of clustering methods, which we called
Line Space Clustering (LSC), a representation that transforms data points into
lines in a newly defined feature space, enabling clustering based on the
similarity of feature value patterns, essentially treating features as
sequences. LSC employs a combined distance metric that uses Euclidean and
Dynamic Time Warping (DTW) distances, weighted by a parameter {\alpha},
allowing flexibility in emphasizing shape or magnitude similarities. We delve
deeply into the mechanics of DTW and the Savitzky Golay filter, explaining
their roles in the algorithm. Extensive experiments demonstrate the efficacy of
LSC on synthetic and real-world datasets, showing that randomly experimenting
with time-series optimized methods sometimes might surprisingly work on a
complex dataset, particularly in noisy environments.
  Source code and experiments are available at:
https://github.com/JoanikijChulev/LSC.","['Joanikij Chulev', 'Angela Mladenovska']",2025-03-20,['cs.LG'],"8 pages, 5 figures, 3 tables",http://arxiv.org/pdf/2503.15777v1
2503.15769v1,Prediction of Permissioned Blockchain Performance for Resource Scaling Configurations,"Blockchain is increasingly offered as blockchain-as-a-service (BaaS) by cloud
service providers. However, configuring BaaS appropriately for optimal
performance and reliability resorts to try-and-error. A key challenge is that
BaaS is often perceived as a ``black-box,'' leading to uncertainties in
performance and resource provisioning. Previous studies attempted to address
this challenge; however, the impacts of both vertical and horizontal scaling
remain elusive. To this end, we present machine learning-based models to
predict network reliability and throughput based on scaling configurations. In
our evaluation, the models exhibit prediction errors of ~1.9%, which is highly
accurate and can be applied in the real-world.","['Seungwoo Jung', 'Yeonho Yoo', 'Gyeongsik Yang', 'Chuck Yoo']",2025-03-20,"['cs.DC', 'cs.LG', 'cs.SY', 'eess.SY']",,http://arxiv.org/pdf/2503.15769v1
2503.15766v1,Accelerating Transient CFD through Machine Learning-Based Flow Initialization,"Transient computational fluid dynamics (CFD) simulations are essential for
many industrial applications, but a significant portion of their computational
cost stems from the time needed to reach statistical steadiness from initial
conditions. We present a novel machine learning-based initialization method
that reduces the cost of this subsequent transient solve substantially,
achieving a 50% reduction in time-to-convergence compared to traditional
uniform and potential flow-based initializations. Through a case study in
automotive aerodynamics using a 16.7M-cell unsteady RANS simulation, we
evaluate three ML-based initialization strategies. Two of these strategies are
recommended for general use: (1) a physics-informed hybrid method combining ML
predictions with potential flow solutions, and (2) a more versatile approach
integrating ML predictions with uniform flow. Both strategies enable CFD
solvers to achieve convergence times comparable to computationally expensive
steady RANS initializations, while requiring only seconds of computation. We
develop a robust statistical convergence metric based on windowed
time-averaging for performance comparison between initialization strategies.
Notably, these improvements are achieved using an ML model trained on a
different dataset of automotive geometries, demonstrating strong generalization
capabilities. The proposed methods integrate seamlessly with existing CFD
workflows without requiring modifications to the underlying flow solver,
providing a practical approach to accelerating industrial CFD simulations
through improved ML-based initialization strategies.","['Peter Sharpe', 'Rishikesh Ranade', 'Sanjay Choudhry']",2025-03-20,"['cs.LG', 'physics.flu-dyn']","17 pages, 8 figures",http://arxiv.org/pdf/2503.15766v1
2503.15758v1,ATTENTION2D: Communication Efficient Distributed Self-Attention Mechanism,"Transformer-based models have emerged as a leading architecture for natural
language processing, natural language generation, and image generation tasks. A
fundamental element of the transformer architecture is self-attention, which
allows the model to capture intricate dependencies within the data. However,
the self-attention mechanism also incurs significant computational and memory
costs, particularly for long sequences.
  In this paper, we introduce ATTENTION2D, a novel approach that exploits
parallelism along two dimensions - query and key/value - of the self-attention
operation. This method enables efficient distribution and parallelization of
computations across multiple devices. Our approach facilitates asymptotically
faster training and inference phases compared to previous methods, without
relying on approximations or incurring additional computational or memory
overheads. Furthermore, unlike existing techniques that struggle to scale with
an increasing number of processing units, our approach effectively scales with
additional processing units.
  Our experimental results confirm the effectiveness of our method in improving
communication efficiency and scalability. Compared to Ring Attention, our
approach demonstrated up to a 5x performance boost on a GPT-3-like model using
64 NVIDIA A100 GPUs across 16 nodes, and up to a 9.4x performance boost on 64
NVIDIA H100 GPUs across 64 nodes.",['Venmugil Elango'],2025-03-20,"['cs.LG', 'cs.AI', 'cs.DC']",,http://arxiv.org/pdf/2503.15758v1
2503.15748v1,PARQ: Piecewise-Affine Regularized Quantization,"We develop a principled method for quantization-aware training (QAT) of
large-scale machine learning models. Specifically, we show that convex,
piecewise-affine regularization (PAR) can effectively induce the model
parameters to cluster towards discrete values. We minimize PAR-regularized loss
functions using an aggregate proximal stochastic gradient method (AProx) and
prove that it has last-iterate convergence. Our approach provides an
interpretation of the straight-through estimator (STE), a widely used heuristic
for QAT, as the asymptotic form of PARQ. We conduct experiments to demonstrate
that PARQ obtains competitive performance on convolution- and transformer-based
vision tasks.","['Lisa Jin', 'Jianhao Ma', 'Zechun Liu', 'Andrey Gromov', 'Aaron Defazio', 'Lin Xiao']",2025-03-19,"['cs.LG', 'math.OC']",,http://arxiv.org/pdf/2503.15748v1
2503.15706v1,Using machine learning to map simulated noisy and laser-limited multidimensional spectra to molecular electronic couplings,"Two-dimensional electronic spectroscopy (2DES) has enabled significant
discoveries in both biological and synthetic energy-transducing systems.
Although deriving chemical information from 2DES is a complex task, machine
learning (ML) offers exciting opportunities to translate complicated
spectroscopic data into physical insight. Recent studies have found that neural
networks (NNs) can map simulated multidimensional spectra to molecular-scale
properties with high accuracy. However, simulations often do not capture
experimental factors that influence real spectra, including noise and
suboptimal pulse resonance conditions, bringing into question the experimental
utility of NNs trained on simulated data. Here, we show how factors associated
with experimental 2D spectral data influence the ability of NNs to map
simulated 2DES spectra onto underlying intermolecular electronic couplings. By
systematically introducing multisourced noise into a library of 356000
simulated 2D spectra, we show that noise does not hamper NN performance for
spectra exceeding threshold signal-to-noise ratios (SNR) (> 6.6 if background
noise dominates vs. > 2.5 for intensity-dependent noise). In stark contrast to
human-based analyses of 2DES data, we find that the NN accuracy improves
significantly (ca. 84% $\rightarrow$ 96%) when the data are constrained by the
bandwidth and center frequency of the pump pulses. This result is consistent
with the NN learning the optical trends described by Kasha's theory of
molecular excitons. Our findings convey positive prospects for adapting
simulation-trained NNs to extract molecular properties from inherently
imperfect experimental 2DES data. More broadly, we propose that machine-learned
perspectives of nonlinear spectroscopic data may produce unique and, perhaps,
counterintuitive guidelines for experimental design.","['Jonathan D. Schultz', 'Kelsey A. Parker', 'Bashir Sbaiti', 'David N. Beratan']",2025-03-19,"['physics.chem-ph', 'cs.LG', 'quant-ph']","24 pages, 15 figures",http://arxiv.org/pdf/2503.15706v1
2503.15704v1,Tuning Sequential Monte Carlo Samplers via Greedy Incremental Divergence Minimization,"The performance of sequential Monte Carlo (SMC) samplers heavily depends on
the tuning of the Markov kernels used in the path proposal. For SMC samplers
with unadjusted Markov kernels, standard tuning objectives, such as the
Metropolis-Hastings acceptance rate or the expected-squared jump distance, are
no longer applicable. While stochastic gradient-based end-to-end optimization
has been explored for tuning SMC samplers, they often incur excessive training
costs, even for tuning just the kernel step sizes. In this work, we propose a
general adaptation framework for tuning the Markov kernels in SMC samplers by
minimizing the incremental Kullback-Leibler (KL) divergence between the
proposal and target paths. For step size tuning, we provide a gradient- and
tuning-free algorithm that is generally applicable for kernels such as Langevin
Monte Carlo (LMC). We further demonstrate the utility of our approach by
providing a tailored scheme for tuning \textit{kinetic} LMC used in SMC
samplers. Our implementations are able to obtain a full \textit{schedule} of
tuned parameters at the cost of a few vanilla SMC runs, which is a fraction of
gradient-based approaches.","['Kyurae Kim', 'Zuheng Xu', 'Jacob R. Gardner', 'Trevor Campbell']",2025-03-19,"['stat.ML', 'cs.LG', 'stat.CO']",,http://arxiv.org/pdf/2503.15704v1
2503.15696v1,Approximation properties of neural ODEs,"We study the approximation properties of shallow neural networks whose
activation function is defined as the flow of a neural ordinary differential
equation (neural ODE) at the final time of the integration interval. We prove
the universal approximation property (UAP) of such shallow neural networks in
the space of continuous functions. Furthermore, we investigate the
approximation properties of shallow neural networks whose parameters are
required to satisfy some constraints. In particular, we constrain the Lipschitz
constant of the flow of the neural ODE to increase the stability of the shallow
neural network, and we restrict the norm of the weight matrices of the linear
layers to one to make sure that the restricted expansivity of the flow is not
compensated by the increased expansivity of the linear layers. For this
setting, we prove approximation bounds that tell us the accuracy to which we
can approximate a continuous function with a shallow neural network with such
constraints. We prove that the UAP holds if we consider only the constraint on
the Lipschitz constant of the flow or the unit norm constraint on the weight
matrices of the linear layers.","['Arturo De Marinis', 'Davide Murari', 'Elena Celledoni', 'Nicola Guglielmi', 'Brynjulf Owren', 'Francesco Tudisco']",2025-03-19,"['math.NA', 'cs.LG', 'cs.NA']","30 pages, 11 figures, 2 tables",http://arxiv.org/pdf/2503.15696v1
2503.15693v1,"Good Actions Succeed, Bad Actions Generalize: A Case Study on Why RL Generalizes Better","Supervised learning (SL) and reinforcement learning (RL) are both widely used
to train general-purpose agents for complex tasks, yet their generalization
capabilities and underlying mechanisms are not yet fully understood. In this
paper, we provide a direct comparison between SL and RL in terms of zero-shot
generalization. Using the Habitat visual navigation task as a testbed, we
evaluate Proximal Policy Optimization (PPO) and Behavior Cloning (BC) agents
across two levels of generalization: state-goal pair generalization within seen
environments and generalization to unseen environments. Our experiments show
that PPO consistently outperforms BC across both zero-shot settings and
performance metrics-success rate and SPL. Interestingly, even though additional
optimal training data enables BC to match PPO's zero-shot performance in SPL,
it still falls significantly behind in success rate. We attribute this to a
fundamental difference in how models trained by these algorithms generalize:
BC-trained models generalize by imitating successful trajectories, whereas
TD-based RL-trained models generalize through combinatorial experience
stitching-leveraging fragments of past trajectories (mostly failed ones) to
construct solutions for new tasks. This allows RL to efficiently find solutions
in vast state space and discover novel strategies beyond the scope of human
knowledge. Besides providing empirical evidence and understanding, we also
propose practical guidelines for improving the generalization capabilities of
RL and SL through algorithm design.",['Meng Song'],2025-03-19,['cs.LG'],,http://arxiv.org/pdf/2503.15693v1
2503.15685v1,Robotic Paper Wrapping by Learning Force Control,"Robotic packaging using wrapping paper poses significant challenges due to
the material's complex deformation properties. The packaging process itself
involves multiple steps, primarily categorized as folding the paper or creating
creases. Small deviations in the robot's arm trajectory or force vector can
lead to tearing or wrinkling of the paper, exacerbated by the variability in
material properties.
  This study introduces a novel framework that combines imitation learning and
reinforcement learning to enable a robot to perform each step of the packaging
process efficiently. The framework allows the robot to follow approximate
trajectories of the tool-center point (TCP) based on human demonstrations while
optimizing force control parameters to prevent tearing or wrinkling, even with
variable wrapping paper materials.
  The proposed method was validated through ablation studies, which
demonstrated successful task completion with a significant reduction in tear
and wrinkle rates. Furthermore, the force control strategy proved to be
adaptable across different wrapping paper materials and robust against
variations in the size of the target object.","['Hiroki Hanai', 'Takuya Kiyokawa', 'Weiwei Wan', 'Kensuke Harada']",2025-03-19,"['cs.RO', 'cs.LG']",,http://arxiv.org/pdf/2503.15685v1
2503.15679v1,Sequential learning based PINNs to overcome temporal domain complexities in unsteady flow past flapping wings,"For a data-driven and physics combined modelling of unsteady flow systems
with moving immersed boundaries, Sundar {\it et al.} introduced an immersed
boundary-aware (IBA) framework, combining Physics-Informed Neural Networks
(PINNs) and the immersed boundary method (IBM). This approach was beneficial
because it avoided case-specific transformations to a body-attached reference
frame. Building on this, we now address the challenges of long time integration
in velocity reconstruction and pressure recovery by extending this IBA
framework with sequential learning strategies. Key difficulties for PINNs in
long time integration include temporal sparsity, long temporal domains and rich
spectral content. To tackle these, a moving boundary-enabled PINN is developed,
proposing two sequential learning strategies: - a time marching with gradual
increase in time domain size, however, this approach struggles with error
accumulation over long time domains; and - a time decomposition which divides
the temporal domain into smaller segments, combined with transfer learning it
effectively reduces error propagation and computational complexity. The key
findings for modelling of incompressible unsteady flows past a flapping airfoil
include: - for quasi-periodic flows, the time decomposition approach with
preferential spatio-temporal sampling improves accuracy and efficiency for
pressure recovery and aerodynamic load reconstruction, and, - for long time
domains, decomposing it into smaller temporal segments and employing multiple
sub-networks, simplifies the problem ensuring stability and reduced network
sizes. This study highlights the limitations of traditional PINNs for long time
integration of flow-structure interaction problems and demonstrates the
benefits of decomposition-based strategies for addressing error accumulation,
computational cost, and complex dynamics.","['Rahul Sundar', 'Didier Lucor', 'Sunetra Sarkar']",2025-03-19,"['physics.flu-dyn', 'cs.LG']",,http://arxiv.org/pdf/2503.15679v1
2503.15668v1,Model Risk Management for Generative AI In Financial Institutions,"The success of OpenAI's ChatGPT in 2023 has spurred financial enterprises
into exploring Generative AI applications to reduce costs or drive revenue
within different lines of businesses in the Financial Industry. While these
applications offer strong potential for efficiencies, they introduce new model
risks, primarily hallucinations and toxicity. As highly regulated entities,
financial enterprises (primarily large US banks) are obligated to enhance their
model risk framework with additional testing and controls to ensure safe
deployment of such applications. This paper outlines the key aspects for model
risk management of generative AI model with a special emphasis on additional
practices required in model validation.","['Anwesha Bhattacharyya', 'Ye Yu', 'Hanyu Yang', 'Rahul Singh', 'Tarun Joshi', 'Jie Chen', 'Kiran Yalavarthy']",2025-03-19,"['q-fin.RM', 'cs.LG']",,http://arxiv.org/pdf/2503.15668v1
2503.15650v1,Survey on Generalization Theory for Graph Neural Networks,"Message-passing graph neural networks (MPNNs) have emerged as the leading
approach for machine learning on graphs, attracting significant attention in
recent years. While a large set of works explored the expressivity of MPNNs,
i.e., their ability to separate graphs and approximate functions over them,
comparatively less attention has been directed toward investigating their
generalization abilities, i.e., making meaningful predictions beyond the
training data. Here, we systematically review the existing literature on the
generalization abilities of MPNNs. We analyze the strengths and limitations of
various studies in these domains, providing insights into their methodologies
and findings. Furthermore, we identify potential avenues for future research,
aiming to deepen our understanding of the generalization abilities of MPNNs.","['Antonis Vasileiou', 'Stefanie Jegelka', 'Ron Levie', 'Christopher Morris']",2025-03-19,"['cs.LG', 'cs.AI', 'stat.ML']",,http://arxiv.org/pdf/2503.15650v1
2503.15647v1,Multi-Modal Gesture Recognition from Video and Surgical Tool Pose Information via Motion Invariants,"Recognizing surgical gestures in real-time is a stepping stone towards
automated activity recognition, skill assessment, intra-operative assistance,
and eventually surgical automation. The current robotic surgical systems
provide us with rich multi-modal data such as video and kinematics. While some
recent works in multi-modal neural networks learn the relationships between
vision and kinematics data, current approaches treat kinematics information as
independent signals, with no underlying relation between tool-tip poses.
However, instrument poses are geometrically related, and the underlying
geometry can aid neural networks in learning gesture representation. Therefore,
we propose combining motion invariant measures (curvature and torsion) with
vision and kinematics data using a relational graph network to capture the
underlying relations between different data streams. We show that gesture
recognition improves when combining invariant signals with tool position,
achieving 90.3\% frame-wise accuracy on the JIGSAWS suturing dataset. Our
results show that motion invariant signals coupled with position are better
representations of gesture motion compared to traditional position and
quaternion representations. Our results highlight the need for geometric-aware
modeling of kinematics for gesture recognition.","['Jumanh Atoum', 'Garrison L. H. Johnston', 'Nabil Simaan', 'Jie Ying Wu']",2025-03-19,"['cs.CV', 'cs.LG']",,http://arxiv.org/pdf/2503.15647v1
2503.15638v1,Using machine learning to measure evidence of students' sensemaking in physics courses,"In the education system, problem-solving correctness is often inappropriately
conflated with student learning. Advances in both Physics Education Research
(PER) and Machine Learning (ML) provide the initial tools to develop a more
meaningful and efficient measurement scheme for whether physics students are
engaging in sensemaking: a learning process of figuring out the how and why for
a particular phenomena. In this work, we contribute such a measurement scheme,
which quantifies the evidence of students' physical sensemaking given their
written explanations for their solutions to physics problems. We outline how
the proposed human annotation scheme can be automated into a deployable ML
model using language encoders and shared probabilistic classifiers. The
procedure is scalable for a large number of problems and students. We implement
three unique language encoders with logistic regression, and provide a
deployability analysis on 385 real student explanations from the 2023
Introduction to Physics course at Tufts University. Furthermore, we compute
sensemaking scores for all students, and analyze these measurements alongside
their corresponding problem-solving accuracies. We find no linear relationship
between these two variables, supporting the hypothesis that one is not a
reliable proxy for the other. We discuss how sensemaking scores can be used
alongside problem-solving accuracies to provide a more nuanced snapshot of
student performance in physics class.","['Kaitlin Gili', 'Kyle Heuton', 'Astha Shah', 'Michael C. Hughes']",2025-03-19,"['physics.ed-ph', 'cs.LG']",,http://arxiv.org/pdf/2503.15638v1
2503.15629v1,Neural Lyapunov Function Approximation with Self-Supervised Reinforcement Learning,"Control Lyapunov functions are traditionally used to design a controller
which ensures convergence to a desired state, yet deriving these functions for
nonlinear systems remains a complex challenge. This paper presents a novel,
sample-efficient method for neural approximation of nonlinear Lyapunov
functions, leveraging self-supervised Reinforcement Learning (RL) to enhance
training data generation, particularly for inaccurately represented regions of
the state space. The proposed approach employs a data-driven World Model to
train Lyapunov functions from off-policy trajectories. The method is validated
on both standard and goal-conditioned robotic tasks, demonstrating faster
convergence and higher approximation accuracy compared to the state-of-the-art
neural Lyapunov approximation baseline. The code is available at:
https://github.com/CAV-Research-Lab/SACLA.git","['Luc McCutcheon', 'Bahman Gharesifard', 'Saber Fallah']",2025-03-19,"['cs.RO', 'cs.AI', 'cs.CG', 'cs.LG']","Accepted at IEEE International Conference on Robotics and Automation
  (ICRA)",http://arxiv.org/pdf/2503.15629v1
2503.15620v1,Does Context Matter? ContextualJudgeBench for Evaluating LLM-based Judges in Contextual Settings,"The large language model (LLM)-as-judge paradigm has been used to meet the
demand for a cheap, reliable, and fast evaluation of model outputs during AI
system development and post-deployment monitoring. While judge models -- LLMs
finetuned to specialize in assessing and critiquing model outputs -- have been
touted as general purpose evaluators, they are typically evaluated only on
non-contextual scenarios, such as instruction following. The omission of
contextual settings -- those where external information is used as context to
generate an output -- is surprising given the increasing prevalence of
retrieval-augmented generation (RAG) and summarization use cases. Contextual
assessment is uniquely challenging, as evaluation often depends on practitioner
priorities, leading to conditional evaluation criteria (e.g., comparing
responses based on factuality and then considering completeness if they are
equally factual). To address the gap, we propose ContextualJudgeBench, a judge
benchmark with 2,000 challenging response pairs across eight splits inspired by
real-world contextual evaluation scenarios. We build our benchmark with a
multi-pronged data construction pipeline that leverages both existing human
annotations and model-based perturbations. Our comprehensive study across 11
judge models and 9 general purpose models, reveals that the contextual
information and its assessment criteria present a significant challenge to even
state-of-the-art models. For example, OpenAI's o1, the best-performing model,
barely reaches 55% consistent accuracy.","['Austin Xu', 'Srijan Bansal', 'Yifei Ming', 'Semih Yavuz', 'Shafiq Joty']",2025-03-19,"['cs.CL', 'cs.AI', 'cs.LG']","23 pages, 13 figures, 6 tables",http://arxiv.org/pdf/2503.15620v1
2503.15615v1,PEnGUiN: Partially Equivariant Graph NeUral Networks for Sample Efficient MARL,"Equivariant Graph Neural Networks (EGNNs) have emerged as a promising
approach in Multi-Agent Reinforcement Learning (MARL), leveraging symmetry
guarantees to greatly improve sample efficiency and generalization. However,
real-world environments often exhibit inherent asymmetries arising from factors
such as external forces, measurement inaccuracies, or intrinsic system biases.
This paper introduces \textit{Partially Equivariant Graph NeUral Networks
(PEnGUiN)}, a novel architecture specifically designed to address these
challenges. We formally identify and categorize various types of partial
equivariance relevant to MARL, including subgroup equivariance, feature-wise
equivariance, regional equivariance, and approximate equivariance. We
theoretically demonstrate that PEnGUiN is capable of learning both fully
equivariant (EGNN) and non-equivariant (GNN) representations within a unified
framework. Through extensive experiments on a range of MARL problems
incorporating various asymmetries, we empirically validate the efficacy of
PEnGUiN. Our results consistently demonstrate that PEnGUiN outperforms both
EGNNs and standard GNNs in asymmetric environments, highlighting their
potential to improve the robustness and applicability of graph-based MARL
algorithms in real-world scenarios.","['Joshua McClellan', 'Greyson Brothers', 'Furong Huang', 'Pratap Tokekar']",2025-03-19,"['cs.LG', 'cs.AI', 'cs.RO']",,http://arxiv.org/pdf/2503.15615v1
2503.15485v1,TULIP: Towards Unified Language-Image Pretraining,"Despite the recent success of image-text contrastive models like CLIP and
SigLIP, these models often struggle with vision-centric tasks that demand
high-fidelity image understanding, such as counting, depth estimation, and
fine-grained object recognition. These models, by performing language
alignment, tend to prioritize high-level semantics over visual understanding,
weakening their image understanding. On the other hand, vision-focused models
are great at processing visual information but struggle to understand language,
limiting their flexibility for language-driven tasks. In this work, we
introduce TULIP, an open-source, drop-in replacement for existing CLIP-like
models. Our method leverages generative data augmentation, enhanced image-image
and text-text contrastive learning, and image/text reconstruction
regularization to learn fine-grained visual features while preserving global
semantic alignment. Our approach, scaling to over 1B parameters, outperforms
existing state-of-the-art (SOTA) models across multiple benchmarks,
establishing a new SOTA zero-shot performance on ImageNet-1K, delivering up to
a $2\times$ enhancement over SigLIP on RxRx1 in linear probing for few-shot
classification, and improving vision-language models, achieving over $3\times$
higher scores than SigLIP on MMVP. Our code/checkpoints are available at
https://tulip-berkeley.github.io","['Zineng Tang', 'Long Lian', 'Seun Eisape', 'XuDong Wang', 'Roei Herzig', 'Adam Yala', 'Alane Suhr', 'Trevor Darrell', 'David M. Chan']",2025-03-19,"['cs.CV', 'cs.AI', 'cs.CL', 'cs.LG']",,http://arxiv.org/pdf/2503.15485v1
2503.15484v1,Value Profiles for Encoding Human Variation,"Modelling human variation in rating tasks is crucial for enabling AI systems
for personalization, pluralistic model alignment, and computational social
science. We propose representing individuals using value profiles -- natural
language descriptions of underlying values compressed from in-context
demonstrations -- along with a steerable decoder model to estimate ratings
conditioned on a value profile or other rater information. To measure the
predictive information in rater representations, we introduce an
information-theoretic methodology. We find that demonstrations contain the most
information, followed by value profiles and then demographics. However, value
profiles offer advantages in terms of scrutability, interpretability, and
steerability due to their compressed natural language format. Value profiles
effectively compress the useful information from demonstrations (>70%
information preservation). Furthermore, clustering value profiles to identify
similarly behaving individuals better explains rater variation than the most
predictive demographic groupings. Going beyond test set performance, we show
that the decoder models interpretably change ratings according to semantic
profile differences, are well-calibrated, and can help explain instance-level
disagreement by simulating an annotator population. These results demonstrate
that value profiles offer novel, predictive ways to describe individual
variation beyond demographics or group information.","['Taylor Sorensen', 'Pushkar Mishra', 'Roma Patel', 'Michael Henry Tessler', 'Michiel Bakker', 'Georgina Evans', 'Iason Gabriel', 'Noah Goodman', 'Verena Rieser']",2025-03-19,"['cs.CL', 'cs.AI', 'cs.HC', 'cs.LG']",,http://arxiv.org/pdf/2503.15484v1
2503.15482v1,Natural Quantization of Neural Networks,"We propose a natural quantization of a standard neural network, where the
neurons correspond to qubits and the activation functions are implemented via
quantum gates and measurements. The simplest quantized neural network
corresponds to applying single-qubit rotations, with the rotation angles being
dependent on the weights and measurement outcomes of the previous layer. This
realization has the advantage of being smoothly tunable from the purely
classical limit with no quantum uncertainty (thereby reproducing the classical
neural network exactly) to a quantum case, where superpositions introduce an
intrinsic uncertainty in the network. We benchmark this architecture on a
subset of the standard MNIST dataset and find a regime of ""quantum advantage,""
where the validation error rate in the quantum realization is smaller than that
in the classical model. We also consider another approach where quantumness is
introduced via weak measurements of ancilla qubits entangled with the neuron
qubits. This quantum neural network also allows for smooth tuning of the degree
of quantumness by controlling an entanglement angle, $g$, with $g=\frac\pi 2$
replicating the classical regime. We find that validation error is also
minimized within the quantum regime in this approach. We also observe a quantum
transition, with sharp loss of the quantum network's ability to learn at a
critical point $g_c$. The proposed quantum neural networks are readily
realizable in present-day quantum computers on commercial datasets.","['Richard Barney', 'Djamil Lakhdar-Hamina', 'Victor Galitski']",2025-03-19,"['quant-ph', 'cond-mat.dis-nn', 'cs.LG']","7 pages, 8 figures, 1 table",http://arxiv.org/pdf/2503.15482v1
2503.15481v1,Learning to Play Piano in the Real World,"Towards the grand challenge of achieving human-level manipulation in robots,
playing piano is a compelling testbed that requires strategic, precise, and
flowing movements. Over the years, several works demonstrated hand-designed
controllers on real world piano playing, while other works evaluated robot
learning approaches on simulated piano scenarios. In this paper, we develop the
first piano playing robotic system that makes use of learning approaches while
also being deployed on a real world dexterous robot. Specifically, we make use
of Sim2Real to train a policy in simulation using reinforcement learning before
deploying the learned policy on a real world dexterous robot. In our
experiments, we thoroughly evaluate the interplay between domain randomization
and the accuracy of the dynamics model used in simulation. Moreover, we
evaluate the robot's performance across multiple songs with varying complexity
to study the generalization of our learned policy. By providing a
proof-of-concept of learning to play piano in the real world, we want to
encourage the community to adopt piano playing as a compelling benchmark
towards human-level manipulation. We open-source our code and show additional
videos at https://lasr.org/research/learning-to-play-piano .","['Yves-Simon Zeulner', 'Sandeep Selvaraj', 'Roberto Calandra']",2025-03-19,"['cs.RO', 'cs.AI', 'cs.LG']",10 pages,http://arxiv.org/pdf/2503.15481v1
2503.15478v1,SWEET-RL: Training Multi-Turn LLM Agents on Collaborative Reasoning Tasks,"Large language model (LLM) agents need to perform multi-turn interactions in
real-world tasks. However, existing multi-turn RL algorithms for optimizing LLM
agents fail to perform effective credit assignment over multiple turns while
leveraging the generalization capabilities of LLMs and it remains unclear how
to develop such algorithms. To study this, we first introduce a new benchmark,
ColBench, where an LLM agent interacts with a human collaborator over multiple
turns to solve realistic tasks in backend programming and frontend design.
Building on this benchmark, we propose a novel RL algorithm, SWEET-RL (RL with
Step-WisE Evaluation from Training-time information), that uses a carefully
designed optimization objective to train a critic model with access to
additional training-time information. The critic provides step-level rewards
for improving the policy model. Our experiments demonstrate that SWEET-RL
achieves a 6% absolute improvement in success and win rates on ColBench
compared to other state-of-the-art multi-turn RL algorithms, enabling
Llama-3.1-8B to match or exceed the performance of GPT4-o in realistic
collaborative content creation.","['Yifei Zhou', 'Song Jiang', 'Yuandong Tian', 'Jason Weston', 'Sergey Levine', 'Sainbayar Sukhbaatar', 'Xian Li']",2025-03-19,['cs.LG'],"29 pages, 16 figures",http://arxiv.org/pdf/2503.15478v1
2503.15477v1,What Makes a Reward Model a Good Teacher? An Optimization Perspective,"The success of Reinforcement Learning from Human Feedback (RLHF) critically
depends on the quality of the reward model. While this quality is primarily
evaluated through accuracy, it remains unclear whether accuracy fully captures
what makes a reward model an effective teacher. We address this question from
an optimization perspective. First, we prove that regardless of how accurate a
reward model is, if it induces low reward variance, then the RLHF objective
suffers from a flat landscape. Consequently, even a perfectly accurate reward
model can lead to extremely slow optimization, underperforming less accurate
models that induce higher reward variance. We additionally show that a reward
model that works well for one language model can induce low reward variance,
and thus a flat objective landscape, for another. These results establish a
fundamental limitation of evaluating reward models solely based on accuracy or
independently of the language model they guide. Experiments using models of up
to 8B parameters corroborate our theory, demonstrating the interplay between
reward variance, accuracy, and reward maximization rate. Overall, our findings
highlight that beyond accuracy, a reward model needs to induce sufficient
variance for efficient optimization.","['Noam Razin', 'Zixuan Wang', 'Hubert Strauss', 'Stanley Wei', 'Jason D. Lee', 'Sanjeev Arora']",2025-03-19,"['cs.LG', 'cs.AI', 'cs.CL', 'stat.ML']",Code available at https://github.com/princeton-pli/what-makes-good-rm,http://arxiv.org/pdf/2503.15477v1
2503.15457v1,Di$\mathtt{[M]}$O: Distilling Masked Diffusion Models into One-step Generator,"Masked Diffusion Models (MDMs) have emerged as a powerful generative modeling
technique. Despite their remarkable results, they typically suffer from slow
inference with several steps. In this paper, we propose Di$\mathtt{[M]}$O, a
novel approach that distills masked diffusion models into a one-step generator.
Di$\mathtt{[M]}$O addresses two key challenges: (1) the intractability of using
intermediate-step information for one-step generation, which we solve through
token-level distribution matching that optimizes model output logits by an
'on-policy framework' with the help of an auxiliary model; and (2) the lack of
entropy in the initial distribution, which we address through a token
initialization strategy that injects randomness while maintaining similarity to
teacher training distribution. We show Di$\mathtt{[M]}$O's effectiveness on
both class-conditional and text-conditional image generation, impressively
achieving performance competitive to multi-step teacher outputs while
drastically reducing inference time. To our knowledge, we are the first to
successfully achieve one-step distillation of masked diffusion models and the
first to apply discrete distillation to text-to-image generation, opening new
paths for efficient generative modeling.","['Yuanzhi Zhu', 'Xi Wang', 'Stéphane Lathuilière', 'Vicky Kalogeiton']",2025-03-19,"['cs.CV', 'cs.AI', 'cs.LG']",,http://arxiv.org/pdf/2503.15457v1
2503.15456v1,Temporal Encoding Strategies for Energy Time Series Prediction,"In contemporary power systems, energy consumption prediction plays a crucial
role in maintaining grid stability and resource allocation enabling power
companies to minimize energy waste and avoid overloading the grid. While there
are several research works on energy optimization, they often fail to address
the complexities of real-time fluctuations and the cyclic pattern of energy
consumption. This work proposes a novel approach to enhance the accuracy of
predictive models by employing sinusoidal encoding on periodic features of
time-series data. To demonstrate the increase in performance, several
statistical and ensemble machine learning models were trained on an energy
demand dataset, using the proposed sinusoidal encoding. The performance of
these models was then benchmarked against identical models trained on
traditional encoding methods. The results demonstrated a 12.6% improvement of
Root Mean Squared Error (from 0.5497 to 0.4802) and a 7.8% increase in the R^2
score (from 0.7530 to 0.8118), indicating that the proposed encoding better
captures the cyclic nature of temporal patterns than traditional methods. The
proposed methodology significantly improves prediction accuracy while
maintaining computational efficiency, making it suitable for real-time
applications in smart grid systems.","['Aayam Bansal', 'Keertan Balaji', 'Zeus Lalani']",2025-03-19,['cs.LG'],,http://arxiv.org/pdf/2503.15456v1
2503.15448v1,Reducing Communication Overhead in Federated Learning for Network Anomaly Detection with Adaptive Client Selection,"Communication overhead in federated learning (FL) poses a significant
challenge for network anomaly detection systems, where diverse client
configurations and network conditions impact efficiency and detection accuracy.
Existing approaches attempt optimization individually but struggle to balance
reduced overhead with performance. This paper presents an adaptive FL framework
combining batch size optimization, client selection, and asynchronous updates
for efficient anomaly detection. Using UNSW-NB15 for general network traffic
and ROAD for automotive networks, our framework reduces communication overhead
by 97.6% (700.0s to 16.8s) while maintaining comparable accuracy (95.10% vs.
95.12%). The Mann-Whitney U test confirms significant improvements (p < 0.05).
Profiling analysis reveals efficiency gains via reduced GPU operations and
memory transfers, ensuring robust detection across varying client conditions.","['William Marfo', 'Deepak Tosh', 'Shirley Moore', 'Joshua Suetterlein', 'Joseph Manzano']",2025-03-19,"['cs.DC', 'cs.LG']",,http://arxiv.org/pdf/2503.15448v1
2503.15441v1,A discontinuity-capturing neural network with categorical embedding and its application to anisotropic elliptic interface problems,"In this paper, we propose a discontinuity-capturing shallow neural network
with categorical embedding to represent piecewise smooth functions. The network
comprises three hidden layers, a discontinuity-capturing layer, a categorical
embedding layer, and a fully-connected layer. Under such a design, we show that
a piecewise smooth function, even with a large number of pieces, can be
approximated by a single neural network with high prediction accuracy. We then
leverage the proposed network model to solve anisotropic elliptic interface
problems. The network is trained by minimizing the mean squared error loss of
the system. Our results show that, despite its simple and shallow structure,
the proposed neural network model exhibits comparable efficiency and accuracy
to traditional grid-based numerical methods.","['Wei-Fan Hu', 'Te-Sheng Lin', 'Ming-Chih Lai']",2025-03-19,"['math.NA', 'cs.LG', 'cs.NA', '41A46, 65C05, 65N99, 68T01']",,http://arxiv.org/pdf/2503.15441v1
2503.15432v1,"Accurate, transferable, and verifiable machine-learned interatomic potentials for layered materials","Twisted layered van-der-Waals materials often exhibit unique electronic and
optical properties absent in their non-twisted counterparts. Unfortunately,
predicting such properties is hindered by the difficulty in determining the
atomic structure in materials displaying large moir\'e domains. Here, we
introduce a split machine-learned interatomic potential and dataset curation
approach that separates intralayer and interlayer interactions and
significantly improves model accuracy -- with a tenfold increase in energy and
force prediction accuracy relative to conventional models. We further
demonstrate that traditional MLIP validation metrics -- force and energy errors
-- are inadequate for moir\'e structures and develop a more holistic,
physically-motivated metric based on the distribution of stacking
configurations. This metric effectively compares the entirety of large-scale
moir\'e domains between two structures instead of relying on conventional
measures evaluated on smaller commensurate cells. Finally, we establish that
one-dimensional instead of two-dimensional moir\'e structures can serve as
efficient surrogate systems for validating MLIPs, allowing for a practical
model validation protocol against explicit DFT calculations. Applying our
framework to HfS2/GaS bilayers reveals that accurate structural predictions
directly translate into reliable electronic properties. Our model-agnostic
approach integrates seamlessly with various intralayer and interlayer
interaction models, enabling computationally tractable relaxation of moir\'e
materials, from bilayer to complex multilayers, with rigorously validated
accuracy.","['Johnathan D. Georgaras', 'Akash Ramdas', 'Chung Hsuan Shan', 'Elena Halsted', 'Berwyn', 'Tianshu Li', 'Felipe H. da Jornada']",2025-03-19,"['cond-mat.mtrl-sci', 'cs.LG']","10 pages, 5 figures",http://arxiv.org/pdf/2503.15432v1
2503.15420v1,LIFT: Latent Implicit Functions for Task- and Data-Agnostic Encoding,"Implicit Neural Representations (INRs) are proving to be a powerful paradigm
in unifying task modeling across diverse data domains, offering key advantages
such as memory efficiency and resolution independence. Conventional deep
learning models are typically modality-dependent, often requiring custom
architectures and objectives for different types of signals. However, existing
INR frameworks frequently rely on global latent vectors or exhibit
computational inefficiencies that limit their broader applicability. We
introduce LIFT, a novel, high-performance framework that addresses these
challenges by capturing multiscale information through meta-learning. LIFT
leverages multiple parallel localized implicit functions alongside a
hierarchical latent generator to produce unified latent representations that
span local, intermediate, and global features. This architecture facilitates
smooth transitions across local regions, enhancing expressivity while
maintaining inference efficiency. Additionally, we introduce ReLIFT, an
enhanced variant of LIFT that incorporates residual connections and expressive
frequency encodings. With this straightforward approach, ReLIFT effectively
addresses the convergence-capacity gap found in comparable methods, providing
an efficient yet powerful solution to improve capacity and speed up
convergence. Empirical results show that LIFT achieves state-of-the-art (SOTA)
performance in generative modeling and classification tasks, with notable
reductions in computational costs. Moreover, in single-task settings, the
streamlined ReLIFT architecture proves effective in signal representations and
inverse problem tasks.","['Amirhossein Kazerouni', 'Soroush Mehraban', 'Michael Brudno', 'Babak Taati']",2025-03-19,"['cs.LG', 'cs.CV']",,http://arxiv.org/pdf/2503.15420v1
2503.15407v1,Exploiting Prior Knowledge in Preferential Learning of Individualized Autonomous Vehicle Driving Styles,"Trajectory planning for automated vehicles commonly employs optimization over
a moving horizon - Model Predictive Control - where the cost function
critically influences the resulting driving style. However, finding a suitable
cost function that results in a driving style preferred by passengers remains
an ongoing challenge. We employ preferential Bayesian optimization to learn the
cost function by iteratively querying a passenger's preference. Due to
increasing dimensionality of the parameter space, preference learning
approaches might struggle to find a suitable optimum with a limited number of
experiments and expose the passenger to discomfort when exploring the parameter
space. We address these challenges by incorporating prior knowledge into the
preferential Bayesian optimization framework. Our method constructs a virtual
decision maker from real-world human driving data to guide parameter sampling.
In a simulation experiment, we achieve faster convergence of the
prior-knowledge-informed learning procedure compared to existing preferential
Bayesian optimization approaches and reduce the number of inadequate driving
styles sampled.","['Lukas Theiner', 'Sebastian Hirt', 'Alexander Steinke', 'Rolf Findeisen']",2025-03-19,"['eess.SY', 'cs.LG', 'cs.SY']","6 pages, 6 figures, accepted for ECC 2025",http://arxiv.org/pdf/2503.15407v1
2503.15583v1,Efficient Post-Hoc Uncertainty Calibration via Variance-Based Smoothing,"Since state-of-the-art uncertainty estimation methods are often
computationally demanding, we investigate whether incorporating prior
information can improve uncertainty estimates in conventional deep neural
networks. Our focus is on machine learning tasks where meaningful predictions
can be made from sub-parts of the input. For example, in speaker
classification, the speech waveform can be divided into sequential patches,
each containing information about the same speaker. We observe that the
variance between sub-predictions serves as a reliable proxy for uncertainty in
such settings. Our proposed variance-based scaling framework produces
competitive uncertainty estimates in classification while being less
computationally demanding and allowing for integration as a post-hoc
calibration tool. This approach also leads to a simple extension of deep
ensembles, improving the expressiveness of their predicted distributions.","['Fabian Denoodt', 'José Oramas']",2025-03-19,['cs.LG'],,http://arxiv.org/pdf/2503.15583v1
2503.15403v1,HQNN-FSP: A Hybrid Classical-Quantum Neural Network for Regression-Based Financial Stock Market Prediction,"Financial time-series forecasting remains a challenging task due to complex
temporal dependencies and market fluctuations. This study explores the
potential of hybrid quantum-classical approaches to assist in financial trend
prediction by leveraging quantum resources for improved feature representation
and learning. A custom Quantum Neural Network (QNN) regressor is introduced,
designed with a novel ansatz tailored for financial applications. Two hybrid
optimization strategies are proposed: (1) a sequential approach where classical
recurrent models (RNN/LSTM) extract temporal dependencies before quantum
processing, and (2) a joint learning framework that optimizes classical and
quantum parameters simultaneously. Systematic evaluation using TimeSeriesSplit,
k-fold cross-validation, and predictive error analysis highlights the ability
of these hybrid models to integrate quantum computing into financial
forecasting workflows. The findings demonstrate how quantum-assisted learning
can contribute to financial modeling, offering insights into the practical role
of quantum resources in time-series analysis.","['Prashant Kumar Choudhary', 'Nouhaila Innan', 'Muhammad Shafique', 'Rajeev Singh']",2025-03-19,"['q-fin.ST', 'cs.LG', 'quant-ph']",11 pages and 11 figures,http://arxiv.org/pdf/2503.15403v1
2503.15371v1,Geometrically-Aware One-Shot Skill Transfer of Category-Level Objects,"Robotic manipulation of unfamiliar objects in new environments is challenging
and requires extensive training or laborious pre-programming. We propose a new
skill transfer framework, which enables a robot to transfer complex object
manipulation skills and constraints from a single human demonstration. Our
approach addresses the challenge of skill acquisition and task execution by
deriving geometric representations from demonstrations focusing on
object-centric interactions. By leveraging the Functional Maps (FM) framework,
we efficiently map interaction functions between objects and their
environments, allowing the robot to replicate task operations across objects of
similar topologies or categories, even when they have significantly different
shapes. Additionally, our method incorporates a Task-Space Imitation Algorithm
(TSIA) which generates smooth, geometrically-aware robot paths to ensure the
transferred skills adhere to the demonstrated task constraints. We validate the
effectiveness and adaptability of our approach through extensive experiments,
demonstrating successful skill transfer and task execution in diverse
real-world environments without requiring additional training.","['Cristiana de Farias', 'Luis Figueredo', 'Riddhiman Laha', 'Maxime Adjigble', 'Brahim Tamadazte', 'Rustam Stolkin', 'Sami Haddadin', 'Naresh Marturi']",2025-03-19,"['cs.RO', 'cs.LG']","7 pages, 6 figures",http://arxiv.org/pdf/2503.15371v1
2503.15368v1,Online Imitation Learning for Manipulation via Decaying Relative Correction through Teleoperation,"Teleoperated robotic manipulators enable the collection of demonstration
data, which can be used to train control policies through imitation learning.
However, such methods can require significant amounts of training data to
develop robust policies or adapt them to new and unseen tasks. While expert
feedback can significantly enhance policy performance, providing continuous
feedback can be cognitively demanding and time-consuming for experts. To
address this challenge, we propose to use a cable-driven teleoperation system
which can provide spatial corrections with 6 degree of freedom to the
trajectories generated by a policy model. Specifically, we propose a correction
method termed Decaying Relative Correction (DRC) which is based upon the
spatial offset vector provided by the expert and exists temporarily, and which
reduces the intervention steps required by an expert. Our results demonstrate
that DRC reduces the required expert intervention rate by 30\% compared to a
standard absolute corrective method. Furthermore, we show that integrating DRC
within an online imitation learning framework rapidly increases the success
rate of manipulation tasks such as raspberry harvesting and cloth wiping.","['Cheng Pan', 'Hung Hon Cheng', 'Josie Hughes']",2025-03-19,"['cs.RO', 'cs.LG']",,http://arxiv.org/pdf/2503.15368v1
2503.15367v1,FedBEns: One-Shot Federated Learning based on Bayesian Ensemble,"One-Shot Federated Learning (FL) is a recent paradigm that enables multiple
clients to cooperatively learn a global model in a single round of
communication with a central server. In this paper, we analyze the One-Shot FL
problem through the lens of Bayesian inference and propose FedBEns, an
algorithm that leverages the inherent multimodality of local loss functions to
find better global models. Our algorithm leverages a mixture of Laplace
approximations for the clients' local posteriors, which the server then
aggregates to infer the global model. We conduct extensive experiments on
various datasets, demonstrating that the proposed method outperforms competing
baselines that typically rely on unimodal approximations of the local losses.","['Jacopo Talpini', 'Marco Savi', 'Giovanni Neglia']",2025-03-19,['cs.LG'],,http://arxiv.org/pdf/2503.15367v1
2503.15355v1,Robustness of Nonlinear Representation Learning,"We study the problem of unsupervised representation learning in slightly
misspecified settings, and thus formalize the study of robustness of nonlinear
representation learning. We focus on the case where the mixing is close to a
local isometry in a suitable distance and show based on existing rigidity
results that the mixing can be identified up to linear transformations and
small errors. In a second step, we investigate Independent Component Analysis
(ICA) with observations generated according to $x=f(s)=As+h(s)$ where $A$ is an
invertible mixing matrix and $h$ a small perturbation. We show that we can
approximately recover the matrix $A$ and the independent components. Together,
these two results show approximate identifiability of nonlinear ICA with almost
isometric mixing functions. Those results are a step towards identifiability
results for unsupervised representation learning for real-world data that do
not follow restrictive model classes.","['Simon Buchholz', 'Bernhard Schölkopf']",2025-03-19,"['stat.ML', 'cs.LG']",37 pages,http://arxiv.org/pdf/2503.15355v1
2503.15352v1,Leveraging Perfect Multimodal Alignment and Gaussian Assumptions for Cross-modal Transfer,"Multimodal alignment aims to construct a joint latent vector space where two
modalities representing the same concept map to the same vector. We formulate
this as an inverse problem and show that under certain conditions perfect
alignment can be achieved. We then address a specific application of alignment
referred to as cross-modal transfer. Unsupervised cross-modal transfer aims to
leverage a model trained with one modality to perform inference on another
modality, without any labeled fine-tuning on the new modality. Assuming that
semantic classes are represented as a mixture of Gaussians in the latent space,
we show how cross-modal transfer can be performed by projecting the data points
from the representation space onto different subspaces representing each
modality. Our experiments on synthetic multimodal Gaussian data verify the
effectiveness of our perfect alignment and cross-modal transfer method. We hope
these findings inspire further exploration of the applications of perfect
alignment and the use of Gaussian models for cross-modal learning.","['Abhi Kamboj', 'Minh N. Do']",2025-03-19,"['cs.LG', 'cs.AI', 'cs.CV', 'eess.SP']",,http://arxiv.org/pdf/2503.15352v1
2503.15582v1,Hierarchical clustering with maximum density paths and mixture models,"Hierarchical clustering is an effective and interpretable technique for
analyzing structure in data, offering a nuanced understanding by revealing
insights at multiple scales and resolutions. It is particularly helpful in
settings where the exact number of clusters is unknown, and provides a robust
framework for exploring complex datasets. Additionally, hierarchical clustering
can uncover inner structures within clusters, capturing subtle relationships
and nested patterns that may be obscured by traditional flat clustering
methods. However, existing hierarchical clustering methods struggle with
high-dimensional data, especially when there are no clear density gaps between
modes. Our method addresses this limitation by leveraging a two-stage approach,
first employing a Gaussian or Student's t mixture model to overcluster the
data, and then hierarchically merging clusters based on the induced density
landscape. This approach yields state-of-the-art clustering performance while
also providing a meaningful hierarchy, making it a valuable tool for
exploratory data analysis. Code is available at
https://github.com/ecker-lab/tneb clustering.","['Martin Ritzert', 'Polina Turishcheva', 'Laura Hansel', 'Paul Wollenhaupt', 'Marissa Weis', 'Alexander Ecker']",2025-03-19,"['stat.ML', 'cs.LG']",,http://arxiv.org/pdf/2503.15582v1
2503.15294v1,Borsuk-Ulam and Replicable Learning of Large-Margin Halfspaces,"Recent advances in learning theory have established that, for total concepts,
list replicability, global stability, differentially private (DP) learnability,
and shared-randomness replicability coincide precisely with the finiteness of
the Littlestone dimension. Does the same hold for partial concept classes?
  We answer this question by studying the large-margin half-spaces class, which
has bounded Littlestone dimension and is purely DP-learnable and
shared-randomness replicable even in high dimensions.
  We prove that the list replicability number of $\gamma$-margin half-spaces
satisfies \[ \frac{d}{2} + 1 \le \mathrm{LR}(H_{\gamma}^d) \le d, \] which
increases with the dimension $d$. This reveals a surprising separation for
partial concepts: list replicability and global stability do not follow from
bounded Littlestone dimension, DP-learnability, or shared-randomness
replicability.
  By applying our main theorem, we also answer the following open problems.
  - We prove that any disambiguation of an infinite-dimensional large-margin
half-space to a total concept class has unbounded Littlestone dimension,
answering an open question of Alon et al. (FOCS '21). - We prove that the
maximum list-replicability number of any *finite* set of points and homogeneous
half-spaces in $d$-dimensional Euclidean space is $d$, resolving a problem of
Chase et al. (FOCS '23). - We prove that any disambiguation of the Gap Hamming
Distance problem in the large gap regime has unbounded public-coin randomized
communication complexity. This answers an open problem of Fang et al. (STOC
'25).
  We prove the lower bound via a topological argument involving the local
Borsuk-Ulam theorem of Chase et al. (STOC '24). For the upper bound, we design
a learning rule that relies on certain triangulations of the cross-polytope and
recent results on the generalization properties of SVM.","['Ari Blondal', 'Hamed Hatami', 'Pooya Hatami', 'Chavdar Lalov', 'Sivan Tretiak']",2025-03-19,['cs.LG'],,http://arxiv.org/pdf/2503.15294v1
2503.15288v1,Beacon2Science: Enhancing STEREO/HI beacon data1 with machine learning for efficient CME tracking,"Observing and forecasting coronal mass ejections (CME) in real-time is
crucial due to the strong geomagnetic storms they can generate that can have a
potentially damaging effect, for example, on satellites and electrical devices.
With its near-real-time availability, STEREO/HI beacon data is the perfect
candidate for early forecasting of CMEs. However, previous work concluded that
CME arrival prediction based on beacon data could not achieve the same accuracy
as with high-resolution science data due to data gaps and lower quality. We
present our novel pipeline entitled ''Beacon2Science'', bridging the gap
between beacon and science data to improve CME tracking. Through this pipeline,
we first enhance the quality (signal-to-noise ratio and spatial resolution) of
beacon data. We then increase the time resolution of enhanced beacon images
through learned interpolation to match science data's 40-minute resolution. We
maximize information coherence between consecutive frames with adapted model
architecture and loss functions through the different steps. The improved
beacon images are comparable to science data, showing better CME visibility
than the original beacon data. Furthermore, we compare CMEs tracked in beacon,
enhanced beacon, and science images. The tracks extracted from enhanced beacon
data are closer to those from science images, with a mean average error of
$\sim 0.5 ^\circ$ of elongation compared to $1^\circ$ with original beacon
data. The work presented in this paper paves the way for its application to
forthcoming missions such as Vigil and PUNCH.","['Justin Le Louëdec', 'Maike Bauer', 'Tanja Amerstorfer', 'Jackie A. Davies']",2025-03-19,"['physics.space-ph', 'cs.CV', 'cs.LG']","24 pages, 11 figures, 1 tables, submitted to AGU Space Weather on
  14th Marc 2025",http://arxiv.org/pdf/2503.15288v1
2503.15581v1,Performance-bounded Online Ensemble Learning Method Based on Multi-armed bandits and Its Applications in Real-time Safety Assessment,"Ensemble learning plays a crucial role in practical applications of online
learning due to its enhanced classification performance and adaptable
adjustment mechanisms. However, most weight allocation strategies in ensemble
learning are heuristic, making it challenging to theoretically guarantee that
the ensemble classifier outperforms its base classifiers. To address this
issue, a performance-bounded online ensemble learning method based on
multi-armed bandits, named PB-OEL, is proposed in this paper. Specifically,
multi-armed bandit with expert advice is incorporated into online ensemble
learning, aiming to update the weights of base classifiers and make
predictions. A theoretical framework is established to bound the performance of
the ensemble classifier relative to base classifiers. By setting expert advice
of bandits, the bound exceeds the performance of any base classifier when the
length of data stream is sufficiently large. Additionally, performance bounds
for scenarios with limited annotations are also derived. Numerous experiments
on benchmark datasets and a dataset of real-time safety assessment tasks are
conducted. The experimental results validate the theoretical bound to a certain
extent and demonstrate that the proposed method outperforms existing
state-of-the-art methods.","['Songqiao Hu', 'Zeyi Liu', 'Xiao He']",2025-03-19,"['cs.LG', 'cs.SY', 'eess.SY']","14 pages, 9 figures",http://arxiv.org/pdf/2503.15581v1
2503.15267v1,Learning to quantify graph nodes,"Network Quantification is the problem of estimating the class proportions in
unlabeled subsets of graph nodes. When prior probability shift is at play, this
task cannot be effectively addressed by first classifying the nodes and then
counting the class predictions. In addition, unlike non-relational
quantification on i.i.d. datapoints, Network Quantification demands enhanced
flexibility to capture a broad range of connectivity patterns, resilience to
the challenge of heterophily, and efficiency to scale to larger networks. To
meet these stringent requirements we introduce XNQ, a novel method that
synergizes the flexibility and efficiency of the unsupervised node embeddings
computed by randomized recursive Graph Neural Networks, with an
Expectation-Maximization algorithm that provides a robust quantification-aware
adjustment to the output probabilities of a calibrated node classifier. We
validate the design choices underpinning our method through comprehensive
ablation experiments. In an extensive evaluation, we find that our approach
consistently and significantly improves on the best Network Quantification
methods to date, thereby setting the new state of the art for this challenging
task. Simultaneously, it provides a training speed-up of up to 10x-100x over
other graph learning based methods.","['Alessio Micheli', 'Alejandro Moreo', 'Marco Podda', 'Fabrizio Sebastiani', 'William Simoni', 'Domenico Tortorella']",2025-03-19,['cs.LG'],,http://arxiv.org/pdf/2503.15267v1
2503.15259v1,Fast MLE and MAPE-Based Device Activity Detection for Grant-Free Access via PSCA and PSCA-Net,"Fast and accurate device activity detection is the critical challenge in
grant-free access for supporting massive machine-type communications (mMTC) and
ultra-reliable low-latency communications (URLLC) in 5G and beyond. The
state-of-the-art methods have unsatisfactory error rates or computation times.
To address these outstanding issues, we propose new maximum likelihood
estimation (MLE) and maximum a posterior estimation (MAPE) based device
activity detection methods for known and unknown pathloss that achieve superior
error rate and computation time tradeoffs using optimization and deep learning
techniques. Specifically, we investigate four non-convex optimization problems
for MLE and MAPE in the two pathloss cases, with one MAPE problem being
formulated for the first time. For each non-convex problem, we develop an
innovative parallel iterative algorithm using the parallel successive convex
approximation (PSCA) method. Each PSCA-based algorithm allows parallel
computations, uses up to the objective function's second-order information,
converges to the problem's stationary points, and has a low per-iteration
computational complexity compared to the state-of-the-art algorithms. Then, for
each PSCA-based iterative algorithm, we present a deep unrolling neural network
implementation, called PSCA-Net, to further reduce the computation time. Each
PSCA-Net elegantly marries the underlying PSCA-based algorithm's parallel
computation mechanism with the parallelizable neural network architecture and
effectively optimizes its step sizes based on vast data samples to speed up the
convergence. Numerical results demonstrate that the proposed methods can
significantly reduce the error rate and computation time compared to the
state-of-the-art methods, revealing their significant values for grant-free
access.","['Bowen Tan', 'Ying Cui']",2025-03-19,"['math.OC', 'cs.LG']",,http://arxiv.org/pdf/2503.15259v1
2503.15250v1,ImputeGAP: A Comprehensive Library for Time Series Imputation,"With the prevalence of sensor failures, imputation--the process of estimating
missing values--has emerged as the cornerstone of time series data preparation.
While numerous imputation algorithms have been developed to address these data
gaps, existing libraries provide limited support. Furthermore, they often lack
the ability to simulate realistic patterns of time series missing data and fail
to account for the impact of imputation on subsequent downstream analysis.
  This paper introduces ImputeGAP, a comprehensive library for time series
imputation that supports a diverse range of imputation methods and modular
missing data simulation catering to datasets with varying characteristics. The
library includes extensive customization options, such as automated
hyperparameter tuning, benchmarking, explainability, downstream evaluation, and
compatibility with popular time series frameworks.","['Quentin Nater', 'Mourad Khayati', 'Jacques Pasquier']",2025-03-19,"['cs.LG', 'cs.DB']",,http://arxiv.org/pdf/2503.15250v1
2503.15225v1,A Personalized Data-Driven Generative Model of Human Motion,"The deployment of autonomous virtual avatars (in extended reality) and robots
in human group activities - such as rehabilitation therapy, sports, and
manufacturing - is expected to increase as these technologies become more
pervasive. Designing cognitive architectures and control strategies to drive
these agents requires realistic models of human motion. However, existing
models only provide simplified descriptions of human motor behavior. In this
work, we propose a fully data-driven approach, based on Long Short-Term Memory
neural networks, to generate original motion that captures the unique
characteristics of specific individuals. We validate the architecture using
real data of scalar oscillatory motion. Extensive analyses show that our model
effectively replicates the velocity distribution and amplitude envelopes of the
individual it was trained on, remaining different from other individuals, and
outperforming state-of-the-art models in terms of similarity to human data.","['Angelo Di Porzio', 'Marco Coraggio']",2025-03-19,"['cs.GR', 'cs.AI', 'cs.LG', 'cs.SY', 'eess.SY']","6 pages, 9 figures",http://arxiv.org/pdf/2503.15225v1
2503.15221v1,A Foundation Model for Patient Behavior Monitoring and Suicide Detection,"Foundation models (FMs) have achieved remarkable success across various
domains, yet their adoption in healthcare remains limited. While significant
advances have been made in medical imaging, genetic biomarkers, and time series
from electronic health records, the potential of FMs for patient behavior
monitoring through wearable devices remains underexplored. These datasets are
inherently heterogeneous, multisource, and often exhibit high rates of missing
data, posing unique challenges. This paper introduces a novel FM based on a
modified vector quantized variational autoencoder (VQ-VAE), specifically
designed to process real-world data from wearable devices. We demonstrate that
our pretrained FM, trained on a broad cohort of psychiatric patients, performs
downstream tasks via its latent representation without fine-tuning on a
held-out cohort of suicidal patients. To illustrate this, we develop a
probabilistic change-point detection algorithm for suicide detection and
demonstrate the FM's effectiveness in predicting emotional states. Our results
show that the discrete latent structure of the VQ-VAE outperforms a
state-of-the-art Informer architecture in unsupervised suicide detection, while
matching its performance in supervised emotion prediction when the latent
dimensionality is increased, though at the cost of reduced unsupervised
accuracy. This trade-off highlights the need for future FMs to integrate hybrid
discrete-continuous structures for balanced performance across tasks.","['Rodrigo Oliver', 'Josué Pérez-Sabater', 'Leire Paz-Arbaizar', 'Alejandro Lancho', 'Antonio Artés', 'Pablo M. Olmos']",2025-03-19,['cs.LG'],"10 pages (31 with appendices), 6 figures (13 with appendices);
  submitted to UAI 2025",http://arxiv.org/pdf/2503.15221v1
2503.15210v1,Online federated learning framework for classification,"In this paper, we develop a novel online federated learning framework for
classification, designed to handle streaming data from multiple clients while
ensuring data privacy and computational efficiency. Our method leverages the
generalized distance-weighted discriminant technique, making it robust to both
homogeneous and heterogeneous data distributions across clients. In particular,
we develop a new optimization algorithm based on the Majorization-Minimization
principle, integrated with a renewable estimation procedure, enabling efficient
model updates without full retraining. We provide a theoretical guarantee for
the convergence of our estimator, proving its consistency and asymptotic
normality under standard regularity conditions. In addition, we establish that
our method achieves Bayesian risk consistency, ensuring its reliability for
classification tasks in federated environments. We further incorporate
differential privacy mechanisms to enhance data security, protecting client
information while maintaining model performance. Extensive numerical
experiments on both simulated and real-world datasets demonstrate that our
approach delivers high classification accuracy, significant computational
efficiency gains, and substantial savings in data storage requirements compared
to existing methods.","['Wenxing Guo', 'Jinhan Xie', 'Jianya Lu', 'Bei jiang', 'Hongsheng Dai', 'Linglong Kong']",2025-03-19,"['stat.ML', 'cs.LG']",,http://arxiv.org/pdf/2503.15210v1
2503.15209v1,Kolmogorov-Arnold Network for Transistor Compact Modeling,"Neural network (NN)-based transistor compact modeling has recently emerged as
a transformative solution for accelerating device modeling and SPICE circuit
simulations. However, conventional NN architectures, despite their widespread
adoption in state-of-the-art methods, primarily function as black-box problem
solvers. This lack of interpretability significantly limits their capacity to
extract and convey meaningful insights into learned data patterns, posing a
major barrier to their broader adoption in critical modeling tasks. This work
introduces, for the first time, Kolmogorov-Arnold network (KAN) for the
transistor - a groundbreaking NN architecture that seamlessly integrates
interpretability with high precision in physics-based function modeling. We
systematically evaluate the performance of KAN and Fourier KAN for FinFET
compact modeling, benchmarking them against the golden industry-standard
compact model and the widely used MLP architecture. Our results reveal that KAN
and FKAN consistently achieve superior prediction accuracy for critical figures
of merit, including gate current, drain charge, and source charge. Furthermore,
we demonstrate and improve the unique ability of KAN to derive symbolic
formulas from learned data patterns - a capability that not only enhances
interpretability but also facilitates in-depth transistor analysis and
optimization. This work highlights the transformative potential of KAN in
bridging the gap between interpretability and precision in NN-driven transistor
compact modeling. By providing a robust and transparent approach to transistor
modeling, KAN represents a pivotal advancement for the semiconductor industry
as it navigates the challenges of advanced technology scaling.","['Rodion Novkin', 'Hussam Amrouch']",2025-03-19,['cs.LG'],"13 pages, 8 figures",http://arxiv.org/pdf/2503.15209v1
2503.15579v1,Understanding the Generalization of In-Context Learning in Transformers: An Empirical Study,"Large language models (LLMs) like GPT-4 and LLaMA-3 utilize the powerful
in-context learning (ICL) capability of Transformer architecture to learn on
the fly from limited examples. While ICL underpins many LLM applications, its
full potential remains hindered by a limited understanding of its
generalization boundaries and vulnerabilities. We present a systematic
investigation of transformers' generalization capability with ICL relative to
training data coverage by defining a task-centric framework along three
dimensions: inter-problem, intra-problem, and intra-task generalization.
Through extensive simulation and real-world experiments, encompassing tasks
such as function fitting, API calling, and translation, we find that
transformers lack inter-problem generalization with ICL, but excel in
intra-task and intra-problem generalization. When the training data includes a
greater variety of mixed tasks, it significantly enhances the generalization
ability of ICL on unseen tasks and even on known simple tasks. This guides us
in designing training data to maximize the diversity of tasks covered and to
combine different tasks whenever possible, rather than solely focusing on the
target task for testing.","['Xingxuan Zhang', 'Haoran Wang', 'Jiansheng Li', 'Yuan Xue', 'Shikai Guan', 'Renzhe Xu', 'Hao Zou', 'Han Yu', 'Peng Cui']",2025-03-19,['cs.LG'],32 pages,http://arxiv.org/pdf/2503.15579v1
2503.15200v1,Partially Observable Reinforcement Learning with Memory Traces,"Partially observable environments present a considerable computational
challenge in reinforcement learning due to the need to consider long histories.
Learning with a finite window of observations quickly becomes intractable as
the window length grows. In this work, we introduce memory traces. Inspired by
eligibility traces, these are compact representations of the history of
observations in the form of exponential moving averages. We prove sample
complexity bounds for the problem of offline on-policy evaluation that quantify
the value errors achieved with memory traces for the class of Lipschitz
continuous value estimates. We establish a close connection to the window
approach, and demonstrate that, in certain environments, learning with memory
traces is significantly more sample efficient. Finally, we underline the
effectiveness of memory traces empirically in online reinforcement learning
experiments for both value prediction and control.","['Onno Eberhard', 'Michael Muehlebach', 'Claire Vernade']",2025-03-19,['cs.LG'],,http://arxiv.org/pdf/2503.15200v1
2503.15578v1,Sparseformer: a Transferable Transformer with Multi-granularity Token Sparsification for Medical Time Series Classification,"Medical time series (MedTS) classification is crucial for improved diagnosis
in healthcare, and yet it is challenging due to the varying granularity of
patterns, intricate inter-channel correlation, information redundancy, and
label scarcity. While existing transformer-based models have shown promise in
time series analysis, they mainly focus on forecasting and fail to fully
exploit the distinctive characteristics of MedTS data. In this paper, we
introduce Sparseformer, a transformer specifically designed for MedTS
classification. We propose a sparse token-based dual-attention mechanism that
enables global modeling and token compression, allowing dynamic focus on the
most informative tokens while distilling redundant features. This mechanism is
then applied to the multi-granularity, cross-channel encoding of medical
signals, capturing intra- and inter-granularity correlations and inter-channel
connections. The sparsification design allows our model to handle heterogeneous
inputs of varying lengths and channels directly. Further, we introduce an
adaptive label encoder to address label space misalignment across datasets,
equipping our model with cross-dataset transferability to alleviate the medical
label scarcity issue. Our model outperforms 12 baselines across seven medical
datasets under supervised learning. In the few-shot learning experiments, our
model also achieves superior average results. In addition, the in-domain and
cross-domain experiments among three diagnostic scenarios demonstrate our
model's zero-shot learning capability. Collectively, these findings underscore
the robustness and transferability of our model in various medical
applications.","['Jiexia Ye', 'Weiqi Zhang', 'Ziyue Li', 'Jia Li', 'Fugee Tsung']",2025-03-19,['cs.LG'],"3 figures, 16 pages, 5 tables",http://arxiv.org/pdf/2503.15578v1
2503.15190v1,Learning Topology Actions for Power Grid Control: A Graph-Based Soft-Label Imitation Learning Approach,"The rising proportion of renewable energy in the electricity mix introduces
significant operational challenges for power grid operators. Effective power
grid management demands adaptive decision-making strategies capable of handling
dynamic conditions. With the increase in complexity, more and more Deep
Learning (DL) approaches have been proposed to find suitable grid topologies
for congestion management. In this work, we contribute to this research by
introducing a novel Imitation Learning (IL) approach that leverages soft labels
derived from simulated topological action outcomes, thereby capturing multiple
viable actions per state. Unlike traditional IL methods that rely on hard
labels to enforce a single optimal action, our method constructs soft labels
over actions, by leveraging effective actions that prove suitable in resolving
grid congestion. To further enhance decision-making, we integrate Graph Neural
Networks (GNNs) to encode the structural properties of power grids, ensuring
that the topology-aware representations contribute to better agent performance.
Our approach significantly outperforms state-of-the-art baselines, all of which
use only topological actions, as well as feedforward and GNN-based
architectures with hard labels. Most notably, it achieves a 17% better
performance compared to the greedy expert agent from which the imitation
targets were derived.","['Mohamed Hassouna', 'Clara Holzhüter', 'Malte Lehna', 'Matthijs de Jong', 'Jan Viebahn', 'Bernhard Sick', 'Christoph Scholz']",2025-03-19,['cs.LG'],,http://arxiv.org/pdf/2503.15190v1
2503.15576v1,A Bird Song Detector for improving bird identification through Deep Learning: a case study from Doñana,"Passive Acoustic Monitoring with automatic recorders is essential for
ecosystem conservation but generates vast unsupervised audio data, posing
challenges for extracting meaningful information. Deep Learning techniques
offer a promising solution. BirdNET, a widely used model for bird
identification, has shown success in many study systems but is limited in some
regions due to biases in its training data. A key challenge in bird species
detection is that many recordings either lack target species or contain
overlapping vocalizations. To overcome these problems, we developed a
multi-stage pipeline for automatic bird vocalization identification in Do\~nana
National Park (SW Spain), a region facing significant conservation threats. Our
approach included a Bird Song Detector to isolate vocalizations and custom
classifiers trained with BirdNET embeddings. We manually annotated 461 minutes
of audio from three habitats across nine locations, yielding 3,749 annotations
for 34 classes. Spectrograms facilitated the use of image processing
techniques. Applying the Bird Song Detector before classification improved
species identification, as all classification models performed better when
analyzing only the segments where birds were detected. Specifically, the
combination of the Bird Song Detector and fine-tuned BirdNET compared to the
baseline without the Bird Song Detector. Our approach demonstrated the
effectiveness of integrating a Bird Song Detector with fine-tuned
classification models for bird identification at local soundscapes. These
findings highlight the need to adapt general-purpose tools for specific
ecological challenges, as demonstrated in Do\~nana. Automatically detecting
bird species serves for tracking the health status of this threatened
ecosystem, given the sensitivity of birds to environmental changes, and helps
in the design of conservation measures for reducing biodiversity loss","['Alba Márquez-Rodríguez', 'Miguel Ángel Mohedano-Munoz', 'Manuel J. Marín-Jiménez', 'Eduardo Santamaría-García', 'Giulia Bastianelli', 'Pedro Jordano', 'Irene Mendoza']",2025-03-19,"['cs.SD', 'cs.AI', 'cs.CV', 'cs.LG', 'cs.NE', 'I.5.4; I.2.6; I.4.8']","20 pages, 13 images, for associated dataset see
  https://huggingface.co/datasets/GrunCrow/BIRDeep_AudioAnnotations , for
  associated code see
  https://github.com/GrunCrow/BIRDeep_BirdSongDetector_NeuralNetworks and
  https://github.com/GrunCrow/Bird-Song-Detector",http://arxiv.org/pdf/2503.15576v1
2503.15177v1,Food Delivery Time Prediction in Indian Cities Using Machine Learning Models,"Accurate prediction of food delivery times significantly impacts customer
satisfaction, operational efficiency, and profitability in food delivery
services. However, existing studies primarily utilize static historical data
and often overlook dynamic, real-time contextual factors crucial for precise
prediction, particularly in densely populated Indian cities. This research
addresses these gaps by integrating real-time contextual variables such as
traffic density, weather conditions, local events, and geospatial data
(restaurant and delivery location coordinates) into predictive models. We
systematically compare various machine learning algorithms, including Linear
Regression, Decision Trees, Bagging, Random Forest, XGBoost, and LightGBM, on a
comprehensive food delivery dataset specific to Indian urban contexts. Rigorous
data preprocessing and feature selection significantly enhanced model
performance. Experimental results demonstrate that the LightGBM model achieves
superior predictive accuracy, with an R2 score of 0.76 and Mean Squared Error
(MSE) of 20.59, outperforming traditional baseline approaches. Our study thus
provides actionable insights for improving logistics strategies in complex
urban environments. The complete methodology and code are publicly available
for reproducibility and further research.","['Ananya Garg', 'Mohmmad Ayaan', 'Swara Parekh', 'Vikranth Udandarao']",2025-03-19,['cs.LG'],"for code implementation, check
  https://github.com/Vikranth3140/Food-Delivery-Time-Prediction",http://arxiv.org/pdf/2503.15177v1
2503.15172v1,Multi-Agent Actor-Critic with Harmonic Annealing Pruning for Dynamic Spectrum Access Systems,"Multi-Agent Deep Reinforcement Learning (MADRL) has emerged as a powerful
tool for optimizing decentralized decision-making systems in complex settings,
such as Dynamic Spectrum Access (DSA). However, deploying deep learning models
on resource-constrained edge devices remains challenging due to their high
computational cost. To address this challenge, in this paper, we present a
novel sparse recurrent MARL framework integrating gradual neural network
pruning into the independent actor global critic paradigm. Additionally, we
introduce a harmonic annealing sparsity scheduler, which achieves comparable,
and in certain cases superior, performance to standard linear and polynomial
pruning schedulers at large sparsities. Our experimental investigation
demonstrates that the proposed DSA framework can discover superior policies,
under diverse training conditions, outperforming conventional DSA, MADRL
baselines, and state-of-the-art pruning techniques.","['George Stamatelis', 'Angelos-Nikolaos Kanatas', 'George C. Alexandropoulos']",2025-03-19,"['cs.LG', 'cs.AI', 'cs.NI']","5 pages, 3 figures, 1 table, submited to an IEEE conference",http://arxiv.org/pdf/2503.15172v1
2503.15168v1,"World Models in Artificial Intelligence: Sensing, Learning, and Reasoning Like a Child","World Models help Artificial Intelligence (AI) predict outcomes, reason about
its environment, and guide decision-making. While widely used in reinforcement
learning, they lack the structured, adaptive representations that even young
children intuitively develop. Advancing beyond pattern recognition requires
dynamic, interpretable frameworks inspired by Piaget's cognitive development
theory. We highlight six key research areas -- physics-informed learning,
neurosymbolic learning, continual learning, causal inference, human-in-the-loop
AI, and responsible AI -- as essential for enabling true reasoning in AI. By
integrating statistical learning with advances in these areas, AI can evolve
from pattern recognition to genuine understanding, adaptation and reasoning
capabilities.","['Javier Del Ser', 'Jesus L. Lobo', 'Heimo Müller', 'Andreas Holzinger']",2025-03-19,"['cs.AI', 'cs.CV', 'cs.ET', 'cs.LG', '68T05']","11 pages, 1 figure",http://arxiv.org/pdf/2503.15168v1
2503.15166v1,Machine Unlearning in Hyperbolic vs. Euclidean Multimodal Contrastive Learning: Adapting Alignment Calibration to MERU,"Machine unlearning methods have become increasingly important for selective
concept removal in large pre-trained models. While recent work has explored
unlearning in Euclidean contrastive vision-language models, the effectiveness
of concept removal in hyperbolic spaces remains unexplored. This paper
investigates machine unlearning in hyperbolic contrastive learning by adapting
Alignment Calibration to MERU, a model that embeds images and text in
hyperbolic space to better capture semantic hierarchies. Through systematic
experiments and ablation studies, we demonstrate that hyperbolic geometry
offers distinct advantages for concept removal, achieving near perfect
forgetting with reasonable performance on retained concepts, particularly when
scaling to multiple concept removal. Our approach introduces
hyperbolic-specific components including entailment calibration and norm
regularization that leverage the unique properties of hyperbolic space.
Comparative analysis with Euclidean models reveals fundamental differences in
unlearning dynamics, with hyperbolic unlearning reorganizing the semantic
hierarchy while Euclidean approaches merely disconnect cross-modal
associations. These findings not only advance machine unlearning techniques but
also provide insights into the geometric properties that influence concept
representation and removal in multimodal models. Source code available at
https://github.com/alex-pv01/HAC","['Àlex Pujol Vidal', 'Sergio Escalera', 'Kamal Nasrollahi', 'Thomas B. Moeslund']",2025-03-19,"['cs.CV', 'cs.AI', 'cs.CL', 'cs.LG', 'cs.MM']",Preprint,http://arxiv.org/pdf/2503.15166v1
2503.15163v1,Global Group Fairness in Federated Learning via Function Tracking,"We investigate group fairness regularizers in federated learning, aiming to
train a globally fair model in a distributed setting. Ensuring global fairness
in distributed training presents unique challenges, as fairness regularizers
typically involve probability metrics between distributions across all clients
and are not naturally separable by client. To address this, we introduce a
function-tracking scheme for the global fairness regularizer based on a Maximum
Mean Discrepancy (MMD), which incurs a small communication overhead. This
scheme seamlessly integrates into most federated learning algorithms while
preserving rigorous convergence guarantees, as demonstrated in the context of
FedAvg. Additionally, when enforcing differential privacy, the kernel-based MMD
regularization enables straightforward analysis through a change of kernel,
leveraging an intuitive interpretation of kernel convolution. Numerical
experiments confirm our theoretical insights.","['Yves Rychener', 'Daniel Kuhn', 'Yifan Hu']",2025-03-19,"['cs.LG', 'math.OC', 'stat.ME']",The paper is accepted to AISTATS 2025,http://arxiv.org/pdf/2503.15163v1
2503.15150v1,Preference Construction: A Bayesian Interactive Preference Elicitation Framework Based on Monte Carlo Tree Search,"We present a novel preference learning framework to capture participant
preferences efficiently within limited interaction rounds. It involves three
main contributions. First, we develop a variational Bayesian approach to infer
the participant's preference model by estimating posterior distributions and
managing uncertainty from limited information. Second, we propose an adaptive
questioning policy that maximizes cumulative uncertainty reduction, formulating
questioning as a finite Markov decision process and using Monte Carlo Tree
Search to prioritize promising question trajectories. By considering long-term
effects and leveraging the efficiency of the Bayesian approach, the policy
avoids shortsightedness. Third, we apply the framework to Multiple Criteria
Decision Aiding, with pairwise comparison as the preference information and an
additive value function as the preference model. We integrate the
reparameterization trick to address high-variance issues, enhancing robustness
and efficiency. Computational studies on real-world and synthetic datasets
demonstrate the framework's practical usability, outperforming baselines in
capturing preferences and achieving superior uncertainty reduction within
limited interactions.","['Yan Wang', 'Jiapeng Liu', 'Milosz Kadziński', 'Xiuwu Liao']",2025-03-19,['cs.LG'],,http://arxiv.org/pdf/2503.15150v1
2503.15149v1,Machine learning surrogate models of many-body dispersion interactions in polymer melts,"Accurate prediction of many-body dispersion (MBD) interactions is essential
for understanding the van der Waals forces that govern the behavior of many
complex molecular systems. However, the high computational cost of MBD
calculations limits their direct application in large-scale simulations. In
this work, we introduce a machine learning surrogate model specifically
designed to predict MBD forces in polymer melts, a system that demands accurate
MBD description and offers structural advantages for machine learning
approaches. Our model is based on a trimmed SchNet architecture that
selectively retains the most relevant atomic connections and incorporates
trainable radial basis functions for geometric encoding. We validate our
surrogate model on datasets from polyethylene, polypropylene, and polyvinyl
chloride melts, demonstrating high predictive accuracy and robust
generalization across diverse polymer systems. In addition, the model captures
key physical features, such as the characteristic decay behavior of MBD
interactions, providing valuable insights for optimizing cutoff strategies.
Characterized by high computational efficiency, our surrogate model enables
practical incorporation of MBD effects into large-scale molecular simulations.","['Zhaoxiang Shen', 'Raúl I. Sosa', 'Jakub Lengiewicz', 'Alexandre Tkatchenko', 'Stéphane P. A. Bordas']",2025-03-19,"['cs.LG', 'physics.comp-ph']",,http://arxiv.org/pdf/2503.15149v1
2503.15574v1,Machine Learning Techniques for Multifactor Analysis of National Carbon Dioxide Emissions,"This paper presents a comprehensive study leveraging Support Vector Machine
(SVM) regression and Principal Component Regression (PCR) to analyze carbon
dioxide emissions in a global dataset of 62 countries and their dependence on
idiosyncratic, country-specific parameters. The objective is to understand the
factors contributing to carbon dioxide emissions and identify the most
predictive elements. The analysis provides country-specific emission estimates,
highlighting diverse national trajectories and pinpointing areas for targeted
interventions in climate change mitigation, sustainable development, and the
growing carbon credit markets and green finance sector. The study aims to
support policymaking with accurate representations of carbon dioxide emissions,
offering nuanced information for formulating effective strategies to address
climate change while informing initiatives related to carbon trading and
environmentally sustainable investments.","['Wenjia Xie', 'Jinhui Li', 'Kai Zong', 'Luis Seco']",2025-03-19,['cs.LG'],,http://arxiv.org/pdf/2503.15574v1
2503.15573v1,Neuronal Activation States as Sample Embeddings for Data Selection in Task-Specific Instruction Tuning,"Task-specific instruction tuning enhances the performance of large language
models (LLMs) on specialized tasks, yet efficiently selecting relevant data for
this purpose remains a challenge. Inspired by neural coactivation in the human
brain, we propose a novel data selection method called NAS, which leverages
neuronal activation states as embeddings for samples in the feature space.
Extensive experiments show that NAS outperforms classical data selection
methods in terms of both effectiveness and robustness across different models,
datasets, and selection ratios.","['Da Ma', 'Gonghu Shang', 'Zhi Chen', 'Libo Qin', 'Yijie Luo', 'Lei Pan', 'Shuai Fan', 'Lu Chen', 'Kai Yu']",2025-03-19,['cs.LG'],preprint,http://arxiv.org/pdf/2503.15573v1
2503.15114v1,DeCaFlow: A Deconfounding Causal Generative Model,"Causal generative models (CGMs) have recently emerged as capable approaches
to simulate the causal mechanisms generating our observations, enabling causal
inference. Unfortunately, existing approaches either are overly restrictive,
assuming the absence of hidden confounders, or lack generality, being tailored
to a particular query and graph. In this work, we introduce DeCaFlow, a CGM
that accounts for hidden confounders in a single amortized training process
using only observational data and the causal graph. Importantly, DeCaFlow can
provably identify all causal queries with a valid adjustment set or
sufficiently informative proxy variables. Remarkably, for the first time to our
knowledge, we show that a confounded counterfactual query is identifiable, and
thus solvable by DeCaFlow, as long as its interventional counterpart is as
well. Our empirical results on diverse settings (including the Ecoli70 dataset,
with 3 independent hidden confounders, tens of observed variables and hundreds
of causal queries) show that DeCaFlow outperforms existing approaches, while
demonstrating its out-of-the-box flexibility.","['Alejandro Almodóvar', 'Adrián Javaloy', 'Juan Parras', 'Santiago Zazo', 'Isabel Valera']",2025-03-19,['cs.LG'],"32 pages, 22 figures. Under submission",http://arxiv.org/pdf/2503.15114v1
2503.15111v1,FedLWS: Federated Learning with Adaptive Layer-wise Weight Shrinking,"In Federated Learning (FL), weighted aggregation of local models is conducted
to generate a new global model, and the aggregation weights are typically
normalized to 1. A recent study identifies the global weight shrinking effect
in FL, indicating an enhancement in the global model's generalization when the
sum of weights (i.e., the shrinking factor) is smaller than 1, where how to
learn the shrinking factor becomes crucial. However, principled approaches to
this solution have not been carefully studied from the adequate consideration
of privacy concerns and layer-wise distinctions. To this end, we propose a
novel model aggregation strategy, Federated Learning with Adaptive Layer-wise
Weight Shrinking (FedLWS), which adaptively designs the shrinking factor in a
layer-wise manner and avoids optimizing the shrinking factors on a proxy
dataset. We initially explored the factors affecting the shrinking factor
during the training process. Then we calculate the layer-wise shrinking factors
by considering the distinctions among each layer of the global model. FedLWS
can be easily incorporated with various existing methods due to its
flexibility. Extensive experiments under diverse scenarios demonstrate the
superiority of our method over several state-of-the-art approaches, providing a
promising tool for enhancing the global model in FL.","['Changlong Shi', 'Jinmeng Li', 'He Zhao', 'Dan dan Guo', 'Yi Chang']",2025-03-19,['cs.LG'],Accepted in ICLR 2025,http://arxiv.org/pdf/2503.15111v1
2503.15108v1,VIPER: Visual Perception and Explainable Reasoning for Sequential Decision-Making,"While Large Language Models (LLMs) excel at reasoning on text and
Vision-Language Models (VLMs) are highly effective for visual perception,
applying those models for visual instruction-based planning remains a widely
open problem. In this paper, we introduce VIPER, a novel framework for
multimodal instruction-based planning that integrates VLM-based perception with
LLM-based reasoning. Our approach uses a modular pipeline where a frozen VLM
generates textual descriptions of image observations, which are then processed
by an LLM policy to predict actions based on the task goal. We fine-tune the
reasoning module using behavioral cloning and reinforcement learning, improving
our agent's decision-making capabilities. Experiments on the ALFWorld benchmark
show that VIPER significantly outperforms state-of-the-art visual
instruction-based planners while narrowing the gap with purely text-based
oracles. By leveraging text as an intermediate representation, VIPER also
enhances explainability, paving the way for a fine-grained analysis of
perception and reasoning components.","['Mohamed Salim Aissi', 'Clemence Grislain', 'Mohamed Chetouani', 'Olivier Sigaud', 'Laure Soulier', 'Nicolas Thome']",2025-03-19,"['cs.LG', 'cs.AI', 'cs.RO']",,http://arxiv.org/pdf/2503.15108v1
2503.15107v1,Interpretability of Graph Neural Networks to Assert Effects of Global Change Drivers on Ecological Networks,"Pollinators play a crucial role for plant reproduction, either in natural
ecosystem or in human-modified landscape. Global change drivers,including
climate change or land use modifications, can alter the plant-pollinator
interactions. To assert the potential influence of global change drivers on
pollination, large-scale interactions, climate and land use data are required.
While recent machine learning methods, such as graph neural networks (GNNs),
allow the analysis of such datasets, interpreting their results can be
challenging. We explore existing methods for interpreting GNNs in order to
highlight the effects of various environmental covariates on pollination
network connectivity. A large simulation study is performed to confirm whether
these methods can detect the interactive effect between a covariate and a genus
of plant on connectivity, and whether the application of debiasing techniques
influences the estimation of these effects. An application on the Spipoll
dataset, with and without accounting for sampling effects, highlights the
potential impact of land use on network connectivity and shows that accounting
for sampling effects partially alters the estimation of these effects.","['Emre Anakok', 'Pierre Barbillon', 'Colin Fontaine', 'Elisa Thebault']",2025-03-19,"['stat.ML', 'cs.LG']",,http://arxiv.org/pdf/2503.15107v1
2503.15105v1,"Control, Optimal Transport and Neural Differential Equations in Supervised Learning","From the perspective of control theory, neural differential equations (neural
ODEs) have become an important tool for supervised learning. In the fundamental
work of Ruiz-Balet and Zuazua (SIAM REVIEW 2023), the authors pose an open
problem regarding the connection between control theory, optimal transport
theory, and neural differential equations. More precisely, they inquire how one
can quantify the closeness of the optimal flows in neural transport equations
to the true dynamic optimal transport. In this work, we propose a construction
of neural differential equations that converge to the true dynamic optimal
transport in the limit, providing a significant step in solving the formerly
mentioned open problem.","['Minh-Nhat Phung', 'Minh-Binh Tran']",2025-03-19,"['math.NA', 'cs.LG', 'cs.NA', 'math.OC']",,http://arxiv.org/pdf/2503.15105v1
2503.15571v1,LLM-Aided Customizable Profiling of Code Data Based On Programming Language Concepts,"Data profiling is critical in machine learning for generating descriptive
statistics, supporting both deeper understanding and downstream tasks like data
valuation and curation. This work addresses profiling specifically in the
context of code datasets for Large Language Models (code-LLMs), where data
quality directly influences tasks such as code generation and summarization.
Characterizing code datasets in terms of programming language concepts enables
better insights and targeted data curation. Our proposed methodology decomposes
code data profiling into two phases: (1) an offline phase where LLMs are
leveraged to derive and learn rules for extracting syntactic and semantic
concepts across various programming languages, including previously unseen or
low-resource languages, and (2) an online deterministic phase applying these
derived rules for efficient real-time analysis. This hybrid approach is
customizable, extensible to new syntactic and semantic constructs, and scalable
to multiple languages. Experimentally, our LLM-aided method achieves a mean
accuracy of 90.33% for syntactic extraction rules and semantic classification
accuracies averaging 80% and 77% across languages and semantic concepts,
respectively.","['Pankaj Thorat', 'Adnan Qidwai', 'Adrija Dhar', 'Aishwariya Chakraborty', 'Anand Eswaran', 'Hima Patel', 'Praveen Jayachandran']",2025-03-19,"['cs.SE', 'cs.ET', 'cs.IR', 'cs.LG', 'cs.PL']",21 pages,http://arxiv.org/pdf/2503.15571v1
2503.15095v1,Diffusion-Based Forecasting for Uncertainty-Aware Model Predictive Control,"We propose Diffusion-Informed Model Predictive Control (D-I MPC), a generic
framework for uncertainty-aware prediction and decision-making in partially
observable stochastic systems by integrating diffusion-based time series
forecasting models in Model Predictive Control algorithms. In our approach, a
diffusion-based time series forecasting model is used to probabilistically
estimate the evolution of the system's stochastic components. These forecasts
are then incorporated into MPC algorithms to estimate future trajectories and
optimize action selection under the uncertainty of the future. We evaluate the
framework on the task of energy arbitrage, where a Battery Energy Storage
System participates in the day-ahead electricity market of the New York state.
Experimental results indicate that our model-based approach with a
diffusion-based forecaster significantly outperforms both implementations with
classical forecasting methods and model-free reinforcement learning baselines.","['Stelios Zarifis', 'Ioannis Kordonis', 'Petros Maragos']",2025-03-19,"['cs.LG', 'cs.AI', 'cs.SY', 'eess.SY', 'I.2.6; I.5.1']","5 pages, 3 figures, 3 tables. This version is submitted to the 33rd
  European Signal Processing Conference (EUSIPCO 2025), to be held in Isola
  delle Femmine - Palermo - Italy, on September 8-12, 2025",http://arxiv.org/pdf/2503.15095v1
2503.15089v1,Continual Contrastive Learning on Tabular Data with Out of Distribution,"Out-of-distribution (OOD) prediction remains a significant challenge in
machine learning, particularly for tabular data where traditional methods often
fail to generalize beyond their training distribution. This paper introduces
Tabular Continual Contrastive Learning (TCCL), a novel framework designed to
address OOD challenges in tabular data processing. TCCL integrates contrastive
learning principles with continual learning mechanisms, featuring a
three-component architecture: an Encoder for data transformation, a Decoder for
representation learning, and a Learner Head. We evaluate TCCL against 14
baseline models, including state-of-the-art deep learning approaches and
gradient-boosted decision trees (GBDT), across eight diverse tabular datasets.
Our experimental results demonstrate that TCCL consistently outperforms
existing methods in both classification and regression tasks on OOD data, with
particular strength in handling distribution shifts. These findings suggest
that TCCL represents a significant advancement in handling OOD scenarios for
tabular data.","['Achmad Ginanjar', 'Xue Li', 'Priyanka Singh', 'Wen Hua']",2025-03-19,['cs.LG'],accepeted on esann 2025,http://arxiv.org/pdf/2503.15089v1
2503.15569v1,RAG-based User Profiling for Precision Planning in Mixed-precision Over-the-Air Federated Learning,"Mixed-precision computing, a widely applied technique in AI, offers a larger
trade-off space between accuracy and efficiency. The recent purposed
Mixed-Precision Over-the-Air Federated Learning (MP-OTA-FL) enables clients to
operate at appropriate precision levels based on their heterogeneous hardware,
taking advantages of the larger trade-off space while covering the quantization
overheads in the mixed-precision modulation scheme for the OTA aggregation
process. A key to further exploring the potential of the MP-OTA-FL framework is
the optimization of client precision levels. The choice of precision level
hinges on multifaceted factors including hardware capability, potential client
contribution, and user satisfaction, among which factors can be difficult to
define or quantify.
  In this paper, we propose a RAG-based User Profiling for precision planning
framework that integrates retrieval-augmented LLMs and dynamic client profiling
to optimize satisfaction and contributions. This includes a hybrid interface
for gathering device/user insights and an RAG database storing historical
quantization decisions with feedback. Experiments show that our method boosts
satisfaction, energy savings, and global model accuracy in MP-OTA-FL systems.","['Jinsheng Yuan', 'Yun Tang', 'Weisi Guo']",2025-03-19,"['cs.LG', 'cs.HC']","5 pages, 4 figures, 2 tables, submitted to IEEE VTC 2025 fall for
  possible publication",http://arxiv.org/pdf/2503.15569v1
2503.15036v1,Multivariate Gaussian Topic Modelling: A novel approach to discover topics with greater semantic coherence,"An important aspect of text mining involves information retrieval in form of
discovery of semantic themes (topics) from documents using topic modelling.
While generative topic models like Latent Dirichlet Allocation (LDA) elegantly
model topics as probability distributions and are useful in identifying latent
topics from large document corpora with minimal supervision, they suffer from
difficulty in topic interpretability and reduced performance in shorter texts.
Here we propose a novel Multivariate Gaussian Topic modelling (MGD) approach.
In this approach topics are presented as Multivariate Gaussian Distributions
and documents as Gaussian Mixture Models. Using EM algorithm, the various
constituent Multivariate Gaussian Distributions and their corresponding
parameters are identified. Analysis of the parameters helps identify the
keywords having the highest variance and mean contributions to the topic, and
from these key-words topic annotations are carried out. This approach is first
applied on a synthetic dataset to demonstrate the interpretability benefits
vis-\`a-vis LDA. A real-world application of this topic model is demonstrated
in analysis of risks and hazards at a petrochemical plant by applying the model
on safety incident reports to identify the major latent hazards plaguing the
plant. This model achieves a higher mean topic coherence of 0.436 vis-\`a-vis
0.294 for LDA.","['Satyajeet Sahoo', 'Jhareswar Maiti', 'Virendra Kumar Tewari']",2025-03-19,['cs.LG'],12 pages,http://arxiv.org/pdf/2503.15036v1
2503.15568v1,Mixed precision accumulation for neural network inference guided by componentwise forward error analysis,"This work proposes a mathematically founded mixed precision accumulation
strategy for the inference of neural networks. Our strategy is based on a new
componentwise forward error analysis that explains the propagation of errors in
the forward pass of neural networks. Specifically, our analysis shows that the
error in each component of the output of a layer is proportional to the
condition number of the inner product between the weights and the input,
multiplied by the condition number of the activation function. These condition
numbers can vary widely from one component to the other, thus creating a
significant opportunity to introduce mixed precision: each component should be
accumulated in a precision inversely proportional to the product of these
condition numbers. We propose a practical algorithm that exploits this
observation: it first computes all components in low precision, uses this
output to estimate the condition numbers, and recomputes in higher precision
only the components associated with large condition numbers. We test our
algorithm on various networks and datasets and confirm experimentally that it
can significantly improve the cost--accuracy tradeoff compared with uniform
precision accumulation baselines.","['El-Mehdi El Arar', 'Silviu-Ioan Filip', 'Theo Mary', 'Elisa Riccietti']",2025-03-19,"['cs.LG', 'cs.NA', 'math.NA']",,http://arxiv.org/pdf/2503.15568v1
2503.15016v1,Manifold Learning for Hyperspectral Images,"Traditional feature extraction and projection techniques, such as Principal
Component Analysis, struggle to adequately represent X-Ray Transmission (XRT)
Multi-Energy (ME) images, limiting the performance of neural networks in
decision-making processes. To address this issue, we propose a method that
approximates the dataset topology by constructing adjacency graphs using the
Uniform Manifold Approximation and Projection. This approach captures nonlinear
correlations within the data, significantly improving the performance of
machine learning algorithms, particularly in processing Hyperspectral Images
(HSI) from X-ray transmission spectroscopy. This technique not only preserves
the global structure of the data but also enhances feature separability,
leading to more accurate and robust classification results.","['Fethi Harkat', 'Tiphaine Deuberet', 'Guillaume Gey', 'Valérie Perrier', 'Kévin Polisano']",2025-03-19,"['cs.CV', 'cs.LG']",,http://arxiv.org/pdf/2503.15016v1
2503.15013v1,Ambient Noise Full Waveform Inversion with Neural Operators,"Numerical simulations of seismic wave propagation are crucial for
investigating velocity structures and improving seismic hazard assessment.
However, standard methods such as finite difference or finite element are
computationally expensive. Recent studies have shown that a new class of
machine learning models, called neural operators, can solve the elastodynamic
wave equation orders of magnitude faster than conventional methods. Full
waveform inversion is a prime beneficiary of the accelerated simulations.
Neural operators, as end-to-end differentiable operators, combined with
automatic differentiation, provide an alternative approach to the adjoint-state
method. Since neural operators do not involve the Born approximation, when used
for full waveform inversion they have the potential to include additional
phases and alleviate cycle-skipping problems present in traditional
adjoint-state formulations. In this study, we demonstrate the application of
neural operators for full waveform inversion on a real seismic dataset, which
consists of several nodal transects collected across the San Gabriel, Chino,
and San Bernardino basins in the Los Angeles metropolitan area.","['Caifeng Zou', 'Zachary E. Ross', 'Robert W. Clayton', 'Fan-Chi Lin', 'Kamyar Azizzadenesheli']",2025-03-19,"['physics.geo-ph', 'cs.LG']",,http://arxiv.org/pdf/2503.15013v1
2503.15008v1,A Novel Channel Boosted Residual CNN-Transformer with Regional-Boundary Learning for Breast Cancer Detection,"Recent advancements in detecting tumors using deep learning on breast
ultrasound images (BUSI) have demonstrated significant success. Deep CNNs and
vision-transformers (ViTs) have demonstrated individually promising initial
performance. However, challenges related to model complexity and contrast,
texture, and tumor morphology variations introduce uncertainties that hinder
the effectiveness of current methods. This study introduces a novel hybrid
framework, CB-Res-RBCMT, combining customized residual CNNs and new ViT
components for detailed BUSI cancer analysis. The proposed RBCMT uses stem
convolution blocks with CNN Meet Transformer (CMT) blocks, followed by new
Regional and boundary (RB) feature extraction operations for capturing contrast
and morphological variations. Moreover, the CMT block incorporates global
contextual interactions through multi-head attention, enhancing computational
efficiency with a lightweight design. Additionally, the customized inverse
residual and stem CNNs within the CMT effectively extract local texture
information and handle vanishing gradients. Finally, the new channel-boosted
(CB) strategy enriches the feature diversity of the limited dataset by
combining the original RBCMT channels with transfer learning-based residual
CNN-generated maps. These diverse channels are processed through a spatial
attention block for optimal pixel selection, reducing redundancy and improving
the discrimination of minor contrast and texture variations. The proposed
CB-Res-RBCMT achieves an F1-score of 95.57%, accuracy of 95.63%, sensitivity of
96.42%, and precision of 94.79% on the standard harmonized stringent BUSI
dataset, outperforming existing ViT and CNN methods. These results demonstrate
the versatility of our integrated CNN-Transformer framework in capturing
diverse features and delivering superior performance in BUSI cancer diagnosis.","['Aamir Mehmood', 'Yue Hu', 'Saddam Hussain Khan']",2025-03-19,"['eess.IV', 'cs.AI', 'cs.CV', 'cs.LG']","12 pages, 10 Figures, 2 Tables. arXiv admin note: substantial text
  overlap with arXiv:2405.12986",http://arxiv.org/pdf/2503.15008v1
2503.15567v1,Towards Unified Latent Space for 3D Molecular Latent Diffusion Modeling,"3D molecule generation is crucial for drug discovery and material science,
requiring models to process complex multi-modalities, including atom types,
chemical bonds, and 3D coordinates. A key challenge is integrating these
modalities of different shapes while maintaining SE(3) equivariance for 3D
coordinates. To achieve this, existing approaches typically maintain separate
latent spaces for invariant and equivariant modalities, reducing efficiency in
both training and sampling. In this work, we propose \textbf{U}nified
Variational \textbf{A}uto-\textbf{E}ncoder for \textbf{3D} Molecular Latent
Diffusion Modeling (\textbf{UAE-3D}), a multi-modal VAE that compresses 3D
molecules into latent sequences from a unified latent space, while maintaining
near-zero reconstruction error. This unified latent space eliminates the
complexities of handling multi-modality and equivariance when performing latent
diffusion modeling. We demonstrate this by employing the Diffusion
Transformer--a general-purpose diffusion model without any molecular inductive
bias--for latent generation. Extensive experiments on GEOM-Drugs and QM9
datasets demonstrate that our method significantly establishes new benchmarks
in both \textit{de novo} and conditional 3D molecule generation, achieving
leading efficiency and quality.","['Yanchen Luo', 'Zhiyuan Liu', 'Yi Zhao', 'Sihang Li', 'Kenji Kawaguchi', 'Tat-Seng Chua', 'Xiang Wang']",2025-03-19,['cs.LG'],,http://arxiv.org/pdf/2503.15567v1
2503.15002v1,Scalable Trajectory-User Linking with Dual-Stream Representation Networks,"Trajectory-user linking (TUL) aims to match anonymous trajectories to the
most likely users who generated them, offering benefits for a wide range of
real-world spatio-temporal applications. However, existing TUL methods are
limited by high model complexity and poor learning of the effective
representations of trajectories, rendering them ineffective in handling
large-scale user trajectory data. In this work, we propose a novel
$\underline{Scal}$abl$\underline{e}$ Trajectory-User Linking with dual-stream
representation networks for large-scale $\underline{TUL}$ problem, named
ScaleTUL. Specifically, ScaleTUL generates two views using temporal and spatial
augmentations to exploit supervised contrastive learning framework to
effectively capture the irregularities of trajectories. In each view, a
dual-stream trajectory encoder, consisting of a long-term encoder and a
short-term encoder, is designed to learn unified trajectory representations
that fuse different temporal-spatial dependencies. Then, a TUL layer is used to
associate the trajectories with the corresponding users in the representation
space using a two-stage training model. Experimental results on check-in
mobility datasets from three real-world cities and the nationwide U.S.
demonstrate the superiority of ScaleTUL over state-of-the-art baselines for
large-scale TUL tasks.","['Hao Zhang', 'Wei Chen', 'Xingyu Zhao', 'Jianpeng Qi', 'Guiyuan Jiang', 'Yanwei Yu']",2025-03-19,['cs.LG'],The paper has been accepted by AAAI 2025,http://arxiv.org/pdf/2503.15002v1
2503.14980v1,Embedding spatial context in urban traffic forecasting with contrastive pre-training,"Urban traffic forecasting is a commonly encountered problem, with
wide-ranging applications in fields such as urban planning, civil engineering
and transport. In this paper, we study the enhancement of traffic forecasting
with pre-training, focusing on spatio-temporal graph methods. While various
machine learning methods to solve traffic forecasting problems have been
explored and extensively studied, there is a gap of a more contextual approach:
studying how relevant non-traffic data can improve prediction performance on
traffic forecasting problems. We call this data spatial context. We introduce a
novel method of combining road and traffic information through the notion of a
traffic quotient graph, a quotient graph formed from road geometry and traffic
sensors. We also define a way to encode this relationship in the form of a
geometric encoder, pre-trained using contrastive learning methods and enhanced
with OpenStreetMap data. We introduce and discuss ways to integrate this
geometric encoder with existing graph neural network (GNN)-based traffic
forecasting models, using a contrastive pre-training paradigm. We demonstrate
the potential for this hybrid model to improve generalisation and performance
with zero additional traffic data. Code for this paper is available at
https://github.com/mattchrlw/forecasting-on-new-roads.","['Matthew Low', 'Arian Prabowo', 'Hao Xue', 'Flora Salim']",2025-03-19,['cs.LG'],"21 pages with references, 10 figures",http://arxiv.org/pdf/2503.14980v1
2503.14976v1,Application of linear regression method to the deep reinforcement learning in continuous action cases,"The linear regression (LR) method offers the advantage that optimal
parameters can be calculated relatively easily, although its representation
capability is limited than that of the deep learning technique. To improve deep
reinforcement learning, the Least Squares Deep Q Network (LS-DQN) method was
proposed by Levine et al., which combines Deep Q Network (DQN) with LR method.
However, the LS-DQN method assumes that the actions are discrete. In this
study, we propose the Double Least Squares Deep Deterministic Policy Gradient
(DLS-DDPG) method to address this limitation. This method combines the LR
method with the Deep Deterministic Policy Gradient (DDPG) technique, one of the
representative deep reinforcement learning algorithms for continuous action
cases. Numerical experiments conducted in MuJoCo environments showed that the
LR update improved performance at least in some tasks, although there are
difficulties such as the inability to make the regularization terms small.",['Hisato Komatsu'],2025-03-19,"['cs.LG', 'cs.AI']","21 pages, 6 figures",http://arxiv.org/pdf/2503.14976v1
2503.14963v1,Continual Multimodal Contrastive Learning,"Multimodal contrastive learning (MCL) advances in aligning different
modalities and generating multimodal representations in a joint space. By
leveraging contrastive learning across diverse modalities, large-scale
multimodal data enhances representational quality. However, a critical yet
often overlooked challenge remains: multimodal data is rarely collected in a
single process, and training from scratch is computationally expensive.
Instead, emergent multimodal data can be used to optimize existing models
gradually, \textit{i.e.}, models are trained on a sequence of modality pair
data. We define this problem as Continual Multimodal Contrastive Learning
(CMCL), an underexplored yet crucial research direction at the intersection of
multimodal and continual learning. In this paper, we formulate CMCL through two
specialized principles of stability and plasticity. We theoretically derive a
novel optimization-based method, which projects updated gradients from dual
sides onto subspaces where any gradient is prevented from interfering with the
previously learned knowledge. Two upper bounds provide theoretical insights on
both stability and plasticity in our solution. Beyond our theoretical
contributions, we conduct experiments on multiple datasets by comparing our
method against advanced continual learning baselines. The empirical results
further support our claims and demonstrate the efficacy of our method. The code
will be publicly available.","['Xiaohao Liu', 'Xiaobo Xia', 'See-Kiong Ng', 'Tat-Seng Chua']",2025-03-19,['cs.LG'],"36 pages, 9 figures, 4 tables",http://arxiv.org/pdf/2503.14963v1
2503.14937v1,Proceedings of the 3rd Italian Conference on Big Data and Data Science (ITADATA2024),"Proceedings of the 3rd Italian Conference on Big Data and Data Science
(ITADATA2024), held in Pisa, Italy, September 17-19, 2024.
  The Italian Conference on Big Data and Data Science (ITADATA2024) is the
annual event supported by the CINI Big Data National Laboratory and ISTI CNR
that aims to put together Italian researchers and professionals from academia,
industry, government, and public administration working in the field of big
data and data science, as well as related fields (e.g., security and privacy,
HPC, Cloud).
  ITADATA2024 covered research on all theoretical and practical aspects of Big
Data and data science including data governance, data processing, data
analysis, data reporting, data protection, as well as experimental studies and
lessons learned. In particular, ITADATA2024 focused on
  - Data spaces
  - Data processing life cycle
  - Machine learning and Large Language Models
  - Applications of big data and data science in healthcare, finance, industry
5.0, and beyond
  - Data science for social network analysis","['Nicola Bena', 'Claudia Diamantini', 'Michela Natilli', 'Luigi Romano', 'Giovanni Stilo', 'Valentina Pansanella', 'Claudio A. Ardagna', 'Anna Monreale', 'Roberto Trasarti']",2025-03-19,"['cs.DB', 'cs.LG']",,http://arxiv.org/pdf/2503.14937v1
2503.14936v1,Enhancing Code LLM Training with Programmer Attention,"Human attention provides valuable yet underexploited signals for code LLM
training, offering a perspective beyond purely machine-driven attention.
Despite the complexity and cost of collecting eye-tracking data, there has also
been limited progress in systematically using these signals for code LLM
training. To address both issues, we propose a cohesive pipeline spanning
augmentation and reward-based fine-tuning. Specifically, we introduce (1) an
eye-tracking path augmentation method to expand programmer attention datasets,
(2) a pattern abstraction step that refines raw fixations into learnable
attention motifs, and (3) a reward-guided strategy for integrating these
insights directly into a CodeT5 supervised fine-tuning process. Our experiments
yield +7.16 in CodeBLEU on the CodeXGlue benchmark for code summarization,
underscoring how uniting human and machine attention can boost code
intelligence. We hope this work encourages broader exploration of human-centric
methods in next-generation AI4SE.","['Yifan Zhang', 'Chen Huang', 'Zachary Karas', 'Dung Thuy Nguyen', 'Kevin Leach', 'Yu Huang']",2025-03-19,"['cs.SE', 'cs.HC', 'cs.LG']",,http://arxiv.org/pdf/2503.14936v1
2503.14932v1,Prada: Black-Box LLM Adaptation with Private Data on Resource-Constrained Devices,"In recent years, Large Language Models (LLMs) have demonstrated remarkable
abilities in various natural language processing tasks. However, adapting these
models to specialized domains using private datasets stored on
resource-constrained edge devices, such as smartphones and personal computers,
remains challenging due to significant privacy concerns and limited
computational resources. Existing model adaptation methods either compromise
data privacy by requiring data transmission or jeopardize model privacy by
exposing proprietary LLM parameters. To address these challenges, we propose
Prada, a novel privacy-preserving and efficient black-box LLM adaptation system
using private on-device datasets. Prada employs a lightweight proxy model
fine-tuned with Low-Rank Adaptation (LoRA) locally on user devices. During
inference, Prada leverages the logits offset, i.e., difference in outputs
between the base and adapted proxy models, to iteratively refine outputs from a
remote black-box LLM. This offset-based adaptation approach preserves both data
privacy and model privacy, as there is no need to share sensitive data or
proprietary model parameters. Furthermore, we incorporate speculative decoding
to further speed up the inference process of Prada, making the system
practically deployable on bandwidth-constrained edge devices, enabling a more
practical deployment of Prada. Extensive experiments on various downstream
tasks demonstrate that Prada achieves performance comparable to centralized
fine-tuning methods while significantly reducing computational overhead by up
to 60% and communication costs by up to 80%.","['Ziyao Wang', 'Yexiao He', 'Zheyu Shen', 'Yu Li', 'Guoheng Sun', 'Myungjin Lee', 'Ang Li']",2025-03-19,"['cs.CR', 'cs.DC', 'cs.LG']",,http://arxiv.org/pdf/2503.14932v1
2503.15566v1,Enforcing Consistency and Fairness in Multi-level Hierarchical Classification with a Mask-based Output Layer,"Traditional Multi-level Hierarchical Classification (MLHC) classifiers often
rely on backbone models with $n$ independent output layers. This structure
tends to overlook the hierarchical relationships between classes, leading to
inconsistent predictions that violate the underlying taxonomy. Additionally,
once a backbone architecture for an MLHC classifier is selected, adapting the
model to accommodate new tasks can be challenging. For example, incorporating
fairness to protect sensitive attributes within a hierarchical classifier
necessitates complex adjustments to maintain the class hierarchy while
enforcing fairness constraints. In this paper, we extend this concept to
hierarchical classification by introducing a fair, model-agnostic layer
designed to enforce taxonomy and optimize specific objectives, including
consistency, fairness, and exact match. Our evaluations demonstrate that the
proposed layer not only improves the fairness of predictions but also enforces
the taxonomy, resulting in consistent predictions and superior performance.
Compared to Large Language Models (LLMs) employing in-processing de-biasing
techniques and models without any bias correction, our approach achieves better
outcomes in both fairness and accuracy, making it particularly valuable in
sectors like e-commerce, healthcare, and education, where predictive
reliability is crucial.","['Shijing Chen', 'Shoaib Jameel', 'Mohamed Reda Bouadjenek', 'Feilong Tang', 'Usman Naseem', 'Basem Suleiman', 'Hakim Hacid', 'Flora D. Salim', 'Imran Razzak']",2025-03-19,['cs.LG'],"14 pages, 14 figures. arXiv admin note: text overlap with
  arXiv:2501.06827",http://arxiv.org/pdf/2503.15566v1
2503.14929v1,ACE: A Cardinality Estimator for Set-Valued Queries,"Cardinality estimation is a fundamental functionality in database systems.
Most existing cardinality estimators focus on handling predicates over numeric
or categorical data. They have largely omitted an important data type,
set-valued data, which frequently occur in contemporary applications such as
information retrieval and recommender systems. The few existing estimators for
such data either favor high-frequency elements or rely on a partial
independence assumption, which limits their practical applicability. We propose
ACE, an Attention-based Cardinality Estimator for estimating the cardinality of
queries over set-valued data. We first design a distillation-based data encoder
to condense the dataset into a compact matrix. We then design an
attention-based query analyzer to capture correlations among query elements. To
handle variable-sized queries, a pooling module is introduced, followed by a
regression model (MLP) to generate final cardinality estimates. We evaluate ACE
on three datasets with varying query element distributions, demonstrating that
ACE outperforms the state-of-the-art competitors in terms of both accuracy and
efficiency.","['Yufan Sheng', 'Xin Cao', 'Kaiqi Zhao', 'Yixiang Fang', 'Jianzhong Qi', 'Wenjie Zhang', 'Christian S. Jensen']",2025-03-19,"['cs.DB', 'cs.LG']",This paper has been accepted by PVLDB Vol 18,http://arxiv.org/pdf/2503.14929v1
2503.14927v1,Semi-Gradient SARSA Routing with Theoretical Guarantee on Traffic Stability and Weight Convergence,"We consider the traffic control problem of dynamic routing over parallel
servers, which arises in a variety of engineering systems such as
transportation and data transmission. We propose a semi-gradient, on-policy
algorithm that learns an approximate optimal routing policy. The algorithm uses
generic basis functions with flexible weights to approximate the value function
across the unbounded state space. Consequently, the training process lacks
Lipschitz continuity of the gradient, boundedness of the temporal-difference
error, and a prior guarantee on ergodicity, which are the standard
prerequisites in existing literature on reinforcement learning theory. To
address this, we combine a Lyapunov approach and an ordinary differential
equation-based method to jointly characterize the behavior of traffic state and
approximation weights. Our theoretical analysis proves that the training scheme
guarantees traffic state stability and ensures almost surely convergence of the
weights to the approximate optimum. We also demonstrate via simulations that
our algorithm attains significantly faster convergence than neural
network-based methods with an insignificant approximation error.","['Yidan Wu', 'Yu Yu', 'Jianan Zhang', 'Li Jin']",2025-03-19,"['cs.LG', 'cs.SY', 'eess.SY', 'math.DS']",arXiv admin note: text overlap with arXiv:2404.09188,http://arxiv.org/pdf/2503.14927v1
2503.14925v1,pFedFair: Towards Optimal Group Fairness-Accuracy Trade-off in Heterogeneous Federated Learning,"Federated learning (FL) algorithms commonly aim to maximize clients' accuracy
by training a model on their collective data. However, in several FL
applications, the model's decisions should meet a group fairness constraint to
be independent of sensitive attributes such as gender or race. While such group
fairness constraints can be incorporated into the objective function of the FL
optimization problem, in this work, we show that such an approach would lead to
suboptimal classification accuracy in an FL setting with heterogeneous client
distributions. To achieve an optimal accuracy-group fairness trade-off, we
propose the Personalized Federated Learning for Client-Level Group Fairness
(pFedFair) framework, where clients locally impose their fairness constraints
over the distributed training process. Leveraging the image embedding models,
we extend the application of pFedFair to computer vision settings, where we
numerically show that pFedFair achieves an optimal group fairness-accuracy
trade-off in heterogeneous FL settings. We present the results of several
numerical experiments on benchmark and synthetic datasets, which highlight the
suboptimality of non-personalized FL algorithms and the improvements made by
the pFedFair method.","['Haoyu Lei', 'Shizhan Gong', 'Qi Dou', 'Farzan Farnia']",2025-03-19,['cs.LG'],,http://arxiv.org/pdf/2503.14925v1
2503.14922v1,A Semantic and Clean-label Backdoor Attack against Graph Convolutional Networks,"Graph Convolutional Networks (GCNs) have shown excellent performance in
graph-structured tasks such as node classification and graph classification.
However, recent research has shown that GCNs are vulnerable to a new type of
threat called the backdoor attack, where the adversary can inject a hidden
backdoor into the GCNs so that the backdoored model performs well on benign
samples, whereas its prediction will be maliciously changed to the
attacker-specified target label if the hidden backdoor is activated by the
attacker-defined trigger. Clean-label backdoor attack and semantic backdoor
attack are two new backdoor attacks to Deep Neural Networks (DNNs), they are
more imperceptible and have posed new and serious threats. The semantic and
clean-label backdoor attack is not fully explored in GCNs. In this paper, we
propose a semantic and clean-label backdoor attack against GCNs under the
context of graph classification to reveal the existence of this security
vulnerability in GCNs. Specifically, SCLBA conducts an importance analysis on
graph samples to select one type of node as semantic trigger, which is then
inserted into the graph samples to create poisoning samples without changing
the labels of the poisoning samples to the attacker-specified target label. We
evaluate SCLBA on multiple datasets and the results show that SCLBA can achieve
attack success rates close to 99% with poisoning rates of less than 3%, and
with almost no impact on the performance of model on benign samples.","['Jiazhu Dai', 'Haoyu Sun']",2025-03-19,"['cs.LG', 'cs.AI', 'cs.CR']",,http://arxiv.org/pdf/2503.14922v1
2503.14887v1,Pseudo-Relevance Feedback Can Improve Zero-Shot LLM-Based Dense Retrieval,"Pseudo-relevance feedback (PRF) refines queries by leveraging initially
retrieved documents to improve retrieval effectiveness. In this paper, we
investigate how large language models (LLMs) can facilitate PRF for zero-shot
LLM-based dense retrieval, extending the recently proposed PromptReps method.
Specifically, our approach uses LLMs to extract salient passage features-such
as keywords and summaries-from top-ranked documents, which are then integrated
into PromptReps to produce enhanced query representations. Experiments on
passage retrieval benchmarks demonstrate that incorporating PRF significantly
boosts retrieval performance. Notably, smaller rankers with PRF can match the
effectiveness of larger rankers without PRF, highlighting PRF's potential to
improve LLM-driven search while maintaining an efficient balance between
effectiveness and resource usage.","['Hang Li', 'Xiao Wang', 'Bevan Koopman', 'Guido Zuccon']",2025-03-19,"['cs.IR', 'cs.LG']",,http://arxiv.org/pdf/2503.14887v1
2503.14881v1,Exploring the Limits of KV Cache Compression in Visual Autoregressive Transformers,"A fundamental challenge in Visual Autoregressive models is the substantial
memory overhead required during inference to store previously generated
representations. Despite various attempts to mitigate this issue through
compression techniques, prior works have not explicitly formalized the problem
of KV-cache compression in this context. In this work, we take the first step
in formally defining the KV-cache compression problem for Visual Autoregressive
transformers. We then establish a fundamental negative result, proving that any
mechanism for sequential visual token generation under attention-based
architectures must use at least $\Omega(n^2 d)$ memory, when $d = \Omega(\log
n)$, where $n$ is the number of tokens generated and $d$ is the embedding
dimensionality. This result demonstrates that achieving truly sub-quadratic
memory usage is impossible without additional structural constraints. Our proof
is constructed via a reduction from a computational lower bound problem,
leveraging randomized embedding techniques inspired by dimensionality reduction
principles. Finally, we discuss how sparsity priors on visual representations
can influence memory efficiency, presenting both impossibility results and
potential directions for mitigating memory overhead.","['Bo Chen', 'Xiaoyu Li', 'Yekun Ke', 'Yingyu Liang', 'Zhenmei Shi', 'Zhao Song']",2025-03-19,"['cs.LG', 'cs.AI', 'cs.CV']",,http://arxiv.org/pdf/2503.14881v1
2503.15564v1,GReaTER: Generate Realistic Tabular data after data Enhancement and Reduction,"Tabular data synthesis involves not only multi-table synthesis but also
generating multi-modal data (e.g., strings and categories), which enables
diverse knowledge synthesis. However, separating numerical and categorical data
has limited the effectiveness of tabular data generation. The GReaT (Generate
Realistic Tabular Data) framework uses Large Language Models (LLMs) to encode
entire rows, eliminating the need to partition data types. Despite this, the
framework's performance is constrained by two issues: (1) tabular data entries
lack sufficient semantic meaning, limiting LLM's ability to leverage
pre-trained knowledge for in-context learning, and (2) complex multi-table
datasets struggle to establish effective relationships for collaboration. To
address these, we propose GReaTER (Generate Realistic Tabular Data after data
Enhancement and Reduction), which includes: (1) a data semantic enhancement
system that improves LLM's understanding of tabular data through mapping,
enabling better in-context learning, and (2) a cross-table connecting method to
establish efficient relationships across complex tables. Experimental results
show that GReaTER outperforms the GReaT framework.","['Tung Sum Thomas Kwok', 'Chi-Hua Wang', 'Guang Cheng']",2025-03-19,['cs.LG'],"Accepted by Data Engineering Meets Large Language Models: Challenges
  and Opportunities Workshop@ICDE2025 Workshop at ICDE 2025",http://arxiv.org/pdf/2503.15564v1
2503.14873v1,Robust Support Vector Machines for Imbalanced and Noisy Data via Benders Decomposition,"This study introduces a novel formulation to enhance Support Vector Machines
(SVMs) in handling class imbalance and noise. Unlike the conventional Soft
Margin SVM, which penalizes the magnitude of constraint violations, the
proposed model quantifies the number of violations and aims to minimize their
frequency. To achieve this, a binary variable is incorporated into the
objective function of the primal SVM formulation, replacing the traditional
slack variable. Furthermore, each misclassified sample is assigned a priority
and an associated constraint. The resulting formulation is a mixed-integer
programming model, efficiently solved using Benders decomposition. The proposed
model's performance was benchmarked against existing models, including Soft
Margin SVM, weighted SVM, and NuSVC. Two primary hypotheses were examined: 1)
The proposed model improves the F1-score for the minority class in imbalanced
classification tasks. 2) The proposed model enhances classification accuracy in
noisy datasets. These hypotheses were evaluated using a Wilcoxon test across
multiple publicly available datasets from the OpenML repository. The results
supported both hypotheses (\( p < 0.05 \)). In addition, the proposed model
exhibited several interesting properties, such as improved robustness to noise,
a decision boundary shift favoring the minority class, a reduced number of
support vectors, and decreased prediction time. The open-source Python
implementation of the proposed SVM model is available.","['Seyed Mojtaba Mohasel', 'Hamidreza Koosha']",2025-03-19,['cs.LG'],,http://arxiv.org/pdf/2503.14873v1
2503.14869v1,Evaluating Time Series Models with Knowledge Discovery,"Time series data is one of the most ubiquitous data modalities existing in a
diverse critical domains such as healthcare, seismology, manufacturing and
energy. Recent years, there are increasing interest of the data mining
community to develop time series deep learning models to pursue better
performance. The models performance often evaluate by certain evaluation
metrics such as RMSE, Accuracy, and F1-score. Yet time series data are often
hard to interpret and are collected with unknown environmental factors, sensor
configuration, latent physic mechanisms, and non-stationary evolving behavior.
As a result, a model that is better on standard metric-based evaluation may not
always perform better in real-world tasks. In this blue sky paper, we aim to
explore the challenge that exists in the metric-based evaluation framework for
time series data mining and propose a potential blue-sky idea -- developing a
knowledge-discovery-based evaluation framework, which aims to effectively
utilize domain-expertise knowledge to evaluate a model. We demonstrate that an
evidence-seeking explanation can potentially have stronger persuasive power
than metric-based evaluation and obtain better generalization ability for time
series data mining tasks.",['Li Zhang'],2025-03-19,['cs.LG'],accepted in SIAM SDM 2025 - Blue Sky Track (to appear),http://arxiv.org/pdf/2503.14869v1
2503.14860v1,Global Renewables Watch: A Temporal Dataset of Solar and Wind Energy Derived from Satellite Imagery,"We present a comprehensive global temporal dataset of commercial solar
photovoltaic (PV) farms and onshore wind turbines, derived from high-resolution
satellite imagery analyzed quarterly from the fourth quarter of 2017 to the
second quarter of 2024. We create this dataset by training deep learning-based
segmentation models to identify these renewable energy installations from
satellite imagery, then deploy them on over 13 trillion pixels covering the
world. For each detected feature, we estimate the construction date and the
preceding land use type. This dataset offers crucial insights into progress
toward sustainable development goals and serves as a valuable resource for
policymakers, researchers, and stakeholders aiming to assess and promote
effective strategies for renewable energy deployment. Our final spatial dataset
includes 375,197 individual wind turbines and 86,410 solar PV installations. We
aggregate our predictions to the country level -- estimating total power
capacity based on construction date, solar PV area, and number of windmills --
and find an $r^2$ value of $0.96$ and $0.93$ for solar PV and onshore wind
respectively compared to IRENA's most recent 2023 country-level capacity
estimates.","['Caleb Robinson', 'Anthony Ortiz', 'Allen Kim', 'Rahul Dodhia', 'Andrew Zolli', 'Shivaprakash K Nagaraju', 'James Oakleaf', 'Joe Kiesecker', 'Juan M. Lavista Ferres']",2025-03-19,"['cs.LG', 'cs.CV']",,http://arxiv.org/pdf/2503.14860v1
2503.14858v1,1000 Layer Networks for Self-Supervised RL: Scaling Depth Can Enable New Goal-Reaching Capabilities,"Scaling up self-supervised learning has driven breakthroughs in language and
vision, yet comparable progress has remained elusive in reinforcement learning
(RL). In this paper, we study building blocks for self-supervised RL that
unlock substantial improvements in scalability, with network depth serving as a
critical factor. Whereas most RL papers in recent years have relied on shallow
architectures (around 2 - 5 layers), we demonstrate that increasing the depth
up to 1024 layers can significantly boost performance. Our experiments are
conducted in an unsupervised goal-conditioned setting, where no demonstrations
or rewards are provided, so an agent must explore (from scratch) and learn how
to maximize the likelihood of reaching commanded goals. Evaluated on simulated
locomotion and manipulation tasks, our approach increases performance by
$2\times$ - $50\times$. Increasing the model depth not only increases success
rates but also qualitatively changes the behaviors learned.","['Kevin Wang', 'Ishaan Javali', 'Michał Bortkiewicz', 'Tomasz Trzciński', 'Benjamin Eysenbach']",2025-03-19,"['cs.LG', 'cs.AI']","Link to project website:
  https://wang-kevin3290.github.io/scaling-crl/",http://arxiv.org/pdf/2503.14858v1
2503.15563v1,Dynamic Power Flow Analysis and Fault Characteristics: A Graph Attention Neural Network,"We propose the joint graph attention neural network (GAT), clustering with
adaptive neighbors (CAN) and probabilistic graphical model for dynamic power
flow analysis and fault characteristics. In fact, computational efficiency is
the main focus to enhance, whilst we ensure the performance accuracy at the
accepted level. Note that Machine Learning (ML) based schemes have a
requirement of sufficient labeled data during training, which is not easily
satisfied in practical applications. Also, there are unknown data due to new
arrived measurements or incompatible smart devices in complex smart grid
systems. These problems would be resolved by our proposed GAT based framework,
which models the label dependency between the network data and learns object
representations such that it could achieve the semi-supervised fault diagnosis.
To create the joint label dependency, we develop the graph construction from
the raw acquired signals by using CAN. Next, we develop the probabilistic
graphical model of Markov random field for graph representation, which supports
for the GAT based framework. We then evaluate the proposed framework in the
use-case application in smart grid and make a fair comparison to the existing
methods.","['Tan Le', 'Van Le']",2025-03-19,['cs.LG'],"The 2025 International Conference on the AI Revolution: Research,
  Ethics, and Society (AIR-RES 2025)",http://arxiv.org/pdf/2503.15563v1
2503.14849v1,LogLLaMA: Transformer-based log anomaly detection with LLaMA,"Log anomaly detection refers to the task that distinguishes the anomalous log
messages from normal log messages. Transformer-based large language models
(LLMs) are becoming popular for log anomaly detection because of their superb
ability to understand complex and long language patterns. In this paper, we
propose LogLLaMA, a novel framework that leverages LLaMA2. LogLLaMA is first
finetuned on normal log messages from three large-scale datasets to learn their
patterns. After finetuning, the model is capable of generating successive log
messages given previous log messages. Our generative model is further trained
to identify anomalous log messages using reinforcement learning (RL). The
experimental results show that LogLLaMA outperforms the state-of-the-art
approaches for anomaly detection on BGL, Thunderbird, and HDFS datasets.","['Zhuoyi Yang', 'Ian G. Harris']",2025-03-19,"['cs.LG', 'cs.CL']","8 pages, 5 figures",http://arxiv.org/pdf/2503.14849v1
2503.14836v1,On the Robustness Tradeoff in Fine-Tuning,"Fine-tuning has become the standard practice for adapting pre-trained
(upstream) models to downstream tasks. However, the impact on model robustness
is not well understood. In this work, we characterize the robustness-accuracy
trade-off in fine-tuning. We evaluate the robustness and accuracy of fine-tuned
models over 6 benchmark datasets and 7 different fine-tuning strategies. We
observe a consistent trade-off between adversarial robustness and accuracy.
Peripheral updates such as BitFit are more effective for simple tasks--over 75%
above the average measured with area under the Pareto frontiers on CIFAR-10 and
CIFAR-100. In contrast, fine-tuning information-heavy layers, such as attention
layers via Compacter, achieves a better Pareto frontier on more complex
tasks--57.5% and 34.6% above the average on Caltech-256 and CUB-200,
respectively. Lastly, we observe that robustness of fine-tuning against
out-of-distribution data closely tracks accuracy. These insights emphasize the
need for robustness-aware fine-tuning to ensure reliable real-world
deployments.","['Kunyang Li', 'Jean-Charles Noirot Ferrand', 'Ryan Sheatsley', 'Blaine Hoak', 'Yohan Beugin', 'Eric Pauley', 'Patrick McDaniel']",2025-03-19,"['cs.LG', 'cs.CV']",,http://arxiv.org/pdf/2503.14836v1
2503.14833v1,Curiosity-Diffuser: Curiosity Guide Diffusion Models for Reliability,"One of the bottlenecks in robotic intelligence is the instability of neural
network models, which, unlike control models, lack a well-defined convergence
domain and stability. This leads to risks when applying intelligence in the
physical world. Specifically, imitation policy based on neural network may
generate hallucinations, leading to inaccurate behaviors that impact the safety
of real-world applications. To address this issue, this paper proposes the
Curiosity-Diffuser, aimed at guiding the conditional diffusion model to
generate trajectories with lower curiosity, thereby improving the reliability
of policy. The core idea is to use a Random Network Distillation (RND)
curiosity module to assess whether the model's behavior aligns with the
training data, and then minimize curiosity by classifier guidance diffusion to
reduce overgeneralization during inference. Additionally, we propose a
computationally efficient metric for evaluating the reliability of the policy,
measuring the similarity between the generated behaviors and the training
dataset, to facilitate research about reliability learning. Finally, simulation
verify the effectiveness and applicability of the proposed method to a variety
of scenarios, showing that Curiosity-Diffuser significantly improves task
performance and produces behaviors that are more similar to the training data.
The code for this work is available at: github.com/CarlDegio/Curiosity-Diffuser","['Zihao Liu', 'Xing Liu', 'Yizhai Zhang', 'Zhengxiong Liu', 'Panfeng Huang']",2025-03-19,"['cs.RO', 'cs.AI', 'cs.LG']",,http://arxiv.org/pdf/2503.14833v1
2503.14832v1,H2ST: Hierarchical Two-Sample Tests for Continual Out-of-Distribution Detection,"Task Incremental Learning (TIL) is a specialized form of Continual Learning
(CL) in which a model incrementally learns from non-stationary data streams.
Existing TIL methodologies operate under the closed-world assumption, presuming
that incoming data remains in-distribution (ID). However, in an open-world
setting, incoming samples may originate from out-of-distribution (OOD) sources,
with their task identities inherently unknown. Continually detecting OOD
samples presents several challenges for current OOD detection methods: reliance
on model outputs leads to excessive dependence on model performance, selecting
suitable thresholds is difficult, hindering real-world deployment, and binary
ID/OOD classification fails to provide task-level identification. To address
these issues, we propose a novel continual OOD detection method called the
Hierarchical Two-sample Tests (H2ST). H2ST eliminates the need for threshold
selection through hypothesis testing and utilizes feature maps to better
exploit model capabilities without excessive dependence on model performance.
The proposed hierarchical architecture enables task-level detection with
superior performance and lower overhead compared to non-hierarchical classifier
two-sample tests. Extensive experiments and analysis validate the effectiveness
of H2ST in open-world TIL scenarios and its superiority to the existing
methods. Code is available at
\href{https://github.com/YuhangLiuu/H2ST}{https://github.com/YuhangLiuu/H2ST}.","['Yuhang Liu', 'Wenjie Zhao', 'Yunhui Guo']",2025-03-19,"['cs.CV', 'cs.LG']","15 pages, 8 figures",http://arxiv.org/pdf/2503.14832v1
2503.14831v1,Robust Transmission of Punctured Text with Large Language Model-based Recovery,"With the recent advancements in deep learning, semantic communication which
transmits only task-oriented features, has rapidly emerged. However, since
feature extraction relies on learning-based models, its performance
fundamentally depends on the training dataset or tasks. For practical
scenarios, it is essential to design a model that demonstrates robust
performance regardless of dataset or tasks. In this correspondence, we propose
a novel text transmission model that selects and transmits only a few
characters and recovers the missing characters at the receiver using a large
language model (LLM). Additionally, we propose a novel importance character
extractor (ICE), which selects transmitted characters to enhance LLM recovery
performance. Simulations demonstrate that the proposed filter selection by ICE
outperforms random filter selection, which selects transmitted characters
randomly. Moreover, the proposed model exhibits robust performance across
different datasets and tasks and outperforms traditional bit-based
communication in low signal-to-noise ratio conditions.","['Sojeong Park', 'Hyeonho Noh', 'Hyun Jong Yang']",2025-03-19,"['eess.SP', 'cs.LG']",This work has been submitted to the IEEE for possible publication,http://arxiv.org/pdf/2503.14831v1
2503.14813v1,Scaled Supervision is an Implicit Lipschitz Regularizer,"In modern social media, recommender systems (RecSys) rely on the
click-through rate (CTR) as the standard metric to evaluate user engagement.
CTR prediction is traditionally framed as a binary classification task to
predict whether a user will interact with a given item. However, this approach
overlooks the complexity of real-world social modeling, where the user, item,
and their interactive features change dynamically in fast-paced online
environments. This dynamic nature often leads to model instability, reflected
in overfitting short-term fluctuations rather than higher-level interactive
patterns. While overfitting calls for more scaled and refined supervisions,
current solutions often rely on binary labels that overly simplify fine-grained
user preferences through the thresholding process, which significantly reduces
the richness of the supervision. Therefore, we aim to alleviate the overfitting
problem by increasing the supervision bandwidth in CTR training. Specifically,
(i) theoretically, we formulate the impact of fine-grained preferences on model
stability as a Lipschitz constrain; (ii) empirically, we discover that scaling
the supervision bandwidth can act as an implicit Lipschitz regularizer, stably
optimizing existing CTR models to achieve better generalizability. Extensive
experiments show that this scaled supervision significantly and consistently
improves the optimization process and the performance of existing CTR models,
even without the need for additional hyperparameter tuning.","['Zhongyu Ouyang', 'Chunhui Zhang', 'Yaning Jia', 'Soroush Vosoughi']",2025-03-19,"['cs.LG', 'cs.IR']","Accepted to the International AAAI Conference on Web and Social Media
  (ICWSM 2025)",http://arxiv.org/pdf/2503.14813v1
2503.14809v1,Learning with Expert Abstractions for Efficient Multi-Task Continuous Control,"Decision-making in complex, continuous multi-task environments is often
hindered by the difficulty of obtaining accurate models for planning and the
inefficiency of learning purely from trial and error. While precise environment
dynamics may be hard to specify, human experts can often provide high-fidelity
abstractions that capture the essential high-level structure of a task and user
preferences in the target environment. Existing hierarchical approaches often
target discrete settings and do not generalize across tasks. We propose a
hierarchical reinforcement learning approach that addresses these limitations
by dynamically planning over the expert-specified abstraction to generate
subgoals to learn a goal-conditioned policy. To overcome the challenges of
learning under sparse rewards, we shape the reward based on the optimal state
value in the abstract model. This structured decision-making process enhances
sample efficiency and facilitates zero-shot generalization. Our empirical
evaluation on a suite of procedurally generated continuous control environments
demonstrates that our approach outperforms existing hierarchical reinforcement
learning methods in terms of sample efficiency, task completion rate,
scalability to complex tasks, and generalization to novel scenarios.","['Jeff Jewett', 'Sandhya Saisubramanian']",2025-03-19,"['cs.LG', 'cs.AI']","12 pages, 6 figures. Submitted to RLC 2025. Code and experiments at
  https://github.com/Intelligent-Reliable-Autonomous-Systems/gcrs-expert-abstractions",http://arxiv.org/pdf/2503.14809v1
2503.14800v1,Long Context Modeling with Ranked Memory-Augmented Retrieval,"Effective long-term memory management is crucial for language models handling
extended contexts. We introduce a novel framework that dynamically ranks memory
entries based on relevance. Unlike previous works, our model introduces a novel
relevance scoring and a pointwise re-ranking model for key-value embeddings,
inspired by learning-to-rank techniques in information retrieval. Enhanced
Ranked Memory Augmented Retrieval ERMAR achieves state-of-the-art results on
standard benchmarks.","['Ghadir Alselwi', 'Hao Xue', 'Shoaib Jameel', 'Basem Suleiman', 'Flora D. Salim', 'Imran Razzak']",2025-03-19,"['cs.IR', 'cs.AI', 'cs.LG']",,http://arxiv.org/pdf/2503.14800v1
2503.14799v1,Pruning-Based TinyML Optimization of Machine Learning Models for Anomaly Detection in Electric Vehicle Charging Infrastructure,"With the growing need for real-time processing on IoT devices, optimizing
machine learning (ML) models' size, latency, and computational efficiency is
essential. This paper investigates a pruning method for anomaly detection in
resource-constrained environments, specifically targeting Electric Vehicle
Charging Infrastructure (EVCI). Using the CICEVSE2024 dataset, we trained and
optimized three models-Multi-Layer Perceptron (MLP), Long Short-Term Memory
(LSTM), and XGBoost-through hyperparameter tuning with Optuna, further refining
them using SHapley Additive exPlanations (SHAP)-based feature selection (FS)
and unstructured pruning techniques. The optimized models achieved significant
reductions in model size and inference times, with only a marginal impact on
their performance. Notably, our findings indicate that, in the context of EVCI,
pruning and FS can enhance computational efficiency while retaining critical
anomaly detection capabilities.","['Fatemeh Dehrouyeh', 'Ibrahim Shaer', 'Soodeh Nikan', 'Firouz Badrkhani Ajaei', 'Abdallah Shami']",2025-03-19,"['cs.LG', 'eess.SP']","This paper has been accepted for presentation at IEEE ICC 2025. The
  final published version will be available in the conference proceedings. The
  implementation and code are available at:
  https://github.com/Western-OC2-Lab/EVCI-Pruning",http://arxiv.org/pdf/2503.14799v1
2503.14796v1,A New Benchmark for Online Learning with Budget-Balancing Constraints,"The adversarial Bandit with Knapsack problem is a multi-armed bandits problem
with budget constraints and adversarial rewards and costs. In each round, a
learner selects an action to take and observes the reward and cost of the
selected action. The goal is to maximize the sum of rewards while satisfying
the budget constraint. The classical benchmark to compare against is the best
fixed distribution over actions that satisfies the budget constraint in
expectation. Unlike its stochastic counterpart, where rewards and costs are
drawn from some fixed distribution (Badanidiyuru et al., 2018), the adversarial
BwK problem does not admit a no-regret algorithm for every problem instance due
to the ""spend-or-save"" dilemma (Immorlica et al., 2022).
  A key problem left open by existing works is whether there exists a weaker
but still meaningful benchmark to compare against such that no-regret learning
is still possible. In this work, we present a new benchmark to compare against,
motivated both by real-world applications such as autobidding and by its
underlying mathematical structure. The benchmark is based on the Earth Mover's
Distance (EMD), and we show that sublinear regret is attainable against any
strategy whose spending pattern is within EMD $o(T^2)$ of any sub-pacing
spending pattern.
  As a special case, we obtain results against the ""pacing over windows""
benchmark, where we partition time into disjoint windows of size $w$ and allow
the benchmark strategies to choose a different distribution over actions for
each window while satisfying a pacing budget constraint. Against this
benchmark, our algorithm obtains a regret bound of
$\tilde{O}(T/\sqrt{w}+\sqrt{wT})$. We also show a matching lower bound, proving
the optimality of our algorithm in this important special case. In addition, we
provide further evidence of the necessity of the EMD condition for obtaining a
sublinear regret.","['Mark Braverman', 'Jingyi Liu', 'Jieming Mao', 'Jon Schneider', 'Eric Xue']",2025-03-19,"['cs.LG', 'cs.GT']",,http://arxiv.org/pdf/2503.14796v1
2503.14795v1,The Hardness of Validating Observational Studies with Experimental Data,"Observational data is often readily available in large quantities, but can
lead to biased causal effect estimates due to the presence of unobserved
confounding. Recent works attempt to remove this bias by supplementing
observational data with experimental data, which, when available, is typically
on a smaller scale due to the time and cost involved in running a randomised
controlled trial. In this work, we prove a theorem that places fundamental
limits on this ``best of both worlds'' approach. Using the framework of
impossible inference, we show that although it is possible to use experimental
data to \emph{falsify} causal effect estimates from observational data, in
general it is not possible to \emph{validate} such estimates. Our theorem
proves that while experimental data can be used to detect bias in observational
studies, without additional assumptions on the smoothness of the correction
function, it can not be used to remove it. We provide a practical example of
such an assumption, developing a novel Gaussian Process based approach to
construct intervals which contain the true treatment effect with high
probability, both inside and outside of the support of the experimental data.
We demonstrate our methodology on both simulated and semi-synthetic datasets
and make the \href{https://github.com/Jakefawkes/Obs_and_exp_data}{code
available}.","['Jake Fawkes', ""Michael O'Riordan"", 'Athanasios Vlontzos', 'Oriol Corcoll', 'Ciarán Mark Gilligan-Lee']",2025-03-19,"['stat.ML', 'cs.LG', 'stat.ME']",Published at AISTATS 2025,http://arxiv.org/pdf/2503.14795v1
2503.14785v1,SEEK: Self-adaptive Explainable Kernel For Nonstationary Gaussian Processes,"Gaussian processes (GPs) are powerful probabilistic models that define
flexible priors over functions, offering strong interpretability and
uncertainty quantification. However, GP models often rely on simple, stationary
kernels which can lead to suboptimal predictions and miscalibrated uncertainty
estimates, especially in nonstationary real-world applications. In this paper,
we introduce SEEK, a novel class of learnable kernels to model complex,
nonstationary functions via GPs. Inspired by artificial neurons, SEEK is
derived from first principles to ensure symmetry and positive
semi-definiteness, key properties of valid kernels. The proposed method
achieves flexible and adaptive nonstationarity by learning a mapping from a set
of base kernels. Compared to existing techniques, our approach is more
interpretable and much less prone to overfitting. We conduct comprehensive
sensitivity analyses and comparative studies to demonstrate that our approach
is not robust to only many of its design choices, but also outperforms existing
stationary/nonstationary kernels in both mean prediction accuracy and
uncertainty quantification.","['Nima Negarandeh', 'Carlos Mora', 'Ramin Bostanabad']",2025-03-18,['cs.LG'],,http://arxiv.org/pdf/2503.14785v1
2503.14783v1,RAT: Boosting Misclassification Detection Ability without Extra Data,"As deep neural networks(DNN) become increasingly prevalent, particularly in
high-stakes areas such as autonomous driving and healthcare, the ability to
detect incorrect predictions of models and intervene accordingly becomes
crucial for safety. In this work, we investigate the detection of misclassified
inputs for image classification models from the lens of adversarial
perturbation: we propose to use robust radius (a.k.a. input-space margin) as a
confidence metric and design two efficient estimation algorithms, RR-BS and
RR-Fast, for misclassification detection. Furthermore, we design a training
method called Radius Aware Training (RAT) to boost models' ability to identify
mistakes. Extensive experiments show our method could achieve up to 29.3%
reduction on AURC and 21.62% reduction in FPR@95TPR, compared with previous
methods.","['Ge Yan', 'Tsui-Wei Weng']",2025-03-18,"['cs.CV', 'cs.AI', 'cs.LG']",,http://arxiv.org/pdf/2503.14783v1
2503.14781v1,"Fake Runs, Real Fixes -- Analyzing xPU Performance Through Simulation","As models become larger, ML accelerators are a scarce resource whose
performance must be continually optimized to improve efficiency. Existing
performance analysis tools are coarse grained, and fail to capture model
performance at the machine-code level. In addition, these tools often do not
provide specific recommendations for optimizations. We present xPU-Shark, a
fine-grained methodology for analyzing ML models at the machine-code level that
provides actionable optimization suggestions. Our core insight is to use a
hardware-level simulator, an artifact of the hardware design process that we
can re-purpose for performance analysis. xPU-Shark captures traces from
production deployments running on accelerators and replays them in a modified
microarchitecture simulator to gain low-level insights into the model's
performance. We implement xPU-Shark for our in-house accelerator and used it to
analyze the performance of several of our production LLMs, revealing several
previously-unknown microarchitecture inefficiencies. Leveraging these insights,
we optimize a common communication collective by up to 15% and reduce token
generation latency by up to 4.1%.","['Ioannis Zarkadas', 'Amanda Tomlinson', 'Asaf Cidon', 'Baris Kasikci', 'Ofir Weisse']",2025-03-18,"['cs.PF', 'cs.DC', 'cs.LG']",,http://arxiv.org/pdf/2503.14781v1
2503.15561v1,Localized Physics-informed Gaussian Processes with Curriculum Training for Topology Optimization,"We introduce a simultaneous and meshfree topology optimization (TO) framework
based on physics-informed Gaussian processes (GPs). Our framework endows all
design and state variables via GP priors which have a shared, multi-output mean
function that is parametrized via a customized deep neural network (DNN). The
parameters of this mean function are estimated by minimizing a multi-component
loss function that depends on the performance metric, design constraints, and
the residuals on the state equations. Our TO approach yields well-defined
material interfaces and has a built-in continuation nature that promotes global
optimality. Other unique features of our approach include (1) its customized
DNN which, unlike fully connected feed-forward DNNs, has a localized learning
capacity that enables capturing intricate topologies and reducing residuals in
high gradient fields, (2) its loss function that leverages localized weights to
promote solution accuracy around interfaces, and (3) its use of curriculum
training to avoid local optimality.To demonstrate the power of our framework,
we validate it against commercial TO package COMSOL on three problems involving
dissipated power minimization in Stokes flow.","['Amin Yousefpour', 'Shirin Hosseinmardi', 'Xiangyu Sun', 'Ramin Bostanabad']",2025-03-18,['cs.LG'],,http://arxiv.org/pdf/2503.15561v1
2503.15560v1,Temporal Context Awareness: A Defense Framework Against Multi-turn Manipulation Attacks on Large Language Models,"Large Language Models (LLMs) are increasingly vulnerable to sophisticated
multi-turn manipulation attacks, where adversaries strategically build context
through seemingly benign conversational turns to circumvent safety measures and
elicit harmful or unauthorized responses. These attacks exploit the temporal
nature of dialogue to evade single-turn detection methods, representing a
critical security vulnerability with significant implications for real-world
deployments.
  This paper introduces the Temporal Context Awareness (TCA) framework, a novel
defense mechanism designed to address this challenge by continuously analyzing
semantic drift, cross-turn intention consistency and evolving conversational
patterns. The TCA framework integrates dynamic context embedding analysis,
cross-turn consistency verification, and progressive risk scoring to detect and
mitigate manipulation attempts effectively. Preliminary evaluations on
simulated adversarial scenarios demonstrate the framework's potential to
identify subtle manipulation patterns often missed by traditional detection
techniques, offering a much-needed layer of security for conversational AI
systems. In addition to outlining the design of TCA , we analyze diverse attack
vectors and their progression across multi-turn conversation, providing
valuable insights into adversarial tactics and their impact on LLM
vulnerabilities. Our findings underscore the pressing need for robust,
context-aware defenses in conversational AI systems and highlight TCA framework
as a promising direction for securing LLMs while preserving their utility in
legitimate applications. We make our implementation available to support
further research in this emerging area of AI security.","['Prashant Kulkarni', 'Assaf Namer']",2025-03-18,"['cs.CR', 'cs.LG']","6 pages, 2 figures, IEEE CAI",http://arxiv.org/pdf/2503.15560v1
2503.15559v1,Advanced Relay-Based Collaborative Framework for Optimizing Synchronization in Split Federated Learning over Wireless Networks,"Split Federated Learning (SFL) offers a promising approach for distributed
model training in edge computing, combining the strengths of split learning in
reducing computational demands on edge devices and enhancing data privacy, with
the role of federated aggregation to ensure model convergence and
synchronization across users. However, synchronization issues caused by user
heterogeneity have hindered the development of the framework. To optimize
synchronization efficiency among users and improve overall system performance,
we propose a collaborative SFL framework (CSFL). Based on the model's
partitioning capabilities, we design a mechanism called the collaborative relay
optimization mechanism (CROM), where the assistance provided by high-efficiency
users is seen as a relay process, with the portion of the model they compute
acting as the relay point. Wireless communication between users facilitates
real-time collaboration, allowing high-efficiency users to assist bottleneck
users in handling part of the model's computation, thereby alleviating the
computational load on bottleneck users. Simulation results show that our
proposed CSFL framework reduces synchronization delays and improves overall
system throughput while maintaining similar performance and convergence rate to
the SFL framework. This demonstrates that the collaboration not only reduces
synchronization waiting time but also accelerates model convergence.","['Haoran Gao', 'Samuel D. Okegbile', 'Jun Cai']",2025-03-18,['cs.LG'],,http://arxiv.org/pdf/2503.15559v1
2503.15558v1,Cosmos-Reason1: From Physical Common Sense To Embodied Reasoning,"Physical AI systems need to perceive, understand, and perform complex actions
in the physical world. In this paper, we present the Cosmos-Reason1 models that
can understand the physical world and generate appropriate embodied decisions
(e.g., next step action) in natural language through long chain-of-thought
reasoning processes. We begin by defining key capabilities for Physical AI
reasoning, with a focus on physical common sense and embodied reasoning. To
represent physical common sense, we use a hierarchical ontology that captures
fundamental knowledge about space, time, and physics. For embodied reasoning,
we rely on a two-dimensional ontology that generalizes across different
physical embodiments. Building on these capabilities, we develop two multimodal
large language models, Cosmos-Reason1-8B and Cosmos-Reason1-56B. We curate data
and train our models in four stages: vision pre-training, general supervised
fine-tuning (SFT), Physical AI SFT, and Physical AI reinforcement learning (RL)
as the post-training. To evaluate our models, we build comprehensive benchmarks
for physical common sense and embodied reasoning according to our ontologies.
Evaluation results show that Physical AI SFT and reinforcement learning bring
significant improvements. To facilitate the development of Physical AI, we will
make our code and pre-trained models available under the NVIDIA Open Model
License at https://github.com/nvidia-cosmos/cosmos-reason1.","['NVIDIA', ':', 'Alisson Azzolini', 'Hannah Brandon', 'Prithvijit Chattopadhyay', 'Huayu Chen', 'Jinju Chu', 'Yin Cui', 'Jenna Diamond', 'Yifan Ding', 'Francesco Ferroni', 'Rama Govindaraju', 'Jinwei Gu', 'Siddharth Gururani', 'Imad El Hanafi', 'Zekun Hao', 'Jacob Huffman', 'Jingyi Jin', 'Brendan Johnson', 'Rizwan Khan', 'George Kurian', 'Elena Lantz', 'Nayeon Lee', 'Zhaoshuo Li', 'Xuan Li', 'Tsung-Yi Lin', 'Yen-Chen Lin', 'Ming-Yu Liu', 'Andrew Mathau', 'Yun Ni', 'Lindsey Pavao', 'Wei Ping', 'David W. Romero', 'Misha Smelyanskiy', 'Shuran Song', 'Lyne Tchapmi', 'Andrew Z. Wang', 'Boxin Wang', 'Haoxiang Wang', 'Fangyin Wei', 'Jiashu Xu', 'Yao Xu', 'Xiaodong Yang', 'Zhuolin Yang', 'Xiaohui Zeng', 'Zhe Zhang']",2025-03-18,"['cs.AI', 'cs.CV', 'cs.LG', 'cs.RO']",,http://arxiv.org/pdf/2503.15558v1
2503.14757v1,RETHINED: A New Benchmark and Baseline for Real-Time High-Resolution Image Inpainting On Edge Devices,"Existing image inpainting methods have shown impressive completion results
for low-resolution images. However, most of these algorithms fail at high
resolutions and require powerful hardware, limiting their deployment on edge
devices. Motivated by this, we propose the first baseline for REal-Time
High-resolution image INpainting on Edge Devices (RETHINED) that is able to
inpaint at ultra-high-resolution and can run in real-time ($\leq$ 30ms) in a
wide variety of mobile devices. A simple, yet effective novel method formed by
a lightweight Convolutional Neural Network (CNN) to recover structure, followed
by a resolution-agnostic patch replacement mechanism to provide detailed
texture. Specially our pipeline leverages the structural capacity of CNN and
the high-level detail of patch-based methods, which is a key component for
high-resolution image inpainting. To demonstrate the real application of our
method, we conduct an extensive analysis on various mobile-friendly devices and
demonstrate similar inpainting performance while being $\mathrm{100 \times
faster}$ than existing state-of-the-art methods. Furthemore, we realease
DF8K-Inpainting, the first free-form mask UHD inpainting dataset.","['Marcelo Sanchez', 'Gil Triginer', 'Ignacio Sarasua', 'Lara Raad', 'Coloma Ballester']",2025-03-18,"['cs.CV', 'cs.LG']",,http://arxiv.org/pdf/2503.14757v1
2503.14754v1,Bayesian Modeling of Zero-Shot Classifications for Urban Flood Detection,"Street scene datasets, collected from Street View or dashboard cameras, offer
a promising means of detecting urban objects and incidents like street
flooding. However, a major challenge in using these datasets is their lack of
reliable labels: there are myriad types of incidents, many types occur rarely,
and ground-truth measures of where incidents occur are lacking. Here, we
propose BayFlood, a two-stage approach which circumvents this difficulty.
First, we perform zero-shot classification of where incidents occur using a
pretrained vision-language model (VLM). Second, we fit a spatial Bayesian model
on the VLM classifications. The zero-shot approach avoids the need to annotate
large training sets, and the Bayesian model provides frequent desiderata in
urban settings - principled measures of uncertainty, smoothing across
locations, and incorporation of external data like stormwater accumulation
zones. We comprehensively validate this two-stage approach, showing that VLMs
provide strong zero-shot signal for floods across multiple cities and time
periods, the Bayesian model improves out-of-sample prediction relative to
baseline methods, and our inferred flood risk correlates with known external
predictors of risk. Having validated our approach, we show it can be used to
improve urban flood detection: our analysis reveals 113,738 people who are at
high risk of flooding overlooked by current methods, identifies demographic
biases in existing methods, and suggests locations for new flood sensors. More
broadly, our results showcase how Bayesian modeling of zero-shot LM annotations
represents a promising paradigm because it avoids the need to collect large
labeled datasets and leverages the power of foundation models while providing
the expressiveness and uncertainty quantification of Bayesian models.","['Matt Franchi', 'Nikhil Garg', 'Wendy Ju', 'Emma Pierson']",2025-03-18,"['cs.LG', 'cs.AI', 'cs.CV']",In review,http://arxiv.org/pdf/2503.14754v1
2503.14751v1,LipShiFT: A Certifiably Robust Shift-based Vision Transformer,"Deriving tight Lipschitz bounds for transformer-based architectures presents
a significant challenge. The large input sizes and high-dimensional attention
modules typically prove to be crucial bottlenecks during the training process
and leads to sub-optimal results. Our research highlights practical constraints
of these methods in vision tasks. We find that Lipschitz-based margin training
acts as a strong regularizer while restricting weights in successive layers of
the model. Focusing on a Lipschitz continuous variant of the ShiftViT model, we
address significant training challenges for transformer-based architectures
under norm-constrained input setting. We provide an upper bound estimate for
the Lipschitz constants of this model using the $l_2$ norm on common image
classification datasets. Ultimately, we demonstrate that our method scales to
larger models and advances the state-of-the-art in certified robustness for
transformer-based architectures.","['Rohan Menon', 'Nicola Franco', 'Stephan Günnemann']",2025-03-18,"['cs.LG', 'cs.AI', 'cs.CV']",ICLR 2025 Workshop: VerifAI: AI Verification in the Wild,http://arxiv.org/pdf/2503.14751v1
2503.14749v1,Uncertainty Distillation: Teaching Language Models to Express Semantic Confidence,"As large language models (LLMs) are increasingly used for factual
question-answering, it becomes more important for LLMs to have the capability
to communicate the likelihood that their answer is correct. For these
verbalized expressions of uncertainty to be meaningful, they should reflect the
error rates at the expressed level of confidence. However, when prompted to
express confidence, the error rates of current LLMs are inconsistent with their
communicated confidences, highlighting the need for uncertainty quantification
methods. Many prior methods calculate lexical uncertainty, estimating a model's
confidence in the specific string it generated. In some cases, however, it may
be more useful to estimate semantic uncertainty, or the model's confidence in
the answer regardless of how it is verbalized. We propose a simple procedure,
uncertainty distillation, to teach an LLM to verbalize calibrated semantic
confidences. Using held-out data to map initial uncertainty estimates to
meaningful probabilities, we create examples annotated with verbalized
probabilities for supervised fine-tuning. We demonstrate our method yields
verbalized confidences that correlate with observed error rates with a small
fine-tuned language model as well as with larger instruction-tuned models, and
find that our semantic uncertainty correlates well with lexical uncertainty on
short answers.","['Sophia Hager', 'David Mueller', 'Kevin Duh', 'Nicholas Andrews']",2025-03-18,"['cs.CL', 'cs.LG']",,http://arxiv.org/pdf/2503.14749v1
2503.14734v1,GR00T N1: An Open Foundation Model for Generalist Humanoid Robots,"General-purpose robots need a versatile body and an intelligent mind. Recent
advancements in humanoid robots have shown great promise as a hardware platform
for building generalist autonomy in the human world. A robot foundation model,
trained on massive and diverse data sources, is essential for enabling the
robots to reason about novel situations, robustly handle real-world
variability, and rapidly learn new tasks. To this end, we introduce GR00T N1,
an open foundation model for humanoid robots. GR00T N1 is a
Vision-Language-Action (VLA) model with a dual-system architecture. The
vision-language module (System 2) interprets the environment through vision and
language instructions. The subsequent diffusion transformer module (System 1)
generates fluid motor actions in real time. Both modules are tightly coupled
and jointly trained end-to-end. We train GR00T N1 with a heterogeneous mixture
of real-robot trajectories, human videos, and synthetically generated datasets.
We show that our generalist robot model GR00T N1 outperforms the
state-of-the-art imitation learning baselines on standard simulation benchmarks
across multiple robot embodiments. Furthermore, we deploy our model on the
Fourier GR-1 humanoid robot for language-conditioned bimanual manipulation
tasks, achieving strong performance with high data efficiency.","['NVIDIA', 'Johan Bjorck', 'Fernando Castañeda', 'Nikita Cherniadev', 'Xingye Da', 'Runyu Ding', 'Linxi ""Jim"" Fan', 'Yu Fang', 'Dieter Fox', 'Fengyuan Hu', 'Spencer Huang', 'Joel Jang', 'Zhenyu Jiang', 'Jan Kautz', 'Kaushil Kundalia', 'Lawrence Lao', 'Zhiqi Li', 'Zongyu Lin', 'Kevin Lin', 'Guilin Liu', 'Edith Llontop', 'Loic Magne', 'Ajay Mandlekar', 'Avnish Narayan', 'Soroush Nasiriany', 'Scott Reed', 'You Liang Tan', 'Guanzhi Wang', 'Zu Wang', 'Jing Wang', 'Qi Wang', 'Jiannan Xiang', 'Yuqi Xie', 'Yinzhen Xu', 'Zhenjia Xu', 'Seonghyeon Ye', 'Zhiding Yu', 'Ao Zhang', 'Hao Zhang', 'Yizhou Zhao', 'Ruijie Zheng', 'Yuke Zhu']",2025-03-18,"['cs.RO', 'cs.AI', 'cs.LG']","Authors are listed alphabetically. Project leads are Linxi ""Jim"" Fan
  and Yuke Zhu",http://arxiv.org/pdf/2503.14734v1
2503.14710v1,Variational Autoencoded Multivariate Spatial Fay-Herriot Models,"Small area estimation models are essential for estimating population
characteristics in regions with limited sample sizes, thereby supporting policy
decisions, demographic studies, and resource allocation, among other use cases.
The spatial Fay-Herriot model is one such approach that incorporates spatial
dependence to improve estimation by borrowing strength from neighboring
regions. However, this approach often requires substantial computational
resources, limiting its scalability for high-dimensional datasets, especially
when considering multiple (multivariate) responses. This paper proposes two
methods that integrate the multivariate spatial Fay-Herriot model with spatial
random effects, learned through variational autoencoders, to efficiently
leverage spatial structure. Importantly, after training the variational
autoencoder to represent spatial dependence for a given set of geographies, it
may be used again in future modeling efforts, without the need for retraining.
Additionally, the use of the variational autoencoder to represent spatial
dependence results in extreme improvements in computational efficiency, even
for massive datasets. We demonstrate the effectiveness of our approach using
5-year period estimates from the American Community Survey over all census
tracts in California.","['Zhenhua Wang', 'Paul A. Parker', 'Scott H. Holan']",2025-03-18,"['stat.ML', 'cs.LG']",,http://arxiv.org/pdf/2503.14710v1
2503.14709v1,Better Private Distribution Testing by Leveraging Unverified Auxiliary Data,"We extend the framework of augmented distribution testing (Aliakbarpour,
Indyk, Rubinfeld, and Silwal, NeurIPS 2024) to the differentially private
setting. This captures scenarios where a data analyst must perform hypothesis
testing tasks on sensitive data, but is able to leverage prior knowledge
(public, but possibly erroneous or untrusted) about the data distribution.
  We design private algorithms in this augmented setting for three flagship
distribution testing tasks, uniformity, identity, and closeness testing, whose
sample complexity smoothly scales with the claimed quality of the auxiliary
information. We complement our algorithms with information-theoretic lower
bounds, showing that their sample complexity is optimal (up to logarithmic
factors).","['Maryam Aliakbarpour', 'Arnav Burudgunte', 'Clément Cannone', 'Ronitt Rubinfeld']",2025-03-18,"['cs.LG', 'cs.CR', 'cs.DS']",,http://arxiv.org/pdf/2503.14709v1
2503.15554v1,A Comprehensive Study of LLM Secure Code Generation,"LLMs are widely used in software development. However, the code generated by
LLMs often contains vulnerabilities. Several secure code generation methods
have been proposed to address this issue, but their current evaluation schemes
leave several concerns unaddressed. Specifically, most existing studies
evaluate security and functional correctness separately, using different
datasets. That is, they assess vulnerabilities using security-related code
datasets while validating functionality with general code datasets. In
addition, prior research primarily relies on a single static analyzer, CodeQL,
to detect vulnerabilities in generated code, which limits the scope of security
evaluation.
  In this work, we conduct a comprehensive study to systematically assess the
improvements introduced by four state-of-the-art secure code generation
techniques. Specifically, we apply both security inspection and functionality
validation to the same generated code and evaluate these two aspects together.
We also employ three popular static analyzers and two LLMs to identify
potential vulnerabilities in the generated code. Our study reveals that
existing techniques often compromise the functionality of generated code to
enhance security. Their overall performance remains limited when evaluating
security and functionality together. In fact, many techniques even degrade the
performance of the base LLM. Our further inspection reveals that these
techniques often either remove vulnerable lines of code entirely or generate
``garbage code'' that is unrelated to the intended task. Moreover, the commonly
used static analyzer CodeQL fails to detect several vulnerabilities, further
obscuring the actual security improvements achieved by existing techniques. Our
study serves as a guideline for a more rigorous and comprehensive evaluation of
secure code generation performance in future work.","['Shih-Chieh Dai', 'Jun Xu', 'Guanhong Tao']",2025-03-18,"['cs.CR', 'cs.LG', 'cs.SE']",,http://arxiv.org/pdf/2503.15554v1
2503.14663v1,Sepsyn-OLCP: An Online Learning-based Framework for Early Sepsis Prediction with Uncertainty Quantification using Conformal Prediction,"Sepsis is a life-threatening syndrome with high morbidity and mortality in
hospitals. Early prediction of sepsis plays a crucial role in facilitating
early interventions for septic patients. However, early sepsis prediction
systems with uncertainty quantification and adaptive learning are scarce. This
paper proposes Sepsyn-OLCP, a novel online learning algorithm for early sepsis
prediction by integrating conformal prediction for uncertainty quantification
and Bayesian bandits for adaptive decision-making. By combining the robustness
of Bayesian models with the statistical uncertainty guarantees of conformal
prediction methodologies, this algorithm delivers accurate and trustworthy
predictions, addressing the critical need for reliable and adaptive systems in
high-stakes healthcare applications such as early sepsis prediction. We
evaluate the performance of Sepsyn-OLCP in terms of regret in stochastic bandit
setting, the area under the receiver operating characteristic curve (AUROC),
and F-measure. Our results show that Sepsyn-OLCP outperforms existing
individual models, increasing AUROC of a neural network from 0.64 to 0.73
without retraining and high computational costs. And the model selection policy
converges to the optimal strategy in the long run. We propose a novel
reinforcement learning-based framework integrated with conformal prediction
techniques to provide uncertainty quantification for early sepsis prediction.
The proposed methodology delivers accurate and trustworthy predictions,
addressing a critical need in high-stakes healthcare applications like early
sepsis prediction.","['Anni Zhou', 'Beyah Raheem', 'Rishikesan Kamaleswaran', 'Yao Xie']",2025-03-18,['cs.LG'],,http://arxiv.org/pdf/2503.14663v1
2503.14637v1,Reinforcement learning-based motion imitation for physiologically plausible musculoskeletal motor control,"How do humans move? The quest to understand human motion has broad
applications in numerous fields, ranging from computer animation and motion
synthesis to neuroscience, human prosthetics and rehabilitation. Although
advances in reinforcement learning (RL) have produced impressive results in
capturing human motion using simplified humanoids, controlling physiologically
accurate models of the body remains an open challenge. In this work, we present
a model-free motion imitation framework (KINESIS) to advance the understanding
of muscle-based motor control. Using a musculoskeletal model of the lower body
with 80 muscle actuators and 20 DoF, we demonstrate that KINESIS achieves
strong imitation performance on 1.9 hours of motion capture data, is
controllable by natural language through pre-trained text-to-motion generative
models, and can be fine-tuned to carry out high-level tasks such as target goal
reaching. Importantly, KINESIS generates muscle activity patterns that
correlate well with human EMG activity. The physiological plausibility makes
KINESIS a promising model for tackling challenging problems in human motor
control theory, which we highlight by investigating Bernstein's redundancy
problem in the context of locomotion. Code, videos and benchmarks will be
available at https://github.com/amathislab/Kinesis.","['Merkourios Simos', 'Alberto Silvio Chiappa', 'Alexander Mathis']",2025-03-18,"['cs.RO', 'cs.AI', 'cs.CV', 'cs.LG', 'q-bio.NC']",,http://arxiv.org/pdf/2503.14637v1
2503.14630v1,Assessing Large Language Models for Automated Feedback Generation in Learning Programming Problem Solving,"Providing effective feedback is important for student learning in programming
problem-solving. In this sense, Large Language Models (LLMs) have emerged as
potential tools to automate feedback generation. However, their reliability and
ability to identify reasoning errors in student code remain not well
understood. This study evaluates the performance of four LLMs (GPT-4o, GPT-4o
mini, GPT-4-Turbo, and Gemini-1.5-pro) on a benchmark dataset of 45 student
solutions. We assessed the models' capacity to provide accurate and insightful
feedback, particularly in identifying reasoning mistakes. Our analysis reveals
that 63\% of feedback hints were accurate and complete, while 37\% contained
mistakes, including incorrect line identification, flawed explanations, or
hallucinated issues. These findings highlight the potential and limitations of
LLMs in programming education and underscore the need for improvements to
enhance reliability and minimize risks in educational applications.","['Priscylla Silva', 'Evandro Costa']",2025-03-18,"['cs.SE', 'cs.AI', 'cs.LG']",,http://arxiv.org/pdf/2503.14630v1
2503.14621v1,Reducing False Ventricular Tachycardia Alarms in ICU Settings: A Machine Learning Approach,"False arrhythmia alarms in intensive care units (ICUs) are a significant
challenge, contributing to alarm fatigue and potentially compromising patient
safety. Ventricular tachycardia (VT) alarms are particularly difficult to
detect accurately due to their complex nature. This paper presents a machine
learning approach to reduce false VT alarms using the VTaC dataset, a benchmark
dataset of annotated VT alarms from ICU monitors. We extract time-domain and
frequency-domain features from waveform data, preprocess the data, and train
deep learning models to classify true and false VT alarms. Our results
demonstrate high performance, with ROC-AUC scores exceeding 0.96 across various
training configurations. This work highlights the potential of machine learning
to improve the accuracy of VT alarm detection in clinical settings.","['Grace Funmilayo Farayola', 'Akinyemi Sadeeq Akintola', 'Oluwole Fagbohun', 'Chukwuka Michael Oforgu', 'Bisola Faith Kayode', 'Christian Chimezie', 'Temitope Kadri', 'Abiola Oludotun', 'Nelson Ogbeide', 'Mgbame Michael', 'Adeseye Ifaturoti', 'Toyese Oloyede']",2025-03-18,"['cs.LG', 'cs.AI']","Preprint, Accepted to the International Conference on Machine
  Learning Technologies (ICMLT 2025), Helsinki, Finland",http://arxiv.org/pdf/2503.14621v1
2503.14618v1,Anomaly-Flow: A Multi-domain Federated Generative Adversarial Network for Distributed Denial-of-Service Detection,"Distributed denial-of-service (DDoS) attacks remain a critical threat to
Internet services, causing costly disruptions. While machine learning (ML) has
shown promise in DDoS detection, current solutions struggle with multi-domain
environments where attacks must be detected across heterogeneous networks and
organizational boundaries. This limitation severely impacts the practical
deployment of ML-based defenses in real-world settings.
  This paper introduces Anomaly-Flow, a novel framework that addresses this
critical gap by combining Federated Learning (FL) with Generative Adversarial
Networks (GANs) for privacy-preserving, multi-domain DDoS detection. Our
proposal enables collaborative learning across diverse network domains while
preserving data privacy through synthetic flow generation. Through extensive
evaluation across three distinct network datasets, Anomaly-Flow achieves an
average F1-score of $0.747$, outperforming baseline models. Importantly, our
framework enables organizations to share attack detection capabilities without
exposing sensitive network data, making it particularly valuable for critical
infrastructure and privacy-sensitive sectors.
  Beyond immediate technical contributions, this work provides insights into
the challenges and opportunities in multi-domain DDoS detection, establishing a
foundation for future research in collaborative network defense systems. Our
findings have important implications for academic research and industry
practitioners working to deploy practical ML-based security solutions.","['Leonardo Henrique de Melo', 'Gustavo de Carvalho Bertoli', 'Michele Nogueira', 'Aldri Luiz dos Santos', 'Lourenço Alves Pereira Junior']",2025-03-18,"['cs.CR', 'cs.LG']","8 pages, 4 figures",http://arxiv.org/pdf/2503.14618v1
2503.14615v1,Unique Hard Attention: A Tale of Two Sides,"Understanding the expressive power of transformers has recently attracted
attention, as it offers insights into their abilities and limitations. Many
studies analyze unique hard attention transformers, where attention selects a
single position that maximizes the attention scores. When multiple positions
achieve the maximum score, either the rightmost or the leftmost of those is
chosen. In this paper, we highlight the importance of this seeming triviality.
Recently, finite-precision transformers with both leftmost- and rightmost-hard
attention were shown to be equivalent to Linear Temporal Logic (LTL). We show
that this no longer holds with only leftmost-hard attention -- in that case,
they correspond to a \emph{strictly weaker} fragment of LTL. Furthermore, we
show that models with leftmost-hard attention are equivalent to \emph{soft}
attention, suggesting they may better approximate real-world transformers than
right-attention models. These findings refine the landscape of transformer
expressivity and underscore the role of attention directionality.","['Selim Jerad', 'Anej Svete', 'Jiaoda Li', 'Ryan Cotterell']",2025-03-18,"['cs.LG', 'cs.CC', 'cs.CL', 'cs.FL']",,http://arxiv.org/pdf/2503.14615v1
2503.14603v1,"Command R7B Arabic: A Small, Enterprise Focused, Multilingual, and Culturally Aware Arabic LLM","Building high-quality large language models (LLMs) for enterprise Arabic
applications remains challenging due to the limited availability of digitized
Arabic data. In this work, we present a data synthesis and refinement strategy
to help address this problem, namely, by leveraging synthetic data generation
and human-in-the-loop annotation to expand our Arabic training corpus. We
further present our iterative post training recipe that is essential to
achieving state-of-the-art performance in aligning the model with human
preferences, a critical aspect to enterprise use cases. The culmination of this
effort is the release of a small, 7B, open-weight model that outperforms
similarly sized peers in head-to-head comparisons and on Arabic-focused
benchmarks covering cultural knowledge, instruction following, RAG, and
contextual faithfulness.","['Yazeed Alnumay', 'Alexandre Barbet', 'Anna Bialas', 'William Darling', 'Shaan Desai', 'Joan Devassy', 'Kyle Duffy', 'Stephanie Howe', 'Olivia Lasche', 'Justin Lee', 'Anirudh Shrinivason', 'Jennifer Tracey']",2025-03-18,"['cs.CL', 'cs.LG']",,http://arxiv.org/pdf/2503.14603v1
2503.14505v1,MusicInfuser: Making Video Diffusion Listen and Dance,"We introduce MusicInfuser, an approach for generating high-quality dance
videos that are synchronized to a specified music track. Rather than attempting
to design and train a new multimodal audio-video model, we show how existing
video diffusion models can be adapted to align with musical inputs by
introducing lightweight music-video cross-attention and a low-rank adapter.
Unlike prior work requiring motion capture data, our approach fine-tunes only
on dance videos. MusicInfuser achieves high-quality music-driven video
generation while preserving the flexibility and generative capabilities of the
underlying models. We introduce an evaluation framework using Video-LLMs to
assess multiple dimensions of dance generation quality. The project page and
code are available at https://susunghong.github.io/MusicInfuser.","['Susung Hong', 'Ira Kemelmacher-Shlizerman', 'Brian Curless', 'Steven M. Seitz']",2025-03-18,"['cs.CV', 'cs.AI', 'cs.LG']",Project page: https://susunghong.github.io/MusicInfuser,http://arxiv.org/pdf/2503.14505v1
2503.14503v1,The Power of Context: How Multimodality Improves Image Super-Resolution,"Single-image super-resolution (SISR) remains challenging due to the inherent
difficulty of recovering fine-grained details and preserving perceptual quality
from low-resolution inputs. Existing methods often rely on limited image
priors, leading to suboptimal results. We propose a novel approach that
leverages the rich contextual information available in multiple modalities --
including depth, segmentation, edges, and text prompts -- to learn a powerful
generative prior for SISR within a diffusion model framework. We introduce a
flexible network architecture that effectively fuses multimodal information,
accommodating an arbitrary number of input modalities without requiring
significant modifications to the diffusion process. Crucially, we mitigate
hallucinations, often introduced by text prompts, by using spatial information
from other modalities to guide regional text-based conditioning. Each
modality's guidance strength can also be controlled independently, allowing
steering outputs toward different directions, such as increasing bokeh through
depth or adjusting object prominence via segmentation. Extensive experiments
demonstrate that our model surpasses state-of-the-art generative SISR methods,
achieving superior visual quality and fidelity. See project page at
https://mmsr.kfmei.com/.","['Kangfu Mei', 'Hossein Talebi', 'Mojtaba Ardakani', 'Vishal M. Patel', 'Peyman Milanfar', 'Mauricio Delbracio']",2025-03-18,"['cs.CV', 'cs.AI', 'cs.LG']",accepted by CVPR2025,http://arxiv.org/pdf/2503.14503v1
2503.14500v1,Utilization of Neighbor Information for Image Classification with Different Levels of Supervision,"We propose to bridge the gap between semi-supervised and unsupervised image
recognition with a flexible method that performs well for both generalized
category discovery (GCD) and image clustering. Despite the overlap in
motivation between these tasks, the methods themselves are restricted to a
single task -- GCD methods are reliant on the labeled portion of the data, and
deep image clustering methods have no built-in way to leverage the labels
efficiently. We connect the two regimes with an innovative approach that
Utilizes Neighbor Information for Classification (UNIC) both in the
unsupervised (clustering) and semisupervised (GCD) setting. State-of-the-art
clustering methods already rely heavily on nearest neighbors. We improve on
their results substantially in two parts, first with a sampling and cleaning
strategy where we identify accurate positive and negative neighbors, and
secondly by finetuning the backbone with clustering losses computed by sampling
both types of neighbors. We then adapt this pipeline to GCD by utilizing the
labelled images as ground truth neighbors. Our method yields state-of-the-art
results for both clustering (+3% ImageNet-100, Imagenet200) and GCD (+0.8%
ImageNet-100, +5% CUB, +2% SCars, +4% Aircraft).","['Gihan Jayatilaka', 'Abhinav Shrivastava', 'Matthew Gwilliam']",2025-03-18,"['cs.CV', 'cs.LG']","18 pages, 16 figures, 7 tables",http://arxiv.org/pdf/2503.14500v1
2503.14499v1,Measuring AI Ability to Complete Long Tasks,"Despite rapid progress on AI benchmarks, the real-world meaning of benchmark
performance remains unclear. To quantify the capabilities of AI systems in
terms of human capabilities, we propose a new metric: 50%-task-completion time
horizon. This is the time humans typically take to complete tasks that AI
models can complete with 50% success rate. We first timed humans with relevant
domain expertise on a combination of RE-Bench, HCAST, and 66 novel shorter
tasks. On these tasks, current frontier AI models such as Claude 3.7 Sonnet
have a 50% time horizon of around 50 minutes. Furthermore, frontier AI time
horizon has been doubling approximately every seven months since 2019, though
the trend may have accelerated in 2024. The increase in AI models' time
horizons seems to be primarily driven by greater reliability and ability to
adapt to mistakes, combined with better logical reasoning and tool use
capabilities. We discuss the limitations of our results -- including their
degree of external validity -- and the implications of increased autonomy for
dangerous capabilities. If these results generalize to real-world software
tasks, extrapolation of this trend predicts that within 5 years, AI systems
will be capable of automating many software tasks that currently take humans a
month.","['Thomas Kwa', 'Ben West', 'Joel Becker', 'Amy Deng', 'Katharyn Garcia', 'Max Hasin', 'Sami Jawhar', 'Megan Kinniment', 'Nate Rush', 'Sydney Von Arx', 'Ryan Bloom', 'Thomas Broadley', 'Haoxing Du', 'Brian Goodrich', 'Nikola Jurkovic', 'Luke Harold Miles', 'Seraphina Nix', 'Tao Lin', 'Neev Parikh', 'David Rein', 'Lucas Jun Koba Sato', 'Hjalmar Wijk', 'Daniel M. Ziegler', 'Elizabeth Barnes', 'Lawrence Chan']",2025-03-18,"['cs.AI', 'cs.LG']",,http://arxiv.org/pdf/2503.14499v1
2503.14495v1,Temporal Consistency for LLM Reasoning Process Error Identification,"Verification is crucial for effective mathematical reasoning. We present a
new temporal consistency method where verifiers iteratively refine their
judgments based on the previous assessment. Unlike one-round verification or
multi-model debate approaches, our method leverages consistency in a sequence
of self-reflection actions to improve verification accuracy. Empirical
evaluations across diverse mathematical process error identification benchmarks
(Mathcheck, ProcessBench, and PRM800K) show consistent performance improvements
over baseline methods. When applied to the recent DeepSeek R1 distilled models,
our method demonstrates strong performance, enabling 7B/8B distilled models to
outperform all 70B/72B models and GPT-4o on ProcessBench. Notably, the
distilled 14B model with our method achieves performance comparable to
Deepseek-R1. Our codes are available at
https://github.com/jcguo123/Temporal-Consistency","['Jiacheng Guo', 'Yue Wu', 'Jiahao Qiu', 'Kaixuan Huang', 'Xinzhe Juan', 'Ling Yang', 'Mengdi Wang']",2025-03-18,"['cs.CL', 'cs.LG']",,http://arxiv.org/pdf/2503.14495v1
2503.14492v1,Cosmos-Transfer1: Conditional World Generation with Adaptive Multimodal Control,"We introduce Cosmos-Transfer, a conditional world generation model that can
generate world simulations based on multiple spatial control inputs of various
modalities such as segmentation, depth, and edge. In the design, the spatial
conditional scheme is adaptive and customizable. It allows weighting different
conditional inputs differently at different spatial locations. This enables
highly controllable world generation and finds use in various world-to-world
transfer use cases, including Sim2Real. We conduct extensive evaluations to
analyze the proposed model and demonstrate its applications for Physical AI,
including robotics Sim2Real and autonomous vehicle data enrichment. We further
demonstrate an inference scaling strategy to achieve real-time world generation
with an NVIDIA GB200 NVL72 rack. To help accelerate research development in the
field, we open-source our models and code at
https://github.com/nvidia-cosmos/cosmos-transfer1.","['NVIDIA', ':', 'Hassan Abu Alhaija', 'Jose Alvarez', 'Maciej Bala', 'Tiffany Cai', 'Tianshi Cao', 'Liz Cha', 'Joshua Chen', 'Mike Chen', 'Francesco Ferroni', 'Sanja Fidler', 'Dieter Fox', 'Yunhao Ge', 'Jinwei Gu', 'Ali Hassani', 'Michael Isaev', 'Pooya Jannaty', 'Shiyi Lan', 'Tobias Lasser', 'Huan Ling', 'Ming-Yu Liu', 'Xian Liu', 'Yifan Lu', 'Alice Luo', 'Qianli Ma', 'Hanzi Mao', 'Fabio Ramos', 'Xuanchi Ren', 'Tianchang Shen', 'Shitao Tang', 'Ting-Chun Wang', 'Jay Wu', 'Jiashu Xu', 'Stella Xu', 'Kevin Xie', 'Yuchong Ye', 'Xiaodong Yang', 'Xiaohui Zeng', 'Yu Zeng']",2025-03-18,"['cs.CV', 'cs.AI', 'cs.LG', 'cs.RO']",,http://arxiv.org/pdf/2503.14492v1
2503.14481v1,Don't lie to your friends: Learning what you know from collaborative self-play,"To be helpful assistants, AI agents must be aware of their own capabilities
and limitations. This includes knowing when to answer from parametric knowledge
versus using tools, when to trust tool outputs, and when to abstain or hedge.
Such capabilities are hard to teach through supervised fine-tuning because they
require constructing examples that reflect the agent's specific capabilities.
We therefore propose a radically new approach to teaching agents what they
know: \emph{collaborative self-play}. We construct multi-agent collaborations
in which the group is rewarded for collectively arriving at correct answers.
The desired meta-knowledge emerges from the incentives built into the structure
of the interaction. We focus on small societies of agents that have access to
heterogeneous tools (corpus-specific retrieval), and therefore must collaborate
to maximize their success while minimizing their effort. Experiments show that
group-level rewards for multi-agent communities can induce policies that
\emph{transfer} to improve tool use and selective prediction in settings where
individual agents are deployed in isolation.","['Jacob Eisenstein', 'Reza Aghajani', 'Adam Fisch', 'Dheeru Dua', 'Fantine Huot', 'Mirella Lapata', 'Vicky Zayats', 'Jonathan Berant']",2025-03-18,"['cs.LG', 'cs.CL']",,http://arxiv.org/pdf/2503.14481v1
2503.14476v1,DAPO: An Open-Source LLM Reinforcement Learning System at Scale,"Inference scaling empowers LLMs with unprecedented reasoning ability, with
reinforcement learning as the core technique to elicit complex reasoning.
However, key technical details of state-of-the-art reasoning LLMs are concealed
(such as in OpenAI o1 blog and DeepSeek R1 technical report), thus the
community still struggles to reproduce their RL training results. We propose
the $\textbf{D}$ecoupled Clip and $\textbf{D}$ynamic s$\textbf{A}$mpling
$\textbf{P}$olicy $\textbf{O}$ptimization ($\textbf{DAPO}$) algorithm, and
fully open-source a state-of-the-art large-scale RL system that achieves 50
points on AIME 2024 using Qwen2.5-32B base model. Unlike previous works that
withhold training details, we introduce four key techniques of our algorithm
that make large-scale LLM RL a success. In addition, we open-source our
training code, which is built on the verl framework, along with a carefully
curated and processed dataset. These components of our open-source system
enhance reproducibility and support future research in large-scale LLM RL.","['Qiying Yu', 'Zheng Zhang', 'Ruofei Zhu', 'Yufeng Yuan', 'Xiaochen Zuo', 'Yu Yue', 'Tiantian Fan', 'Gaohong Liu', 'Lingjun Liu', 'Xin Liu', 'Haibin Lin', 'Zhiqi Lin', 'Bole Ma', 'Guangming Sheng', 'Yuxuan Tong', 'Chi Zhang', 'Mofan Zhang', 'Wang Zhang', 'Hang Zhu', 'Jinhua Zhu', 'Jiaze Chen', 'Jiangjie Chen', 'Chengyi Wang', 'Hongli Yu', 'Weinan Dai', 'Yuxuan Song', 'Xiangpeng Wei', 'Hao Zhou', 'Jingjing Liu', 'Wei-Ying Ma', 'Ya-Qin Zhang', 'Lin Yan', 'Mu Qiao', 'Yonghui Wu', 'Mingxuan Wang']",2025-03-18,"['cs.LG', 'cs.CL']",Project Page: https://dapo-sia.github.io/,http://arxiv.org/pdf/2503.14476v1
2503.14473v1,EnQode: Fast Amplitude Embedding for Quantum Machine Learning Using Classical Data,"Amplitude embedding (AE) is essential in quantum machine learning (QML) for
encoding classical data onto quantum circuits. However, conventional AE methods
suffer from deep, variable-length circuits that introduce high output error due
to extensive gate usage and variable error rates across samples, resulting in
noise-driven inconsistencies that degrade model accuracy. We introduce EnQode,
a fast AE technique based on symbolic representation that addresses these
limitations by clustering dataset samples and solving for cluster mean states
through a low-depth, machine-specific ansatz. Optimized to reduce physical
gates and SWAP operations, EnQode ensures all samples face consistent, low
noise levels by standardizing circuit depth and composition. With over 90%
fidelity in data mapping, EnQode enables robust, high-performance QML on noisy
intermediate-scale quantum (NISQ) devices. Our open-source solution provides a
scalable and efficient alternative for integrating classical data with quantum
models.","['Jason Han', 'Nicholas S. DiBrita', 'Younghyun Cho', 'Hengrui Luo', 'Tirthak Patel']",2025-03-18,"['quant-ph', 'cs.ET', 'cs.LG']","EnQode will appear in the Proceedings of the Design Automation
  Conference (DAC), 2025",http://arxiv.org/pdf/2503.14473v1
2503.14459v1,Doubly robust identification of treatment effects from multiple environments,"Practical and ethical constraints often require the use of observational data
for causal inference, particularly in medicine and social sciences. Yet,
observational datasets are prone to confounding, potentially compromising the
validity of causal conclusions. While it is possible to correct for biases if
the underlying causal graph is known, this is rarely a feasible ask in
practical scenarios. A common strategy is to adjust for all available
covariates, yet this approach can yield biased treatment effect estimates,
especially when post-treatment or unobserved variables are present. We propose
RAMEN, an algorithm that produces unbiased treatment effect estimates by
leveraging the heterogeneity of multiple data sources without the need to know
or learn the underlying causal graph. Notably, RAMEN achieves doubly robust
identification: it can identify the treatment effect whenever the causal
parents of the treatment or those of the outcome are observed, and the node
whose parents are observed satisfies an invariance assumption. Empirical
evaluations on synthetic and real-world datasets show that our approach
outperforms existing methods.","['Piersilvio De Bartolomeis', 'Julia Kostin', 'Javier Abad', 'Yixin Wang', 'Fanny Yang']",2025-03-18,"['stat.ML', 'cs.LG', 'stat.ME']","Accepted for presentation at the International Conference on Learning
  Representations (ICLR) 2025",http://arxiv.org/pdf/2503.14459v1
2503.14456v1,"RWKV-7 ""Goose"" with Expressive Dynamic State Evolution","We present RWKV-7 ""Goose"", a new sequence modeling architecture, along with
pre-trained language models that establish a new state-of-the-art in downstream
performance at the 3 billion parameter scale on multilingual tasks, and match
current SoTA English language performance despite being trained on dramatically
fewer tokens than other top 3B models. Nevertheless, RWKV-7 models require only
constant memory usage and constant inference time per token. RWKV-7 introduces
a newly generalized formulation of the delta rule with vector-valued gating and
in-context learning rates, as well as a relaxed value replacement rule. We show
that RWKV-7 can perform state tracking and recognize all regular languages,
while retaining parallelizability of training. This exceeds the capabilities of
Transformers under standard complexity conjectures, which are limited to
$\mathsf{TC}^0$. To demonstrate RWKV-7's language modeling capability, we also
present an extended open source 3.1 trillion token multilingual corpus, and
train four RWKV-7 models ranging from 0.19 billion to 2.9 billion parameters on
this dataset.
  To foster openness, reproduction, and adoption, we release our models and
dataset component listing at https://huggingface.co/RWKV, and our training and
inference code at https://github.com/RWKV/RWKV-LM all under the Apache 2.0
License.","['Bo Peng', 'Ruichong Zhang', 'Daniel Goldstein', 'Eric Alcaide', 'Haowen Hou', 'Janna Lu', 'William Merrill', 'Guangyu Song', 'Kaifeng Tan', 'Saiteja Utpala', 'Nathan Wilce', 'Johan S. Wind', 'Tianyi Wu', 'Daniel Wuttke', 'Christian Zhou-Zheng']",2025-03-18,"['cs.CL', 'cs.AI', 'cs.LG', 'I.2.0; I.2.7']",,http://arxiv.org/pdf/2503.14456v1
2503.14453v1,Online Conformal Probabilistic Numerics via Adaptive Edge-Cloud Offloading,"Consider an edge computing setting in which a user submits queries for the
solution of a linear system to an edge processor, which is subject to
time-varying computing availability. The edge processor applies a probabilistic
linear solver (PLS) so as to be able to respond to the user's query within the
allotted time and computing budget. Feedback to the user is in the form of an
uncertainty set. Due to model misspecification, the uncertainty set obtained
via a direct application of PLS does not come with coverage guarantees with
respect to the true solution of the linear system. This work introduces a new
method to calibrate the uncertainty sets produced by PLS with the aim of
guaranteeing long-term coverage requirements. The proposed method, referred to
as online conformal prediction-PLS (OCP-PLS), assumes sporadic feedback from
cloud to edge. This enables the online calibration of uncertainty thresholds
via online conformal prediction (OCP), an online optimization method previously
studied in the context of prediction models. The validity of OCP-PLS is
verified via experiments that bring insights into trade-offs between coverage,
prediction set size, and cloud usage.","['Qiushuo Hou', 'Sangwoo Park', 'Matteo Zecchin', 'Yunlong Cai', 'Guanding Yu', 'Osvaldo Simeone']",2025-03-18,"['stat.ML', 'cs.LG']",This paper has been submitted to a conference,http://arxiv.org/pdf/2503.14453v1
2503.14443v1,EnvBench: A Benchmark for Automated Environment Setup,"Recent advances in Large Language Models (LLMs) have enabled researchers to
focus on practical repository-level tasks in software engineering domain. In
this work, we consider a cornerstone task for automating work with software
repositories-environment setup, i.e., a task of configuring a
repository-specific development environment on a system. Existing studies on
environment setup introduce innovative agentic strategies, but their evaluation
is often based on small datasets that may not capture the full range of
configuration challenges encountered in practice. To address this gap, we
introduce a comprehensive environment setup benchmark EnvBench. It encompasses
329 Python and 665 JVM-based (Java, Kotlin) repositories, with a focus on
repositories that present genuine configuration challenges, excluding projects
that can be fully configured by simple deterministic scripts. To enable further
benchmark extension and usage for model tuning, we implement two automatic
metrics: a static analysis check for missing imports in Python and a
compilation check for JVM languages. We demonstrate the applicability of our
benchmark by evaluating three environment setup approaches, including a simple
zero-shot baseline and two agentic workflows, that we test with two powerful
LLM backbones, GPT-4o and GPT-4o-mini. The best approach manages to
successfully configure 6.69% repositories for Python and 29.47% repositories
for JVM, suggesting that EnvBench remains challenging for current approaches.
Our benchmark suite is publicly available at
https://github.com/JetBrains-Research/EnvBench. The dataset and experiment
trajectories are available at https://jb.gg/envbench.","['Aleksandra Eliseeva', 'Alexander Kovrigin', 'Ilia Kholkin', 'Egor Bogomolov', 'Yaroslav Zharov']",2025-03-18,"['cs.LG', 'cs.SE']",Accepted at the DL4Code workshop at ICLR'25,http://arxiv.org/pdf/2503.14443v1
2503.14442v1,Inducing Causal Structure for Interpretable Neural Networks Applied to Glucose Prediction for T1DM Patients,"Causal abstraction techniques such as Interchange Intervention Training (IIT)
have been proposed to infuse neural network with expert knowledge encoded in
causal models, but their application to real-world problems remains limited.
This article explores the application of IIT in predicting blood glucose levels
in Type 1 Diabetes Mellitus (T1DM) patients. The study utilizes an acyclic
version of the simglucose simulator approved by the FDA to train a Multi-Layer
Perceptron (MLP) model, employing IIT to impose causal relationships. Results
show that the model trained with IIT effectively abstracted the causal
structure and outperformed the standard one in terms of predictive performance
across different prediction horizons (PHs) post-meal. Furthermore, the
breakdown of the counterfactual loss can be leveraged to explain which part of
the causal mechanism are more or less effectively captured by the model. These
preliminary results suggest the potential of IIT in enhancing predictive models
in healthcare by effectively complying with expert knowledge.","['Ana Esponera', 'Giovanni Cinà']",2025-03-18,"['cs.LG', 'q-bio.BM']","27 pages, 10 pages, to be published in the Proceedings of Machine
  Learning Research (PMLR), to be presented at the conference CLeaR 2025",http://arxiv.org/pdf/2503.14442v1
2503.14439v1,Graph-CNNs for RF Imaging: Learning the Electric Field Integral Equations,"Radio-Frequency (RF) imaging concerns the digital recreation of the surfaces
of scene objects based on the scattered field at distributed receivers. To
solve this difficult inverse scattering problems, data-driven methods are often
employed that extract patterns from similar training examples, while offering
minimal latency. In this paper, we first provide an approximate yet fast
electromagnetic model, which is based on the electric field integral equations,
for data generation, and subsequently propose a Deep Neural Network (DNN)
architecture to learn the corresponding inverse model. A graph-attention
backbone allows for the system geometry to be passed to the DNN, where residual
convolutional layers extract features about the objects, while a UNet head
performs the final image reconstruction. Our quantitative and qualitative
evaluations on two synthetic data sets of different characteristics showcase
the performance gains of thee proposed advanced architecture and its relative
resilience to signal noise levels and various reception configurations.","['Kyriakos Stylianopoulos', 'Panagiotis Gavriilidis', 'Gabriele Gradoni', 'George C. Alexandropoulos']",2025-03-18,"['cs.LG', 'eess.SP']",Submitted to EUSIPCO 2025,http://arxiv.org/pdf/2503.14439v1
2503.14434v1,LLM-FE: Automated Feature Engineering for Tabular Data with LLMs as Evolutionary Optimizers,"Automated feature engineering plays a critical role in improving predictive
model performance for tabular learning tasks. Traditional automated feature
engineering methods are limited by their reliance on pre-defined
transformations within fixed, manually designed search spaces, often neglecting
domain knowledge. Recent advances using Large Language Models (LLMs) have
enabled the integration of domain knowledge into the feature engineering
process. However, existing LLM-based approaches use direct prompting or rely
solely on validation scores for feature selection, failing to leverage insights
from prior feature discovery experiments or establish meaningful reasoning
between feature generation and data-driven performance. To address these
challenges, we propose LLM-FE, a novel framework that combines evolutionary
search with the domain knowledge and reasoning capabilities of LLMs to
automatically discover effective features for tabular learning tasks. LLM-FE
formulates feature engineering as a program search problem, where LLMs propose
new feature transformation programs iteratively, and data-driven feedback
guides the search process. Our results demonstrate that LLM-FE consistently
outperforms state-of-the-art baselines, significantly enhancing the performance
of tabular prediction models across diverse classification and regression
benchmarks.","['Nikhil Abhyankar', 'Parshin Shojaee', 'Chandan K. Reddy']",2025-03-18,"['cs.LG', 'cs.AI', 'cs.CL', 'cs.NE']",,http://arxiv.org/pdf/2503.14434v1
2503.14432v1,PLAY2PROMPT: Zero-shot Tool Instruction Optimization for LLM Agents via Tool Play,"Large language models (LLMs) are increasingly integrated with specialized
external tools, yet many tasks demand zero-shot tool usage with minimal or
noisy documentation. Existing solutions rely on manual rewriting or labeled
data for validation, making them inapplicable in true zero-shot settings. To
address these challenges, we propose PLAY2PROMPT, an automated framework that
systematically ""plays"" with each tool to explore its input-output behaviors.
Through this iterative trial-and-error process, PLAY2PROMPT refines tool
documentation and generates usage examples without any labeled data. These
examples not only guide LLM inference but also serve as validation to further
enhance tool utilization. Extensive experiments on real-world tasks demonstrate
that PLAY2PROMPT significantly improves zero-shot tool performance across both
open and closed models, offering a scalable and effective solution for
domain-specific tool integration.","['Wei Fang', 'Yang Zhang', 'Kaizhi Qian', 'James Glass', 'Yada Zhu']",2025-03-18,"['cs.CL', 'cs.AI', 'cs.LG']",,http://arxiv.org/pdf/2503.14432v1
2503.14421v1,ExDDV: A New Dataset for Explainable Deepfake Detection in Video,"The ever growing realism and quality of generated videos makes it
increasingly harder for humans to spot deepfake content, who need to rely more
and more on automatic deepfake detectors. However, deepfake detectors are also
prone to errors, and their decisions are not explainable, leaving humans
vulnerable to deepfake-based fraud and misinformation. To this end, we
introduce ExDDV, the first dataset and benchmark for Explainable Deepfake
Detection in Video. ExDDV comprises around 5.4K real and deepfake videos that
are manually annotated with text descriptions (to explain the artifacts) and
clicks (to point out the artifacts). We evaluate a number of vision-language
models on ExDDV, performing experiments with various fine-tuning and in-context
learning strategies. Our results show that text and click supervision are both
required to develop robust explainable models for deepfake videos, which are
able to localize and describe the observed artifacts. Our novel dataset and
code to reproduce the results are available at
https://github.com/vladhondru25/ExDDV.","['Vlad Hondru', 'Eduard Hogea', 'Darian Onchis', 'Radu Tudor Ionescu']",2025-03-18,"['cs.CV', 'cs.AI', 'cs.CL', 'cs.LG', 'cs.MM']",,http://arxiv.org/pdf/2503.14421v1
2503.14405v1,DUNE: Distilling a Universal Encoder from Heterogeneous 2D and 3D Teachers,"Recent multi-teacher distillation methods have unified the encoders of
multiple foundation models into a single encoder, achieving competitive
performance on core vision tasks like classification, segmentation, and depth
estimation. This led us to ask: Could similar success be achieved when the pool
of teachers also includes vision models specialized in diverse tasks across
both 2D and 3D perception? In this paper, we define and investigate the problem
of heterogeneous teacher distillation, or co-distillation, a challenging
multi-teacher distillation scenario where teacher models vary significantly in
both (a) their design objectives and (b) the data they were trained on. We
explore data-sharing strategies and teacher-specific encoding, and introduce
DUNE, a single encoder excelling in 2D vision, 3D understanding, and 3D human
perception. Our model achieves performance comparable to that of its larger
teachers, sometimes even outperforming them, on their respective tasks.
Notably, DUNE surpasses MASt3R in Map-free Visual Relocalization with a much
smaller encoder.","['Mert Bulent Sariyildiz', 'Philippe Weinzaepfel', 'Thomas Lucas', 'Pau de Jorge', 'Diane Larlus', 'Yannis Kalantidis']",2025-03-18,"['cs.CV', 'cs.LG']","Accepted to CVPR-2025. Project page:
  https://europe.naverlabs.com/dune",http://arxiv.org/pdf/2503.14405v1
2503.14403v1,Landscape Complexity for the Empirical Risk of Generalized Linear Models: Discrimination between Structured Data,"We use the Kac-Rice formula and results from random matrix theory to obtain
the average number of critical points of a family of high-dimensional empirical
loss functions, where the data are correlated $d$-dimensional Gaussian vectors,
whose number has a fixed ratio with their dimension. The correlations are
introduced to model the existence of structure in the data, as is common in
current Machine-Learning systems. Under a technical hypothesis, our results are
exact in the large-$d$ limit, and characterize the annealed landscape
complexity, namely the logarithm of the expected number of critical points at a
given value of the loss.
  We first address in detail the landscape of the loss function of a single
perceptron and then generalize it to the case where two competing data sets
with different covariance matrices are present, with the perceptron seeking to
discriminate between them. The latter model can be applied to understand the
interplay between adversity and non-trivial data structure. For completeness,
we also treat the case of a loss function used in training Generalized Linear
Models in the presence of correlated input data.","['Theodoros G. Tsironis', 'Aris L. Moustakas']",2025-03-18,"['cs.LG', 'cond-mat.stat-mech', 'stat.ML']",,http://arxiv.org/pdf/2503.14403v1
2503.14396v2,Technical Report: Aggregation on Learnable Manifolds for Asynchronous Federated Optimization,"In Federated Learning (FL), a primary challenge to the server-side
aggregation of client models is device heterogeneity in both loss landscape
geometry and computational capacity. This issue can be particularly pronounced
in clinical contexts where variations in data distribution (aggravated by class
imbalance), infrastructure requirements, and sample sizes are common. We
propose AsyncManifold, a novel asynchronous FL framework to address these
issues by taking advantage of underlying solution space geometry at each of the
local training, delay-correction, and aggregation stages. Our proposal is
accompanied by a convergence proof in a general form and, motivated through
exploratory studies of local behaviour, a proof-of-concept algorithm which
performs aggregation along non-linear mode connections and hence avoids
barriers to convergence that techniques based on linear interpolation will
encounter.",['Archie Licudi'],2025-03-18,['cs.LG'],"22 pages, 3 figures. Preliminary technical project report [v2] fixed
  abstract wording",http://arxiv.org/pdf/2503.14396v2
2503.14393v1,On the clustering behavior of sliding windows,"Things can go spectacularly wrong when clustering timeseries data that has
been preprocessed with a sliding window. We highlight three surprising failures
that emerge depending on how the window size compares with the timeseries
length. In addition to computational examples, we present theoretical
explanations for each of these failure modes.","['Boris Alexeev', 'Wenyan Luo', 'Dustin G. Mixon', 'Yan X Zhang']",2025-03-18,['cs.LG'],,http://arxiv.org/pdf/2503.14393v1
2503.14381v1,Optimizing High-Dimensional Oblique Splits,"Orthogonal-split trees perform well, but evidence suggests oblique splits can
enhance their performance. This paper explores optimizing high-dimensional
$s$-sparse oblique splits from $\{(\vec{w}, \vec{w}^{\top}\boldsymbol{X}_{i}) :
i\in \{1,\dots, n\}, \vec{w} \in \mathbb{R}^p, \| \vec{w} \|_{2} = 1, \|
\vec{w} \|_{0} \leq s \}$ for growing oblique trees, where $ s $ is a
user-defined sparsity parameter. We establish a connection between SID
convergence and $s_0$-sparse oblique splits with $s_0\ge 1$, showing that the
SID function class expands as $s_0$ increases, enabling the capture of more
complex data-generating functions such as the $s_0$-dimensional XOR function.
Thus, $s_0$ represents the unknown potential complexity of the underlying
data-generating function. Learning these complex functions requires an
$s$-sparse oblique tree with $s \geq s_0$ and greater computational resources.
This highlights a trade-off between statistical accuracy, governed by the SID
function class size depending on $s_0$, and computational cost. In contrast,
previous studies have explored the problem of SID convergence using orthogonal
splits with $ s_0 = s = 1 $, where runtime was less critical. Additionally, we
introduce a practical framework for oblique trees that integrates optimized
oblique splits alongside orthogonal splits into random forests. The proposed
approach is assessed through simulations and real-data experiments, comparing
its performance against various oblique tree models.",['Chien-Ming Chi'],2025-03-18,"['stat.ML', 'cs.LG', 'math.ST', 'stat.ME', 'stat.TH']","79 pages, 9 tables",http://arxiv.org/pdf/2503.14381v1
2503.14577v1,PHGNN: A Novel Prompted Hypergraph Neural Network to Diagnose Alzheimer's Disease,"The accurate diagnosis of Alzheimer's disease (AD) and prognosis of mild
cognitive impairment (MCI) conversion are crucial for early intervention.
However, existing multimodal methods face several challenges, from the
heterogeneity of input data, to underexplored modality interactions, missing
data due to patient dropouts, and limited data caused by the time-consuming and
costly data collection process. In this paper, we propose a novel Prompted
Hypergraph Neural Network (PHGNN) framework that addresses these limitations by
integrating hypergraph based learning with prompt learning. Hypergraphs capture
higher-order relationships between different modalities, while our prompt
learning approach for hypergraphs, adapted from NLP, enables efficient training
with limited data. Our model is validated through extensive experiments on the
ADNI dataset, outperforming SOTA methods in both AD diagnosis and the
prediction of MCI conversion.","['Chenyu Liu', 'Luca Rossi']",2025-03-18,"['cs.LG', 'cs.AI']",,http://arxiv.org/pdf/2503.14577v1
2503.14377v1,Advancing Medical Representation Learning Through High-Quality Data,"Despite the growing scale of medical Vision-Language datasets, the impact of
dataset quality on model performance remains under-explored. We introduce
Open-PMC, a high-quality medical dataset from PubMed Central, containing 2.2
million image-text pairs, enriched with image modality annotations, subfigures,
and summarized in-text references. Notably, the in-text references provide
richer medical context, extending beyond the abstract information typically
found in captions. Through extensive experiments, we benchmark Open-PMC against
larger datasets across retrieval and zero-shot classification tasks. Our
results show that dataset quality-not just size-drives significant performance
gains. We complement our benchmark with an in-depth analysis of feature
representation. Our findings highlight the crucial role of data curation
quality in advancing multimodal medical AI. We release Open-PMC, along with the
trained models and our codebase.","['Negin Baghbanzadeh', 'Adibvafa Fallahpour', 'Yasaman Parhizkar', 'Franklin Ogidi', 'Shuvendu Roy', 'Sajad Ashkezari', 'Vahid Reza Khazaie', 'Michael Colacci', 'Ali Etemad', 'Arash Afkanpour', 'Elham Dolatabadi']",2025-03-18,"['eess.IV', 'cs.CV', 'cs.LG']",,http://arxiv.org/pdf/2503.14377v1
2503.14376v1,Tiled Flash Linear Attention: More Efficient Linear RNN and xLSTM Kernels,"Linear RNNs with gating recently demonstrated competitive performance
compared to Transformers in language modeling. Although their linear compute
scaling in sequence length offers theoretical runtime advantages over
Transformers, realizing these benefits in practice requires optimized custom
kernels, as Transformers rely on the highly efficient Flash Attention kernels.
Leveraging the chunkwise-parallel formulation of linear RNNs, Flash Linear
Attention (FLA) shows that linear RNN kernels are faster than Flash Attention,
by parallelizing over chunks of the input sequence. However, since the chunk
size of FLA is limited, many intermediate states must be materialized in GPU
memory. This leads to low arithmetic intensity and causes high memory
consumption and IO cost, especially for long-context pre-training. In this
work, we present Tiled Flash Linear Attention (TFLA), a novel kernel algorithm
for linear RNNs, that enables arbitrary large chunk sizes by introducing an
additional level of sequence parallelization within each chunk. First, we apply
TFLA to the xLSTM with matrix memory, the mLSTM. Second, we propose an mLSTM
variant with sigmoid input gate and reduced computation for even faster kernel
runtimes at equal language modeling performance. In our speed benchmarks, we
show that our new mLSTM kernels based on TFLA outperform highly optimized Flash
Attention, Linear Attention and Mamba kernels, setting a new state of the art
for efficient long-context sequence modeling primitives.","['Maximilian Beck', 'Korbinian Pöppel', 'Phillip Lippe', 'Sepp Hochreiter']",2025-03-18,"['cs.LG', 'cs.AI']",Code available at: https://github.com/NX-AI/mlstm_kernels,http://arxiv.org/pdf/2503.14376v1
2503.14375v1,Evaluating Machine Learning Approaches for ASCII Art Generation,"Generating structured ASCII art using computational techniques demands a
careful interplay between aesthetic representation and computational precision,
requiring models that can effectively translate visual information into
symbolic text characters. Although Convolutional Neural Networks (CNNs) have
shown promise in this domain, the comparative performance of deep learning
architectures and classical machine learning methods remains unexplored. This
paper explores the application of contemporary ML and DL methods to generate
structured ASCII art, focusing on three key criteria: fidelity, character
classification accuracy, and output quality. We investigate deep learning
architectures, including Multilayer Perceptrons (MLPs), ResNet, and
MobileNetV2, alongside classical approaches such as Random Forests, Support
Vector Machines (SVMs) and k-Nearest Neighbors (k-NN), trained on an augmented
synthetic dataset of ASCII characters. Our results show that complex neural
network architectures often fall short in producing high-quality ASCII art,
whereas classical machine learning classifiers, despite their simplicity,
achieve performance similar to CNNs. Our findings highlight the strength of
classical methods in bridging model simplicity with output quality, offering
new insights into ASCII art synthesis and machine learning on image data with
low dimensionality.","['Sai Coumar', 'Zachary Kingston']",2025-03-18,"['cs.GR', 'cs.LG']","9 pages, 7 figures, 3 tables. Code available at
  https://github.com/saiccoumar/deep_ascii_converter",http://arxiv.org/pdf/2503.14375v1
2503.14576v1,SocialJax: An Evaluation Suite for Multi-agent Reinforcement Learning in Sequential Social Dilemmas,"Social dilemmas pose a significant challenge in the field of multi-agent
reinforcement learning (MARL). Melting Pot is an extensive framework designed
to evaluate social dilemma environments, providing an evaluation protocol that
measures generalization to new social partners across various test scenarios.
However, running reinforcement learning algorithms in the official Melting Pot
environments demands substantial computational resources. In this paper, we
introduce SocialJax, a suite of sequential social dilemma environments
implemented in JAX. JAX is a high-performance numerical computing library for
Python that enables significant improvements in the operational efficiency of
SocialJax on GPUs and TPUs. Our experiments demonstrate that the training
pipeline of SocialJax achieves a 50\texttimes{} speedup in real-time
performance compared to Melting Pot's RLlib baselines. Additionally, we
validate the effectiveness of baseline algorithms within the SocialJax
environments. Finally, we use Schelling diagrams to verify the social dilemma
properties of these environments, ensuring they accurately capture the dynamics
of social dilemmas.","['Zihao Guo', 'Richard Willis', 'Shuqing Shi', 'Tristan Tomilin', 'Joel Z. Leibo', 'Yali Du']",2025-03-18,"['cs.LG', 'cs.AI']","9 pages, 18 figures, 1 table",http://arxiv.org/pdf/2503.14576v1
2503.14369v1,C(NN)FD -- Deep Learning Modelling of Multi-Stage Axial Compressors Aerodynamics,"The field of scientific machine learning and its applications to numerical
analyses such as CFD has recently experienced a surge in interest. While its
viability has been demonstrated in different domains, it has not yet reached a
level of robustness and scalability to make it practical for industrial
applications in the turbomachinery field. The highly complex, turbulent, and
three-dimensional flows of multi-stage axial compressors for gas turbine
applications represent a remarkably challenging case. This is due to the
high-dimensionality of the regression of the flow-field from geometrical and
operational variables, and the high computational cost associated with the
large scale of the CFD domains. This paper demonstrates the development and
application of a generalized deep learning framework for predictions of the
flow field and aerodynamic performance of multi-stage axial compressors, also
potentially applicable to any type of turbomachinery. A physics-based
dimensionality reduction unlocks the potential for flow-field predictions for
large-scale domains, re-formulating the regression problem from an unstructured
to a structured one. The relevant physical equations are used to define a
multi-dimensional physical loss function. Compared to ""black-box"" approaches,
the proposed framework has the advantage of physically explainable predictions
of overall performance, as the corresponding aerodynamic drivers can be
identified on a 0D/1D/2D/3D level. An iterative architecture is employed,
improving the accuracy of the predictions, as well as estimating the associated
uncertainty. The model is trained on a series of dataset including
manufacturing and build variations, different geometries, compressor designs
and operating conditions. This demonstrates the capability to predict the
flow-field and the overall performance in a generalizable manner, with accuracy
comparable to the benchmark.","['Giuseppe Bruni', 'Sepehr Maleki', 'Senthil K Krishnababu']",2025-03-18,"['physics.flu-dyn', 'cs.LG']",,http://arxiv.org/pdf/2503.14369v1
2503.14575v1,The Exoplanet Citizen Science Pipeline: Human Factors and Machine Learning,"We present the progress of work to streamline and simplify the process of
exoplanet observation by citizen scientists. International collaborations such
as ExoClock and Exoplanet Watch enable citizen scientists to use small
telescopes to carry out transit observations. These studies provide essential
supports for space missions such as JWST and ARIEL. Contributions include
maintenance or recovery of ephemerides, follow up confirmation and transit time
variations. Ongoing observation programs benefit from a large pool of
observers, with a wide variety of experience levels. Our projects work closely
with these communities to streamline their observation pipelines and enable
wider participation. Two complementary approaches are taken: Star Guide applies
human-centric design and community consultation to identify points of friction
within existing systems and provide complementary online tools and resources to
reduce barriers to entry to the observing community. Machine Learning is used
to accelerate data processing and automate steps which are currently manual,
providing a streamlined tool for citizen science and a scalable solution for
large-scale archival research.","['Oisín Creaner', 'Anna Preis', 'Cormac Ryan', 'Nika Gorchakova']",2025-03-18,"['astro-ph.IM', 'astro-ph.EP', 'cs.LG']","Author's manuscript version of paper accepted for publication in
  Proceedings of the International Astronomical Union, published by Cambridge
  University Press. Presented at Kavli-IAU Symposium 2024 ""(Toward) Discovery
  of life beyond Earth and its impact"". 5 pages, 2 figures",http://arxiv.org/pdf/2503.14575v1
2503.14358v1,RFMI: Estimating Mutual Information on Rectified Flow for Text-to-Image Alignment,"Rectified Flow (RF) models trained with a Flow matching framework have
achieved state-of-the-art performance on Text-to-Image (T2I) conditional
generation. Yet, multiple benchmarks show that synthetic images can still
suffer from poor alignment with the prompt, i.e., images show wrong attribute
binding, subject positioning, numeracy, etc. While the literature offers many
methods to improve T2I alignment, they all consider only Diffusion Models, and
require auxiliary datasets, scoring models, and linguistic analysis of the
prompt. In this paper we aim to address these gaps. First, we introduce RFMI, a
novel Mutual Information (MI) estimator for RF models that uses the pre-trained
model itself for the MI estimation. Then, we investigate a self-supervised
fine-tuning approach for T2I alignment based on RFMI that does not require
auxiliary information other than the pre-trained model itself. Specifically, a
fine-tuning set is constructed by selecting synthetic images generated from the
pre-trained RF model and having high point-wise MI between images and prompts.
Our experiments on MI estimation benchmarks demonstrate the validity of RFMI,
and empirical fine-tuning on SD3.5-Medium confirms the effectiveness of RFMI
for improving T2I alignment while maintaining image quality.","['Chao Wang', 'Giulio Franzese', 'Alessandro Finamore', 'Pietro Michiardi']",2025-03-18,"['cs.CV', 'cs.LG']","to appear at ICLR 2025 Workshop on Deep Generative Model in Machine
  Learning: Theory, Principle and Efficacy",http://arxiv.org/pdf/2503.14358v1
2503.14357v1,Wasserstein-based Kernels for Clustering: Application to Power Distribution Graphs,"Many data clustering applications must handle objects that cannot be
represented as vector data. In this context, the bag-of-vectors representation
can be leveraged to describe complex objects through discrete distributions,
and the Wasserstein distance can effectively measure the dissimilarity between
them. Additionally, kernel methods can be used to embed data into feature
spaces that are easier to analyze. Despite significant progress in data
clustering, a method that simultaneously accounts for distributional and
vectorial dissimilarity measures is still lacking. To tackle this gap, this
work explores kernel methods and Wasserstein distance metrics to develop a
computationally tractable clustering framework. The compositional properties of
kernels allow the simultaneous handling of different metrics, enabling the
integration of both vectors and discrete distributions for object
representation. This approach is flexible enough to be applied in various
domains, such as graph analysis and image processing. The framework consists of
three main components. First, we efficiently approximate pairwise Wasserstein
distances using multiple reference distributions. Second, we employ kernel
functions based on Wasserstein distances and present ways of composing kernels
to express different types of information. Finally, we use the kernels to
cluster data and evaluate the quality of the results using scalable and
distance-agnostic validity indices. A case study involving two datasets of 879
and 34,920 power distribution graphs demonstrates the framework's effectiveness
and efficiency.","['Alfredo Oneto', 'Blazhe Gjorgiev', 'Giovanni Sansavini']",2025-03-18,"['cs.LG', 'stat.AP']",,http://arxiv.org/pdf/2503.14357v1
2503.14574v1,Sequence Analysis Using the Bezier Curve,"The analysis of sequences (e.g., protein, DNA, and SMILES string) is
essential for disease diagnosis, biomaterial engineering, genetic engineering,
and drug discovery domains. Conventional analytical methods focus on
transforming sequences into numerical representations for applying machine
learning/deep learning-based sequence characterization. However, their efficacy
is constrained by the intrinsic nature of deep learning (DL) models, which tend
to exhibit suboptimal performance when applied to tabular data. An alternative
group of methodologies endeavors to convert biological sequences into image
forms by applying the concept of Chaos Game Representation (CGR). However, a
noteworthy drawback of these methods lies in their tendency to map individual
elements of the sequence onto a relatively small subset of designated pixels
within the generated image. The resulting sparse image representation may not
adequately encapsulate the comprehensive sequence information, potentially
resulting in suboptimal predictions. In this study, we introduce a novel
approach to transform sequences into images using the B\'ezier curve concept
for element mapping. Mapping the elements onto a curve enhances the sequence
information representation in the respective images, hence yielding better
DL-based classification performance. We employed different sequence datasets to
validate our system by using different classification tasks, and the results
illustrate that our B\'ezier curve method is able to achieve good performance
for all the tasks.","['Taslim Murad', 'Sarwan Ali', 'Murray Patterson']",2025-03-18,"['q-bio.QM', 'cs.LG']",,http://arxiv.org/pdf/2503.14574v1
2503.14356v1,"Benchmarking community drug response prediction models: datasets, models, tools, and metrics for cross-dataset generalization analysis","Deep learning (DL) and machine learning (ML) models have shown promise in
drug response prediction (DRP), yet their ability to generalize across datasets
remains an open question, raising concerns about their real-world
applicability. Due to the lack of standardized benchmarking approaches, model
evaluations and comparisons often rely on inconsistent datasets and evaluation
criteria, making it difficult to assess true predictive capabilities. In this
work, we introduce a benchmarking framework for evaluating cross-dataset
prediction generalization in DRP models. Our framework incorporates five
publicly available drug screening datasets, six standardized DRP models, and a
scalable workflow for systematic evaluation. To assess model generalization, we
introduce a set of evaluation metrics that quantify both absolute performance
(e.g., predictive accuracy across datasets) and relative performance (e.g.,
performance drop compared to within-dataset results), enabling a more
comprehensive assessment of model transferability. Our results reveal
substantial performance drops when models are tested on unseen datasets,
underscoring the importance of rigorous generalization assessments. While
several models demonstrate relatively strong cross-dataset generalization, no
single model consistently outperforms across all datasets. Furthermore, we
identify CTRPv2 as the most effective source dataset for training, yielding
higher generalization scores across target datasets. By sharing this
standardized evaluation framework with the community, our study aims to
establish a rigorous foundation for model comparison, and accelerate the
development of robust DRP models for real-world applications.","['Alexander Partin', 'Priyanka Vasanthakumari', 'Oleksandr Narykov', 'Andreas Wilke', 'Natasha Koussa', 'Sara E. Jones', 'Yitan Zhu', 'Jamie C. Overbeek', 'Rajeev Jain', 'Gayara Demini Fernando', 'Cesar Sanchez-Villalobos', 'Cristina Garcia-Cardona', 'Jamaludin Mohd-Yusof', 'Nicholas Chia', 'Justin M. Wozniak', 'Souparno Ghosh', 'Ranadip Pal', 'Thomas S. Brettin', 'M. Ryan Weil', 'Rick L. Stevens']",2025-03-18,"['cs.LG', 'q-bio.QM']","18 pages, 9 figures",http://arxiv.org/pdf/2503.14356v1
2503.14353v1,Unified Analysis of Decentralized Gradient Descent: a Contraction Mapping Framework,"The decentralized gradient descent (DGD) algorithm, and its sibling,
diffusion, are workhorses in decentralized machine learning, distributed
inference and estimation, and multi-agent coordination. We propose a novel,
principled framework for the analysis of DGD and diffusion for strongly convex,
smooth objectives, and arbitrary undirected topologies, using contraction
mappings coupled with a result called the mean Hessian theorem (MHT). The use
of these tools yields tight convergence bounds, both in the noise-free and
noisy regimes. While these bounds are qualitatively similar to results found in
the literature, our approach using contractions together with the MHT decouples
the algorithm dynamics (how quickly the algorithm converges to its fixed point)
from its asymptotic convergence properties (how far the fixed point is from the
global optimum). This yields a simple, intuitive analysis that is accessible to
a broader audience. Extensions are provided to multiple local gradient updates,
time-varying step sizes, noisy gradients (stochastic DGD and diffusion),
communication noise, and random topologies.","['Erik G. Larsson', 'Nicolo Michelusi']",2025-03-18,"['eess.SP', 'cs.DC', 'cs.LG']",submitted to the IEEE Open Journal of Signal Processing,http://arxiv.org/pdf/2503.14353v1
2503.14345v2,MoonCast: High-Quality Zero-Shot Podcast Generation,"Recent advances in text-to-speech synthesis have achieved notable success in
generating high-quality short utterances for individual speakers. However,
these systems still face challenges when extending their capabilities to long,
multi-speaker, and spontaneous dialogues, typical of real-world scenarios such
as podcasts. These limitations arise from two primary challenges: 1) long
speech: podcasts typically span several minutes, exceeding the upper limit of
most existing work; 2) spontaneity: podcasts are marked by their spontaneous,
oral nature, which sharply contrasts with formal, written contexts; existing
works often fall short in capturing this spontaneity. In this paper, we propose
MoonCast, a solution for high-quality zero-shot podcast generation, aiming to
synthesize natural podcast-style speech from text-only sources (e.g., stories,
technical reports, news in TXT, PDF, or Web URL formats) using the voices of
unseen speakers. To generate long audio, we adopt a long-context language
model-based audio modeling approach utilizing large-scale long-context speech
data. To enhance spontaneity, we utilize a podcast generation module to
generate scripts with spontaneous details, which have been empirically shown to
be as crucial as the text-to-speech modeling itself. Experiments demonstrate
that MoonCast outperforms baselines, with particularly notable improvements in
spontaneity and coherence.","['Zeqian Ju', 'Dongchao Yang', 'Jianwei Yu', 'Kai Shen', 'Yichong Leng', 'Zhengtao Wang', 'Xu Tan', 'Xinyu Zhou', 'Tao Qin', 'Xiangyang Li']",2025-03-18,"['eess.AS', 'cs.AI', 'cs.CL', 'cs.LG', 'cs.SD']",,http://arxiv.org/pdf/2503.14345v2
2503.14342v1,End-to-End Optimal Detector Design with Mutual Information Surrogates,"We introduce a novel approach for end-to-end black-box optimization of high
energy physics (HEP) detectors using local deep learning (DL) surrogates. These
surrogates approximate a scalar objective function that encapsulates the
complex interplay of particle-matter interactions and physics analysis goals.
In addition to a standard reconstruction-based metric commonly used in the
field, we investigate the information-theoretic metric of mutual information.
Unlike traditional methods, mutual information is inherently task-agnostic,
offering a broader optimization paradigm that is less constrained by predefined
targets. We demonstrate the effectiveness of our method in a realistic physics
analysis scenario: optimizing the thicknesses of calorimeter detector layers
based on simulated particle interactions. The surrogate model learns to
approximate objective gradients, enabling efficient optimization with respect
to energy resolution. Our findings reveal three key insights: (1) end-to-end
black-box optimization using local surrogates is a practical and compelling
approach for detector design, providing direct optimization of detector
parameters in alignment with physics analysis goals; (2) mutual
information-based optimization yields design choices that closely match those
from state-of-the-art physics-informed methods, indicating that these
approaches operate near optimality and reinforcing their reliability in HEP
detector design; and (3) information-theoretic methods provide a powerful,
generalizable framework for optimizing scientific instruments. By reframing the
optimization process through an information-theoretic lens rather than
domain-specific heuristics, mutual information enables the exploration of new
avenues for discovery beyond conventional approaches.","['Kinga Anna Wozniak', 'Stephen Mulligan', 'Jan Kieseler', 'Markus Klute', 'Francois Fleuret', 'Tobias Golling']",2025-03-18,"['cs.LG', 'hep-ph']",,http://arxiv.org/pdf/2503.14342v1
2503.15551v1,Efficient but Vulnerable: Benchmarking and Defending LLM Batch Prompting Attack,"Batch prompting, which combines a batch of multiple queries sharing the same
context in one inference, has emerged as a promising solution to reduce
inference costs. However, our study reveals a significant security
vulnerability in batch prompting: malicious users can inject attack
instructions into a batch, leading to unwanted interference across all queries,
which can result in the inclusion of harmful content, such as phishing links,
or the disruption of logical reasoning. In this paper, we construct
BATCHSAFEBENCH, a comprehensive benchmark comprising 150 attack instructions of
two types and 8k batch instances, to study the batch prompting vulnerability
systematically. Our evaluation of both closed-source and open-weight LLMs
demonstrates that all LLMs are susceptible to batch-prompting attacks. We then
explore multiple defending approaches. While the prompting-based defense shows
limited effectiveness for smaller LLMs, the probing-based approach achieves
about 95% accuracy in detecting attacks. Additionally, we perform a mechanistic
analysis to understand the attack and identify attention heads that are
responsible for it.","['Murong Yue', 'Ziyu Yao']",2025-03-18,"['cs.CR', 'cs.AI', 'cs.LG']",,http://arxiv.org/pdf/2503.15551v1
2503.14338v1,Higher-Order Graphon Neural Networks: Approximation and Cut Distance,"Graph limit models, like graphons for limits of dense graphs, have recently
been used to study size transferability of graph neural networks (GNNs). While
most literature focuses on message passing GNNs (MPNNs), in this work we attend
to the more powerful higher-order GNNs. First, we extend the $k$-WL test for
graphons (B\""oker, 2023) to the graphon-signal space and introduce
signal-weighted homomorphism densities as a key tool. As an exemplary focus, we
generalize Invariant Graph Networks (IGNs) to graphons, proposing Invariant
Graphon Networks (IWNs) defined via a subset of the IGN basis corresponding to
bounded linear operators. Even with this restricted basis, we show that IWNs of
order $k$ are at least as powerful as the $k$-WL test, and we establish
universal approximation results for graphon-signals in $L^p$ distances. This
significantly extends the prior work of Cai & Wang (2022), showing that IWNs--a
subset of their IGN-small--retain effectively the same expressivity as the full
IGN basis in the limit. In contrast to their approach, our blueprint of IWNs
also aligns better with the geometry of graphon space, for example facilitating
comparability to MPNNs. We highlight that, while typical higher-order GNNs are
discontinuous w.r.t. cut distance--which causes their lack of convergence and
is inherently tied to the definition of $k$-WL--their transferability remains
comparable to MPNNs.","['Daniel Herbst', 'Stefanie Jegelka']",2025-03-18,['cs.LG'],"51 pages, 6 figures, ICLR 2025",http://arxiv.org/pdf/2503.14338v1
2503.14337v1,PENCIL: Long Thoughts with Short Memory,"While recent works (e.g. o1, DeepSeek R1) have demonstrated great promise of
using long Chain-of-Thought (CoT) to improve reasoning capabilities of language
models, scaling it up during test-time is challenging due to inefficient memory
usage -- intermediate computations accumulate indefinitely in context even no
longer needed for future thoughts. We propose PENCIL, which incorporates a
reduction mechanism into the autoregressive generation process, allowing the
model to recursively clean up intermediate thoughts based on patterns learned
from training. With this reduction mechanism, PENCIL significantly reduces the
maximal context length required during generation, and thus can generate longer
thoughts with limited memory, solving larger-scale problems given more thinking
time. For example, we demonstrate PENCIL achieves 97\% accuracy on the
challenging Einstein's puzzle -- a task even large models like GPT-4 struggle
with -- using only a small 25M-parameter transformer with 2048 context length.
Theoretically, we prove PENCIL can perform universal space-efficient
computation by simulating Turing machines with optimal time and space
complexity, and thus can solve arbitrary computational tasks that would
otherwise be intractable given context window constraints.","['Chenxiao Yang', 'Nathan Srebro', 'David McAllester', 'Zhiyuan Li']",2025-03-18,"['cs.LG', 'cs.CL']",,http://arxiv.org/pdf/2503.14337v1
2503.14333v1,Revealing higher-order neural representations with generative artificial intelligence,"Studies often aim to reveal how neural representations encode aspects of an
observer's environment, such as its contents or structure. These are
``first-order"" representations (FORs), because they're ``about"" the external
world. A less-common target is ``higher-order"" representations (HORs), which
are ``about"" FORs -- their contents, stability, or uncertainty. HORs of
uncertainty appear critically involved in adaptive behaviors including learning
under uncertainty, influencing learning rates and internal model updating based
on environmental feedback. However, HORs about uncertainty are unlikely to be
direct ``read-outs"" of FOR characteristics, instead reflecting estimation
processes which may be lossy, bias-prone, or distortive and which may also
incorporate estimates of distributions of uncertainty the observer is likely to
experience. While some research has targeted neural representations of
``instantaneously"" estimated uncertainty, how the brain represents
\textit{distributions} of expected uncertainty remains largely unexplored.
Here, we propose a novel reinforcement learning (RL) based generative
artificial intelligence (genAI) approach to explore neural representations of
uncertainty distributions. We use existing functional magnetic resonance
imaging data, where humans learned to `de-noise' their brain states to achieve
target neural patterns, to train denoising diffusion genAI models with RL
algorithms to learn noise distributions similar to how humans might learn to do
the same. We then explore these models' learned noise-distribution HORs
compared to control models trained with traditional backpropagation. Results
reveal model-dependent differences in noise distribution representations --
with the RL-based model offering much higher explanatory power for human
behavior -- offering an exciting path towards using genAI to explore neural
noise-distribution HORs.","['Hojjat Azimi Asrari', 'Megan A. K. Peters']",2025-03-18,"['cs.LG', 'cs.AI', 'q-bio.NC']",,http://arxiv.org/pdf/2503.14333v1
2503.14322v1,Consumer-grade EEG-based Eye Tracking,"Electroencephalography-based eye tracking (EEG-ET) leverages eye movement
artifacts in EEG signals as an alternative to camera-based tracking. While
EEG-ET offers advantages such as robustness in low-light conditions and better
integration with brain-computer interfaces, its development lags behind
traditional methods, particularly in consumer-grade settings. To support
research in this area, we present a dataset comprising simultaneous EEG and
eye-tracking recordings from 113 participants across 116 sessions, amounting to
11 hours and 45 minutes of recordings. Data was collected using a
consumer-grade EEG headset and webcam-based eye tracking, capturing eye
movements under four experimental paradigms with varying complexity. The
dataset enables the evaluation of EEG-ET methods across different gaze
conditions and serves as a benchmark for assessing feasibility with affordable
hardware. Data preprocessing includes handling of missing values and filtering
to enhance usability. In addition to the dataset, code for data preprocessing
and analysis is available to support reproducibility and further research.","['Tiago Vasconcelos Afonso', 'Florian Heinrichs']",2025-03-18,"['eess.SP', 'cs.HC', 'cs.LG', '92C55']","Data descriptor, 13 pages, 8 figures, 5 tables",http://arxiv.org/pdf/2503.14322v1
2503.14321v1,COPA: Comparing the Incomparable to Explore the Pareto Front,"In machine learning (ML), it is common to account for multiple objectives
when, e.g., selecting a model to deploy. However, it is often unclear how one
should compare, aggregate and, ultimately, trade-off these objectives, as they
might be measured in different units or scales. For example, when deploying
large language models (LLMs), we might not only care about their performance,
but also their CO2 consumption. In this work, we investigate how objectives can
be sensibly compared and aggregated to navigate their Pareto front. To do so,
we propose to make incomparable objectives comparable via their CDFs,
approximated by their relative rankings. This allows us to aggregate them while
matching user-specific preferences, allowing practitioners to meaningfully
navigate and search for models in the Pareto front. We demonstrate the
potential impact of our methodology in diverse areas such as LLM selection,
domain generalization, and AutoML benchmarking, where classical ways to
aggregate and normalize objectives fail.","['Adrián Javaloy', 'Antonio Vergari', 'Isabel Valera']",2025-03-18,"['cs.LG', 'cs.AI']","19 pages, 14 figures. Under submission",http://arxiv.org/pdf/2503.14321v1
2503.14301v1,FeNeC: Enhancing Continual Learning via Feature Clustering with Neighbor- or Logit-Based Classification,"The ability of deep learning models to learn continuously is essential for
adapting to new data categories and evolving data distributions. In recent
years, approaches leveraging frozen feature extractors after an initial
learning phase have been extensively studied. Many of these methods estimate
per-class covariance matrices and prototypes based on backbone-derived feature
representations. Within this paradigm, we introduce FeNeC (Feature Neighborhood
Classifier) and FeNeC-Log, its variant based on the log-likelihood function.
Our approach generalizes the existing concept by incorporating data clustering
to capture greater intra-class variability. Utilizing the Mahalanobis distance,
our models classify samples either through a nearest neighbor approach or
trainable logit values assigned to consecutive classes. Our proposition may be
reduced to the existing approaches in a special case while extending them with
the ability of more flexible adaptation to data. We demonstrate that two FeNeC
variants achieve competitive performance in scenarios where task identities are
unknown and establish state-of-the-art results on several benchmarks.","['Kamil Książek', 'Hubert Jastrzębski', 'Bartosz Trojan', 'Krzysztof Pniaczek', 'Michał Karp', 'Jacek Tabor']",2025-03-18,"['cs.LG', '68T07', 'I.2.6']",,http://arxiv.org/pdf/2503.14301v1
2503.14299v1,Unveiling the Role of Randomization in Multiclass Adversarial Classification: Insights from Graph Theory,"Randomization as a mean to improve the adversarial robustness of machine
learning models has recently attracted significant attention. Unfortunately,
much of the theoretical analysis so far has focused on binary classification,
providing only limited insights into the more complex multiclass setting. In
this paper, we take a step toward closing this gap by drawing inspiration from
the field of graph theory. Our analysis focuses on discrete data distributions,
allowing us to cast the adversarial risk minimization problems within the
well-established framework of set packing problems. By doing so, we are able to
identify three structural conditions on the support of the data distribution
that are necessary for randomization to improve robustness. Furthermore, we are
able to construct several data distributions where (contrarily to binary
classification) switching from a deterministic to a randomized solution
significantly reduces the optimal adversarial risk. These findings highlight
the crucial role randomization can play in enhancing robustness to adversarial
attacks in multiclass classification.","['Lucas Gnecco-Heredia', 'Matteo Sammut', 'Muni Sreenivas Pydi', 'Rafael Pinot', 'Benjamin Negrevergne', 'Yann Chevaleyre']",2025-03-18,['cs.LG'],"9 pages (main), 30 in total. Camera-ready version, accepted at
  AISTATS 2025",http://arxiv.org/pdf/2503.14299v1
2503.14297v1,Improved Scalable Lipschitz Bounds for Deep Neural Networks,"Computing tight Lipschitz bounds for deep neural networks is crucial for
analyzing their robustness and stability, but existing approaches either
produce relatively conservative estimates or rely on semidefinite programming
(SDP) formulations (namely the LipSDP condition) that face scalability issues.
Building upon ECLipsE-Fast, the state-of-the-art Lipschitz bound method that
avoids SDP formulations, we derive a new family of improved scalable Lipschitz
bounds that can be combined to outperform ECLipsE-Fast. Specifically, we
leverage more general parameterizations of feasible points of LipSDP to derive
various closed-form Lipschitz bounds, avoiding the use of SDP solvers. In
addition, we show that our technique encompasses ECLipsE-Fast as a special case
and leads to a much larger class of scalable Lipschitz bounds for deep neural
networks. Our empirical study shows that our bounds improve ECLipsE-Fast,
further advancing the scalability and precision of Lipschitz estimation for
large neural networks.","['Usman Syed', 'Bin Hu']",2025-03-18,"['cs.LG', 'cs.SY', 'eess.SY', 'math.OC', 'stat.ML']",,http://arxiv.org/pdf/2503.14297v1
2503.14572v1,Robust Weight Imprinting: Insights from Neural Collapse and Proxy-Based Aggregation,"The capacity of a foundation model allows for adaptation to new downstream
tasks. Weight imprinting is a universal and efficient method to fulfill this
purpose. It has been reinvented several times, but it has not been
systematically studied. In this paper, we propose a framework for imprinting,
identifying three main components: generation, normalization, and aggregation.
This allows us to conduct an in-depth analysis of imprinting and a comparison
of the existing work. We reveal the benefits of representing novel data with
multiple proxies in the generation step and show the importance of proper
normalization. We determine those proxies through clustering and propose a
novel variant of imprinting that outperforms previous work. We motivate this by
the neural collapse phenomenon -- an important connection that we can draw for
the first time. Our results show an increase of up to 4% in challenging
scenarios with complex data distributions for new classes.","['Justus Westerhoff', 'Golzar Atefi', 'Mario Koddenbrock', 'Alexei Figueroa', 'Alexander Löser', 'Erik Rodner', 'Felix A. Gers']",2025-03-18,"['cs.LG', 'cs.AI']",Code: https://github.com/DATEXIS/multi-imprinting/,http://arxiv.org/pdf/2503.14572v1
2503.14286v2,Tapered Off-Policy REINFORCE: Stable and efficient reinforcement learning for LLMs,"We propose a new algorithm for fine-tuning large language models using
reinforcement learning. Tapered Off-Policy REINFORCE (TOPR) uses an asymmetric,
tapered variant of importance sampling to speed up learning while maintaining
stable learning dynamics, even without the use of KL regularization. TOPR can
be applied in a fully offline fashion, allows the handling of positive and
negative examples in a unified framework, and benefits from the
implementational simplicity that is typical of Monte Carlo algorithms. We
demonstrate the effectiveness of our approach with a series of experiments on
the GSM8K and MATH reasoning benchmarks, finding performance gains for training
both a model for solution generation and as a generative verifier. We show that
properly leveraging positive and negative examples alike in the off-policy
regime simultaneously increases test-time accuracy and training data
efficiency, all the while avoiding the ``wasted inference'' that comes with
discarding negative examples. We find that this advantage persists over
multiple iterations of training and can be amplified by dataset curation
techniques, enabling us to match 70B-parameter model performance with 8B
language models. As a corollary to this work, we find that REINFORCE's baseline
parameter plays an important and unexpected role in defining dataset
composition in the presence of negative examples, and is consequently critical
in driving off-policy performance.","['Nicolas Le Roux', 'Marc G. Bellemare', 'Jonathan Lebensold', 'Arnaud Bergeron', 'Joshua Greaves', 'Alex Fréchette', 'Carolyne Pelletier', 'Eric Thibodeau-Laufer', 'Sándor Toth', 'Sam Work']",2025-03-18,['cs.LG'],,http://arxiv.org/pdf/2503.14286v2
2503.14281v1,XOXO: Stealthy Cross-Origin Context Poisoning Attacks against AI Coding Assistants,"AI coding assistants are widely used for tasks like code generation, bug
detection, and comprehension. These tools now require large and complex
contexts, automatically sourced from various origins$\unicode{x2014}$across
files, projects, and contributors$\unicode{x2014}$forming part of the prompt
fed to underlying LLMs. This automatic context-gathering introduces new
vulnerabilities, allowing attackers to subtly poison input to compromise the
assistant's outputs, potentially generating vulnerable code, overlooking flaws,
or introducing critical errors. We propose a novel attack, Cross-Origin Context
Poisoning (XOXO), that is particularly challenging to detect as it relies on
adversarial code modifications that are semantically equivalent. Traditional
program analysis techniques struggle to identify these correlations since the
semantics of the code remain correct, making it appear legitimate. This allows
attackers to manipulate code assistants into producing incorrect outputs,
including vulnerabilities or backdoors, while shifting the blame to the victim
developer or tester. We introduce a novel, task-agnostic black-box attack
algorithm GCGS that systematically searches the transformation space using a
Cayley Graph, achieving an 83.09% attack success rate on average across five
tasks and eleven models, including GPT-4o and Claude 3.5 Sonnet v2 used by many
popular AI coding assistants. Furthermore, existing defenses, including
adversarial fine-tuning, are ineffective against our attack, underscoring the
need for new security measures in LLM-powered coding tools.","['Adam Štorek', 'Mukur Gupta', 'Noopur Bhatt', 'Aditya Gupta', 'Janie Kim', 'Prashast Srivastava', 'Suman Jana']",2025-03-18,"['cs.CR', 'cs.LG', 'cs.SE']",,http://arxiv.org/pdf/2503.14281v1
2503.14260v1,Automating Experimental Optics with Sample Efficient Machine Learning Methods,"As free-space optical systems grow in scale and complexity, troubleshooting
becomes increasingly time-consuming and, in the case of remote installations,
perhaps impractical. An example of a task that is often laborious is the
alignment of a high-finesse optical resonator, which is highly sensitive to the
mode of the input beam. In this work, we demonstrate how machine learning can
be used to achieve autonomous mode-matching of a free-space optical resonator
with minimal supervision. Our approach leverages sample-efficient algorithms to
reduce data requirements while maintaining a simple architecture for easy
deployment. The reinforcement learning scheme that we have developed shows that
automation is feasible even in systems prone to drift in experimental
parameters, as may well be the case in real-world applications.","['Arindam Saha', 'Baramee Charoensombutamon', 'Thibault Michel', 'V. Vijendran', 'Lachlan Walker', 'Akira Furusawa', 'Syed M. Assad', 'Ben C. Buchler', 'Ping Koy Lam', 'Aaron D. Tranter']",2025-03-18,"['physics.optics', 'cs.LG']",,http://arxiv.org/pdf/2503.14260v1
2503.14259v1,Quantization-Free Autoregressive Action Transformer,"Current transformer-based imitation learning approaches introduce discrete
action representations and train an autoregressive transformer decoder on the
resulting latent code. However, the initial quantization breaks the continuous
structure of the action space thereby limiting the capabilities of the
generative model. We propose a quantization-free method instead that leverages
Generative Infinite-Vocabulary Transformers (GIVT) as a direct, continuous
policy parametrization for autoregressive transformers. This simplifies the
imitation learning pipeline while achieving state-of-the-art performance on a
variety of popular simulated robotics tasks. We enhance our policy roll-outs by
carefully studying sampling algorithms, further improving the results.","['Ziyad Sheebaelhamd', 'Michael Tschannen', 'Michael Muehlebach', 'Claire Vernade']",2025-03-18,"['cs.LG', 'cs.RO']",,http://arxiv.org/pdf/2503.14259v1
2503.14253v1,CINNAMON: A hybrid approach to change point detection and parameter estimation in single-particle tracking data,"Change point detection has become an important part of the analysis of the
single-particle tracking data, as it allows one to identify moments, in which
the motion patterns of observed particles undergo significant changes. The
segmentation of diffusive trajectories based on those moments may provide
insight into various phenomena in soft condensed matter and biological physics.
In this paper, we propose CINNAMON, a hybrid approach to classifying
single-particle tracking trajectories, detecting change points within them, and
estimating diffusion parameters in the segments between the change points. Our
method is based on a combination of neural networks, feature-based machine
learning, and statistical techniques. It has been benchmarked in the second
Anomalous Diffusion Challenge. The method offers a high level of
interpretability due to its analytical and feature-based components. A
potential use of features from topological data analysis is also discussed.","['Jakub Malinowski', 'Marcin Kostrzewa', 'Michał Balcerek', 'Weronika Tomczuk', 'Janusz Szwabiński']",2025-03-18,"['q-bio.QM', 'cs.LG']",,http://arxiv.org/pdf/2503.14253v1
2503.14246v1,Trading-off Accuracy and Communication Cost in Federated Learning,"Leveraging the training-by-pruning paradigm introduced by Zhou et al. and
Isik et al. introduced a federated learning protocol that achieves a 34-fold
reduction in communication cost. We achieve a compression improvements of
orders of orders of magnitude over the state-of-the-art. The central idea of
our framework is to encode the network weights $\vec w$ by a the vector of
trainable parameters $\vec p$, such that $\vec w = Q\cdot \vec p$ where $Q$ is
a carefully-generate sparse random matrix (that remains fixed throughout
training). In such framework, the previous work of Zhou et al. [NeurIPS'19] is
retrieved when $Q$ is diagonal and $\vec p$ has the same dimension of $\vec w$.
We instead show that $\vec p$ can effectively be chosen much smaller than $\vec
w$, while retaining the same accuracy at the price of a decrease of the
sparsity of $Q$. Since server and clients only need to share $\vec p$, such a
trade-off leads to a substantial improvement in communication cost. Moreover,
we provide theoretical insight into our framework and establish a novel link
between training-by-sampling and random convex geometry.","['Mattia Jacopo Villani', 'Emanuele Natale', 'Frederik Mallmann-Trenn']",2025-03-18,"['cs.LG', 'cs.AI']",,http://arxiv.org/pdf/2503.14246v1
2503.14240v2,Persistent Homology-induced Graph Ensembles for Time Series Regressions,"The effectiveness of Spatio-temporal Graph Neural Networks (STGNNs) in
time-series applications is often limited by their dependence on fixed,
hand-crafted input graph structures. Motivated by insights from the Topological
Data Analysis (TDA) paradigm, of which real-world data exhibits multi-scale
patterns, we construct several graphs using Persistent Homology Filtration -- a
mathematical framework describing the multiscale structural properties of data
points. Then, we use the constructed graphs as an input to create an ensemble
of Graph Neural Networks. The ensemble aggregates the signals from the
individual learners via an attention-based routing mechanism, thus
systematically encoding the inherent multiscale structures of data. Four
different real-world experiments on seismic activity prediction and traffic
forecasting (PEMS-BAY, METR-LA) demonstrate that our approach consistently
outperforms single-graph baselines while providing interpretable insights.","['Viet The Nguyen', 'Duy Anh Pham', 'An Thai Le', 'Jans Peter', 'Gunther Gust']",2025-03-18,['cs.LG'],,http://arxiv.org/pdf/2503.14240v2
2503.14239v1,Predicting Cardiopulmonary Exercise Testing Outcomes in Congenital Heart Disease Through Multi-modal Data Integration and Geometric Learning,"Cardiopulmonary exercise testing (CPET) provides a comprehensive assessment
of functional capacity by measuring key physiological variables including
oxygen consumption ($VO_2$), carbon dioxide production ($VCO_2$), and pulmonary
ventilation ($VE$) during exercise. Previous research has established that
parameters such as peak $VO_2$ and $VE/VCO_2$ ratio serve as robust predictors
of mortality risk in chronic heart failure patients. In this study, we leverage
CPET variables as surrogate mortality endpoints for patients with Congenital
Heart Disease (CHD). To our knowledge, this represents the first successful
implementation of an advanced machine learning approach that predicts CPET
outcomes by integrating electrocardiograms (ECGs) with information derived from
clinical letters. Our methodology began with extracting unstructured patient
information-including intervention history, diagnoses, and medication
regimens-from clinical letters using natural language processing techniques,
organizing this data into a structured database. We then digitized ECGs to
obtain quantifiable waveforms and established comprehensive data linkages. The
core innovation of our approach lies in exploiting the Riemannian geometric
properties of covariance matrices derived from both 12-lead ECGs and clinical
text data to develop robust regression and classification models. Through
extensive ablation studies, we demonstrated that the integration of ECG signals
with clinical documentation, enhanced by covariance augmentation techniques in
Riemannian space, consistently produced superior predictive performance
compared to conventional approaches.","['Muhammet Alkan', 'Gruschen Veldtman', 'Fani Deligianni']",2025-03-18,['cs.LG'],preprint for Scientific Reports,http://arxiv.org/pdf/2503.14239v1
2503.14232v1,CRCE: Coreference-Retention Concept Erasure in Text-to-Image Diffusion Models,"Text-to-Image diffusion models can produce undesirable content that
necessitates concept erasure techniques. However, existing methods struggle
with under-erasure, leaving residual traces of targeted concepts, or
over-erasure, mistakenly eliminating unrelated but visually similar concepts.
To address these limitations, we introduce CRCE, a novel concept erasure
framework that leverages Large Language Models to identify both semantically
related concepts that should be erased alongside the target and distinct
concepts that should be preserved. By explicitly modeling coreferential and
retained concepts semantically, CRCE enables more precise concept removal,
without unintended erasure. Experiments demonstrate that CRCE outperforms
existing methods on diverse erasure tasks.","['Yuyang Xue', 'Edward Moroshko', 'Feng Chen', 'Steven McDonagh', 'Sotirios A. Tsaftaris']",2025-03-18,"['cs.CV', 'cs.AI', 'cs.CL', 'cs.LG']",,http://arxiv.org/pdf/2503.14232v1
2503.14231v1,Multi-task Learning for Identification of Porcelain in Song and Yuan Dynasties,"Chinese porcelain holds immense historical and cultural value, making its
accurate classification essential for archaeological research and cultural
heritage preservation. Traditional classification methods rely heavily on
expert analysis, which is time-consuming, subjective, and difficult to scale.
This paper explores the application of DL and transfer learning techniques to
automate the classification of porcelain artifacts across four key attributes:
dynasty, glaze, ware, and type. We evaluate four Convolutional Neural Networks
(CNNs) - ResNet50, MobileNetV2, VGG16, and InceptionV3 - comparing their
performance with and without pre-trained weights. Our results demonstrate that
transfer learning significantly enhances classification accuracy, particularly
for complex tasks like type classification, where models trained from scratch
exhibit lower performance. MobileNetV2 and ResNet50 consistently achieve high
accuracy and robustness across all tasks, while VGG16 struggles with more
diverse classifications. We further discuss the impact of dataset limitations
and propose future directions, including domain-specific pre-training,
integration of attention mechanisms, explainable AI methods, and generalization
to other cultural artifacts.","['Ziyao Ling', 'Giovanni Delnevo', 'Paola Salomoni', 'Silvia Mirri']",2025-03-18,"['cs.CV', 'cs.LG']",,http://arxiv.org/pdf/2503.14231v1
2503.14217v1,Decision Tree Induction Through LLMs via Semantically-Aware Evolution,"Decision trees are a crucial class of models offering robust predictive
performance and inherent interpretability across various domains, including
healthcare, finance, and logistics. However, current tree induction methods
often face limitations such as suboptimal solutions from greedy methods or
prohibitive computational costs and limited applicability of exact optimization
approaches. To address these challenges, we propose an evolutionary
optimization method for decision tree induction based on genetic programming
(GP). Our key innovation is the integration of semantic priors and
domain-specific knowledge about the search space into the optimization
algorithm. To this end, we introduce $\texttt{LLEGO}$, a framework that
incorporates semantic priors into genetic search operators through the use of
Large Language Models (LLMs), thereby enhancing search efficiency and targeting
regions of the search space that yield decision trees with superior
generalization performance. This is operationalized through novel genetic
operators that work with structured natural language prompts, effectively
utilizing LLMs as conditional generative models and sources of semantic
knowledge. Specifically, we introduce $\textit{fitness-guided}$ crossover to
exploit high-performing regions, and $\textit{diversity-guided}$ mutation for
efficient global exploration of the search space. These operators are
controlled by corresponding hyperparameters that enable a more nuanced balance
between exploration and exploitation across the search space. Empirically, we
demonstrate across various benchmarks that $\texttt{LLEGO}$ evolves
superior-performing trees compared to existing tree induction methods, and
exhibits significantly more efficient search performance compared to
conventional GP approaches.","['Tennison Liu', 'Nicolas Huynh', 'Mihaela van der Schaar']",2025-03-18,['cs.LG'],"*Liu and Huynh contributed equally. Published as a conference paper
  at ICLR 2025",http://arxiv.org/pdf/2503.14217v1
2503.14571v1,Efficient Data Selection for Training Genomic Perturbation Models,"Genomic studies, including CRISPR-based PerturbSeq analyses, face a vast
hypothesis space, while gene perturbations remain costly and time-consuming.
Gene expression models based on graph neural networks are trained to predict
the outcomes of gene perturbations to facilitate such experiments. Active
learning methods are often employed to train these models due to the cost of
the genomic experiments required to build the training set. However, poor model
initialization in active learning can result in suboptimal early selections,
wasting time and valuable resources. While typical active learning mitigates
this issue over many iterations, the limited number of experimental cycles in
genomic studies exacerbates the risk. To this end, we propose graph-based
one-shot data selection methods for training gene expression models. Unlike
active learning, one-shot data selection predefines the gene perturbations
before training, hence removing the initialization bias. The data selection is
motivated by theoretical studies of graph neural network generalization. The
criteria are defined over the input graph and are optimized with submodular
maximization. We compare them empirically to baselines and active learning
methods that are state-of-the-art on this problem. The results demonstrate that
graph-based one-shot data selection achieves comparable accuracy while
alleviating the aforementioned risks.","['George Panagopoulos', 'Johannes Lutzeyer', 'Sofiane Ennadir', 'Michalis Vazirgiannis', 'Jun Pang']",2025-03-18,"['q-bio.QM', 'cs.LG']",19 pages,http://arxiv.org/pdf/2503.14571v1
2503.14213v1,Rolling Forward: Enhancing LightGCN with Causal Graph Convolution for Credit Bond Recommendation,"Graph Neural Networks have significantly advanced research in recommender
systems over the past few years. These methods typically capture global
interests using aggregated past interactions and rely on static embeddings of
users and items over extended periods of time. While effective in some domains,
these methods fall short in many real-world scenarios, especially in finance,
where user interests and item popularity evolve rapidly over time. To address
these challenges, we introduce a novel extension to Light Graph Convolutional
Network (LightGCN) designed to learn temporal node embeddings that capture
dynamic interests. Our approach employs causal convolution to maintain a
forward-looking model architecture. By preserving the chronological order of
user-item interactions and introducing a dynamic update mechanism for
embeddings through a sliding window, the proposed model generates well-timed
and contextually relevant recommendations. Extensive experiments on a
real-world dataset from BNP Paribas demonstrate that our approach significantly
enhances the performance of LightGCN while maintaining the simplicity and
efficiency of its architecture. Our findings provide new insights into
designing graph-based recommender systems in time-sensitive applications,
particularly for financial product recommendations.","['Ashraf Ghiye', 'Baptiste Barreau', 'Laurent Carlier', 'Michalis Vazirgiannis']",2025-03-18,"['cs.IR', 'cs.LG', 'q-fin.CP']","8 pages, published in the international conference for AI in Finance
  (ACM ICAIF'24)",http://arxiv.org/pdf/2503.14213v1
2503.14205v1,Layer-wise Adaptive Gradient Norm Penalizing Method for Efficient and Accurate Deep Learning,"Sharpness-aware minimization (SAM) is known to improve the generalization
performance of neural networks. However, it is not widely used in real-world
applications yet due to its expensive model perturbation cost. A few variants
of SAM have been proposed to tackle such an issue, but they commonly do not
alleviate the cost noticeably. In this paper, we propose a lightweight
layer-wise gradient norm penalizing method that tackles the expensive
computational cost of SAM while maintaining its superior generalization
performance. Our study empirically proves that the gradient norm of the whole
model can be effectively suppressed by penalizing the gradient norm of only a
few critical layers. We also theoretically show that such a partial model
perturbation does not harm the convergence rate of SAM, allowing them to be
safely adapted in real-world applications. To demonstrate the efficacy of the
proposed method, we perform extensive experiments comparing the proposed method
to mini-batch SGD and the conventional SAM using representative computer vision
and language modeling benchmarks.",['Sunwoo Lee'],2025-03-18,['cs.LG'],Published in KDD 2024,http://arxiv.org/pdf/2503.14205v1
2503.14192v1,"Strategic White Paper on AI Infrastructure for Particle, Nuclear, and Astroparticle Physics: Insights from JENA and EuCAIF","Artificial intelligence (AI) is transforming scientific research, with deep
learning methods playing a central role in data analysis, simulations, and
signal detection across particle, nuclear, and astroparticle physics. Within
the JENA communities-ECFA, NuPECC, and APPEC-and as part of the EuCAIF
initiative, AI integration is advancing steadily. However, broader adoption
remains constrained by challenges such as limited computational resources, a
lack of expertise, and difficulties in transitioning from research and
development (R&D) to production. This white paper provides a strategic roadmap,
informed by a community survey, to address these barriers. It outlines critical
infrastructure requirements, prioritizes training initiatives, and proposes
funding strategies to scale AI capabilities across fundamental physics over the
next five years.","['Sascha Caron', 'Andreas Ipp', 'Gert Aarts', 'Gábor Bíró', 'Daniele Bonacorsi', 'Elena Cuoco', 'Caterina Doglioni', 'Tommaso Dorigo', 'Julián García Pardiñas', 'Stefano Giagu', 'Tobias Golling', 'Lukas Heinrich', 'Ik Siong Heng', 'Paula Gina Isar', 'Karolos Potamianos', 'Liliana Teodorescu', 'John Veitch', 'Pietro Vischia', 'Christoph Weniger']",2025-03-18,"['astro-ph.IM', 'astro-ph.HE', 'cs.AI', 'cs.LG', 'hep-ex', 'hep-ph', 'nucl-th']","19 pages, 5 figures",http://arxiv.org/pdf/2503.14192v1
2503.14569v1,Potential Score Matching: Debiasing Molecular Structure Sampling with Potential Energy Guidance,"The ensemble average of physical properties of molecules is closely related
to the distribution of molecular conformations, and sampling such distributions
is a fundamental challenge in physics and chemistry. Traditional methods like
molecular dynamics (MD) simulations and Markov chain Monte Carlo (MCMC)
sampling are commonly used but can be time-consuming and costly. Recently,
diffusion models have emerged as efficient alternatives by learning the
distribution of training data. Obtaining an unbiased target distribution is
still an expensive task, primarily because it requires satisfying ergodicity.
To tackle these challenges, we propose Potential Score Matching (PSM), an
approach that utilizes the potential energy gradient to guide generative
models. PSM does not require exact energy functions and can debias sample
distributions even when trained on limited and biased data. Our method
outperforms existing state-of-the-art (SOTA) models on the Lennard-Jones (LJ)
potential, a commonly used toy model. Furthermore, we extend the evaluation of
PSM to high-dimensional problems using the MD17 and MD22 datasets. The results
demonstrate that molecular distributions generated by PSM more closely
approximate the Boltzmann distribution compared to traditional diffusion
models.","['Liya Guo', 'Zun Wang', 'Chang Liu', 'Junzhe Li', 'Pipi Hu', 'Yi Zhu']",2025-03-18,"['cs.LG', 'cs.AI']",,http://arxiv.org/pdf/2503.14569v1
2503.14153v1,"Speculative Decoding for Verilog: Speed and Quality, All in One","The rapid advancement of large language models (LLMs) has revolutionized code
generation tasks across various programming languages. However, the unique
characteristics of programming languages, particularly those like Verilog with
specific syntax and lower representation in training datasets, pose significant
challenges for conventional tokenization and decoding approaches. In this
paper, we introduce a novel application of speculative decoding for Verilog
code generation, showing that it can improve both inference speed and output
quality, effectively achieving speed and quality all in one. Unlike standard
LLM tokenization schemes, which often fragment meaningful code structures, our
approach aligns decoding stops with syntactically significant tokens, making it
easier for models to learn the token distribution. This refinement addresses
inherent tokenization issues and enhances the model's ability to capture
Verilog's logical constructs more effectively. Our experimental results show
that our method achieves up to a 5.05x speedup in Verilog code generation and
increases pass@10 functional accuracy on RTLLM by up to 17.19% compared to
conventional training strategies. These findings highlight speculative decoding
as a promising approach to bridge the quality gap in code generation for
specialized programming languages.","['Changran Xu', 'Yi Liu', 'Yunhao Zhou', 'Shan Huang', 'Ningyi Xu', 'Qiang Xu']",2025-03-18,"['cs.LG', 'cs.AR', 'cs.CL']",Accepted by the 62nd Design Automation Conference (DAC 2025),http://arxiv.org/pdf/2503.14153v1
2503.14568v1,"Teaching Artificial Intelligence to Perform Rapid, Resolution-Invariant Grain Growth Modeling via Fourier Neural Operator","Microstructural evolution, particularly grain growth, plays a critical role
in shaping the physical, optical, and electronic properties of materials.
Traditional phase-field modeling accurately simulates these phenomena but is
computationally intensive, especially for large systems and fine spatial
resolutions. While machine learning approaches have been employed to accelerate
simulations, they often struggle with resolution dependence and generalization
across different grain scales. This study introduces a novel approach utilizing
Fourier Neural Operator (FNO) to achieve resolution-invariant modeling of
microstructure evolution in multi-grain systems. FNO operates in the Fourier
space and can inherently handle varying resolutions by learning mappings
between function spaces. By integrating FNO with the phase field method, we
developed a surrogate model that significantly reduces computational costs
while maintaining high accuracy across different spatial scales. We generated a
comprehensive dataset from phase-field simulations using the Fan Chen model,
capturing grain evolution over time. Data preparation involved creating
input-output pairs with a time shift, allowing the model to predict future
microstructures based on current and past states. The FNO-based neural network
was trained using sequences of microstructures and demonstrated remarkable
accuracy in predicting long-term evolution, even for unseen configurations and
higher-resolution grids not encountered during training.","['Iman Peivaste', 'Ahmed Makradi', 'Salim Belouettar']",2025-03-18,"['cond-mat.mtrl-sci', 'cs.AI', 'cs.CE', 'cs.LG']",,http://arxiv.org/pdf/2503.14568v1
2503.14567v1,SpecReX: Explainable AI for Raman Spectroscopy,"Raman spectroscopy is becoming more common for medical diagnostics with deep
learning models being increasingly used to leverage its full potential.
However, the opaque nature of such models and the sensitivity of medical
diagnosis together with regulatory requirements necessitate the need for
explainable AI tools. We introduce SpecReX, specifically adapted to explaining
Raman spectra. SpecReX uses the theory of actual causality to rank causal
responsibility in a spectrum, quantified by iteratively refining mutated
versions of the spectrum and testing if it retains the original classification.
The explanations provided by SpecReX take the form of a responsibility map,
highlighting spectral regions most responsible for the model to make a correct
classification. To assess the validity of SpecReX, we create increasingly
complex simulated spectra, in which a ""ground truth"" signal is seeded, to train
a classifier. We then obtain SpecReX explanations and compare the results with
another explainability tool. By using simulated spectra we establish that
SpecReX localizes to the known differences between classes, under a number of
conditions. This provides a foundation on which we can find the spectral
features which differentiate disease classes. This is an important first step
in proving the validity of SpecReX.","['Nathan Blake', 'David A. Kelly', 'Akchunya Chanchal', 'Sarah Kapllani-Mucaj', 'Geraint Thomas', 'Hana Chockler']",2025-03-18,"['cs.LG', 'cs.AI', 'physics.med-ph']",AAAI Workshop on Health Intelligencee (W3PHIAI-25),http://arxiv.org/pdf/2503.14567v1
2503.14125v1,Frac-Connections: Fractional Extension of Hyper-Connections,"Residual connections are central to modern deep learning architectures,
enabling the training of very deep networks by mitigating gradient vanishing.
Hyper-Connections recently generalized residual connections by introducing
multiple connection strengths at different depths, thereby addressing the
seesaw effect between gradient vanishing and representation collapse. However,
Hyper-Connections increase memory access costs by expanding the width of hidden
states. In this paper, we propose Frac-Connections, a novel approach that
divides hidden states into multiple parts rather than expanding their width.
Frac-Connections retain partial benefits of Hyper-Connections while reducing
memory consumption. To validate their effectiveness, we conduct large-scale
experiments on language tasks, with the largest being a 7B MoE model trained on
up to 3T tokens, demonstrating that Frac-Connections significantly outperform
residual connections.","['Defa Zhu', 'Hongzhi Huang', 'Jundong Zhou', 'Zihao Huang', 'Yutao Zeng', 'Banggu Wu', 'Qiyang Min', 'Xun Zhou']",2025-03-18,"['cs.LG', 'cs.AI', 'cs.CL']",,http://arxiv.org/pdf/2503.14125v1
2503.14121v1,"Fundamental Limits of Matrix Sensing: Exact Asymptotics, Universality, and Applications","In the matrix sensing problem, one wishes to reconstruct a matrix from
(possibly noisy) observations of its linear projections along given directions.
We consider this model in the high-dimensional limit: while previous works on
this model primarily focused on the recovery of low-rank matrices, we consider
in this work more general classes of structured signal matrices with
potentially large rank, e.g. a product of two matrices of sizes proportional to
the dimension. We provide rigorous asymptotic equations characterizing the
Bayes-optimal learning performance from a number of samples which is
proportional to the number of entries in the matrix. Our proof is composed of
three key ingredients: $(i)$ we prove universality properties to handle
structured sensing matrices, related to the ''Gaussian equivalence'' phenomenon
in statistical learning, $(ii)$ we provide a sharp characterization of
Bayes-optimal learning in generalized linear models with Gaussian data and
structured matrix priors, generalizing previously studied settings, and $(iii)$
we leverage previous works on the problem of matrix denoising. The generality
of our results allow for a variety of applications: notably, we mathematically
establish predictions obtained via non-rigorous methods from statistical
physics in [ETB+24] regarding Bilinear Sequence Regression, a benchmark model
for learning from sequences of tokens, and in [MTM+24] on Bayes-optimal
learning in neural networks with quadratic activation function, and width
proportional to the dimension.","['Yizhou Xu', 'Antoine Maillard', 'Lenka Zdeborová', 'Florent Krzakala']",2025-03-18,"['stat.ML', 'cond-mat.dis-nn', 'cs.IT', 'cs.LG', 'math.IT', 'math.PR']",,http://arxiv.org/pdf/2503.14121v1
2503.14118v1,"PET-MAD, a universal interatomic potential for advanced materials modeling","Machine-learning interatomic potentials (MLIPs) have greatly extended the
reach of atomic-scale simulations, offering the accuracy of first-principles
calculations at a fraction of the effort. Leveraging large quantum mechanical
databases and expressive architectures, recent ""universal"" models deliver
qualitative accuracy across the periodic table but are often biased toward
low-energy configurations. We introduce PET-MAD, a generally applicable MLIP
trained on a dataset combining stable inorganic and organic solids,
systematically modified to enhance atomic diversity. Using a moderate but
highly-consistent level of electronic-structure theory, we assess PET-MAD's
accuracy on established benchmarks and advanced simulations of six materials.
PET-MAD rivals state-of-the-art MLIPs for inorganic solids, while also being
reliable for molecules, organic materials, and surfaces. It is stable and fast,
enabling, out-of-the-box, the near-quantitative study of thermal and quantum
mechanical fluctuations, functional properties, and phase transitions. It can
be efficiently fine-tuned to deliver full quantum mechanical accuracy with a
minimal number of targeted calculations.","['Arslan Mazitov', 'Filippo Bigi', 'Matthias Kellner', 'Paolo Pegolo', 'Davide Tisi', 'Guillaume Fraux', 'Sergey Pozdnyakov', 'Philip Loche', 'Michele Ceriotti']",2025-03-18,"['cond-mat.mtrl-sci', 'cs.LG', 'physics.chem-ph']",,http://arxiv.org/pdf/2503.14118v1
2503.14095v1,Towards Location-Specific Precipitation Projections Using Deep Neural Networks,"Accurate precipitation estimates at individual locations are crucial for
weather forecasting and spatial analysis. This study presents a paradigm shift
by leveraging Deep Neural Networks (DNNs) to surpass traditional methods like
Kriging for station-specific precipitation approximation. We propose two
innovative NN architectures: one utilizing precipitation, elevation, and
location, and another incorporating additional meteorological parameters like
humidity, temperature, and wind speed. Trained on a vast dataset (1980-2019),
these models outperform Kriging across various evaluation metrics (correlation
coefficient, root mean square error, bias, and skill score) on a five-year
validation set. This compelling evidence demonstrates the transformative power
of deep learning for spatial prediction, offering a robust and precise
alternative for station-specific precipitation estimation.","['Bipin Kumar', 'Bhvisy Kumar Yadav', 'Soumypdeep Mukhopadhyay', 'Rakshit Rohan', 'Bhupendra Bahadur Singh', 'Rajib Chattopadhyay', 'Nagraju Chilukoti', 'Atul Kumar Sahai']",2025-03-18,"['physics.ao-ph', 'cs.LG']","21 pages, 9 figures",http://arxiv.org/pdf/2503.14095v1
2503.14084v1,Semantic Communication in Dynamic Channel Scenarios: Collaborative Optimization of Dual-Pipeline Joint Source-Channel Coding and Personalized Federated Learning,"Semantic communication is designed to tackle issues like bandwidth
constraints and high latency in communication systems. However, in complex
network topologies with multiple users, the enormous combinations of client
data and channel state information (CSI) pose significant challenges for
existing semantic communication architectures. To improve the generalization
ability of semantic communication models in complex scenarios while meeting the
personalized needs of each user in their local environments, we propose a novel
personalized federated learning framework with dual-pipeline joint
source-channel coding based on channel awareness model (PFL-DPJSCCA). Within
this framework, we present a method that achieves zero optimization gap for
non-convex loss functions. Experiments conducted under varying SNR
distributions validate the outstanding performance of our framework across
diverse datasets.","['Xingrun Yan', 'Shiyuan Zuo', 'Yifeng Lyu', 'Rongfei Fan', 'Han Hu']",2025-03-18,"['eess.IV', 'cs.LG']",,http://arxiv.org/pdf/2503.14084v1
2503.14076v1,"Theoretical Foundation of Flow-Based Time Series Generation: Provable Approximation, Generalization, and Efficiency","Recent studies suggest utilizing generative models instead of traditional
auto-regressive algorithms for time series forecasting (TSF) tasks. These
non-auto-regressive approaches involving different generative methods,
including GAN, Diffusion, and Flow Matching for time series, have empirically
demonstrated high-quality generation capability and accuracy. However, we still
lack an appropriate understanding of how it processes approximation and
generalization. This paper presents the first theoretical framework from the
perspective of flow-based generative models to relieve the knowledge of
limitations. In particular, we provide our insights with strict guarantees from
three perspectives: $\textbf{Approximation}$, $\textbf{Generalization}$ and
$\textbf{Efficiency}$. In detail, our analysis achieves the contributions as
follows:
  $\bullet$ By assuming a general data model, the fitting of the flow-based
generative models is confirmed to converge to arbitrary error under the
universal approximation of Diffusion Transformer (DiT).
  $\bullet$ Introducing a polynomial-based regularization for flow matching,
the generalization error thus be bounded since the generalization of polynomial
approximation.
  $\bullet$ The sampling for generation is considered as an optimization
process, we demonstrate its fast convergence with updating standard first-order
gradient descent of some objective.","['Jiangxuan Long', 'Zhao Song', 'Chiwun Yang']",2025-03-18,"['cs.LG', 'cs.AI']",33 pages,http://arxiv.org/pdf/2503.14076v1
2503.14055v1,Modular Distributed Nonconvex Learning with Error Feedback,"In this paper, we design a novel distributed learning algorithm using
stochastic compressed communications. In detail, we pursue a modular approach,
merging ADMM and a gradient-based approach, benefiting from the robustness of
the former and the computational efficiency of the latter. Additionally, we
integrate a stochastic integral action (error feedback) enabling almost sure
rejection of the compression error. We analyze the resulting method in
nonconvex scenarios and guarantee almost sure asymptotic convergence to the set
of stationary points of the problem. This result is obtained using
system-theoretic tools based on stochastic timescale separation. We corroborate
our findings with numerical simulations in nonconvex classification.","['Guido Carnevale', 'Nicola Bastianello']",2025-03-18,"['math.OC', 'cs.LG', 'cs.SY', 'eess.SY']",,http://arxiv.org/pdf/2503.14055v1
2503.14053v1,ON-Traffic: An Operator Learning Framework for Online Traffic Flow Estimation and Uncertainty Quantification from Lagrangian Sensors,"Accurate traffic flow estimation and prediction are critical for the
efficient management of transportation systems, particularly under increasing
urbanization. Traditional methods relying on static sensors often suffer from
limited spatial coverage, while probe vehicles provide richer, albeit sparse
and irregular data. This work introduces ON-Traffic, a novel deep operator
Network and a receding horizon learning-based framework tailored for online
estimation of spatio-temporal traffic state along with quantified uncertainty
by using measurements from moving probe vehicles and downstream boundary
inputs. Our framework is evaluated in both numerical and simulation datasets,
showcasing its ability to handle irregular, sparse input data, adapt to
time-shifted scenarios, and provide well-calibrated uncertainty estimates. The
results demonstrate that the model captures complex traffic phenomena,
including shockwaves and congestion propagation, while maintaining robustness
to noise and sensor dropout. These advancements present a significant step
toward online, adaptive traffic management systems.","['Jake Rap', 'Amritam Das']",2025-03-18,"['cs.LG', 'cs.AI', 'cs.SY', 'eess.SY']",,http://arxiv.org/pdf/2503.14053v1
2503.14045v1,Empirical risk minimization algorithm for multiclass classification of S.D.E. paths,"We address the multiclass classification problem for stochastic diffusion
paths, assuming that the classes are distinguished by their drift functions,
while the diffusion coefficient remains common across all classes. In this
setting, we propose a classification algorithm that relies on the minimization
of the L 2 risk. We establish rates of convergence for the resulting predictor.
Notably, we introduce a margin assumption under which we show that our
procedure can achieve fast rates of convergence. Finally, a simulation study
highlights the numerical performance of our classification algorithm.","['Christophe Denis', 'Eddy Ella Mintsa']",2025-03-18,"['stat.ML', 'cs.LG']",,http://arxiv.org/pdf/2503.14045v1
2503.14043v1,Learning on LLM Output Signatures for gray-box LLM Behavior Analysis,"Large Language Models (LLMs) have achieved widespread adoption, yet our
understanding of their behavior remains limited, particularly in detecting data
contamination and hallucinations. While recently proposed probing techniques
provide insights through activation analysis, they require ""white-box"" access
to model internals, often unavailable. Current ""gray-box"" approaches typically
analyze only the probability of the actual tokens in the sequence with simple
task-specific heuristics. Importantly, these methods overlook the rich
information contained in the full token distribution at each processing step.
To address these limitations, we propose that gray-box analysis should leverage
the complete observable output of LLMs, consisting of both the previously used
token probabilities as well as the complete token distribution sequences - a
unified data type we term LOS (LLM Output Signature). To this end, we develop a
transformer-based approach to process LOS that theoretically guarantees
approximation of existing techniques while enabling more nuanced analysis. Our
approach achieves superior performance on hallucination and data contamination
detection in gray-box settings, significantly outperforming existing baselines.
Furthermore, it demonstrates strong transfer capabilities across datasets and
LLMs, suggesting that LOS captures fundamental patterns in LLM behavior. Our
code is available at: https://github.com/BarSGuy/LLM-Output-Signatures-Network.","['Guy Bar-Shalom', 'Fabrizio Frasca', 'Derek Lim', 'Yoav Gelberg', 'Yftah Ziser', 'Ran El-Yaniv', 'Gal Chechik', 'Haggai Maron']",2025-03-18,['cs.LG'],,http://arxiv.org/pdf/2503.14043v1
2503.14024v1,Uncertainty-Aware Global-View Reconstruction for Multi-View Multi-Label Feature Selection,"In recent years, multi-view multi-label learning (MVML) has gained popularity
due to its close resemblance to real-world scenarios. However, the challenge of
selecting informative features to ensure both performance and efficiency
remains a significant question in MVML. Existing methods often extract
information separately from the consistency part and the complementary part,
which may result in noise due to unclear segmentation. In this paper, we
propose a unified model constructed from the perspective of global-view
reconstruction. Additionally, while feature selection methods can discern the
importance of features, they typically overlook the uncertainty of samples,
which is prevalent in realistic scenarios. To address this, we incorporate the
perception of sample uncertainty during the reconstruction process to enhance
trustworthiness. Thus, the global-view is reconstructed through the graph
structure between samples, sample confidence, and the view relationship. The
accurate mapping is established between the reconstructed view and the label
matrix. Experimental results demonstrate the superior performance of our method
on multi-view datasets.","['Pingting Hao', 'Kunpeng Liu', 'Wanfu Gao']",2025-03-18,"['cs.LG', 'cs.CV']","9 pages,5 figures, accept in AAAI 25",http://arxiv.org/pdf/2503.14024v1
2503.14004v1,Predicting Human Choice Between Textually Described Lotteries,"Predicting human decision-making under risk and uncertainty is a
long-standing challenge in cognitive science, economics, and AI. While prior
research has focused on numerically described lotteries, real-world decisions
often rely on textual descriptions. This study conducts the first large-scale
exploration of human decision-making in such tasks using a large dataset of
one-shot binary choices between textually described lotteries. We evaluate
multiple computational approaches, including fine-tuning Large Language Models
(LLMs), leveraging embeddings, and integrating behavioral theories of choice
under risk. Our results show that fine-tuned LLMs, specifically RoBERTa and
GPT-4o outperform hybrid models that incorporate behavioral theory, challenging
established methods in numerical settings. These findings highlight fundamental
differences in how textual and numerical information influence decision-making
and underscore the need for new modeling strategies to bridge this gap.","['Eyal Marantz', 'Ori Plonsky']",2025-03-18,['cs.LG'],,http://arxiv.org/pdf/2503.14004v1
2503.14002v1,MeshFleet: Filtered and Annotated 3D Vehicle Dataset for Domain Specific Generative Modeling,"Generative models have recently made remarkable progress in the field of 3D
objects. However, their practical application in fields like engineering
remains limited since they fail to deliver the accuracy, quality, and
controllability needed for domain-specific tasks. Fine-tuning large generative
models is a promising perspective for making these models available in these
fields. Creating high-quality, domain-specific 3D datasets is crucial for
fine-tuning large generative models, yet the data filtering and annotation
process remains a significant bottleneck. We present MeshFleet, a filtered and
annotated 3D vehicle dataset extracted from Objaverse-XL, the most extensive
publicly available collection of 3D objects. Our approach proposes a pipeline
for automated data filtering based on a quality classifier. This classifier is
trained on a manually labeled subset of Objaverse, incorporating DINOv2 and
SigLIP embeddings, refined through caption-based analysis and uncertainty
estimation. We demonstrate the efficacy of our filtering method through a
comparative analysis against caption and image aesthetic score-based techniques
and fine-tuning experiments with SV3D, highlighting the importance of targeted
data selection for domain-specific 3D generative modeling.","['Damian Boborzi', 'Phillip Mueller', 'Jonas Emrich', 'Dominik Schmid', 'Sebastian Mueller', 'Lars Mikelsons']",2025-03-18,"['cs.CV', 'cs.AI', 'cs.LG']",,http://arxiv.org/pdf/2503.14002v1
2503.14564v1,Effortless Active Labeling for Long-Term Test-Time Adaptation,"Long-term test-time adaptation (TTA) is a challenging task due to error
accumulation. Recent approaches tackle this issue by actively labeling a small
proportion of samples in each batch, yet the annotation burden quickly grows as
the batch number increases. In this paper, we investigate how to achieve
effortless active labeling so that a maximum of one sample is selected for
annotation in each batch. First, we annotate the most valuable sample in each
batch based on the single-step optimization perspective in the TTA context. In
this scenario, the samples that border between the source- and target-domain
data distributions are considered the most feasible for the model to learn in
one iteration. Then, we introduce an efficient strategy to identify these
samples using feature perturbation. Second, we discover that the gradient
magnitudes produced by the annotated and unannotated samples have significant
variations. Therefore, we propose balancing their impact on model optimization
using two dynamic weights. Extensive experiments on the popular ImageNet-C, -R,
-K, -A and PACS databases demonstrate that our approach consistently
outperforms state-of-the-art methods with significantly lower annotation costs.","['Guowei Wang', 'Changxing Ding']",2025-03-18,"['cs.CV', 'cs.AI', 'cs.LG']",CVPR 2025.Code:https://github.com/flash1803/EATTA,http://arxiv.org/pdf/2503.14564v1
2503.13985v1,DefectFill: Realistic Defect Generation with Inpainting Diffusion Model for Visual Inspection,"Developing effective visual inspection models remains challenging due to the
scarcity of defect data. While image generation models have been used to
synthesize defect images, producing highly realistic defects remains difficult.
We propose DefectFill, a novel method for realistic defect generation that
requires only a few reference defect images. It leverages a fine-tuned
inpainting diffusion model, optimized with our custom loss functions
incorporating defect, object, and attention terms. It enables precise capture
of detailed, localized defect features and their seamless integration into
defect-free objects. Additionally, our Low-Fidelity Selection method further
enhances the defect sample quality. Experiments show that DefectFill generates
high-quality defect images, enabling visual inspection models to achieve
state-of-the-art performance on the MVTec AD dataset.","['Jaewoo Song', 'Daemin Park', 'Kanghyun Baek', 'Sangyub Lee', 'Jooyoung Choi', 'Eunji Kim', 'Sungroh Yoon']",2025-03-18,"['cs.CV', 'cs.AI', 'cs.LG']",Accepted by CVPR 2025,http://arxiv.org/pdf/2503.13985v1
2503.13980v1,Empowering LLMs in Decision Games through Algorithmic Data Synthesis,"Large Language Models (LLMs) have exhibited impressive capabilities across
numerous domains, yet they often struggle with complex reasoning and
decision-making tasks. Decision-making games, which inherently require
multifaceted reasoning logic, serve as ideal sandboxes for evaluating and
enhancing the reasoning abilities of LLMs. In this work, we first explore
whether LLMs can master complex decision-making games through targeted
post-training. To this end, we design data synthesis strategies and curate
extensive offline datasets from two classic games, Doudizhu and Go. We further
develop a suite of techniques to effectively incorporate this data into LLM
training, resulting in two novel agents: Mastermind-Dou and Mastermind-Go. Our
experimental results demonstrate that these Mastermind LLMs achieve competitive
performance in their respective games. Additionally, we explore whether
integrating decision-making data can enhance the general reasoning abilities of
LLMs. Our findings suggest that such post-training improves certain aspects of
reasoning, providing valuable insights for optimizing LLM data collection and
synthesis strategies.","['Haolin Wang', 'Xueyan Li', 'Yazhe Niu', 'Shuai Hu', 'Hongsheng Li']",2025-03-18,['cs.LG'],,http://arxiv.org/pdf/2503.13980v1
2503.14561v1,Identifying Critical Phases for Disease Onset with Sparse Haematological Biomarkers,"Routinely collected clinical blood tests are an emerging molecular data
source for large-scale biomedical research but inherently feature irregular
sampling and informative observation. Traditional approaches rely on
imputation, which can distort learning signals and bias predictions while
lacking biological interpretability. We propose a novel methodology using Graph
Neural Additive Networks (GNAN) to model biomarker trajectories as
time-weighted directed graphs, where nodes represent sampling events and edges
encode the time delta between events. GNAN's additive structure enables the
explicit decomposition of feature and temporal contributions, allowing the
detection of critical disease-associated time points. Unlike conventional
imputation-based approaches, our method preserves the temporal structure of
sparse data without introducing artificial biases and provides inherently
interpretable predictions by decomposing contributions from each biomarker and
time interval. This makes our model clinically applicable, as well as allowing
it to discover biologically meaningful disease signatures.","['Andrea Zerio', 'Maya Bechler-Speicher', 'Tine Jess', 'Aleksejs Sazonovs']",2025-03-18,"['q-bio.QM', 'cs.LG']",,http://arxiv.org/pdf/2503.14561v1
2503.13976v1,A CNN-based End-to-End Learning for RIS-assisted Communication System,"Reconfigurable intelligent surface (RIS) is an emerging technology that is
used to improve the system performance in beyond 5G systems. In this letter, we
propose a novel convolutional neural network (CNN)-based autoencoder to jointly
optimize the transmitter, the receiver, and the RIS of a RIS-assisted
communication system. The proposed system jointly optimizes the sub-tasks of
the transmitter, the receiver, and the RIS such as encoding/decoding, channel
estimation, phase optimization, and modulation/demodulation. Numerically we
have shown that the bit error rate (BER) performance of the CNN-based
autoencoder system is better than the theoretical BER performance of the
RIS-assisted communication systems.","['Nipuni Ginige', 'Nandana Rajatheva', 'Matti Latva-aho']",2025-03-18,['cs.LG'],,http://arxiv.org/pdf/2503.13976v1
2503.13964v1,MDocAgent: A Multi-Modal Multi-Agent Framework for Document Understanding,"Document Question Answering (DocQA) is a very common task. Existing methods
using Large Language Models (LLMs) or Large Vision Language Models (LVLMs) and
Retrieval Augmented Generation (RAG) often prioritize information from a single
modal, failing to effectively integrate textual and visual cues. These
approaches struggle with complex multi-modal reasoning, limiting their
performance on real-world documents. We present MDocAgent (A Multi-Modal
Multi-Agent Framework for Document Understanding), a novel RAG and multi-agent
framework that leverages both text and image. Our system employs five
specialized agents: a general agent, a critical agent, a text agent, an image
agent and a summarizing agent. These agents engage in multi-modal context
retrieval, combining their individual insights to achieve a more comprehensive
understanding of the document's content. This collaborative approach enables
the system to synthesize information from both textual and visual components,
leading to improved accuracy in question answering. Preliminary experiments on
five benchmarks like MMLongBench, LongDocURL demonstrate the effectiveness of
our MDocAgent, achieve an average improvement of 12.1% compared to current
state-of-the-art method. This work contributes to the development of more
robust and comprehensive DocQA systems capable of handling the complexities of
real-world documents containing rich textual and visual information. Our data
and code are available at https://github.com/aiming-lab/MDocAgent.","['Siwei Han', 'Peng Xia', 'Ruiyi Zhang', 'Tong Sun', 'Yun Li', 'Hongtu Zhu', 'Huaxiu Yao']",2025-03-18,['cs.LG'],,http://arxiv.org/pdf/2503.13964v1
2503.13954v2,Enhanced High-Dimensional Data Visualization through Adaptive Multi-Scale Manifold Embedding,"To address the dual challenges of the curse of dimensionality and the
difficulty in separating intra-cluster and inter-cluster structures in
high-dimensional manifold embedding, we proposes an Adaptive Multi-Scale
Manifold Embedding (AMSME) algorithm. By introducing ordinal distance to
replace traditional Euclidean distances, we theoretically demonstrate that
ordinal distance overcomes the constraints of the curse of dimensionality in
high-dimensional spaces, effectively distinguishing heterogeneous samples. We
design an adaptive neighborhood adjustment method to construct similarity
graphs that simultaneously balance intra-cluster compactness and inter-cluster
separability. Furthermore, we develop a two-stage embedding framework: the
first stage achieves preliminary cluster separation while preserving
connectivity between structurally similar clusters via the similarity graph,
and the second stage enhances inter-cluster separation through a label-driven
distance reweighting. Experimental results demonstrate that AMSME significantly
preserves intra-cluster topological structures and improves inter-cluster
separation on real-world datasets. Additionally, leveraging its
multi-resolution analysis capability, AMSME discovers novel neuronal subtypes
in the mouse lumbar dorsal root ganglion scRNA-seq dataset, with marker gene
analysis revealing their distinct biological roles.","['Tianhao Ni', 'Bingjie Li', 'Zhigang Yao']",2025-03-18,['cs.LG'],,http://arxiv.org/pdf/2503.13954v2
2503.13942v1,Structured Knowledge Accumulation: An Autonomous Framework for Layer-Wise Entropy Reduction in Neural Learning,"We introduce the Structured Knowledge Accumulation (SKA) framework, which
reinterprets entropy as a dynamic, layer-wise measure of knowledge alignment in
neural networks. Instead of relying on traditional gradient-based optimization,
SKA defines entropy in terms of knowledge vectors and their influence on
decision probabilities across multiple layers. This formulation naturally leads
to the emergence of activation functions such as the sigmoid as a consequence
of entropy minimization. Unlike conventional backpropagation, SKA allows each
layer to optimize independently by aligning its knowledge representation with
changes in decision probabilities. As a result, total network entropy decreases
in a hierarchical manner, allowing knowledge structures to evolve
progressively. This approach provides a scalable, biologically plausible
alternative to gradient-based learning, bridging information theory and
artificial intelligence while offering promising applications in
resource-constrained and parallel computing environments.",['Bouarfa Mahi Quantiota'],2025-03-18,"['cs.LG', 'cs.NE', '14J60 (Primary) 14F05, 14J26 (Secondary)', 'F.2.2; I.2.7']","16 pages, 6 figures",http://arxiv.org/pdf/2503.13942v1
2503.13925v1,Reconstructing Cell Lineage Trees from Phenotypic Features with Metric Learning,"How a single fertilized cell gives rise to a complex array of specialized
cell types in development is a central question in biology. The cells grow,
divide, and acquire differentiated characteristics through poorly understood
molecular processes. A key approach to studying developmental processes is to
infer the tree graph of cell lineage division and differentiation histories,
providing an analytical framework for dissecting individual cells' molecular
decisions during replication and differentiation. Although genetically
engineered lineage-tracing methods have advanced the field, they are either
infeasible or ethically constrained in many organisms. In contrast, modern
single-cell technologies can measure high-content molecular profiles (e.g.,
transcriptomes) in a wide range of biological systems.
  Here, we introduce CellTreeQM, a novel deep learning method based on
transformer architectures that learns an embedding space with geometric
properties optimized for tree-graph inference. By formulating lineage
reconstruction as a tree-metric learning problem, we have systematically
explored supervised, weakly supervised, and unsupervised training settings and
present a Lineage Reconstruction Benchmark to facilitate comprehensive
evaluation of our learning method. We benchmarked the method on (1) synthetic
data modeled via Brownian motion with independent noise and spurious signals
and (2) lineage-resolved single-cell RNA sequencing datasets. Experimental
results show that CellTreeQM recovers lineage structures with minimal
supervision and limited data, offering a scalable framework for uncovering cell
lineage relationships in challenging animal models. To our knowledge, this is
the first method to cast cell lineage inference explicitly as a metric learning
task, paving the way for future computational models aimed at uncovering the
molecular dynamics of cell lineage.","['Da Kuang', 'Guanwen Qiu', 'Junhyong Kim']",2025-03-18,['cs.LG'],,http://arxiv.org/pdf/2503.13925v1
2503.13921v1,Learning Accurate Models on Incomplete Data with Minimal Imputation,"Missing data often exists in real-world datasets, requiring significant time
and effort for imputation to learn accurate machine learning (ML) models. In
this paper, we demonstrate that imputing all missing values is not always
necessary to achieve an accurate ML model. We introduce the concept of minimal
data imputation, which ensures accurate ML models trained over the imputed
dataset. Implementing minimal imputation guarantees both minimal imputation
effort and optimal ML models. We propose algorithms to find exact and
approximate minimal imputation for various ML models. Our extensive experiments
indicate that our proposed algorithms significantly reduce the time and effort
required for data imputation.","['Cheng Zhen', 'Nischal Aryal', 'Arash Termehchy', 'Prayoga', 'Garrett Biwer', 'Sankalp Patil']",2025-03-18,"['cs.LG', 'cs.AI']",,http://arxiv.org/pdf/2503.13921v1
2503.13917v1,Robust Machine Unlearning for Quantized Neural Networks via Adaptive Gradient Reweighting with Similar Labels,"Model quantization enables efficient deployment of deep neural networks on
edge devices through low-bit parameter representation, yet raises critical
challenges for implementing machine unlearning (MU) under data privacy
regulations. Existing MU methods designed for full-precision models fail to
address two fundamental limitations in quantized networks: 1) Noise
amplification from label mismatch during data processing, and 2) Gradient
imbalance between forgotten and retained data during training. These issues are
exacerbated by quantized models' constrained parameter space and discrete
optimization. We propose Q-MUL, the first dedicated unlearning framework for
quantized models. Our method introduces two key innovations: 1) Similar Labels
assignment replaces random labels with semantically consistent alternatives to
minimize noise injection, and 2) Adaptive Gradient Reweighting dynamically
aligns parameter update contributions from forgotten and retained data. Through
systematic analysis of quantized model vulnerabilities, we establish
theoretical foundations for these mechanisms. Extensive evaluations on
benchmark datasets demonstrate Q-MUL's superiority over existing approaches.","['Yujia Tong', 'Yuze Wang', 'Jingling Yuan', 'Chuang Hu']",2025-03-18,['cs.LG'],"15 pages, 4 figures",http://arxiv.org/pdf/2503.13917v1
2503.13912v1,KANITE: Kolmogorov-Arnold Networks for ITE estimation,"We introduce KANITE, a framework leveraging Kolmogorov-Arnold Networks (KANs)
for Individual Treatment Effect (ITE) estimation under multiple treatments
setting in causal inference. By utilizing KAN's unique abilities to learn
univariate activation functions as opposed to learning linear weights by
Multi-Layer Perceptrons (MLPs), we improve the estimates of ITEs. The KANITE
framework comprises two key architectures: 1.Integral Probability Metric (IPM)
architecture: This employs an IPM loss in a specialized manner to effectively
align towards ITE estimation across multiple treatments. 2. Entropy Balancing
(EB) architecture: This uses weights for samples that are learned by optimizing
entropy subject to balancing the covariates across treatment groups. Extensive
evaluations on benchmark datasets demonstrate that KANITE outperforms
state-of-the-art algorithms in both $\epsilon_{\text{PEHE}}$ and
$\epsilon_{\text{ATE}}$ metrics. Our experiments highlight the advantages of
KANITE in achieving improved causal estimates, emphasizing the potential of
KANs to advance causal inference methodologies across diverse application
areas.","['Eshan Mehendale', 'Abhinav Thorat', 'Ravi Kolla', 'Niranjan Pedanekar']",2025-03-18,"['cs.LG', 'cs.AI', 'stat.ME']","16 pages, 4 figures",http://arxiv.org/pdf/2503.13912v1
2503.13911v1,Incorporating Attributes and Multi-Scale Structures for Heterogeneous Graph Contrastive Learning,"Heterogeneous graphs (HGs) are composed of multiple types of nodes and edges,
making it more effective in capturing the complex relational structures
inherent in the real world. However, in real-world scenarios, labeled data is
often difficult to obtain, which limits the applicability of semi-supervised
approaches. Self-supervised learning aims to enable models to automatically
learn useful features from data, effectively addressing the challenge of
limited labeling data. In this paper, we propose a novel contrastive learning
framework for heterogeneous graphs (ASHGCL), which incorporates three distinct
views, each focusing on node attributes, high-order and low-order structural
information, respectively, to effectively capture attribute information,
high-order structures, and low-order structures for node representation
learning. Furthermore, we introduce an attribute-enhanced positive sample
selection strategy that combines both structural information and attribute
information, effectively addressing the issue of sampling bias. Extensive
experiments on four real-world datasets show that ASHGCL outperforms
state-of-the-art unsupervised baselines and even surpasses some supervised
benchmarks.","['Ruobing Jiang', 'Yacong Li', 'Haobing Liu', 'Yanwei Yu']",2025-03-18,"['cs.LG', 'cs.SI']",,http://arxiv.org/pdf/2503.13911v1
2503.13909v1,Quantification of Uncertainties in Probabilistic Deep Neural Network by Implementing Boosting of Variational Inference,"Modern neural network architectures have achieved remarkable accuracies but
remain highly dependent on their training data, often lacking interpretability
in their learned mappings. While effective on large datasets, they tend to
overfit on smaller ones. Probabilistic neural networks, such as those utilizing
variational inference, address this limitation by incorporating uncertainty
estimation through weight distributions rather than point estimates. However,
standard variational inference often relies on a single-density approximation,
which can lead to poor posterior estimates and hinder model performance. We
propose Boosted Bayesian Neural Networks (BBNN), a novel approach that enhances
neural network weight distribution approximations using Boosting Variational
Inference (BVI). By iteratively constructing a mixture of densities, BVI
expands the approximating family, enabling a more expressive posterior that
leads to improved generalization and uncertainty estimation. While this
approach increases computational complexity, it significantly enhances accuracy
an essential tradeoff, particularly in high-stakes applications such as medical
diagnostics, where false negatives can have severe consequences. Our
experimental results demonstrate that BBNN achieves ~5% higher accuracy
compared to conventional neural networks while providing superior uncertainty
quantification. This improvement highlights the effectiveness of leveraging a
mixture-based variational family to better approximate the posterior
distribution, ultimately advancing probabilistic deep learning.","['Pavia Bera', 'Sanjukta Bhanja']",2025-03-18,"['cs.LG', 'stat.ML']",,http://arxiv.org/pdf/2503.13909v1
2503.13899v1,Learning local neighborhoods of non-Gaussian graphical models: A measure transport approach,"Identifying the Markov properties or conditional independencies of a
collection of random variables is a fundamental task in statistics for modeling
and inference. Existing approaches often learn the structure of a probabilistic
graphical model, which encodes these dependencies, by assuming that the
variables follow a distribution with a simple parametric form. Moreover, the
computational cost of many algorithms scales poorly for high-dimensional
distributions, as they need to estimate all the edges in the graph
simultaneously. In this work, we propose a scalable algorithm to infer the
conditional independence relationships of each variable by exploiting the local
Markov property. The proposed method, named Localized Sparsity Identification
for Non-Gaussian Distributions (L-SING), estimates the graph by using flexible
classes of transport maps to represent the conditional distribution for each
variable. We show that L-SING includes existing approaches, such as
neighborhood selection with Lasso, as a special case. We demonstrate the
effectiveness of our algorithm in both Gaussian and non-Gaussian settings by
comparing it to existing methods. Lastly, we show the scalability of the
proposed approach by applying it to high-dimensional non-Gaussian examples,
including a biological dataset with more than 150 variables.","['Sarah Liaw', 'Rebecca Morrison', 'Youssef Marzouk', 'Ricardo Baptista']",2025-03-18,"['cs.LG', 'stat.CO']","Accepted in AAAI 2025: 23 pages, 9 figures",http://arxiv.org/pdf/2503.13899v1
2503.13882v1,MoK-RAG: Mixture of Knowledge Paths Enhanced Retrieval-Augmented Generation for Embodied AI Environments,"While human cognition inherently retrieves information from diverse and
specialized knowledge sources during decision-making processes, current
Retrieval-Augmented Generation (RAG) systems typically operate through
single-source knowledge retrieval, leading to a cognitive-algorithmic
discrepancy. To bridge this gap, we introduce MoK-RAG, a novel multi-source RAG
framework that implements a mixture of knowledge paths enhanced retrieval
mechanism through functional partitioning of a large language model (LLM)
corpus into distinct sections, enabling retrieval from multiple specialized
knowledge paths. Applied to the generation of 3D simulated environments, our
proposed MoK-RAG3D enhances this paradigm by partitioning 3D assets into
distinct sections and organizing them based on a hierarchical knowledge tree
structure. Different from previous methods that only use manual evaluation, we
pioneered the introduction of automated evaluation methods for 3D scenes. Both
automatic and human evaluations in our experiments demonstrate that MoK-RAG3D
can assist Embodied AI agents in generating diverse scenes.","['Zhengsheng Guo', 'Linwei Zheng', 'Xinyang Chen', 'Xuefeng Bai', 'Kehai Chen', 'Min Zhang']",2025-03-18,"['cs.LG', 'cs.AI']",,http://arxiv.org/pdf/2503.13882v1
2503.14559v1,Squeeze Out Tokens from Sample for Finer-Grained Data Governance,"Widely observed data scaling laws, in which error falls off as a power of the
training size, demonstrate the diminishing returns of unselective data
expansion. Hence, data governance is proposed to downsize datasets through
pruning non-informative samples. Yet, isolating the impact of a specific sample
on overall model performance is challenging, due to the vast computation
required for tryout all sample combinations. Current data governors circumvent
this complexity by estimating sample contributions through heuristic-derived
scalar scores, thereby discarding low-value ones. Despite thorough sample
sieving, retained samples contain substantial undesired tokens intrinsically,
underscoring the potential for further compression and purification. In this
work, we upgrade data governance from a 'sieving' approach to a 'juicing' one.
Instead of scanning for least-flawed samples, our dual-branch DataJuicer
applies finer-grained intra-sample governance. It squeezes out informative
tokens and boosts image-text alignments. Specifically, the vision branch
retains salient image patches and extracts relevant object classes, while the
text branch incorporates these classes to enhance captions. Consequently,
DataJuicer yields more refined datasets through finer-grained governance.
Extensive experiments across datasets demonstrate that DataJuicer significantly
outperforms existing DataSieve in image-text retrieval, classification, and
dense visual reasoning.","['Weixiong Lin', 'Chen Ju', 'Haicheng Wang', 'Shengchao Hu', 'Shuai Xiao', 'Mengting Chen', 'Yuheng Jiao', 'Mingshuai Yao', 'Jinsong Lan', 'Qingwen Liu', 'Ying Chen']",2025-03-18,"['cs.LG', 'cs.AI', 'cs.CL', 'cs.CV']",,http://arxiv.org/pdf/2503.14559v1
2503.13874v1,Multi-label feature selection based on binary hashing learning and dynamic graph constraints,"Multi-label learning poses significant challenges in extracting reliable
supervisory signals from the label space. Existing approaches often employ
continuous pseudo-labels to replace binary labels, improving supervisory
information representation. However, these methods can introduce noise from
irrelevant labels and lead to unreliable graph structures. To overcome these
limitations, this study introduces a novel multi-label feature selection method
called Binary Hashing and Dynamic Graph Constraint (BHDG), the first method to
integrate binary hashing into multi-label learning. BHDG utilizes
low-dimensional binary hashing codes as pseudo-labels to reduce noise and
improve representation robustness. A dynamically constrained sample projection
space is constructed based on the graph structure of these binary
pseudo-labels, enhancing the reliability of the dynamic graph. To further
enhance pseudo-label quality, BHDG incorporates label graph constraints and
inner product minimization within the sample space. Additionally, an
$l_{2,1}$-norm regularization term is added to the objective function to
facilitate the feature selection process. The augmented Lagrangian multiplier
(ALM) method is employed to optimize binary variables effectively.
Comprehensive experiments on 10 benchmark datasets demonstrate that BHDG
outperforms ten state-of-the-art methods across six evaluation metrics. BHDG
achieves the highest overall performance ranking, surpassing the next-best
method by an average of at least 2.7 ranks per metric, underscoring its
effectiveness and robustness in multi-label feature selection.","['Cong Guo', 'Changqin Huang', 'Wenhua Zhou', 'Xiaodi Huang']",2025-03-18,['cs.LG'],"21 pages,19 figures",http://arxiv.org/pdf/2503.13874v1
2503.13872v1,Empirical Calibration and Metric Differential Privacy in Language Models,"NLP models trained with differential privacy (DP) usually adopt the DP-SGD
framework, and privacy guarantees are often reported in terms of the privacy
budget $\epsilon$. However, $\epsilon$ does not have any intrinsic meaning, and
it is generally not possible to compare across variants of the framework. Work
in image processing has therefore explored how to empirically calibrate noise
across frameworks using Membership Inference Attacks (MIAs). However, this kind
of calibration has not been established for NLP. In this paper, we show that
MIAs offer little help in calibrating privacy, whereas reconstruction attacks
are more useful. As a use case, we define a novel kind of directional privacy
based on the von Mises-Fisher (VMF) distribution, a metric DP mechanism that
perturbs angular distance rather than adding (isotropic) Gaussian noise, and
apply this to NLP architectures. We show that, even though formal guarantees
are incomparable, empirical privacy calibration reveals that each mechanism has
different areas of strength with respect to utility-privacy trade-offs.","['Pedro Faustini', 'Natasha Fernandes', 'Annabelle McIver', 'Mark Dras']",2025-03-18,"['cs.LG', 'cs.CR']",16 pages,http://arxiv.org/pdf/2503.13872v1
2503.13868v1,Out-of-Distribution Generalization in Time Series: A Survey,"Time series frequently manifest distribution shifts, diverse latent features,
and non-stationary learning dynamics, particularly in open and evolving
environments. These characteristics pose significant challenges for
out-of-distribution (OOD) generalization. While substantial progress has been
made, a systematic synthesis of advancements remains lacking. To address this
gap, we present the first comprehensive review of OOD generalization
methodologies for time series, organized to delineate the field's evolutionary
trajectory and contemporary research landscape. We organize our analysis across
three foundational dimensions: data distribution, representation learning, and
OOD evaluation. For each dimension, we present several popular algorithms in
detail. Furthermore, we highlight key application scenarios, emphasizing their
real-world impact. Finally, we identify persistent challenges and propose
future research directions. A detailed summary of the methods reviewed for the
generalization of OOD in time series can be accessed at
https://tsood-generalization.com.","['Xin Wu', 'Fei Teng', 'Xingwang Li', 'Ji Zhang', 'Tianrui Li', 'Qiang Duan']",2025-03-18,"['cs.LG', 'cs.AI']","20 pages, 8 figures, 5 tables. Work in Progress",http://arxiv.org/pdf/2503.13868v1
2503.13862v1,HySurvPred: Multimodal Hyperbolic Embedding with Angle-Aware Hierarchical Contrastive Learning and Uncertainty Constraints for Survival Prediction,"Multimodal learning that integrates histopathology images and genomic data
holds great promise for cancer survival prediction. However, existing methods
face key limitations: 1) They rely on multimodal mapping and metrics in
Euclidean space, which cannot fully capture the hierarchical structures in
histopathology (among patches from different resolutions) and genomics data
(from genes to pathways). 2) They discretize survival time into independent
risk intervals, which ignores its continuous and ordinal nature and fails to
achieve effective optimization. 3) They treat censorship as a binary indicator,
excluding censored samples from model optimization and not making full use of
them. To address these challenges, we propose HySurvPred, a novel framework for
survival prediction that integrates three key modules: Multimodal Hyperbolic
Mapping (MHM), Angle-aware Ranking-based Contrastive Loss (ARCL) and
Censor-Conditioned Uncertainty Constraint (CUC). Instead of relying on
Euclidean space, we design the MHM module to explore the inherent hierarchical
structures within each modality in hyperbolic space. To better integrate
multimodal features in hyperbolic space, we introduce the ARCL module, which
uses ranking-based contrastive learning to preserve the ordinal nature of
survival time, along with the CUC module to fully explore the censored data.
Extensive experiments demonstrate that our method outperforms state-of-the-art
methods on five benchmark datasets. The source code is to be released.","['Jiaqi Yang', 'Wenting Chen', 'Xiaohan Xing', 'Sean He', 'Xiaoling Luo', 'Xinheng Lyu', 'Linlin Shen', 'Guoping Qiu']",2025-03-18,"['cs.CV', 'cs.LG']",submitted to IJCAI2025,http://arxiv.org/pdf/2503.13862v1
2503.13858v1,MamBEV: Enabling State Space Models to Learn Birds-Eye-View Representations,"3D visual perception tasks, such as 3D detection from multi-camera images,
are essential components of autonomous driving and assistance systems. However,
designing computationally efficient methods remains a significant challenge. In
this paper, we propose a Mamba-based framework called MamBEV, which learns
unified Bird's Eye View (BEV) representations using linear spatio-temporal
SSM-based attention. This approach supports multiple 3D perception tasks with
significantly improved computational and memory efficiency. Furthermore, we
introduce SSM based cross-attention, analogous to standard cross attention,
where BEV query representations can interact with relevant image features.
Extensive experiments demonstrate MamBEV's promising performance across diverse
visual perception metrics, highlighting its advantages in input scaling
efficiency compared to existing benchmark models.","['Hongyu Ke', 'Jack Morris', 'Kentaro Oguchi', 'Xiaofei Cao', 'Yongkang Liu', 'Haoxin Wang', 'Yi Ding']",2025-03-18,"['cs.CV', 'cs.LG']",,http://arxiv.org/pdf/2503.13858v1
2503.13844v1,Spotting Persuasion: A Low-cost Model for Persuasion Detection in Political Ads on Social Media,"In the realm of political advertising, persuasion operates as a pivotal
element within the broader framework of propaganda, exerting profound
influences on public opinion and electoral outcomes. In this paper, we (1)
introduce a lightweight model for persuasive text detection that achieves
state-of-the-art performance in Subtask 3 of SemEval 2023 Task 3, while
significantly reducing the computational resource requirements; and (2)
leverage the proposed model to gain insights into political campaigning
strategies on social media platforms by applying it to a real-world dataset we
curated, consisting of Facebook political ads from the 2022 Australian Federal
election campaign. Our study shows how subtleties can be found in persuasive
political advertisements and presents a pragmatic approach to detect and
analyze such strategies with limited resources, enhancing transparency in
social media political campaigns.","['Elyas Meguellati', 'Stefano Civelli', 'Pietro Bernardelle', 'Shazia Sadiq', 'Gianluca Demartini']",2025-03-18,"['cs.CL', 'cs.AI', 'cs.CY', 'cs.LG']",,http://arxiv.org/pdf/2503.13844v1
2503.13842v1,Counterfactual experience augmented off-policy reinforcement learning,"Reinforcement learning control algorithms face significant challenges due to
out-of-distribution and inefficient exploration problems. While model-based
reinforcement learning enhances the agent's reasoning and planning capabilities
by constructing virtual environments, training such virtual environments can be
very complex. In order to build an efficient inference model and enhance the
representativeness of learning data, we propose the Counterfactual Experience
Augmentation (CEA) algorithm. CEA leverages variational autoencoders to model
the dynamic patterns of state transitions and introduces randomness to model
non-stationarity. This approach focuses on expanding the learning data in the
experience pool through counterfactual inference and performs exceptionally
well in environments that follow the bisimulation assumption. Environments with
bisimulation properties are usually represented by discrete observation and
action spaces, we propose a sampling method based on maximum kernel density
estimation entropy to extend CEA to various environments. By providing reward
signals for counterfactual state transitions based on real information, CEA
constructs a complete counterfactual experience to alleviate the
out-of-distribution problem of the learning data, and outperforms general SOTA
algorithms in environments with difference properties. Finally, we discuss the
similarities, differences and properties of generated counterfactual
experiences and real experiences. The code is available at
https://github.com/Aegis1863/CEA.","['Sunbowen Lee', 'Yicheng Gong', 'Chao Deng']",2025-03-18,"['cs.LG', 'cs.AI', 'stat.ML']","Accepted by Neurocomputing,
  https://doi.org/10.1016/j.neucom.2025.130017",http://arxiv.org/pdf/2503.13842v1
2503.13837v2,Self-Vocabularizing Training for Neural Machine Translation,"Past vocabulary learning techniques identify relevant vocabulary before
training, relying on statistical and entropy-based assumptions that largely
neglect the role of model training. Empirically, we observe that trained
translation models are induced to use a byte-pair encoding (BPE) vocabulary
subset distinct from the original BPE vocabulary, leading to performance
improvements when retrained with the induced vocabulary. In this paper, we
analyze this discrepancy in neural machine translation by examining vocabulary
and entropy shifts during self-training--where each iteration generates a
labeled dataset by pairing source sentences with the model's predictions to
define a new vocabulary. Building on these insights, we propose
self-vocabularizing training, an iterative method that self-selects a smaller,
more optimal vocabulary, yielding up to a 1.49 BLEU improvement. Moreover, we
find that deeper model architectures lead to both an increase in unique token
usage and a 6-8% reduction in vocabulary size.","['Pin-Jie Lin', 'Ernie Chang']",2025-03-18,"['cs.CL', 'cs.LG']",Accepted to NAACL SRW 2025,http://arxiv.org/pdf/2503.13837v2
2503.13836v1,SALAD: Skeleton-aware Latent Diffusion for Text-driven Motion Generation and Editing,"Text-driven motion generation has advanced significantly with the rise of
denoising diffusion models. However, previous methods often oversimplify
representations for the skeletal joints, temporal frames, and textual words,
limiting their ability to fully capture the information within each modality
and their interactions. Moreover, when using pre-trained models for downstream
tasks, such as editing, they typically require additional efforts, including
manual interventions, optimization, or fine-tuning. In this paper, we introduce
a skeleton-aware latent diffusion (SALAD), a model that explicitly captures the
intricate inter-relationships between joints, frames, and words. Furthermore,
by leveraging cross-attention maps produced during the generation process, we
enable attention-based zero-shot text-driven motion editing using a pre-trained
SALAD model, requiring no additional user input beyond text prompts. Our
approach significantly outperforms previous methods in terms of text-motion
alignment without compromising generation quality, and demonstrates practical
versatility by providing diverse editing capabilities beyond generation. Code
is available at project page.","['Seokhyeon Hong', 'Chaelin Kim', 'Serin Yoon', 'Junghyun Nam', 'Sihun Cha', 'Junyong Noh']",2025-03-18,"['cs.CV', 'cs.AI', 'cs.GR', 'cs.LG']","CVPR 2025; Project page
  https://seokhyeonhong.github.io/projects/salad/",http://arxiv.org/pdf/2503.13836v1
2503.13833v1,Causal Discovery from Data Assisted by Large Language Models,"Knowledge driven discovery of novel materials necessitates the development of
the causal models for the property emergence. While in classical physical
paradigm the causal relationships are deduced based on the physical principles
or via experiment, rapid accumulation of observational data necessitates
learning causal relationships between dissimilar aspects of materials structure
and functionalities based on observations. For this, it is essential to
integrate experimental data with prior domain knowledge. Here we demonstrate
this approach by combining high-resolution scanning transmission electron
microscopy (STEM) data with insights derived from large language models (LLMs).
By fine-tuning ChatGPT on domain-specific literature, such as arXiv papers on
ferroelectrics, and combining obtained information with data-driven causal
discovery, we construct adjacency matrices for Directed Acyclic Graphs (DAGs)
that map the causal relationships between structural, chemical, and
polarization degrees of freedom in Sm-doped BiFeO3 (SmBFO). This approach
enables us to hypothesize how synthesis conditions influence material
properties, particularly the coercive field (E0), and guides experimental
validation. The ultimate objective of this work is to develop a unified
framework that integrates LLM-driven literature analysis with data-driven
discovery, facilitating the precise engineering of ferroelectric materials by
establishing clear connections between synthesis conditions and their resulting
material properties.","['Kamyar Barakati', 'Alexander Molak', 'Chris Nelson', 'Xiaohang Zhang', 'Ichiro Takeuchi', 'Sergei V. Kalinin']",2025-03-18,"['cond-mat.mtrl-sci', 'cs.LG']","12 pages, 5 figures",http://arxiv.org/pdf/2503.13833v1
2503.13817v1,VARP: Reinforcement Learning from Vision-Language Model Feedback with Agent Regularized Preferences,"Designing reward functions for continuous-control robotics often leads to
subtle misalignments or reward hacking, especially in complex tasks.
Preference-based RL mitigates some of these pitfalls by learning rewards from
comparative feedback rather than hand-crafted signals, yet scaling human
annotations remains challenging. Recent work uses Vision-Language Models (VLMs)
to automate preference labeling, but a single final-state image generally fails
to capture the agent's full motion. In this paper, we present a two-part
solution that both improves feedback accuracy and better aligns reward learning
with the agent's policy. First, we overlay trajectory sketches on final
observations to reveal the path taken, allowing VLMs to provide more reliable
preferences-improving preference accuracy by approximately 15-20% in metaworld
tasks. Second, we regularize reward learning by incorporating the agent's
performance, ensuring that the reward model is optimized based on data
generated by the current policy; this addition boosts episode returns by 20-30%
in locomotion tasks. Empirical studies on metaworld demonstrate that our method
achieves, for instance, around 70-80% success rate in all tasks, compared to
below 50% for standard approaches. These results underscore the efficacy of
combining richer visual representations with agent-aware reward regularization.","['Anukriti Singh', 'Amisha Bhaskar', 'Peihong Yu', 'Souradip Chakraborty', 'Ruthwik Dasyam', 'Amrit Bedi', 'Pratap Tokekar']",2025-03-18,"['cs.AI', 'cs.HC', 'cs.LG', 'cs.RO']",8 pages,http://arxiv.org/pdf/2503.13817v1
2503.13805v1,Text-Guided Image Invariant Feature Learning for Robust Image Watermarking,"Ensuring robustness in image watermarking is crucial for and maintaining
content integrity under diverse transformations. Recent self-supervised
learning (SSL) approaches, such as DINO, have been leveraged for watermarking
but primarily focus on general feature representation rather than explicitly
learning invariant features. In this work, we propose a novel text-guided
invariant feature learning framework for robust image watermarking. Our
approach leverages CLIP's multimodal capabilities, using text embeddings as
stable semantic anchors to enforce feature invariance under distortions. We
evaluate the proposed method across multiple datasets, demonstrating superior
robustness against various image transformations. Compared to state-of-the-art
SSL methods, our model achieves higher cosine similarity in feature consistency
tests and outperforms existing watermarking schemes in extraction accuracy
under severe distortions. These results highlight the efficacy of our method in
learning invariant representations tailored for robust deep learning-based
watermarking.","['Muhammad Ahtesham', 'Xin Zhong']",2025-03-18,"['cs.CV', 'cs.LG', 'cs.MM']",,http://arxiv.org/pdf/2503.13805v1
2503.13798v1,AI-Powered Prediction of Nanoparticle Pharmacokinetics: A Multi-View Learning Approach,"The clinical translation of nanoparticle-based treatments remains limited due
to the unpredictability of (nanoparticle) NP
pharmacokinetics$\unicode{x2014}$how they distribute, accumulate, and clear
from the body. Predicting these behaviours is challenging due to complex
biological interactions and the difficulty of obtaining high-quality
experimental datasets. Existing AI-driven approaches rely heavily on
data-driven learning but fail to integrate crucial knowledge about NP
properties and biodistribution mechanisms. We introduce a multi-view deep
learning framework that enhances pharmacokinetic predictions by incorporating
prior knowledge of key NP properties such as size and charge into a
cross-attention mechanism, enabling context-aware feature selection and
improving generalization despite small datasets. To further enhance prediction
robustness, we employ an ensemble learning approach, combining deep learning
with XGBoost (XGB) and Random Forest (RF), which significantly outperforms
existing AI models. Our interpretability analysis reveals key physicochemical
properties driving NP biodistribution, providing biologically meaningful
insights into possible mechanisms governing NP behaviour in vivo rather than a
black-box model. Furthermore, by bridging machine learning with physiologically
based pharmacokinetic (PBPK) modelling, this work lays the foundation for
data-efficient AI-driven drug discovery and precision nanomedicine.","['Amirhossein Khakpour', 'Lucia Florescu', 'Richard Tilley', 'Haibo Jiang', 'K. Swaminathan Iyer', 'Gustavo Carneiro']",2025-03-18,"['cs.LG', 'cs.AI']",,http://arxiv.org/pdf/2503.13798v1
2503.13795v1,"BurTorch: Revisiting Training from First Principles by Coupling Autodiff, Math Optimization, and Systems","In this work, we introduce BurTorch, a compact high-performance framework
designed to optimize Deep Learning (DL) training on single-node workstations
through an exceptionally efficient CPU-based backpropagation (Rumelhart et al.,
1986; Linnainmaa, 1970) implementation. Although modern DL frameworks rely on
compilerlike optimizations internally, BurTorch takes a different path. It
adopts a minimalist design and demonstrates that, in these circumstances,
classical compiled programming languages can play a significant role in DL
research. By eliminating the overhead of large frameworks and making efficient
implementation choices, BurTorch achieves orders-of-magnitude improvements in
performance and memory efficiency when computing $\nabla f(x)$ on a CPU.
BurTorch features a compact codebase designed to achieve two key goals
simultaneously. First, it provides a user experience similar to script-based
programming environments. Second, it dramatically minimizes runtime overheads.
In large DL frameworks, the primary source of memory overhead for relatively
small computation graphs $f(x)$ is due to feature-heavy implementations. We
benchmarked BurTorch against widely used DL frameworks in their execution
modes: JAX (Bradbury et al., 2018), PyTorch (Paszke et al., 2019), TensorFlow
(Abadi et al., 2016); and several standalone libraries: Autograd (Maclaurin et
al., 2015), Micrograd (Karpathy, 2020), Apple MLX (Hannun et al., 2023). For
small compute graphs, BurTorch outperforms best-practice solutions by up to
$\times 2000$ in runtime and reduces memory consumption by up to $\times 3500$.
For a miniaturized GPT-3 model (Brown et al., 2020), BurTorch achieves up to a
$\times 20$ speedup and reduces memory up to $\times 80$ compared to PyTorch.","['Konstantin Burlachenko', 'Peter Richtárik']",2025-03-18,"['cs.LG', 'cs.MS', '65Y10', 'I.2.6; I.2.8; C.1.3; C.5.3; G.4; C.3']","46 pages, 7 figures, 19 tables",http://arxiv.org/pdf/2503.13795v1
2503.14556v1,Designing and Deploying AI Models for Sustainable Logistics Optimization: A Case Study on Eco-Efficient Supply Chains in the USA,"The rapid evolution of Artificial Intelligence (AI) and Machine Learning (ML)
has significantly transformed logistics and supply chain management,
particularly in the pursuit of sustainability and eco-efficiency. This study
explores AI-based methodologies for optimizing logistics operations in the USA,
focusing on reducing environmental impact, improving fuel efficiency, and
minimizing costs. Key AI applications include predictive analytics for demand
forecasting, route optimization through machine learning, and AI-powered fuel
efficiency strategies. Various models, such as Linear Regression, XGBoost,
Support Vector Machine, and Neural Networks, are applied to real-world
logistics datasets to reduce carbon emissions based on logistics operations,
optimize travel routes to minimize distance and travel time, and predict future
deliveries to plan optimal routes. Other models such as K-Means and DBSCAN are
also used to optimize travel routes to minimize distance and travel time for
logistics operations. This study utilizes datasets from logistics companies'
databases. The study also assesses model performance using metrics such as mean
absolute error (MAE), mean squared error (MSE), and R2 score. This study also
explores how these models can be deployed to various platforms for real-time
logistics and supply chain use. The models are also examined through a thorough
case study, highlighting best practices and regulatory frameworks that promote
sustainability. The findings demonstrate AI's potential to enhance logistics
efficiency, reduce carbon footprints, and contribute to a more resilient and
adaptive supply chain ecosystem.","['Reza E Rabbi Shawon', 'MD Rokibul Hasan', 'Md Anisur Rahman', 'Mohamed Ghandri', 'Iman Ahmed Lamari', 'Mohammed Kawsar', 'Rubi Akter']",2025-03-18,"['cs.LG', 'cs.AI']",,http://arxiv.org/pdf/2503.14556v1
2503.13791v1,ROCK: A variational formulation for occupation kernel methods in Reproducing Kernel Hilbert Spaces,"We present a Representer Theorem result for a large class of weak formulation
problems. We provide examples of applications of our formulation both in
traditional machine learning and numerical methods as well as in new and
emerging techniques. Finally we apply our formulation to generalize the
multivariate occupation kernel (MOCK) method for learning dynamical systems
from data proposing the more general Riesz Occupation Kernel (ROCK) method. Our
generalized methods are both more computationally efficient and performant on
most of the benchmarks we test against.","['Victor Rielly', 'Kamel Lahouel', 'Chau Nguyen', 'Bruno Jedynak']",2025-03-18,"['stat.ML', 'cs.LG']",,http://arxiv.org/pdf/2503.13791v1
2503.13786v1,Evaluating the Application of SOLID Principles in Modern AI Framework Architectures,"This research evaluates the extent to which modern AI frameworks,
specifically TensorFlow and scikit-learn, adhere to the SOLID design principles
- Single Responsibility, Open/Closed, Liskov Substitution, Interface
Segregation, and Dependency Inversion. Analyzing the frameworks architectural
documentation and design philosophies, this research investigates architectural
trade-offs when balancing software engineering best practices with AI-specific
needs. I examined each frameworks documentation, source code, and architectural
components to evaluate their adherence to these principles. The results show
that both frameworks adopt certain aspects of SOLID design principles but make
intentional trade-offs to address performance, scalability, and the
experimental nature of AI development. TensorFlow focuses on performance and
scalability, sometimes sacrificing strict adherence to principles like Single
Responsibility and Interface Segregation. While scikit-learns design philosophy
aligns more closely with SOLID principles through consistent interfaces and
composition principles, sticking closer to SOLID guidelines but with occasional
deviations for performance optimizations and scalability. This research
discovered that applying SOLID principles in AI frameworks depends on context,
as performance, scalability, and flexibility often require deviations from
traditional software engineering principles. This research contributes to
understanding how domain-specific constraints influence architectural decisions
in modern AI frameworks and how these frameworks strategically adapted design
choices to effectively balance these contradicting requirements.",['Jonesh Shrestha'],2025-03-18,"['cs.SE', 'cs.AI', 'cs.LG', '68N19, 68T01', 'D.2.11; I.2.0']","5 pages, 1 figure, 12 references",http://arxiv.org/pdf/2503.13786v1
2503.13766v1,A finite-sample bound for identifying partially observed linear switched systems from a single trajectory,"We derive a finite-sample probabilistic bound on the parameter estimation
error of a system identification algorithm for Linear Switched Systems. The
algorithm estimates Markov parameters from a single trajectory and applies a
variant of the Ho-Kalman algorithm to recover the system matrices. Our bound
guarantees statistical consistency under the assumption that the true system
exhibits quadratic stability. The proof leverages the theory of weakly
dependent processes. To the best of our knowledge, this is the first
finite-sample bound for this algorithm in the single-trajectory setting.","['Daniel Racz', 'Mihaly Petreczky', 'Balint Daroczy']",2025-03-17,"['cs.LG', 'cs.SY', 'eess.SY']",,http://arxiv.org/pdf/2503.13766v1
2503.13764v1,Effective Dimension Aware Fractional-Order Stochastic Gradient Descent for Convex Optimization Problems,"Fractional-order stochastic gradient descent (FOSGD) leverages a fractional
exponent to capture long-memory effects in optimization, yet its practical
impact is often constrained by the difficulty of tuning and stabilizing this
exponent. In this work, we introduce 2SED Fractional-Order Stochastic Gradient
Descent (2SEDFOSGD), a novel method that synergistically combines the Two-Scale
Effective Dimension (2SED) algorithm with FOSGD to automatically calibrate the
fractional exponent in a data-driven manner. By continuously gauging model
sensitivity and effective dimensionality, 2SED dynamically adjusts the exponent
to curb erratic oscillations and enhance convergence rates. Theoretically, we
demonstrate how this dimension-aware adaptation retains the benefits of
fractional memory while averting the sluggish or unstable behaviors frequently
observed in naive fractional SGD. Empirical evaluations across multiple
benchmarks confirm that our 2SED-driven fractional exponent approach not only
converges faster but also achieves more robust final performance, suggesting
broad applicability for fractional-order methodologies in large-scale machine
learning and related domains.","['Mohammad Partohaghighi', 'Roummel Marcia', 'YangQuan Chen']",2025-03-17,"['cs.LG', 'math.OC']",IEEE L-CSS submitted,http://arxiv.org/pdf/2503.13764v1
2503.13763v1,Neural Edge Histogram Descriptors for Underwater Acoustic Target Recognition,"Numerous maritime applications rely on the ability to recognize acoustic
targets using passive sonar. While there is a growing reliance on pre-trained
models for classification tasks, these models often require extensive
computational resources and may not perform optimally when transferred to new
domains due to dataset variations. To address these challenges, this work
adapts the neural edge histogram descriptors (NEHD) method originally developed
for image classification, to classify passive sonar signals. We conduct a
comprehensive evaluation of statistical and structural texture features,
demonstrating that their combination achieves competitive performance with
large pre-trained models. The proposed NEHD-based approach offers a lightweight
and efficient solution for underwater target recognition, significantly
reducing computational costs while maintaining accuracy.","['Atharva Agashe', 'Davelle Carreiro', 'Alexandra Van Dine', 'Joshua Peeples']",2025-03-17,"['cs.LG', 'cs.SD', 'eess.AS']","6 pages, 5 figures. This work has been accepted to IEEE OCEANS 2025",http://arxiv.org/pdf/2503.13763v1
2503.14554v1,Synchronous vs Asynchronous Reinforcement Learning in a Real World Robot,"In recent times, reinforcement learning (RL) with physical robots has
attracted the attention of a wide range of researchers. However,
state-of-the-art RL algorithms do not consider that physical environments do
not wait for the RL agent to make decisions or updates. RL agents learn by
periodically conducting computationally expensive gradient updates. When
decision-making and gradient update tasks are carried out sequentially by the
RL agent in a physical robot, it significantly increases the agent's response
time. In a rapidly changing environment, this increased response time may be
detrimental to the performance of the learning agent. Asynchronous RL methods,
which separate the computation of decision-making and gradient updates, are a
potential solution to this problem. However, only a few comparisons between
asynchronous and synchronous RL have been made with physical robots. For this
reason, the exact performance benefits of using asynchronous RL methods over
synchronous RL methods are still unclear. In this study, we provide a
performance comparison between asynchronous and synchronous RL using a physical
robotic arm called Franka Emika Panda. Our experiments show that the agents
learn faster and attain significantly more returns using asynchronous RL. Our
experiments also demonstrate that the learning agent with a faster response
time performs better than the agent with a slower response time, even if the
agent with a slower response time performs a higher number of gradient updates.","['Ali Parsaee', 'Fahim Shahriar', 'Chuxin He', 'Ruiqing Tan']",2025-03-17,"['cs.RO', 'cs.AI', 'cs.CV', 'cs.LG']","Presented at Alberta Robotics & Intelligent Systems Expo (RISE)
  Conference",http://arxiv.org/pdf/2503.14554v1
2503.13751v1,Optimizing ML Training with Metagradient Descent,"A major challenge in training large-scale machine learning models is
configuring the training process to maximize model performance, i.e., finding
the best training setup from a vast design space. In this work, we unlock a
gradient-based approach to this problem. We first introduce an algorithm for
efficiently calculating metagradients -- gradients through model training -- at
scale. We then introduce a ""smooth model training"" framework that enables
effective optimization using metagradients. With metagradient descent (MGD), we
greatly improve on existing dataset selection methods, outperform
accuracy-degrading data poisoning attacks by an order of magnitude, and
automatically find competitive learning rate schedules.","['Logan Engstrom', 'Andrew Ilyas', 'Benjamin Chen', 'Axel Feldmann', 'William Moses', 'Aleksander Madry']",2025-03-17,"['stat.ML', 'cs.AI', 'cs.LG']",,http://arxiv.org/pdf/2503.13751v1
2503.14553v1,Redefining non-IID Data in Federated Learning for Computer Vision Tasks: Migrating from Labels to Embeddings for Task-Specific Data Distributions,"Federated Learning (FL) represents a paradigm shift in distributed machine
learning (ML), enabling clients to train models collaboratively while keeping
their raw data private. This paradigm shift from traditional centralized ML
introduces challenges due to the non-iid (non-independent and identically
distributed) nature of data across clients, significantly impacting FL's
performance. Existing literature, predominantly model data heterogeneity by
imposing label distribution skew across clients. In this paper, we show that
label distribution skew fails to fully capture the real-world data
heterogeneity among clients in computer vision tasks beyond classification.
Subsequently, we demonstrate that current approaches overestimate FL's
performance by relying on label/class distribution skew, exposing an overlooked
gap in the literature. By utilizing pre-trained deep neural networks to extract
task-specific data embeddings, we define task-specific data heterogeneity
through the lens of each vision task and introduce a new level of data
heterogeneity called embedding-based data heterogeneity. Our methodology
involves clustering data points based on embeddings and distributing them among
clients using the Dirichlet distribution. Through extensive experiments, we
evaluate the performance of different FL methods under our revamped notion of
data heterogeneity, introducing new benchmark performance measures to the
literature. We further unveil a series of open research directions that can be
pursued.","['Kasra Borazjani', 'Payam Abdisarabshali', 'Naji Khosravan', 'Seyyedali Hosseinalipour']",2025-03-17,"['cs.CV', 'cs.LG']","14 pages, 9 figures, 1 table, (implementations are included at our
  GitHub repository: https://github.com/KasraBorazjani/task-perspective-het)",http://arxiv.org/pdf/2503.14553v1
2503.13709v1,Multi-modal Time Series Analysis: A Tutorial and Survey,"Multi-modal time series analysis has recently emerged as a prominent research
area in data mining, driven by the increasing availability of diverse data
modalities, such as text, images, and structured tabular data from real-world
sources. However, effective analysis of multi-modal time series is hindered by
data heterogeneity, modality gap, misalignment, and inherent noise. Recent
advancements in multi-modal time series methods have exploited the multi-modal
context via cross-modal interactions based on deep learning methods,
significantly enhancing various downstream tasks. In this tutorial and survey,
we present a systematic and up-to-date overview of multi-modal time series
datasets and methods. We first state the existing challenges of multi-modal
time series analysis and our motivations, with a brief introduction of
preliminaries. Then, we summarize the general pipeline and categorize existing
methods through a unified cross-modal interaction framework encompassing
fusion, alignment, and transference at different levels (\textit{i.e.}, input,
intermediate, output), where key concepts and ideas are highlighted. We also
discuss the real-world applications of multi-modal analysis for both standard
and spatial time series, tailored to general and specific domains. Finally, we
discuss future research directions to help practitioners explore and exploit
multi-modal time series. The up-to-date resources are provided in the GitHub
repository: https://github.com/UConn-DSIS/Multi-modal-Time-Series-Analysis","['Yushan Jiang', 'Kanghui Ning', 'Zijie Pan', 'Xuyang Shen', 'Jingchao Ni', 'Wenchao Yu', 'Anderson Schneider', 'Haifeng Chen', 'Yuriy Nevmyvaka', 'Dongjin Song']",2025-03-17,['cs.LG'],,http://arxiv.org/pdf/2503.13709v1
2503.13695v1,Mitigating Spectral Bias in Neural Operators via High-Frequency Scaling for Physical Systems,"Neural operators have emerged as powerful surrogates for modeling complex
physical problems. However, they suffer from spectral bias making them
oblivious to high-frequency modes, which are present in multiscale physical
systems. Therefore, they tend to produce over-smoothed solutions, which is
particularly problematic in modeling turbulence and for systems with intricate
patterns and sharp gradients such as multi-phase flow systems. In this work, we
introduce a new approach named high-frequency scaling (HFS) to mitigate
spectral bias in convolutional-based neural operators. By integrating HFS with
proper variants of UNet neural operators, we demonstrate a higher prediction
accuracy by mitigating spectral bias in single and two-phase flow problems.
Unlike Fourier-based techniques, HFS is directly applied to the latent space,
thus eliminating the computational cost associated with the Fourier transform.
Additionally, we investigate alternative spectral bias mitigation through
diffusion models conditioned on neural operators. While the diffusion model
integrated with the standard neural operator may still suffer from significant
errors, these errors are substantially reduced when the diffusion model is
integrated with a HFS-enhanced neural operator.","['Siavash Khodakarami', 'Vivek Oommen', 'Aniruddha Bora', 'George Em Karniadakis']",2025-03-17,"['cs.LG', 'physics.comp-ph']",,http://arxiv.org/pdf/2503.13695v1
2503.13690v1,Atyaephyra at SemEval-2025 Task 4: Low-Rank NPO,"We present a submission to the SemEval 2025 shared task on unlearning
sensitive content from LLMs. Our approach employs negative preference
optimization using low-rank adaptation. We show that we can utilize this
combination to cheaply compute additional regularization terms, which help with
unlearning stabilization. The results of our approach significantly exceed the
shared task baselines.","['Jan Bronec', 'Jindřich Helcl']",2025-03-17,"['cs.CL', 'cs.AI', 'cs.LG', '68T50 (Primary), 68T07 (Secondary)', 'I.2.7']","5 pages, 1 figure, 1 table, submitted to SemEval proceedings for ACL
  Anthology",http://arxiv.org/pdf/2503.13690v1
2503.14550v1,Novel AI-Based Quantification of Breast Arterial Calcification to Predict Cardiovascular Risk,"Women are underdiagnosed and undertreated for cardiovascular disease.
Automatic quantification of breast arterial calcification on screening
mammography can identify women at risk for cardiovascular disease and enable
earlier treatment and management of disease. In this retrospective study of
116,135 women from two healthcare systems, a transformer-based neural network
quantified BAC severity (no BAC, mild, moderate, and severe) on screening
mammograms. Outcomes included major adverse cardiovascular events (MACE) and
all-cause mortality. BAC severity was independently associated with MACE after
adjusting for cardiovascular risk factors, with increasing hazard ratios from
mild (HR 1.18-1.22), moderate (HR 1.38-1.47), to severe BAC (HR 2.03-2.22)
across datasets (all p<0.001). This association remained significant across all
age groups, with even mild BAC indicating increased risk in women under 50. BAC
remained an independent predictor when analyzed alongside ASCVD risk scores,
showing significant associations with myocardial infarction, stroke, heart
failure, and mortality (all p<0.005). Automated BAC quantification enables
opportunistic cardiovascular risk assessment during routine mammography without
additional radiation or cost. This approach provides value beyond traditional
risk factors, particularly in younger women, offering potential for early CVD
risk stratification in the millions of women undergoing annual mammography.","['Theodorus Dapamede', 'Aisha Urooj', 'Vedant Joshi', 'Gabrielle Gershon', 'Frank Li', 'Mohammadreza Chavoshi', 'Beatrice Brown-Mulry', 'Rohan Satya Isaac', 'Aawez Mansuri', 'Chad Robichaux', 'Chadi Ayoub', 'Reza Arsanjani', 'Laurence Sperling', 'Judy Gichoya', 'Marly van Assen', 'Charles W. ONeill', 'Imon Banerjee', 'Hari Trivedi']",2025-03-17,"['eess.IV', 'cs.AI', 'cs.CV', 'cs.LG']",,http://arxiv.org/pdf/2503.14550v1
2503.13679v1,PrETi: Predicting Execution Time in Early Stage with LLVM and Machine Learning,"We introduce preti, a novel framework for predicting software execution time
during the early stages of development. preti leverages an LLVM-based
simulation environment to extract timing-related runtime information, such as
the count of executed LLVM IR instructions. This information, combined with
historical execution time data, is utilized to train machine learning models
for accurate time prediction. To further enhance prediction accuracy, our
approach incorporates simulations of cache accesses and branch prediction. The
evaluations on public benchmarks demonstrate that preti achieves an average
Absolute Percentage Error (APE) of 11.98\%, surpassing state-of-the-art
methods. These results underscore the effectiveness and efficiency of preti as
a robust solution for early-stage timing analysis.","['Risheng Xu', 'Philipp Sieweck', 'Hermann von Hasseln', 'Dirk Nowotka']",2025-03-17,"['cs.PF', 'cs.LG']",,http://arxiv.org/pdf/2503.13679v1
2503.14549v1,Sampling Decisions,"In this manuscript we introduce a novel Decision Flow (DF) framework for
sampling from a target distribution while incorporating additional guidance
from a prior sampler. DF can be viewed as an AI driven algorithmic
reincarnation of the Markov Decision Process (MDP) approach in Stochastic
Optimal Control. It extends the continuous space, continuous time path Integral
Diffusion sampling technique to discrete time and space, while also
generalizing the Generative Flow Network framework. In its most basic form, an
explicit, Neural Network (NN) free formulation, DF leverages the linear
solvability of the the underlying MDP to adjust the transition probabilities of
the prior sampler. The resulting Markov Process is expressed as a convolution
of the reverse time Green's function of the prior sampling with the target
distribution. We illustrate the DF framework through an example of sampling
from the Ising model, discuss potential NN based extensions, and outline how DF
can enhance guided sampling across various applications.","['Michael Chertkov', 'Sungsoo Ahn', 'Hamidreza Behjoo']",2025-03-17,"['cs.LG', 'cond-mat.stat-mech', 'cs.AI', 'cs.SY', 'eess.SY', 'stat.ML']","6 pages, 3 figures",http://arxiv.org/pdf/2503.14549v1
2503.13676v1,Bayesian Kernel Regression for Functional Data,"In supervised learning, the output variable to be predicted is often
represented as a function, such as a spectrum or probability distribution.
Despite its importance, functional output regression remains relatively
unexplored. In this study, we propose a novel functional output regression
model based on kernel methods. Unlike conventional approaches that
independently train regressors with scalar outputs for each measurement point
of the output function, our method leverages the covariance structure within
the function values, akin to multitask learning, leading to enhanced learning
efficiency and improved prediction accuracy. Compared with existing nonlinear
function-on-scalar models in statistical functional data analysis, our model
effectively handles high-dimensional nonlinearity while maintaining a simple
model structure. Furthermore, the fully kernel-based formulation allows the
model to be expressed within the framework of reproducing kernel Hilbert space
(RKHS), providing an analytic form for parameter estimation and a solid
foundation for further theoretical analysis. The proposed model delivers a
functional output predictive distribution derived analytically from a Bayesian
perspective, enabling the quantification of uncertainty in the predicted
function. We demonstrate the model's enhanced prediction performance through
experiments on artificial datasets and density of states prediction tasks in
materials science.","['Minoru Kusaba', 'Megumi Iwayama', 'Ryo Yoshida']",2025-03-17,"['stat.ML', 'cs.LG']",,http://arxiv.org/pdf/2503.13676v1
2503.13647v1,SRBB-Based Quantum State Preparation,"In this work, a scalable algorithm for the approximate quantum state
preparation problem is proposed, facing a challenge of fundamental importance
in many topic areas of quantum computing. The algorithm uses a variational
quantum circuit based on the Standard Recursive Block Basis (SRBB), a
hierarchical construction for the matrix algebra of the $SU(2^n)$ group, which
is capable of linking the variational parameters with the topology of the Lie
group. Compared to the full algebra, using only diagonal components reduces the
number of CNOTs by an exponential factor, as well as the circuit depth, in full
agreement with the relaxation principle, inherent to the approximation
methodology, of minimizing resources while achieving high accuracy. The desired
quantum state is then approximated by a scalable quantum neural network, which
is designed upon the diagonal SRBB sub-algebra. This approach provides a new
scheme for approximate quantum state preparation in a variational framework and
a specific use case for the SRBB hierarchy. The performance of the algorithm is
assessed with different loss functions, like fidelity, trace distance, and
Frobenius norm, in relation to two optimizers: Adam and Nelder-Mead. The
results highlight the potential of SRBB in close connection with the geometry
of unitary groups, achieving high accuracy up to 4 qubits in simulation, but
also its current limitations with an increasing number of qubits. Additionally,
the approximate SRBB-based QSP algorithm has been tested on real quantum
devices to assess its performance with a small number of qubits.","['Giacomo Belli', 'Marco Mordacci', 'Michele Amoretti']",2025-03-17,"['quant-ph', 'cs.LG']","9 pages, 8 figures, 6 tables",http://arxiv.org/pdf/2503.13647v1
2503.13644v1,Quantum EigenGame for excited state calculation,"Computing the excited states of a given Hamiltonian is computationally hard
for large systems, but methods that do so using quantum computers scale
tractably. This problem is equivalent to the PCA problem where we are
interested in decomposing a matrix into a collection of principal components.
Classically, PCA is a well-studied problem setting, for which both centralized
and distributed approaches have been developed. On the distributed side, one
recent approach is that of EigenGame, a game-theoretic approach to finding
eigenvectors where each eigenvector reaches a Nash equilibrium either
sequentially or in parallel. With this work, we extend the EigenGame algorithm
for both a $0^\text{th}$-order approach and for quantum computers, and harness
the framework that quantum computing provides in computing excited states.
Results show that using the Quantum EigenGame allows us to converge to excited
states of a given Hamiltonian without the need of a deflation step. We also
develop theory on error accumulation for finite-differences and parameterized
approaches.","['David Quiroga', 'Jason Han', 'Anastasios Kyrillidis']",2025-03-17,"['quant-ph', 'cs.DS', 'cs.LG', 'math.OC']","Accepted at CPAL 2025, 28 pages",http://arxiv.org/pdf/2503.13644v1
2503.14547v1,Matching Skeleton-based Activity Representations with Heterogeneous Signals for HAR,"In human activity recognition (HAR), activity labels have typically been
encoded in one-hot format, which has a recent shift towards using textual
representations to provide contextual knowledge. Here, we argue that HAR should
be anchored to physical motion data, as motion forms the basis of activity and
applies effectively across sensing systems, whereas text is inherently limited.
We propose SKELAR, a novel HAR framework that pretrains activity
representations from skeleton data and matches them with heterogeneous HAR
signals. Our method addresses two major challenges: (1) capturing core motion
knowledge without context-specific details. We achieve this through a
self-supervised coarse angle reconstruction task that recovers joint rotation
angles, invariant to both users and deployments; (2) adapting the
representations to downstream tasks with varying modalities and focuses. To
address this, we introduce a self-attention matching module that dynamically
prioritizes relevant body parts in a data-driven manner. Given the lack of
corresponding labels in existing skeleton data, we establish MASD, a new HAR
dataset with IMU, WiFi, and skeleton, collected from 20 subjects performing 27
activities. This is the first broadly applicable HAR dataset with
time-synchronized data across three modalities. Experiments show that SKELAR
achieves the state-of-the-art performance in both full-shot and few-shot
settings. We also demonstrate that SKELAR can effectively leverage synthetic
skeleton data to extend its use in scenarios without skeleton collections.","['Shuheng Li', 'Jiayun Zhang', 'Xiaohan Fu', 'Xiyuan Zhang', 'Jingbo Shang', 'Rajesh K. Gupta']",2025-03-17,"['cs.CV', 'cs.LG']",This paper is accepted by SenSys 2025,http://arxiv.org/pdf/2503.14547v1
2503.13623v1,A Convex formulation for linear discriminant analysis,"We present a supervised dimensionality reduction technique called Convex
Linear Discriminant Analysis (ConvexLDA). The proposed model optimizes a
multi-objective cost function by balancing two complementary terms. The first
term pulls the samples of a class towards its centroid by minimizing a sample's
distance from its class-centroid in low dimensional space. The second term
pushes the classes far apart by maximizing their hyperellipsoid scattering
volume via the logarithm of the determinant (\textit{log det}) of the outer
product matrix formed by the low-dimensional class-centroids. Using the
negative of the \textit{log det}, we pose the final cost as a minimization
problem, which balances the two terms using a hyper-parameter $\lambda$. We
demonstrate that the cost function is convex. Unlike Fisher LDA, the proposed
method doesn't require to compute the inverse of a matrix, hence avoiding any
ill-conditioned problem where data dimension is very high, e.g. RNA-seq data.
ConvexLDA doesn't require pair-wise distance calculation, making it faster and
more easily scalable. Moreover, the convex nature of the cost function ensures
global optimality, enhancing the reliability of the learned embedding. Our
experimental evaluation demonstrates that ConvexLDA outperforms several popular
linear discriminant analysis (LDA)-based methods on a range of high-dimensional
biological data, image data sets, etc.","['Sai Vijay Kumar Surineela', 'Prathyusha Kanakamalla', 'Harigovind Harikumar', 'Tomojit Ghosh']",2025-03-17,"['cs.LG', 'cs.CV']","Total pages 29 including references, six figures, seven tables.
  Submitted to an Elsevier journal",http://arxiv.org/pdf/2503.13623v1
2503.13447v1,MetaScale: Test-Time Scaling with Evolving Meta-Thoughts,"One critical challenge for large language models (LLMs) for making complex
reasoning is their reliance on matching reasoning patterns from training data,
instead of proactively selecting the most appropriate cognitive strategy to
solve a given task. Existing approaches impose fixed cognitive structures that
enhance performance in specific tasks but lack adaptability across diverse
scenarios. To address this limitation, we introduce METASCALE, a test-time
scaling framework based on meta-thoughts -- adaptive thinking strategies
tailored to each task. METASCALE initializes a pool of candidate meta-thoughts,
then iteratively selects and evaluates them using a multi-armed bandit
algorithm with upper confidence bound selection, guided by a reward model. To
further enhance adaptability, a genetic algorithm evolves high-reward
meta-thoughts, refining and extending the strategy pool over time. By
dynamically proposing and optimizing meta-thoughts at inference time, METASCALE
improves both accuracy and generalization across a wide range of tasks.
Experimental results demonstrate that MetaScale consistently outperforms
standard inference approaches, achieving an 11% performance gain in win rate on
Arena-Hard for GPT-4o, surpassing o1-mini by 0.9% under style control. Notably,
METASCALE scales more effectively with increasing sampling budgets and produces
more structured, expert-level responses.","['Qin Liu', 'Wenxuan Zhou', 'Nan Xu', 'James Y. Huang', 'Fei Wang', 'Sheng Zhang', 'Hoifung Poon', 'Muhao Chen']",2025-03-17,"['cs.CL', 'cs.AI', 'cs.LG']",Work in progress,http://arxiv.org/pdf/2503.13447v1
2503.13438v1,Deep Belief Markov Models for POMDP Inference,"This work introduces a novel deep learning-based architecture, termed the
Deep Belief Markov Model (DBMM), which provides efficient, model-formulation
agnostic inference in Partially Observable Markov Decision Process (POMDP)
problems. The POMDP framework allows for modeling and solving sequential
decision-making problems under observation uncertainty. In complex,
high-dimensional, partially observable environments, existing methods for
inference based on exact computations (e.g., via Bayes' theorem) or sampling
algorithms do not scale well. Furthermore, ground truth states may not be
available for learning the exact transition dynamics. DBMMs extend deep Markov
models into the partially observable decision-making framework and allow
efficient belief inference entirely based on available observation data via
variational inference methods. By leveraging the potency of neural networks,
DBMMs can infer and simulate non-linear relationships in the system dynamics
and naturally scale to problems with high dimensionality and discrete or
continuous variables. In addition, neural network parameters can be dynamically
updated efficiently based on data availability. DBMMs can thus be used to infer
a belief variable, thus enabling the derivation of POMDP solutions over the
belief space. We evaluate the efficacy of the proposed methodology by
evaluating the capability of model-formulation agnostic inference of DBMMs in
benchmark problems that include discrete and continuous variables.","['Giacomo Arcieri', 'Konstantinos G. Papakonstantinou', 'Daniel Straub', 'Eleni Chatzi']",2025-03-17,"['cs.LG', 'cs.AI']",,http://arxiv.org/pdf/2503.13438v1
2503.13436v1,Unified Autoregressive Visual Generation and Understanding with Continuous Tokens,"We present UniFluid, a unified autoregressive framework for joint visual
generation and understanding leveraging continuous visual tokens. Our unified
autoregressive architecture processes multimodal image and text inputs,
generating discrete tokens for text and continuous tokens for image. We find
though there is an inherent trade-off between the image generation and
understanding task, a carefully tuned training recipe enables them to improve
each other. By selecting an appropriate loss balance weight, the unified model
achieves results comparable to or exceeding those of single-task baselines on
both tasks. Furthermore, we demonstrate that employing stronger pre-trained
LLMs and random-order generation during training is important to achieve
high-fidelity image generation within this unified framework. Built upon the
Gemma model series, UniFluid exhibits competitive performance across both image
generation and understanding, demonstrating strong transferability to various
downstream tasks, including image editing for generation, as well as visual
captioning and question answering for understanding.","['Lijie Fan', 'Luming Tang', 'Siyang Qin', 'Tianhong Li', 'Xuan Yang', 'Siyuan Qiao', 'Andreas Steiner', 'Chen Sun', 'Yuanzhen Li', 'Tao Zhu', 'Michael Rubinstein', 'Michalis Raptis', 'Deqing Sun', 'Radu Soricut']",2025-03-17,"['cs.CV', 'cs.LG']",Tech report,http://arxiv.org/pdf/2503.13436v1
2503.13432v1,Uncovering Utility Functions from Observed Outcomes,"Determining consumer preferences and utility is a foundational challenge in
economics. They are central in determining consumer behaviour through the
utility-maximising consumer decision-making process. However, preferences and
utilities are not observable and may not even be known to the individual making
the choice; only the outcome is observed in the form of demand. Without the
ability to observe the decision-making mechanism, demand estimation becomes a
challenging task and current methods fall short due to lack of scalability or
ability to identify causal effects. Estimating these effects is critical when
considering changes in policy, such as pricing, the impact of taxes and
subsidies, and the effect of a tariff. To address the shortcomings of existing
methods, we combine revealed preference theory and inverse reinforcement
learning to present a novel algorithm, Preference Extraction and Reward
Learning (PEARL) which, to the best of our knowledge, is the only algorithm
that can uncover a representation of the utility function that best
rationalises observed consumer choice data given a specified functional form.
We introduce a flexible utility function, the Input-Concave Neural Network
which captures complex relationships across goods, including cross-price
elasticities. Results show PEARL outperforms the benchmark on both noise-free
and noisy synthetic data.",['Marta Grzeskiewicz'],2025-03-17,['cs.LG'],Working paper,http://arxiv.org/pdf/2503.13432v1
2503.13431v1,Measuring In-Context Computation Complexity via Hidden State Prediction,"Detecting when a neural sequence model does ""interesting"" computation is an
open problem. The next token prediction loss is a poor indicator: Low loss can
stem from trivially predictable sequences that are uninteresting, while high
loss may reflect unpredictable but also irrelevant information that can be
ignored by the model. We propose a better metric: measuring the model's ability
to predict its own future hidden states. We show empirically that this metric
-- in contrast to the next token prediction loss -- correlates with the
intuitive interestingness of the task. To measure predictability, we introduce
the architecture-agnostic ""prediction of hidden states"" (PHi) layer that serves
as an information bottleneck on the main pathway of the network (e.g., the
residual stream in Transformers). We propose a novel learned predictive prior
that enables us to measure the novel information gained in each computation
step, which serves as our metric. We show empirically that our metric predicts
the description length of formal languages learned in-context, the complexity
of mathematical reasoning problems, and the correctness of self-generated
reasoning chains.","['Vincent Herrmann', 'Róbert Csordás', 'Jürgen Schmidhuber']",2025-03-17,"['cs.LG', 'I.2.6']",,http://arxiv.org/pdf/2503.13431v1
2503.13430v1,AugMapNet: Improving Spatial Latent Structure via BEV Grid Augmentation for Enhanced Vectorized Online HD Map Construction,"Autonomous driving requires an understanding of the infrastructure elements,
such as lanes and crosswalks. To navigate safely, this understanding must be
derived from sensor data in real-time and needs to be represented in vectorized
form. Learned Bird's-Eye View (BEV) encoders are commonly used to combine a set
of camera images from multiple views into one joint latent BEV grid.
Traditionally, from this latent space, an intermediate raster map is predicted,
providing dense spatial supervision but requiring post-processing into the
desired vectorized form. More recent models directly derive infrastructure
elements as polylines using vectorized map decoders, providing instance-level
information. Our approach, Augmentation Map Network (AugMapNet), proposes
latent BEV grid augmentation, a novel technique that significantly enhances the
latent BEV representation. AugMapNet combines vector decoding and dense spatial
supervision more effectively than existing architectures while remaining as
straightforward to integrate and as generic as auxiliary supervision.
Experiments on nuScenes and Argoverse2 datasets demonstrate significant
improvements in vectorized map prediction performance up to 13.3% over the
StreamMapNet baseline on 60m range and greater improvements on larger ranges.
We confirm transferability by applying our method to another baseline and find
similar improvements. A detailed analysis of the latent BEV grid confirms a
more structured latent space of AugMapNet and shows the value of our novel
concept beyond pure performance improvement. The code will be released soon.","['Thomas Monninger', 'Md Zafar Anwar', 'Stanislaw Antol', 'Steffen Staab', 'Sihao Ding']",2025-03-17,"['cs.CV', 'cs.AI', 'cs.LG', 'cs.RO']",,http://arxiv.org/pdf/2503.13430v1
2503.13427v1,xLSTM 7B: A Recurrent LLM for Fast and Efficient Inference,"Recent breakthroughs in solving reasoning, math and coding problems with
Large Language Models (LLMs) have been enabled by investing substantial
computation budgets at inference time. Therefore, inference speed is one of the
most critical properties of LLM architectures, and there is a growing need for
LLMs that are efficient and fast at inference. Recently, LLMs built on the
xLSTM architecture have emerged as a powerful alternative to Transformers,
offering linear compute scaling with sequence length and constant memory usage,
both highly desirable properties for efficient inference. However, such
xLSTM-based LLMs have yet to be scaled to larger models and assessed and
compared with respect to inference speed and efficiency. In this work, we
introduce xLSTM 7B, a 7-billion-parameter LLM that combines xLSTM's
architectural benefits with targeted optimizations for fast and efficient
inference. Our experiments demonstrate that xLSTM 7B achieves performance on
downstream tasks comparable to other similar-sized LLMs, while providing
significantly faster inference speeds and greater efficiency compared to Llama-
and Mamba-based LLMs. These results establish xLSTM 7B as the fastest and most
efficient 7B LLM, offering a solution for tasks that require large amounts of
test-time computation. Our work highlights xLSTM's potential as a foundational
architecture for methods building on heavy use of LLM inference. Our model
weights, model code and training code are open-source.","['Maximilian Beck', 'Korbinian Pöppel', 'Phillip Lippe', 'Richard Kurle', 'Patrick M. Blies', 'Günter Klambauer', 'Sebastian Böck', 'Sepp Hochreiter']",2025-03-17,"['cs.LG', 'cs.AI', 'cs.CL']","Code available at: https://github.com/NX-AI/xlstm and
  https://github.com/NX-AI/xlstm-jax",http://arxiv.org/pdf/2503.13427v1
2503.13423v1,SuperBPE: Space Travel for Language Models,"The assumption across nearly all language model (LM) tokenization schemes is
that tokens should be subwords, i.e., contained within word boundaries. While
providing a seemingly reasonable inductive bias, is this common practice
limiting the potential of modern LMs? Whitespace is not a reliable delimiter of
meaning, as evidenced by multi-word expressions (e.g., ""by the way""),
crosslingual variation in the number of words needed to express a concept
(e.g., ""spacesuit helmet"" in German is ""raumanzughelm""), and languages that do
not use whitespace at all (e.g., Chinese). To explore the potential of
tokenization beyond subwords, we introduce a ""superword"" tokenizer, SuperBPE,
which incorporates a simple pretokenization curriculum into the byte-pair
encoding (BPE) algorithm to first learn subwords, then superwords that bridge
whitespace. This brings dramatic improvements in encoding efficiency: when
fixing the vocabulary size to 200k, SuperBPE encodes a fixed piece of text with
up to 33% fewer tokens than BPE on average. In experiments, we pretrain 8B
transformer LMs from scratch while fixing the model size, vocabulary size, and
train compute, varying *only* the algorithm for learning the vocabulary. Our
model trained with SuperBPE achieves an average +4.0% absolute improvement over
the BPE baseline across 30 downstream tasks (including +8.2% on MMLU), while
simultaneously requiring 27% less compute at inference time. In analysis, we
find that SuperBPE results in segmentations of text that are more uniform in
per-token difficulty. Qualitatively, this may be because SuperBPE tokens often
capture common multi-word expressions that function semantically as a single
unit. SuperBPE is a straightforward, local modification to tokenization that
improves both encoding efficiency and downstream performance, yielding better
language models overall.","['Alisa Liu', 'Jonathan Hayase', 'Valentin Hofmann', 'Sewoong Oh', 'Noah A. Smith', 'Yejin Choi']",2025-03-17,"['cs.CL', 'cs.LG']","preprint, code and artifacts will become available at
  https://superbpe.github.io/",http://arxiv.org/pdf/2503.13423v1
2503.14546v1,The Impact of Artificial Intelligence on Emergency Medicine: A Review of Recent Advances,"Artificial Intelligence (AI) is revolutionizing emergency medicine by
enhancing diagnostic processes and improving patient outcomes. This article
provides a review of the current applications of AI in emergency imaging
studies, focusing on the last five years of advancements. AI technologies,
particularly machine learning and deep learning, are pivotal in interpreting
complex imaging data, offering rapid, accurate diagnoses and potentially
surpassing traditional diagnostic methods. Studies highlighted within the
article demonstrate AI's capabilities in accurately detecting conditions such
as fractures, pneumothorax, and pulmonary diseases from various imaging
modalities including X-rays, CT scans, and MRIs. Furthermore, AI's ability to
predict clinical outcomes like mechanical ventilation needs illustrates its
potential in crisis resource optimization. Despite these advancements, the
integration of AI into clinical practice presents challenges such as data
privacy, algorithmic bias, and the need for extensive validation across diverse
settings. This review underscores the transformative potential of AI in
emergency settings, advocating for a future where AI and clinical expertise
synergize to elevate patient care standards.","['Gustavo Correia', 'Victor Alves', 'Paulo Novais']",2025-03-17,"['eess.IV', 'cs.AI', 'cs.CV', 'cs.LG', '68T07']","20 pages, 2 tables, 2 figures",http://arxiv.org/pdf/2503.14546v1
2503.13414v1,Reward Adaptation Via Q-Manipulation,"In this paper, we propose a new solution to reward adaptation (RA), the
problem where the learning agent adapts to a target reward function based on
one or multiple existing behaviors learned a priori under the same domain
dynamics but different reward functions. Learning the target behavior from
scratch is possible but often inefficient given the available source behaviors.
Our work represents a new approach to RA via the manipulation of Q-functions.
Assuming that the target reward function is a known function of the source
reward functions, our approach to RA computes bounds of the Q function. We
introduce an iterative process to tighten the bounds, similar to value
iteration. This enables action pruning in the target domain before learning
even starts. We refer to such a method as Q-Manipulation (Q-M). We formally
prove that our pruning strategy does not affect the optimality of the returned
policy while empirically show that it improves the sample complexity. Q-M is
evaluated in a variety of synthetic and simulation domains to demonstrate its
effectiveness, generalizability, and practicality.","['Kevin Vora', 'Yu Zhang']",2025-03-17,"['cs.LG', 'cs.AI']",,http://arxiv.org/pdf/2503.13414v1
2503.13404v1,Fed-Joint: Joint Modeling of Nonlinear Degradation Signals and Failure Events for Remaining Useful Life Prediction using Federated Learning,"Many failure mechanisms of machinery are closely related to the behavior of
condition monitoring (CM) signals. To achieve a cost-effective preventive
maintenance strategy, accurate remaining useful life (RUL) prediction based on
the signals is of paramount importance. However, the CM signals are often
recorded at different factories and production lines, with limited amounts of
data. Unfortunately, these datasets have rarely been shared between the sites
due to data confidentiality and ownership issues, a lack of computing and
storage power, and high communication costs associated with data transfer
between sites and a data center. Another challenge in real applications is that
the CM signals are often not explicitly specified \textit{a priori}, meaning
that existing methods, which often usually a parametric form, may not be
applicable. To address these challenges, we propose a new prognostic framework
for RUL prediction using the joint modeling of nonlinear degradation signals
and time-to-failure data within a federated learning scheme. The proposed
method constructs a nonparametric degradation model using a federated
multi-output Gaussian process and then employs a federated survival model to
predict failure times and probabilities for in-service machinery. The
superiority of the proposed method over other alternatives is demonstrated
through comprehensive simulation studies and a case study using turbofan engine
degradation signal data that include run-to-failure events.","['Cheoljoon Jeong', 'Xubo Yue', 'Seokhyun Chung']",2025-03-17,"['cs.AI', 'cs.LG', 'stat.ML']",,http://arxiv.org/pdf/2503.13404v1
2503.13399v1,MicroVQA: A Multimodal Reasoning Benchmark for Microscopy-Based Scientific Research,"Scientific research demands sophisticated reasoning over multimodal data, a
challenge especially prevalent in biology. Despite recent advances in
multimodal large language models (MLLMs) for AI-assisted research, existing
multimodal reasoning benchmarks only target up to college-level difficulty,
while research-level benchmarks emphasize lower-level perception, falling short
of the complex multimodal reasoning needed for scientific discovery. To bridge
this gap, we introduce MicroVQA, a visual-question answering (VQA) benchmark
designed to assess three reasoning capabilities vital in research workflows:
expert image understanding, hypothesis generation, and experiment proposal.
MicroVQA consists of 1,042 multiple-choice questions (MCQs) curated by biology
experts across diverse microscopy modalities, ensuring VQA samples represent
real scientific practice. In constructing the benchmark, we find that standard
MCQ generation methods induce language shortcuts, motivating a new two-stage
pipeline: an optimized LLM prompt structures question-answer pairs into MCQs;
then, an agent-based `RefineBot' updates them to remove shortcuts. Benchmarking
on state-of-the-art MLLMs reveal a peak performance of 53\%; models with
smaller LLMs only slightly underperform top models, suggesting that
language-based reasoning is less challenging than multimodal reasoning; and
tuning with scientific articles enhances performance. Expert analysis of
chain-of-thought responses shows that perception errors are the most frequent,
followed by knowledge errors and then overgeneralization errors. These insights
highlight the challenges in multimodal scientific reasoning, showing MicroVQA
is a valuable resource advancing AI-driven biomedical research. MicroVQA is
available at https://huggingface.co/datasets/jmhb/microvqa, and project page at
https://jmhb0.github.io/microvqa.","['James Burgess', 'Jeffrey J Nirschl', 'Laura Bravo-Sánchez', 'Alejandro Lozano', 'Sanket Rajan Gupte', 'Jesus G. Galaz-Montoya', 'Yuhui Zhang', 'Yuchang Su', 'Disha Bhowmik', 'Zachary Coman', 'Sarina M. Hasan', 'Alexandra Johannesson', 'William D. Leineweber', 'Malvika G Nair', 'Ridhi Yarlagadda', 'Connor Zuraski', 'Wah Chiu', 'Sarah Cohen', 'Jan N. Hansen', 'Manuel D Leonetti', 'Chad Liu', 'Emma Lundberg', 'Serena Yeung-Levy']",2025-03-17,"['cs.CV', 'cs.AI', 'cs.CL', 'cs.LG', 'q-bio.CB']","CVPR 2025 (Conference on Computer Vision and Pattern Recognition)
  Project page at https://jmhb0.github.io/microvqa Benchmark at
  https://huggingface.co/datasets/jmhb/microvqa",http://arxiv.org/pdf/2503.13399v1
2503.14545v1,PANDORA: Diffusion Policy Learning for Dexterous Robotic Piano Playing,"We present PANDORA, a novel diffusion-based policy learning framework
designed specifically for dexterous robotic piano performance. Our approach
employs a conditional U-Net architecture enhanced with FiLM-based global
conditioning, which iteratively denoises noisy action sequences into smooth,
high-dimensional trajectories. To achieve precise key execution coupled with
expressive musical performance, we design a composite reward function that
integrates task-specific accuracy, audio fidelity, and high-level semantic
feedback from a large language model (LLM) oracle. The LLM oracle assesses
musical expressiveness and stylistic nuances, enabling dynamic, hand-specific
reward adjustments. Further augmented by a residual inverse-kinematics
refinement policy, PANDORA achieves state-of-the-art performance in the
ROBOPIANIST environment, significantly outperforming baselines in both
precision and expressiveness. Ablation studies validate the critical
contributions of diffusion-based denoising and LLM-driven semantic feedback in
enhancing robotic musicianship. Videos available at:
https://taco-group.github.io/PANDORA","['Yanjia Huang', 'Renjie Li', 'Zhengzhong Tu']",2025-03-17,"['cs.LG', 'cs.RO', 'cs.SD', 'eess.AS']",,http://arxiv.org/pdf/2503.14545v1
2503.13389v1,Investigating the effect of CPT in lateral spreading prediction using Explainable AI,"This study proposes an autoencoder approach to extract latent features from
cone penetration test profiles to evaluate the potential of incorporating CPT
data in an AI model. We employ autoencoders to compress 200 CPT profiles of
soil behavior type index (Ic) and normalized cone resistance (qc1Ncs) into ten
latent features while preserving critical information. We then utilize the
extracted latent features with site parameters to train XGBoost models for
predicting lateral spreading occurrences in the 2011 Christchurch earthquake.
Models using the latent CPT features outperformed models with conventional CPT
metrics or no CPT data, achieving over 83% accuracy. Explainable AI revealed
the most crucial latent feature corresponding to soil behavior between 1-3
meter depths, highlighting this depth range's criticality for liquefaction
evaluation. The autoencoder approach provides an automated technique for
condensing CPT profiles into informative latent features for machine-learning
liquefaction models.","['Cheng-Hsi Hsiao', 'Ellen Rathje', 'Krishna Kumar']",2025-03-17,"['cs.LG', 'physics.geo-ph']",,http://arxiv.org/pdf/2503.13389v1
2503.13582v1,Spectrally-Corrected and Regularized QDA Classifier for Spiked Covariance Model,"Quadratic discriminant analysis (QDA) is a widely used method for
classification problems, particularly preferable over Linear Discriminant
Analysis (LDA) for heterogeneous data. However, QDA loses its effectiveness in
high-dimensional settings, where the data dimension and sample size tend to
infinity. To address this issue, we propose a novel QDA method utilizing
spectral correction and regularization techniques, termed SR-QDA. The
regularization parameters in our method are selected by maximizing the
Fisher-discriminant ratio. We compare SR-QDA with QDA, regularized quadratic
discriminant analysis (R-QDA), and several other competitors. The results
indicate that SR-QDA performs exceptionally well, especially in moderate and
high-dimensional situations. Empirical experiments across diverse datasets
further support this conclusion.","['Wenya Luo', 'Hua Li', 'Zhidong Bai', 'Zhijun Liu']",2025-03-17,"['cs.LG', 'math.ST', 'stat.TH']",,http://arxiv.org/pdf/2503.13582v1
2503.13385v1,Scale Efficient Training for Large Datasets,"The rapid growth of dataset scales has been a key driver in advancing deep
learning research. However, as dataset scale increases, the training process
becomes increasingly inefficient due to the presence of low-value samples,
including excessive redundant samples, overly challenging samples, and
inefficient easy samples that contribute little to model improvement.To address
this challenge, we propose Scale Efficient Training (SeTa) for large datasets,
a dynamic sample pruning approach that losslessly reduces training time. To
remove low-value samples, SeTa first performs random pruning to eliminate
redundant samples, then clusters the remaining samples according to their
learning difficulty measured by loss. Building upon this clustering, a sliding
window strategy is employed to progressively remove both overly challenging and
inefficient easy clusters following an easy-to-hard curriculum.We conduct
extensive experiments on large-scale synthetic datasets, including ToCa, SS1M,
and ST+MJ, each containing over 3 million samples.SeTa reduces training costs
by up to 50\% while maintaining or improving performance, with minimal
degradation even at 70\% cost reduction. Furthermore, experiments on various
scale real datasets across various backbones (CNNs, Transformers, and Mambas)
and diverse tasks (instruction tuning, multi-view stereo, geo-localization,
composed image retrieval, referring image segmentation) demonstrate the
powerful effectiveness and universality of our approach. Code is available at
https://github.com/mrazhou/SeTa.","['Qing Zhou', 'Junyu Gao', 'Qi Wang']",2025-03-17,"['cs.CV', 'cs.AI', 'cs.LG']",Accepted by CVPR2025,http://arxiv.org/pdf/2503.13385v1
2503.13383v1,"Cream of the Crop: Harvesting Rich, Scalable and Transferable Multi-Modal Data for Instruction Fine-Tuning","The hypothesis that pretrained large language models (LLMs) necessitate only
minimal supervision during the fine-tuning (SFT) stage (Zhou et al., 2024) has
been substantiated by recent advancements in data curation and selection
research. However, their stability and generalizability are compromised due to
the vulnerability to experimental setups and validation protocols, falling
short of surpassing random sampling (Diddee & Ippolito, 2024; Xia et al.,
2024b). Built upon LLMs, multi-modal LLMs (MLLMs), combined with the sheer
token volume and heightened heterogeneity of data sources, amplify both the
significance and complexity of data selection.
  To harvest multi-modal instructional data in a robust and efficient manner,
we re-define the granularity of the quality metric by decomposing it into 14
vision-language-related capabilities, and introduce multi-modal rich scorers to
evaluate the capabilities of each data candidate. To promote diversity, in
light of the inherent objective of the alignment stage, we take interaction
style as diversity indicator and use a multi-modal rich styler to identify data
instruction patterns. In doing so, our multi-modal rich scorers and styler
(mmSSR) guarantee that high-scoring information is conveyed to users in
diversified forms. Free from embedding-based clustering or greedy sampling,
mmSSR efficiently scales to millions of data with varying budget constraints,
supports customization for general or specific capability acquisition, and
facilitates training-free generalization to new domains for curation. Across
10+ experimental settings, validated by 14 multi-modal benchmarks, we
demonstrate consistent improvements over random sampling, baseline strategies
and state-of-the-art selection methods, achieving 99.1% of full performance
with only 30% of the 2.6M data.","['Mengyao Lyu', 'Yan Li', 'Huasong Zhong', 'Wenhao Yang', 'Hui Chen', 'Jungong Han', 'Guiguang Ding', 'Zhenheng Yang']",2025-03-17,"['cs.CV', 'cs.AI', 'cs.CL', 'cs.LG']",update comparison with sota and analysis,http://arxiv.org/pdf/2503.13383v1
2503.13371v1,SyncDiff: Diffusion-based Talking Head Synthesis with Bottlenecked Temporal Visual Prior for Improved Synchronization,"Talking head synthesis, also known as speech-to-lip synthesis, reconstructs
the facial motions that align with the given audio tracks. The synthesized
videos are evaluated on mainly two aspects, lip-speech synchronization and
image fidelity. Recent studies demonstrate that GAN-based and diffusion-based
models achieve state-of-the-art (SOTA) performance on this task, with
diffusion-based models achieving superior image fidelity but experiencing lower
synchronization compared to their GAN-based counterparts. To this end, we
propose SyncDiff, a simple yet effective approach to improve diffusion-based
models using a temporal pose frame with information bottleneck and
facial-informative audio features extracted from AVHuBERT, as conditioning
input into the diffusion process. We evaluate SyncDiff on two canonical talking
head datasets, LRS2 and LRS3 for direct comparison with other SOTA models.
Experiments on LRS2/LRS3 datasets show that SyncDiff achieves a synchronization
score 27.7%/62.3% relatively higher than previous diffusion-based methods,
while preserving their high-fidelity characteristics.","['Xulin Fan', 'Heting Gao', 'Ziyi Chen', 'Peng Chang', 'Mei Han', 'Mark Hasegawa-Johnson']",2025-03-17,['cs.LG'],Accepted to WACV 2025,http://arxiv.org/pdf/2503.13371v1
2503.13366v1,Follow-the-Regularized-Leader with Adversarial Constraints,"Constrained Online Convex Optimization (COCO) can be seen as a generalization
of the standard Online Convex Optimization (OCO) framework. At each round, a
cost function and constraint function are revealed after a learner chooses an
action. The goal is to minimize both the regret and cumulative constraint
violation (CCV) against an adaptive adversary. We show for the first time that
is possible to obtain the optimal $O(\sqrt{T})$ bound on both regret and CCV,
improving the best known bounds of $O \left( \sqrt{T} \right)$ and $\~{O}
\left( \sqrt{T} \right)$ for the regret and CCV, respectively.","['Ricardo N. Ferreira', 'Cláudia Soares']",2025-03-17,"['cs.LG', 'cs.DS', 'math.OC', 'stat.ML']",,http://arxiv.org/pdf/2503.13366v1
2503.13360v1,Mitigating Visual Forgetting via Take-along Visual Conditioning for Multi-modal Long CoT Reasoning,"Recent advancements in Large Language Models (LLMs) have demonstrated
enhanced reasoning capabilities, evolving from Chain-of-Thought (CoT) prompting
to advanced, product-oriented solutions like OpenAI o1. During our
re-implementation of this model, we noticed that in multimodal tasks requiring
visual input (e.g., geometry problems), Multimodal LLMs (MLLMs) struggle to
maintain focus on the visual information, in other words, MLLMs suffer from a
gradual decline in attention to visual information as reasoning progresses,
causing text-over-relied outputs. To investigate this, we ablate image inputs
during long-chain reasoning. Concretely, we truncate the reasoning process
midway, then re-complete the reasoning process with the input image removed. We
observe only a ~2% accuracy drop on MathVista's test-hard subset, revealing the
model's textual outputs dominate the following reasoning process. Motivated by
this, we propose Take-along Visual Conditioning (TVC), a strategy that shifts
image input to critical reasoning stages and compresses redundant visual tokens
via dynamic pruning. This methodology helps the model retain attention to the
visual components throughout the reasoning. Our approach achieves
state-of-the-art performance on average across five mathematical reasoning
benchmarks (+3.4% vs previous sota), demonstrating the effectiveness of TVC in
enhancing multimodal reasoning systems.","['Hai-Long Sun', 'Zhun Sun', 'Houwen Peng', 'Han-Jia Ye']",2025-03-17,"['cs.CV', 'cs.AI', 'cs.LG']","The project page is available at
  https://sun-hailong.github.io/projects/TVC",http://arxiv.org/pdf/2503.13360v1
2503.13356v1,Agents Play Thousands of 3D Video Games,"We present PORTAL, a novel framework for developing artificial intelligence
agents capable of playing thousands of 3D video games through language-guided
policy generation. By transforming decision-making problems into language
modeling tasks, our approach leverages large language models (LLMs) to generate
behavior trees represented in domain-specific language (DSL). This method
eliminates the computational burden associated with traditional reinforcement
learning approaches while preserving strategic depth and rapid adaptability.
Our framework introduces a hybrid policy structure that combines rule-based
nodes with neural network components, enabling both high-level strategic
reasoning and precise low-level control. A dual-feedback mechanism
incorporating quantitative game metrics and vision-language model analysis
facilitates iterative policy improvement at both tactical and strategic levels.
The resulting policies are instantaneously deployable, human-interpretable, and
capable of generalizing across diverse gaming environments. Experimental
results demonstrate PORTAL's effectiveness across thousands of first-person
shooter (FPS) games, showcasing significant improvements in development
efficiency, policy generalization, and behavior diversity compared to
traditional approaches. PORTAL represents a significant advancement in game AI
development, offering a practical solution for creating sophisticated agents
that can operate across thousands of commercial video games with minimal
development overhead. Experiment results on the 3D video games are best viewed
on https://zhongwen.one/projects/portal .","['Zhongwen Xu', 'Xianliang Wang', 'Siyi Li', 'Tao Yu', 'Liang Wang', 'Qiang Fu', 'Wei Yang']",2025-03-17,['cs.LG'],,http://arxiv.org/pdf/2503.13356v1
2503.13352v1,Strain Problems got you in a Twist? Try StrainRelief: A Quantum-Accurate Tool for Ligand Strain Calculations,"Ligand strain energy, the energy difference between the bound and unbound
conformations of a ligand, is an important component of structure-based small
molecule drug design. A large majority of observed ligands in protein-small
molecule co-crystal structures bind in low-strain conformations, making strain
energy a useful filter for structure-based drug design. In this work we present
a tool for calculating ligand strain with a high accuracy. StrainRelief uses a
MACE Neural Network Potential (NNP), trained on a large database of Density
Functional Theory (DFT) calculations to estimate ligand strain of neutral
molecules with quantum accuracy. We show that this tool estimates strain energy
differences relative to DFT to within 1.4 kcal/mol, more accurately than
alternative NNPs. These results highlight the utility of NNPs in drug
discovery, and provide a useful tool for drug discovery teams.","['Ewan R. S. Wallace', 'Nathan C. Frey', 'Joshua A. Rackers']",2025-03-17,"['physics.chem-ph', 'cs.LG']",,http://arxiv.org/pdf/2503.13352v1
2503.13335v1,Reliable and Efficient Amortized Model-based Evaluation,"Comprehensive evaluations of language models (LM) during both development and
deployment phases are necessary because these models possess numerous
capabilities (e.g., mathematical reasoning, legal support, or medical
diagnostic) as well as safety risks (e.g., racial bias, toxicity, or
misinformation). The average score across a wide range of benchmarks provides a
signal that helps guide the use of these LMs in practice. Currently, holistic
evaluations are costly due to the large volume of benchmark questions, making
frequent evaluations impractical. A popular attempt to lower the cost is to
compute the average score on a subset of the benchmark. This approach,
unfortunately, often renders an unreliable measure of LM performance because
the average score is often confounded with the difficulty of the questions in
the benchmark subset. Item response theory (IRT) was designed to address this
challenge, providing a reliable measurement by careful controlling for question
difficulty. Unfortunately, question difficulty is expensive to estimate. Facing
this challenge, we train a model that predicts question difficulty from its
content, enabling a reliable measurement at a fraction of the cost. In
addition, we leverage this difficulty predictor to further improve the
evaluation efficiency through training a question generator given a difficulty
level. This question generator is essential in adaptive testing, where, instead
of using a random subset of the benchmark questions, informative questions are
adaptively chosen based on the current estimation of LLM performance.
Experiments on 22 common natural language benchmarks and 172 LMs show that this
approach is more reliable and efficient compared to current common practice.","['Sang Truong', 'Yuheng Tu', 'Percy Liang', 'Bo Li', 'Sanmi Koyejo']",2025-03-17,"['cs.CL', 'cs.AI', 'cs.LG', 'stat.AP']",,http://arxiv.org/pdf/2503.13335v1
2503.13329v1,"PERC: a suite of software tools for the curation of cryoEM data with application to simulation, modelling and machine learning","Ease of access to data, tools and models expedites scientific research. In
structural biology there are now numerous open repositories of experimental and
simulated datasets. Being able to easily access and utilise these is crucial
for allowing researchers to make optimal use of their research effort. The
tools presented here are useful for collating existing public cryoEM datasets
and/or creating new synthetic cryoEM datasets to aid the development of novel
data processing and interpretation algorithms. In recent years, structural
biology has seen the development of a multitude of machine-learning based
algorithms for aiding numerous steps in the processing and reconstruction of
experimental datasets and the use of these approaches has become widespread.
Developing such techniques in structural biology requires access to large
datasets which can be cumbersome to curate and unwieldy to make use of. In this
paper we present a suite of Python software packages which we collectively
refer to as PERC (profet, EMPIARreader and CAKED). These are designed to reduce
the burden which data curation places upon structural biology research. The
protein structure fetcher (profet) package allows users to conveniently
download and cleave sequences or structures from the Protein Data Bank or
Alphafold databases. EMPIARreader allows lazy loading of Electron Microscopy
Public Image Archive datasets in a machine-learning compatible structure. The
Class Aggregator for Key Electron-microscopy Data (CAKED) package is designed
to seamlessly facilitate the training of machine learning models on electron
microscopy data, including electron-cryo-microscopy-specific data augmentation
and labelling. These packages may be utilised independently or as building
blocks in workflows. All are available in open source repositories and designed
to be easily extensible to facilitate more advanced workflows if required.","['Beatriz Costa-Gomes', 'Joel Greer', 'Nikolai Juraschko', 'James Parkhurst', 'Jola Mirecka', 'Marjan Famili', 'Camila Rangel-Smith', 'Oliver Strickson', 'Alan Lowe', 'Mark Basham', 'Tom Burnley']",2025-03-17,"['cs.LG', 'cs.CE', 'q-bio.BM']","22 pages, 4 figures",http://arxiv.org/pdf/2503.13329v1
2503.13322v1,SMPR: A structure-enhanced multimodal drug-disease prediction model for drug repositioning and cold start,"Repositioning drug-disease relationships has always been a hot field of
research. However, actual cases of biologically validated drug relocation
remain very limited, and existing models have not yet fully utilized the
structural information of the drug. Furthermore, most repositioning models are
only used to complete the relationship matrix, and their practicality is poor
when dealing with drug cold start problems. This paper proposes a
structure-enhanced multimodal relationship prediction model (SMRP). SMPR is
based on the SMILE structure of the drug, using the Mol2VEC method to generate
drug embedded representations, and learn disease embedded representations
through heterogeneous network graph neural networks. Ultimately, a drug-disease
relationship matrix is constructed. In addition, to reduce the difficulty of
users' use, SMPR also provides a cold start interface based on structural
similarity based on reposition results to simply and quickly predict
drug-related diseases. The repositioning ability and cold start capability of
the model are verified from multiple perspectives. While the AUC and ACUPR
scores of repositioning reach 99% and 61% respectively, the AUC of cold start
achieve 80%. In particular, the cold start Recall indicator can reach more than
70%, which means that SMPR is more sensitive to positive samples. Finally, case
analysis is used to verify the practical value of the model and visual analysis
directly demonstrates the improvement of the structure to the model. For quick
use, we also provide local deployment of the model and package it into an
executable program.","['Xin Dong', 'Rui Miao', 'Suyan Zhang', 'Shuaibing Jia', 'Leifeng Zhang', 'Yong Liang', 'Jianhua Zhang', 'Yi Zhun Zhu']",2025-03-17,['cs.LG'],,http://arxiv.org/pdf/2503.13322v1
2503.13579v1,ASMR: Adaptive Skeleton-Mesh Rigging and Skinning via 2D Generative Prior,"Despite the growing accessibility of skeletal motion data, integrating it for
animating character meshes remains challenging due to diverse configurations of
both skeletons and meshes. Specifically, the body scale and bone lengths of the
skeleton should be adjusted in accordance with the size and proportions of the
mesh, ensuring that all joints are accurately positioned within the character
mesh. Furthermore, defining skinning weights is complicated by variations in
skeletal configurations, such as the number of joints and their hierarchy, as
well as differences in mesh configurations, including their connectivity and
shapes. While existing approaches have made efforts to automate this process,
they hardly address the variations in both skeletal and mesh configurations. In
this paper, we present a novel method for the automatic rigging and skinning of
character meshes using skeletal motion data, accommodating arbitrary
configurations of both meshes and skeletons. The proposed method predicts the
optimal skeleton aligned with the size and proportion of the mesh as well as
defines skinning weights for various mesh-skeleton configurations, without
requiring explicit supervision tailored to each of them. By incorporating
Diffusion 3D Features (Diff3F) as semantic descriptors of character meshes, our
method achieves robust generalization across different configurations. To
assess the performance of our method in comparison to existing approaches, we
conducted comprehensive evaluations encompassing both quantitative and
qualitative analyses, specifically examining the predicted skeletons, skinning
weights, and deformation quality.","['Seokhyeon Hong', 'Soojin Choi', 'Chaelin Kim', 'Sihun Cha', 'Junyong Noh']",2025-03-17,"['cs.GR', 'cs.AI', 'cs.LG']","Eurographics 2025; Project Page
  https://seokhyeonhong.github.io/projects/asmr/",http://arxiv.org/pdf/2503.13579v1
2503.13317v1,Do you understand epistemic uncertainty? Think again! Rigorous frequentist epistemic uncertainty estimation in regression,"Quantifying model uncertainty is critical for understanding prediction
reliability, yet distinguishing between aleatoric and epistemic uncertainty
remains challenging. We extend recent work from classification to regression to
provide a novel frequentist approach to epistemic and aleatoric uncertainty
estimation. We train models to generate conditional predictions by feeding
their initial output back as an additional input. This method allows for a
rigorous measurement of model uncertainty by observing how prediction responses
change when conditioned on the model's previous answer. We provide a complete
theoretical framework to analyze epistemic uncertainty in regression in a
frequentist way, and explain how it can be exploited in practice to gauge a
model's uncertainty, with minimal changes to the original architecture.","['Enrico Foglia', 'Benjamin Bobbia', 'Nikita Durasov', 'Michael Bauerheim', 'Pascal Fua', 'Stephane Moreau', 'Thierry Jardin']",2025-03-17,"['stat.ML', 'cs.LG']",,http://arxiv.org/pdf/2503.13317v1
2503.13316v1,RainScaleGAN: a Conditional Generative Adversarial Network for Rainfall Downscaling,"To this day, accurately simulating local-scale precipitation and reliably
reproducing its distribution remains a challenging task. The limited horizontal
resolution of Global Climate Models is among the primary factors undermining
their skill in this context. The physical mechanisms driving the onset and
development of precipitation, especially in extreme events, operate at
spatio-temporal scales smaller than those numerically resolved, thus struggling
to be captured accurately. In order to circumvent this limitation, several
downscaling approaches have been developed over the last decades to address the
discrepancy between the spatial resolution of models output and the resolution
required by local-scale applications. In this paper, we introduce RainScaleGAN,
a conditional deep convolutional Generative Adversarial Network (GAN) for
precipitation downscaling. GANs have been effectively used in image
super-resolution, an approach highly relevant for downscaling tasks.
RainScaleGAN's capabilities are tested in a perfect-model setup, where the
spatial resolution of a precipitation dataset is artificially degraded from
0.25$^{\circ}\times$0.25$^{\circ}$ to 2$^{\circ}\times$2$^\circ$, and
RainScaleGAN is used to restore it. The developed model outperforms one of the
leading precipitation downscaling method found in the literature. RainScaleGAN
not only generates a synthetic dataset featuring plausible high-resolution
spatial patterns and intensities, but also produces a precipitation
distribution with statistics closely mirroring those of the ground-truth
dataset. Given that RainScaleGAN's approach is agnostic with respect to the
underlying physics, the method has the potential to be applied to other
physical variables such as surface winds or temperature.","['Marcello Iotti', 'Paolo Davini', 'Jost von Hardenberg', 'Giuseppe Zappa']",2025-03-17,"['physics.ao-ph', 'cs.AI', 'cs.LG']","38 pages, 16 figures",http://arxiv.org/pdf/2503.13316v1
2503.13304v1,GFSNetwork: Differentiable Feature Selection via Gumbel-Sigmoid Relaxation,"Feature selection in deep learning remains a critical challenge, particularly
for high-dimensional tabular data where interpretability and computational
efficiency are paramount. We present GFSNetwork, a novel neural architecture
that performs differentiable feature selection through temperature-controlled
Gumbel-Sigmoid sampling. Unlike traditional methods, where the user has to
define the requested number of features, GFSNetwork selects it automatically
during an end-to-end process. Moreover, GFSNetwork maintains constant
computational overhead regardless of the number of input features. We evaluate
GFSNetwork on a series of classification and regression benchmarks, where it
consistently outperforms recent methods including DeepLasso, attention maps, as
well as traditional feature selectors, while using significantly fewer
features. Furthermore, we validate our approach on real-world metagenomic
datasets, demonstrating its effectiveness in high-dimensional biological data.
Concluding, our method provides a scalable solution that bridges the gap
between neural network flexibility and traditional feature selection
interpretability. We share our python implementation of GFSNetwork at
https://github.com/wwydmanski/GFSNetwork, as well as a PyPi package
(gfs_network).","['Witold Wydmański', 'Marek Śmieja']",2025-03-17,['cs.LG'],,http://arxiv.org/pdf/2503.13304v1
2503.13296v1,On Local Posterior Structure in Deep Ensembles,"Bayesian Neural Networks (BNNs) often improve model calibration and
predictive uncertainty quantification compared to point estimators such as
maximum-a-posteriori (MAP). Similarly, deep ensembles (DEs) are also known to
improve calibration, and therefore, it is natural to hypothesize that deep
ensembles of BNNs (DE-BNNs) should provide even further improvements. In this
work, we systematically investigate this across a number of datasets, neural
network architectures, and BNN approximation methods and surprisingly find that
when the ensembles grow large enough, DEs consistently outperform DE-BNNs on
in-distribution data. To shine light on this observation, we conduct several
sensitivity and ablation studies. Moreover, we show that even though DE-BNNs
outperform DEs on out-of-distribution metrics, this comes at the cost of
decreased in-distribution performance. As a final contribution, we open-source
the large pool of trained models to facilitate further research on this topic.","['Mikkel Jordahn', 'Jonas Vestergaard Jensen', 'Mikkel N. Schmidt', 'Michael Riis Andersen']",2025-03-17,"['cs.LG', 'stat.ML']","Code and models available at
  https://github.com/jonasvj/OnLocalPosteriorStructureInDeepEnsembles",http://arxiv.org/pdf/2503.13296v1
2503.13288v1,$φ$-Decoding: Adaptive Foresight Sampling for Balanced Inference-Time Exploration and Exploitation,"Inference-time optimization scales computation to derive deliberate reasoning
steps for effective performance. While previous search-based strategies address
the short-sightedness of auto-regressive generation, the vast search space
leads to excessive exploration and insufficient exploitation. To strike an
efficient balance to derive the optimal step, we frame the decoding strategy as
foresight sampling, leveraging simulated future steps to obtain globally
optimal step estimation. Built on it, we propose a novel decoding strategy,
named $\phi$-Decoding. To provide a precise and expressive estimation of step
value, $\phi$-Decoding approximates two distributions via foresight and
clustering. Sampling from the joint distribution, the optimal steps can be
selected for exploitation. To support adaptive computation allocation, we
propose in-width and in-depth pruning strategies, featuring a light-weight
solution to achieve inference efficiency. Extensive experiments across seven
benchmarks show $\phi$-Decoding outperforms strong baselines in both
performance and efficiency. Additional analysis demonstrates its generalization
across various LLMs and scalability across a wide range of computing budgets.
The code will be released at https://github.com/xufangzhi/phi-Decoding, and the
open-source PyPI package is coming soon.","['Fangzhi Xu', 'Hang Yan', 'Chang Ma', 'Haiteng Zhao', 'Jun Liu', 'Qika Lin', 'Zhiyong Wu']",2025-03-17,"['cs.LG', 'cs.AI', 'cs.CL']","13 pages, 6 figures",http://arxiv.org/pdf/2503.13288v1
2503.13281v2,LLM-Match: An Open-Sourced Patient Matching Model Based on Large Language Models and Retrieval-Augmented Generation,"Patient matching is the process of linking patients to appropriate clinical
trials by accurately identifying and matching their medical records with trial
eligibility criteria. We propose LLM-Match, a novel framework for patient
matching leveraging fine-tuned open-source large language models. Our approach
consists of four key components. First, a retrieval-augmented generation (RAG)
module extracts relevant patient context from a vast pool of electronic health
records (EHRs). Second, a prompt generation module constructs input prompts by
integrating trial eligibility criteria (both inclusion and exclusion criteria),
patient context, and system instructions. Third, a fine-tuning module with a
classification head optimizes the model parameters using structured prompts and
ground-truth labels. Fourth, an evaluation module assesses the fine-tuned
model's performance on the testing datasets. We evaluated LLM-Match on four
open datasets - n2c2, SIGIR, TREC 2021, and TREC 2022 - using open-source
models, comparing it against TrialGPT, Zero-Shot, and GPT-4-based closed
models. LLM-Match outperformed all baselines.","['Xiaodi Li', 'Shaika Chowdhury', 'Chung Il Wi', 'Maria Vassilaki', 'Ken Liu', 'Terence T Sio', 'Owen Garrick', 'Young J Juhn', 'James R Cerhan', 'Cui Tao', 'Nansu Zong']",2025-03-17,"['cs.CL', 'cs.AI', 'cs.LG']","10 pages, 1 figure",http://arxiv.org/pdf/2503.13281v2
2503.13271v1,Graph Generative Models Evaluation with Masked Autoencoder,"In recent years, numerous graph generative models (GGMs) have been proposed.
However, evaluating these models remains a considerable challenge, primarily
due to the difficulty in extracting meaningful graph features that accurately
represent real-world graphs. The traditional evaluation techniques, which rely
on graph statistical properties like node degree distribution, clustering
coefficients, or Laplacian spectrum, overlook node features and lack
scalability. There are newly proposed deep learning-based methods employing
graph random neural networks or contrastive learning to extract graph features,
demonstrating superior performance compared to traditional statistical methods,
but their experimental results also demonstrate that these methods do not
always working well across different metrics. Although there are overlaps among
these metrics, they are generally not interchangeable, each evaluating
generative models from a different perspective. In this paper, we propose a
novel method that leverages graph masked autoencoders to effectively extract
graph features for GGM evaluations. We conduct extensive experiments on graphs
and empirically demonstrate that our method can be more reliable and effective
than previously proposed methods across a number of GGM evaluation metrics,
such as ""Fr\'echet Distance (FD)"" and ""MMD Linear"". However, no single method
stands out consistently across all metrics and datasets. Therefore, this study
also aims to raise awareness of the significance and challenges associated with
GGM evaluation techniques, especially in light of recent advances in generative
models.","['Chengen Wang', 'Murat Kantarcioglu']",2025-03-17,['cs.LG'],,http://arxiv.org/pdf/2503.13271v1
2503.13578v1,Convolutional neural network for early detection of lameness and irregularity in horses using an IMU sensor,"Lameness and gait irregularities are significant concerns in equine health
management, affecting performance, welfare, and economic value. Traditional
observational methods rely on subjective expert assessments, which can lead to
inconsistencies in detecting subtle or early-stage lameness. While AI-based
approaches have emerged, many require multiple sensors, force plates, or video
systems, making them costly and impractical for field deployment. In this
applied research study, we present a stride-level classification system that
utilizes a single inertial measurement unit (IMU) and a one-dimensional
convolutional neural network (1D CNN) to objectively differentiate between
sound and lame horses, with a primary focus on the trot gait. The proposed
system was tested under real-world conditions, achieving a 90% session-level
accuracy with no false positives, demonstrating its robustness for practical
applications. By employing a single, non-intrusive, and readily available
sensor, our approach significantly reduces the complexity and cost of hardware
requirements while maintaining high classification performance. These results
highlight the potential of our CNN-based method as a field-tested, scalable
solution for automated lameness detection. By enabling early diagnosis, this
system offers a valuable tool for preventing minor gait irregularities from
developing into severe conditions, ultimately contributing to improved equine
welfare and performance in veterinary and equestrian practice.","['Benoît Savoini', 'Jonathan Bertolaccini', 'Stéphane Montavon', 'Michel Deriaz']",2025-03-17,"['eess.SP', 'cs.AI', 'cs.LG']",Accepted at AMLDS 2025,http://arxiv.org/pdf/2503.13578v1
2503.14542v1,AI-Driven Rapid Identification of Bacterial and Fungal Pathogens in Blood Smears of Septic Patients,"Sepsis is a life-threatening condition which requires rapid diagnosis and
treatment. Traditional microbiological methods are time-consuming and
expensive. In response to these challenges, deep learning algorithms were
developed to identify 14 bacteria species and 3 yeast-like fungi from
microscopic images of Gram-stained smears of positive blood samples from sepsis
patients.
  A total of 16,637 Gram-stained microscopic images were used in the study. The
analysis used the Cellpose 3 model for segmentation and Attention-based Deep
Multiple Instance Learning for classification. Our model achieved an accuracy
of 77.15% for bacteria and 71.39% for fungi, with ROC AUC of 0.97 and 0.88,
respectively. The highest values, reaching up to 96.2%, were obtained for
Cutibacterium acnes, Enterococcus faecium, Stenotrophomonas maltophilia and
Nakaseomyces glabratus. Classification difficulties were observed in closely
related species, such as Staphylococcus hominis and Staphylococcus
haemolyticus, due to morphological similarity, and within Candida albicans due
to high morphotic diversity.
  The study confirms the potential of our model for microbial classification,
but it also indicates the need for further optimisation and expansion of the
training data set. In the future, this technology could support microbial
diagnosis, reducing diagnostic time and improving the effectiveness of sepsis
treatment due to its simplicity and accessibility. Part of the results
presented in this publication was covered by a patent application at the
European Patent Office EP24461637.1 ""A computer implemented method for
identifying a microorganism in a blood and a data processing system therefor"".","['Agnieszka Sroka-Oleksiak', 'Adam Pardyl', 'Dawid Rymarczyk', 'Aldona Olechowska-Jarząb', 'Katarzyna Biegun-Drożdż', 'Dorota Ochońska', 'Michał Wronka', 'Adriana Borowa', 'Tomasz Gosiewski', 'Miłosz Adamczyk', 'Henryk Telega', 'Bartosz Zieliński', 'Monika Brzychczy-Włoch']",2025-03-17,"['eess.IV', 'cs.AI', 'cs.CE', 'cs.CV', 'cs.LG']",,http://arxiv.org/pdf/2503.14542v1
2503.13248v1,Neural network-based Godunov corrections for approximate Riemann solvers using bi-fidelity learning,"The Riemann problem is fundamental in the computational modeling of
hyperbolic partial differential equations, enabling the development of stable
and accurate upwind schemes. While exact solvers provide robust upwinding
fluxes, their high computational cost necessitates approximate solvers.
Although approximate solvers achieve accuracy in many scenarios, they produce
inaccurate solutions in certain cases. To overcome this limitation, we propose
constructing neural network-based surrogate models, trained using supervised
learning, designed to map interior and exterior conservative state variables to
the corresponding exact flux. Specifically, we propose two distinct approaches:
one utilizing a vanilla neural network and the other employing a bi-fidelity
neural network. The performance of the proposed approaches is demonstrated
through applications to one-dimensional and two-dimensional partial
differential equations, showcasing their robustness and accuracy.","['Akshay Thakur', 'Matthew J. Zahr']",2025-03-17,"['math.NA', 'cs.LG', 'cs.NA', 'physics.flu-dyn']","22 pages, 16 figures",http://arxiv.org/pdf/2503.13248v1
2503.13246v1,Highly Efficient Direct Analytics on Semantic-aware Time Series Data Compression,"Semantic communication has emerged as a promising paradigm to tackle the
challenges of massive growing data traffic and sustainable data communication.
It shifts the focus from data fidelity to goal-oriented or task-oriented
semantic transmission. While deep learning-based methods are commonly used for
semantic encoding and decoding, they struggle with the sequential nature of
time series data and high computation cost, particularly in
resource-constrained IoT environments. Data compression plays a crucial role in
reducing transmission and storage costs, yet traditional data compression
methods fall short of the demands of goal-oriented communication systems. In
this paper, we propose a novel method for direct analytics on time series data
compressed by the SHRINK compression algorithm. Through experimentation using
outlier detection as a case study, we show that our method outperforms
baselines running on uncompressed data in multiple cases, with merely 1%
difference in the worst case. Additionally, it achieves four times lower
runtime on average and accesses approximately 10% of the data volume, which
enables edge analytics with limited storage and computation power. These
results demonstrate that our approach offers reliable, high-speed outlier
detection analytics for diverse IoT applications while extracting semantics
from time-series data, achieving high compression, and reducing data
transmission.","['Guoyou Sun', 'Panagiotis Karras', 'Qi Zhang']",2025-03-17,"['cs.LG', 'eess.SP']",,http://arxiv.org/pdf/2503.13246v1
2503.13236v1,Gradient Extrapolation for Debiased Representation Learning,"Machine learning classification models trained with empirical risk
minimization (ERM) often inadvertently rely on spurious correlations. When
absent in the test data, these unintended associations between non-target
attributes and target labels lead to poor generalization. This paper addresses
this problem from a model optimization perspective and proposes a novel method,
Gradient Extrapolation for Debiased Representation Learning (GERNE), designed
to learn debiased representations in both known and unknown attribute training
cases. GERNE uses two distinct batches with different amounts of spurious
correlations to define the target gradient as the linear extrapolation of two
gradients computed from each batch's loss. It is demonstrated that the
extrapolated gradient, if directed toward the gradient of the batch with fewer
amount of spurious correlation, can guide the training process toward learning
a debiased model. GERNE can serve as a general framework for debiasing with
methods, such as ERM, reweighting, and resampling, being shown as special
cases. The theoretical upper and lower bounds of the extrapolation factor are
derived to ensure convergence. By adjusting this factor, GERNE can be adapted
to maximize the Group-Balanced Accuracy (GBA) or the Worst-Group Accuracy. The
proposed approach is validated on five vision and one NLP benchmarks,
demonstrating competitive and often superior performance compared to
state-of-the-art baseline methods.","['Ihab Asaad', 'Maha Shadaydeh', 'Joachim Denzler']",2025-03-17,"['cs.LG', 'cs.CV']",,http://arxiv.org/pdf/2503.13236v1
2503.13227v1,Mind the Gap: Confidence Discrepancy Can Guide Federated Semi-Supervised Learning Across Pseudo-Mismatch,"Federated Semi-Supervised Learning (FSSL) aims to leverage unlabeled data
across clients with limited labeled data to train a global model with strong
generalization ability. Most FSSL methods rely on consistency regularization
with pseudo-labels, converting predictions from local or global models into
hard pseudo-labels as supervisory signals. However, we discover that the
quality of pseudo-label is largely deteriorated by data heterogeneity, an
intrinsic facet of federated learning. In this paper, we study the problem of
FSSL in-depth and show that (1) heterogeneity exacerbates pseudo-label
mismatches, further degrading model performance and convergence, and (2) local
and global models' predictive tendencies diverge as heterogeneity increases.
Motivated by these findings, we propose a simple and effective method called
Semi-supervised Aggregation for Globally-Enhanced Ensemble (SAGE), that can
flexibly correct pseudo-labels based on confidence discrepancies. This strategy
effectively mitigates performance degradation caused by incorrect pseudo-labels
and enhances consensus between local and global models. Experimental results
demonstrate that SAGE outperforms existing FSSL methods in both performance and
convergence. Our code is available at https://github.com/Jay-Codeman/SAGE","['Yijie Liu', 'Xinyi Shang', 'Yiqun Zhang', 'Yang Lu', 'Chen Gong', 'Jing-Hao Xue', 'Hanzi Wang']",2025-03-17,"['cs.LG', 'cs.CV']",Accepted by CVPR 2025,http://arxiv.org/pdf/2503.13227v1
2503.13224v1,ProDiF: Protecting Domain-Invariant Features to Secure Pre-Trained Models Against Extraction,"Pre-trained models are valuable intellectual property, capturing both
domain-specific and domain-invariant features within their weight spaces.
However, model extraction attacks threaten these assets by enabling
unauthorized source-domain inference and facilitating cross-domain transfer via
the exploitation of domain-invariant features. In this work, we introduce
**ProDiF**, a novel framework that leverages targeted weight space manipulation
to secure pre-trained models against extraction attacks. **ProDiF** quantifies
the transferability of filters and perturbs the weights of critical filters in
unsecured memory, while preserving actual critical weights in a Trusted
Execution Environment (TEE) for authorized users. A bi-level optimization
further ensures resilience against adaptive fine-tuning attacks. Experimental
results show that **ProDiF** reduces source-domain accuracy to near-random
levels and decreases cross-domain transferability by 74.65\%, providing robust
protection for pre-trained models. This work offers comprehensive protection
for pre-trained DNN models and highlights the potential of weight space
manipulation as a novel approach to model security.","['Tong Zhou', 'Shijin Duan', 'Gaowen Liu', 'Charles Fleming', 'Ramana Rao Kompella', 'Shaolei Ren', 'Xiaolin Xu']",2025-03-17,"['cs.CR', 'cs.LG']","Accepted at the ICLR Workshop on Neural Network Weights as a New Data
  Modality 2025",http://arxiv.org/pdf/2503.13224v1
2503.13217v1,Dense Policy: Bidirectional Autoregressive Learning of Actions,"Mainstream visuomotor policies predominantly rely on generative models for
holistic action prediction, while current autoregressive policies, predicting
the next token or chunk, have shown suboptimal results. This motivates a search
for more effective learning methods to unleash the potential of autoregressive
policies for robotic manipulation. This paper introduces a bidirectionally
expanded learning approach, termed Dense Policy, to establish a new paradigm
for autoregressive policies in action prediction. It employs a lightweight
encoder-only architecture to iteratively unfold the action sequence from an
initial single frame into the target sequence in a coarse-to-fine manner with
logarithmic-time inference. Extensive experiments validate that our dense
policy has superior autoregressive learning capabilities and can surpass
existing holistic generative policies. Our policy, example data, and training
code will be publicly available upon publication. Project page: https:
//selen-suyue.github.io/DspNet/.","['Yue Su', 'Xinyu Zhan', 'Hongjie Fang', 'Han Xue', 'Hao-Shu Fang', 'Yong-Lu Li', 'Cewu Lu', 'Lixin Yang']",2025-03-17,"['cs.RO', 'cs.CV', 'cs.LG']",,http://arxiv.org/pdf/2503.13217v1
2503.13577v1,When Should We Orchestrate Multiple Agents?,"Strategies for orchestrating the interactions between multiple agents, both
human and artificial, can wildly overestimate performance and underestimate the
cost of orchestration. We design a framework to orchestrate agents under
realistic conditions, such as inference costs or availability constraints. We
show theoretically that orchestration is only effective if there are
performance or cost differentials between agents. We then empirically
demonstrate how orchestration between multiple agents can be helpful for
selecting agents in a simulated environment, picking a learning strategy in the
infamous Rogers' Paradox from social science, and outsourcing tasks to other
agents during a question-answer task in a user study.","['Umang Bhatt', 'Sanyam Kapoor', 'Mihir Upadhyay', 'Ilia Sucholutsky', 'Francesco Quinzan', 'Katherine M. Collins', 'Adrian Weller', 'Andrew Gordon Wilson', 'Muhammad Bilal Zafar']",2025-03-17,"['cs.MA', 'cs.CY', 'cs.LG']",,http://arxiv.org/pdf/2503.13577v1
2503.13212v1,MAME: Multidimensional Adaptive Metamer Exploration with Human Perceptual Feedback,"Alignment between human brain networks and artificial models is actively
studied in machine learning and neuroscience. A widely adopted approach to
explore their functional alignment is to identify metamers for both humans and
models. Metamers refer to input stimuli that are physically different but
equivalent within a given system. If a model's metameric space completely
matched the human metameric space, the model would achieve functional alignment
with humans. However, conventional methods lack direct ways to search for human
metamers. Instead, researchers first develop biologically inspired models and
then infer about human metamers indirectly by testing whether model metamers
also appear as metamers to humans. Here, we propose the Multidimensional
Adaptive Metamer Exploration (MAME) framework, enabling direct high-dimensional
exploration of human metameric space. MAME leverages online image generation
guided by human perceptual feedback. Specifically, it modulates reference
images across multiple dimensions by leveraging hierarchical responses from
convolutional neural networks (CNNs). Generated images are presented to
participants whose perceptual discriminability is assessed in a behavioral
task. Based on participants' responses, subsequent image generation parameters
are adaptively updated online. Using our MAME framework, we successfully
measured a human metameric space of over fifty dimensions within a single
experiment. Experimental results showed that human discrimination sensitivity
was lower for metameric images based on low-level features compared to
high-level features, which image contrast metrics could not explain. The
finding suggests that the model computes low-level information not essential
for human perception. Our framework has the potential to contribute to
developing interpretable AI and understanding of brain function in
neuroscience.","['Mina Kamao', 'Hayato Ono', 'Ayumu Yamashita', 'Kaoru Amano', 'Masataka Sawayama']",2025-03-17,['cs.LG'],"14 pages, 9 figures",http://arxiv.org/pdf/2503.13212v1
2503.14538v2,Vision-Language Models for Acute Tuberculosis Diagnosis: A Multimodal Approach Combining Imaging and Clinical Data,"Background: This study introduces a Vision-Language Model (VLM) leveraging
SIGLIP and Gemma-3b architectures for automated acute tuberculosis (TB)
screening. By integrating chest X-ray images and clinical notes, the model aims
to enhance diagnostic accuracy and efficiency, particularly in resource-limited
settings.
  Methods: The VLM combines visual data from chest X-rays with clinical context
to generate detailed, context-aware diagnostic reports. The architecture
employs SIGLIP for visual encoding and Gemma-3b for decoding, ensuring
effective representation of acute TB-specific pathologies and clinical
insights.
  Results: Key acute TB pathologies, including consolidation, cavities, and
nodules, were detected with high precision (97percent) and recall (96percent).
The model demonstrated strong spatial localization capabilities and robustness
in distinguishing TB-positive cases, making it a reliable tool for acute TB
diagnosis.
  Conclusion: The multimodal capability of the VLM reduces reliance on
radiologists, providing a scalable solution for acute TB screening. Future work
will focus on improving the detection of subtle pathologies and addressing
dataset biases to enhance its generalizability and application in diverse
global healthcare settings.","['Ananya Ganapthy', 'Praveen Shastry', 'Naveen Kumarasami', 'Anandakumar D', 'Keerthana R', 'Mounigasri M', 'Varshinipriya M', 'Kishore Prasath Venkatesh', 'Bargava Subramanian', 'Kalyan Sivasailam']",2025-03-17,"['eess.IV', 'cs.AI', 'cs.CV', 'cs.LG', '68T07, 68T45, 92C55, 92C50, 68U10']","11 pages, 3 figures",http://arxiv.org/pdf/2503.14538v2
2503.13200v1,Timing the Match: A Deep Reinforcement Learning Approach for Ride-Hailing and Ride-Pooling Services,"Efficient timing in ride-matching is crucial for improving the performance of
ride-hailing and ride-pooling services, as it determines the number of drivers
and passengers considered in each matching process. Traditional batched
matching methods often use fixed time intervals to accumulate ride requests
before assigning matches. While this approach increases the number of available
drivers and passengers for matching, it fails to adapt to real-time
supply-demand fluctuations, often leading to longer passenger wait times and
driver idle periods. To address this limitation, we propose an adaptive
ride-matching strategy using deep reinforcement learning (RL) to dynamically
determine when to perform matches based on real-time system conditions. Unlike
fixed-interval approaches, our method continuously evaluates system states and
executes matching at moments that minimize total passenger wait time.
Additionally, we incorporate a potential-based reward shaping (PBRS) mechanism
to mitigate sparse rewards, accelerating RL training and improving decision
quality. Extensive empirical evaluations using a realistic simulator trained on
real-world data demonstrate that our approach outperforms fixed-interval
matching strategies, significantly reducing passenger waiting times and detour
delays, thereby enhancing the overall efficiency of ride-hailing and
ride-pooling systems.","['Yiman Bao', 'Jie Gao', 'Jinke He', 'Frans A. Oliehoek', 'Oded Cats']",2025-03-17,"['cs.LG', 'cs.AI']",,http://arxiv.org/pdf/2503.13200v1
2503.13195v1,Deep Learning Advancements in Anomaly Detection: A Comprehensive Survey,"The rapid expansion of data from diverse sources has made anomaly detection
(AD) increasingly essential for identifying unexpected observations that may
signal system failures, security breaches, or fraud. As datasets become more
complex and high-dimensional, traditional detection methods struggle to
effectively capture intricate patterns. Advances in deep learning have made AD
methods more powerful and adaptable, improving their ability to handle
high-dimensional and unstructured data. This survey provides a comprehensive
review of over 180 recent studies, focusing on deep learning-based AD
techniques. We categorize and analyze these methods into reconstruction-based
and prediction-based approaches, highlighting their effectiveness in modeling
complex data distributions. Additionally, we explore the integration of
traditional and deep learning methods, highlighting how hybrid approaches
combine the interpretability of traditional techniques with the flexibility of
deep learning to enhance detection accuracy and model transparency. Finally, we
identify open issues and propose future research directions to advance the
field of AD. This review bridges gaps in existing literature and serves as a
valuable resource for researchers and practitioners seeking to enhance AD
techniques using deep learning.","['Haoqi Huang', 'Ping Wang', 'Jianhua Pei', 'Jiacheng Wang', 'Shahen Alexanian', 'Dusit Niyato']",2025-03-17,['cs.LG'],,http://arxiv.org/pdf/2503.13195v1
2503.13194v1,A representational framework for learning and encoding structurally enriched trajectories in complex agent environments,"The ability of artificial intelligence agents to make optimal decisions and
generalise them to different domains and tasks is compromised in complex
scenarios. One way to address this issue has focused on learning efficient
representations of the world and on how the actions of agents affect them, such
as disentangled representations that exploit symmetries. Whereas such
representations are procedurally efficient, they are based on the compression
of low-level state-action transitions, which lack structural richness. To
address this problem, we propose to enrich the agent's ontology and extend the
traditional conceptualisation of trajectories to provide a more nuanced view of
task execution. Structurally Enriched Trajectories (SETs) extend the encoding
of sequences of states and their transitions by incorporating hierarchical
relations between objects, interactions and affordances. SETs are built as
multi-level graphs, providing a detailed representation of the agent dynamics
and a transferable functional abstraction of the task. SETs are integrated into
an architecture, Structurally Enriched Trajectory Learning and Encoding
(SETLE), that employs a heterogeneous graph-based memory structure of
multi-level relational dependencies essential for generalisation. Using
reinforcement learning as a data generation tool, we demonstrate that SETLE can
support downstream tasks, enabling agents to recognise task-relevant structural
patterns across diverse environments.","['Corina Catarau-Cotutiu', 'Esther Mondragon', 'Eduardo Alonso']",2025-03-17,"['cs.AI', 'cs.LG']",,http://arxiv.org/pdf/2503.13194v1
2503.13180v2,GC-Fed: Gradient Centralized Federated Learning with Partial Client Participation,"Federated Learning (FL) enables privacy-preserving multi-source information
fusion (MSIF) but is challenged by client drift in highly heterogeneous data
settings. Many existing drift-mitigation strategies rely on reference-based
techniques--such as gradient adjustments or proximal loss--that use historical
snapshots (e.g., past gradients or previous global models) as reference points.
When only a subset of clients participates in each training round, these
historical references may not accurately capture the overall data distribution,
leading to unstable training. In contrast, our proposed Gradient Centralized
Federated Learning (GC-Fed) employs a hyperplane as a historically independent
reference point to guide local training and enhance inter-client alignment.
GC-Fed comprises two complementary components: Local GC, which centralizes
gradients during local training, and Global GC, which centralizes updates
during server aggregation. In our hybrid design, Local GC is applied to
feature-extraction layers to harmonize client contributions, while Global GC
refines classifier layers to stabilize round-wise performance. Theoretical
analysis and extensive experiments on benchmark FL tasks demonstrate that
GC-Fed effectively mitigates client drift and achieves up to a 20% improvement
in accuracy under heterogeneous and partial participation conditions.","['Jungwon Seo', 'Ferhat Ozgur Catak', 'Chunming Rong', 'Kibeom Hong', 'Minhoe Kim']",2025-03-17,"['cs.LG', 'cs.AI', 'cs.DC']",,http://arxiv.org/pdf/2503.13180v2
2503.13178v1,Rapfi: Distilling Efficient Neural Network for the Game of Gomoku,"Games have played a pivotal role in advancing artificial intelligence, with
AI agents using sophisticated techniques to compete. Despite the success of
neural network based game AIs, their performance often requires significant
computational resources. In this paper, we present Rapfi, an efficient Gomoku
agent that outperforms CNN-based agents in limited computation environments.
Rapfi leverages a compact neural network with a pattern-based codebook
distilled from CNNs, and an incremental update scheme that minimizes
computation when input changes are minor. This new network uses computation
that is orders of magnitude less to reach a similar accuracy of much larger
neural networks such as Resnet. Thanks to our incremental update scheme,
depth-first search methods such as the alpha-beta search can be significantly
accelerated. With a carefully tuned evaluation and search, Rapfi reached
strength surpassing Katagomo, the strongest open-source Gomoku AI based on
AlphaZero's algorithm, under limited computational resources where accelerators
like GPUs are absent. Rapfi ranked first among 520 Gomoku agents on Botzone and
won the championship in GomoCup 2024.","['Zhanggen Jin', 'Haobin Duan', 'Zhiyang Hang']",2025-03-17,"['cs.AI', 'cs.LG']",,http://arxiv.org/pdf/2503.13178v1
2503.13173v1,PAUSE: Low-Latency and Privacy-Aware Active User Selection for Federated Learning,"Federated learning (FL) enables multiple edge devices to collaboratively
train a machine learning model without the need to share potentially private
data. Federated learning proceeds through iterative exchanges of model updates,
which pose two key challenges: First, the accumulation of privacy leakage over
time, and second, communication latency. These two limitations are typically
addressed separately: The former via perturbed updates to enhance privacy and
the latter using user selection to mitigate latency - both at the expense of
accuracy. In this work, we propose a method that jointly addresses the
accumulation of privacy leakage and communication latency via active user
selection, aiming to improve the trade-off among privacy, latency, and model
performance. To achieve this, we construct a reward function that accounts for
these three objectives. Building on this reward, we propose a multi-armed
bandit (MAB)-based algorithm, termed Privacy-aware Active User SElection
(PAUSE) which dynamically selects a subset of users each round while ensuring
bounded overall privacy leakage. We establish a theoretical analysis,
systematically showing that the reward growth rate of PAUSE follows that of the
best-known rate in MAB literature. To address the complexity overhead of active
user selection, we propose a simulated annealing-based relaxation of PAUSE and
analyze its ability to approximate the reward-maximizing policy under reduced
complexity. We numerically validate the privacy leakage, associated improved
latency, and accuracy gains of our methods for the federated training in
various scenarios.","['Ori Peleg', 'Natalie Lang', 'Stefano Rini', 'Nir Shlezinger', 'Kobi Cohen']",2025-03-17,"['cs.LG', 'eess.SP']",,http://arxiv.org/pdf/2503.13173v1
2503.14536v1,Advancing Chronic Tuberculosis Diagnostics Using Vision-Language Models: A Multi modal Framework for Precision Analysis,"Background This study proposes a Vision-Language Model (VLM) leveraging the
SIGLIP encoder and Gemma-3b transformer decoder to enhance automated chronic
tuberculosis (TB) screening. By integrating chest X-ray images with clinical
data, the model addresses the challenges of manual interpretation, improving
diagnostic consistency and accessibility, particularly in resource-constrained
settings.
  Methods The VLM architecture combines a Vision Transformer (ViT) for visual
encoding and a transformer-based text encoder to process clinical context, such
as patient histories and treatment records. Cross-modal attention mechanisms
align radiographic features with textual information, while the Gemma-3b
decoder generates comprehensive diagnostic reports. The model was pre-trained
on 5 million paired medical images and texts and fine-tuned using 100,000
chronic TB-specific chest X-rays.
  Results The model demonstrated high precision (94 percent) and recall (94
percent) for detecting key chronic TB pathologies, including fibrosis,
calcified granulomas, and bronchiectasis. Area Under the Curve (AUC) scores
exceeded 0.93, and Intersection over Union (IoU) values were above 0.91,
validating its effectiveness in detecting and localizing TB-related
abnormalities.
  Conclusion The VLM offers a robust and scalable solution for automated
chronic TB diagnosis, integrating radiographic and clinical data to deliver
actionable and context-aware insights. Future work will address subtle
pathologies and dataset biases to enhance the model's generalizability,
ensuring equitable performance across diverse populations and healthcare
settings.","['Praveen Shastry', 'Sowmya Chowdary Muthulur', 'Naveen Kumarasami', 'Anandakumar D', 'Mounigasri M', 'Keerthana R', 'Kishore Prasath Venkatesh', 'Bargava Subramanian', 'Kalyan Sivasailam', 'Revathi Ezhumalai', 'Abitha Marimuthu']",2025-03-17,"['eess.IV', 'cs.AI', 'cs.CV', 'cs.LG', '68T07, 92C55, 68U10, 92C50, 60G35']","10 pages , 3 figures",http://arxiv.org/pdf/2503.14536v1
2503.13575v1,Analytic Subspace Routing: How Recursive Least Squares Works in Continual Learning of Large Language Model,"Large Language Models (LLMs) possess encompassing capabilities that can
process diverse language-related tasks. However, finetuning on LLMs will
diminish this general skills and continual finetuning will further cause severe
degradation on accumulated knowledge. Recently, Continual Learning (CL) in
Large Language Models (LLMs) arises which aims to continually adapt the LLMs to
new tasks while maintaining previously learned knowledge and inheriting general
skills. Existing techniques either leverage previous data to replay, leading to
extra computational costs, or utilize a single parameter-efficient module to
learn the downstream task, constraining new knowledge absorption with
interference between different tasks. Toward these issues, this paper proposes
Analytic Subspace Routing(ASR) to address these challenges. For each task, we
isolate the learning within a subspace of deep layers' features via low-rank
adaptation, eliminating knowledge interference between different tasks.
Additionally, we propose an analytic routing mechanism to properly utilize
knowledge learned in different subspaces. Our approach employs Recursive Least
Squares to train a multi-task router model, allowing the router to dynamically
adapt to incoming data without requiring access to historical data. Also, the
router effectively assigns the current task to an appropriate subspace and has
a non-forgetting property of previously learned tasks with a solid theoretical
guarantee. Experimental results demonstrate that our method achieves
near-perfect retention of prior knowledge while seamlessly integrating new
information, effectively overcoming the core limitations of existing methods.
Our code will be released after acceptance.","['Kai Tong', 'Kang Pan', 'Xiao Zhang', 'Erli Meng', 'Run He', 'Yawen Cui', 'Nuoyan Guo', 'Huiping Zhuang']",2025-03-17,"['cs.LG', 'cs.AI', 'cs.CL']","11 pages, 4 figures",http://arxiv.org/pdf/2503.13575v1
2503.13162v1,Efficient Imitation Under Misspecification,"Interactive imitation learning (IL) is a powerful paradigm for learning to
make sequences of decisions from an expert demonstrating how to perform a task.
Prior work in efficient imitation learning has focused on the realizable
setting, where the expert's policy lies within the learner's policy class (i.e.
the learner can perfectly imitate the expert in all states). However, in
practice, perfect imitation of the expert is often impossible due to
differences in state information and action space expressiveness (e.g.
morphological differences between robots and humans.) In this paper, we
consider the more general misspecified setting, where no assumptions are made
about the expert policy's realizability. We introduce a novel structural
condition, reward-agnostic policy completeness, and prove that it is sufficient
for interactive IL algorithms to efficiently avoid the quadratically
compounding errors that stymie offline approaches like behavioral cloning. We
address an additional practical constraint-the case of limited expert data-and
propose a principled method for using additional offline data to further
improve the sample-efficiency of interactive IL algorithms. Finally, we
empirically investigate the optimal reset distribution in efficient IL under
misspecification with a suite of continuous control tasks.","['Nicolas Espinosa-Dice', 'Sanjiban Choudhury', 'Wen Sun', 'Gokul Swamy']",2025-03-17,"['cs.LG', 'cs.AI']","37 pages, 5 figures. Published as a conference paper at ICLR 2025",http://arxiv.org/pdf/2503.13162v1
2503.13158v1,Laplace-Net: Learning Dynamical Systems with External Forcing,"Modelling forced dynamical systems - where an external input drives the
system state - is critical across diverse domains such as engineering, finance,
and the natural sciences. In this work, we propose Laplace-Net, a decoupled,
solver-free neural framework for learning forced and delay-aware systems. It
leverages a Laplace transform-based approach to decompose internal dynamics,
external inputs, and initial values into established theoretical concepts,
enhancing interpretability. Laplace-Net promotes transferability since the
system can be rapidly re-trained or fine-tuned for new forcing signals,
providing flexibility in applications ranging from controller adaptation to
long-horizon forecasting. Experimental results on eight benchmark datasets -
including linear, non-linear, and delayed systems - demonstrate the method's
improved accuracy and robustness compared to state-of-the-art approaches,
particularly in handling complex and previously unseen inputs.","['Bernd Zimmering', 'Cecília Coelho', 'Vaibhav Gupta', 'Maria Maleshkova', 'Oliver Niggemann']",2025-03-17,"['cs.LG', 'cs.SY', 'eess.SY']",Preprint - under review,http://arxiv.org/pdf/2503.13158v1
2503.13145v1,High-entropy Advantage in Neural Networks' Generalizability,"While the 2024 Nobel Prize in Physics ignites a worldwide discussion on the
origins of neural networks and their foundational links to physics, modern
machine learning research predominantly focuses on computational and
algorithmic advancements, overlooking a picture of physics. Here we introduce
the concept of entropy into neural networks by reconceptualizing them as
hypothetical physical systems where each parameter is a non-interacting
'particle' within a one-dimensional space. By employing a Wang-Landau
algorithms, we construct the neural networks' (with up to 1 million parameters)
entropy landscapes as functions of training loss and test accuracy (or loss)
across four distinct machine learning tasks, including arithmetic question,
real-world tabular data, image recognition, and language modeling. Our results
reveal the existence of \textit{entropy advantage}, where the high-entropy
states generally outperform the states reached via classical training optimizer
like stochastic gradient descent. We also find this advantage is more
pronounced in narrower networks, indicating a need of different training
optimizers tailored to different sizes of neural networks.","['Entao Yang', 'Xiaotian Zhang', 'Yue Shang', 'Ge Zhang']",2025-03-17,"['cs.LG', 'cond-mat.stat-mech']",,http://arxiv.org/pdf/2503.13145v1
2503.13573v1,Online Signature Verification based on the Lagrange formulation with 2D and 3D robotic models,"Online Signature Verification commonly relies on function-based features,
such as time-sampled horizontal and vertical coordinates, as well as the
pressure exerted by the writer, obtained through a digitizer. Although
inferring additional information about the writers arm pose, kinematics, and
dynamics based on digitizer data can be useful, it constitutes a challenge. In
this paper, we tackle this challenge by proposing a new set of features based
on the dynamics of online signatures. These new features are inferred through a
Lagrangian formulation, obtaining the sequences of generalized coordinates and
torques for 2D and 3D robotic arm models. By combining kinematic and dynamic
robotic features, our results demonstrate their significant effectiveness for
online automatic signature verification and achieving state-of-the-art results
when integrated into deep learning models.","['Moises Diaz', 'Miguel A. Ferrer', 'Juan M. Gil', 'Rafael Rodriguez', 'Peirong Zhang', 'Lianwen Jin']",2025-03-17,"['cs.RO', 'cs.CV', 'cs.LG']",,http://arxiv.org/pdf/2503.13573v1
2503.13116v1,VeriLeaky: Navigating IP Protection vs Utility in Fine-Tuning for LLM-Driven Verilog Coding,"Large language models (LLMs) offer significant potential for coding, yet
fine-tuning (FT) with curated data is essential for niche languages like
Verilog. Using proprietary intellectual property (IP) for FT presents a serious
risk, as FT data can be leaked through LLM inference. This leads to a critical
dilemma for design houses: seeking to build externally accessible LLMs offering
competitive Verilog coding, how can they leverage in-house IP to enhance FT
utility while ensuring IP protection?
  For the first time in the literature, we study this dilemma. Using LLaMA
3.1-8B, we conduct in-house FT on a baseline Verilog dataset (RTLCoder)
supplemented with our own in-house IP, which is validated through multiple
tape-outs. To rigorously assess IP leakage, we quantify structural similarity
(AST/Dolos) and functional equivalence (Synopsys Formality) between generated
codes and our in-house IP. We show that our IP can indeed be leaked, confirming
the threat. As defense, we evaluate logic locking of Verilog codes (ASSURE).
This offers some level of protection, yet reduces the IP's utility for FT and
degrades the LLM's performance. Our study shows the need for novel strategies
that are both effective and minimally disruptive to FT, an essential effort for
enabling design houses to fully utilize their proprietary IP toward LLM-driven
Verilog coding.","['Zeng Wang', 'Minghao Shao', 'Mohammed Nabeel', 'Prithwish Basu Roy', 'Likhitha Mankali', 'Jitendra Bhandari', 'Ramesh Karri', 'Ozgur Sinanoglu', 'Muhammad Shafique', 'Johann Knechtel']",2025-03-17,"['cs.CR', 'cs.AR', 'cs.LG']",,http://arxiv.org/pdf/2503.13116v1
2503.13115v1,Beyond Propagation of Chaos: A Stochastic Algorithm for Mean Field Optimization,"Gradient flow in the 2-Wasserstein space is widely used to optimize
functionals over probability distributions and is typically implemented using
an interacting particle system with $n$ particles. Analyzing these algorithms
requires showing (a) that the finite-particle system converges and/or (b) that
the resultant empirical distribution of the particles closely approximates the
optimal distribution (i.e., propagation of chaos). However, establishing
efficient sufficient conditions can be challenging, as the finite particle
system may produce heavily dependent random variables.
  In this work, we study the virtual particle stochastic approximation,
originally introduced for Stein Variational Gradient Descent. This method can
be viewed as a form of stochastic gradient descent in the Wasserstein space and
can be implemented efficiently. In popular settings, we demonstrate that our
algorithm's output converges to the optimal distribution under conditions
similar to those for the infinite particle limit, and it produces i.i.d.
samples without the need to explicitly establish propagation of chaos bounds.","['Chandan Tankala', 'Dheeraj M. Nagaraj', 'Anant Raj']",2025-03-17,"['cs.LG', 'cs.AI', 'math.PR', 'stat.ML']",,http://arxiv.org/pdf/2503.13115v1
2503.13113v1,Exploring the Potential of Bilevel Optimization for Calibrating Neural Networks,"Handling uncertainty is critical for ensuring reliable decision-making in
intelligent systems. Modern neural networks are known to be poorly calibrated,
resulting in predicted confidence scores that are difficult to use. This
article explores improving confidence estimation and calibration through the
application of bilevel optimization, a framework designed to solve hierarchical
problems with interdependent optimization levels. A self-calibrating bilevel
neural-network training approach is introduced to improve a model's predicted
confidence scores. The effectiveness of the proposed framework is analyzed
using toy datasets, such as Blobs and Spirals, as well as more practical
simulated datasets, such as Blood Alcohol Concentration (BAC). It is compared
with a well-known and widely used calibration strategy, isotonic regression.
The reported experimental results reveal that the proposed bilevel optimization
approach reduces the calibration error while preserving accuracy.","['Gabriele Sanguin', 'Arjun Pakrashi', 'Marco Viola', 'Francesco Rinaldi']",2025-03-17,['cs.LG'],,http://arxiv.org/pdf/2503.13113v1
2503.13111v1,MM-Spatial: Exploring 3D Spatial Understanding in Multimodal LLMs,"Multimodal large language models (MLLMs) excel at 2D visual understanding but
remain limited in their ability to reason about 3D space. In this work, we
leverage large-scale high-quality 3D scene data with open-set annotations to
introduce 1) a novel supervised fine-tuning dataset and 2) a new evaluation
benchmark, focused on indoor scenes. Our Cubify Anything VQA (CA-VQA) data
covers diverse spatial tasks including spatial relationship prediction, metric
size and distance estimation, and 3D grounding. We show that CA-VQA enables us
to train MM-Spatial, a strong generalist MLLM that also achieves
state-of-the-art performance on 3D spatial understanding benchmarks, including
our own. We show how incorporating metric depth and multi-view inputs (provided
in CA-VQA) can further improve 3D understanding, and demonstrate that data
alone allows our model to achieve depth perception capabilities comparable to
dedicated monocular depth estimation models. We will publish our SFT dataset
and benchmark.","['Erik Daxberger', 'Nina Wenzel', 'David Griffiths', 'Haiming Gang', 'Justin Lazarow', 'Gefen Kohavi', 'Kai Kang', 'Marcin Eichner', 'Yinfei Yang', 'Afshin Dehghan', 'Peter Grasch']",2025-03-17,"['cs.CV', 'cs.CL', 'cs.LG']",,http://arxiv.org/pdf/2503.13111v1
2503.13572v1,VeriContaminated: Assessing LLM-Driven Verilog Coding for Data Contamination,"Large Language Models (LLMs) have revolutionized code generation, achieving
exceptional results on various established benchmarking frameworks. However,
concerns about data contamination - where benchmark data inadvertently leaks
into pre-training or fine-tuning datasets - raise questions about the validity
of these evaluations. While this issue is known, limiting the industrial
adoption of LLM-driven software engineering, hardware coding has received
little to no attention regarding these risks. For the first time, we analyze
state-of-the-art (SOTA) evaluation frameworks for Verilog code generation
(VerilogEval and RTLLM), using established methods for contamination detection
(CCD and Min-K% Prob). We cover SOTA commercial and open-source LLMs
(CodeGen2.5, Minitron 4b, Mistral 7b, phi-4 mini, LLaMA-{1,2,3.1},
GPT-{2,3.5,4o}, Deepseek-Coder, and CodeQwen 1.5), in baseline and fine-tuned
models (RTLCoder and Verigen). Our study confirms that data contamination is a
critical concern. We explore mitigations and the resulting trade-offs for code
quality vs fairness (i.e., reducing contamination toward unbiased
benchmarking).","['Zeng Wang', 'Minghao Shao', 'Jitendra Bhandari', 'Likhitha Mankali', 'Ramesh Karri', 'Ozgur Sinanoglu', 'Muhammad Shafique', 'Johann Knechtel']",2025-03-17,"['cs.AR', 'cs.CR', 'cs.LG']",,http://arxiv.org/pdf/2503.13572v1
2503.13570v1,ExChanGeAI: An End-to-End Platform and Efficient Foundation Model for Electrocardiogram Analysis and Fine-tuning,"Electrocardiogram data, one of the most widely available biosignal data, has
become increasingly valuable with the emergence of deep learning methods,
providing novel insights into cardiovascular diseases and broader health
conditions. However, heterogeneity of electrocardiogram formats, limited access
to deep learning model weights and intricate algorithmic steps for effective
fine-tuning for own disease target labels result in complex workflows. In this
work, we introduce ExChanGeAI, a web-based end-to-end platform that streamlines
the reading of different formats, pre-processing, visualization and custom
machine learning with local and privacy-preserving fine-tuning. ExChanGeAI is
adaptable for use on both personal computers and scalable to high performance
server environments. The platform offers state-of-the-art deep learning models
for training from scratch, alongside our novel open-source electrocardiogram
foundation model CardX, pre-trained on over one million electrocardiograms.
Evaluation across three external validation sets, including an entirely new
testset extracted from routine care, demonstrate the fine-tuning capabilities
of ExChanGeAI. CardX outperformed the benchmark foundation model while
requiring significantly fewer parameters and lower computational resources. The
platform enables users to empirically determine the most suitable model for
their specific tasks based on systematic validations.The code is available at
https://imigitlab.uni-muenster.de/published/exchangeai .","['Lucas Bickmann', 'Lucas Plagwitz', 'Antonius Büscher', 'Lars Eckardt', 'Julian Varghese']",2025-03-17,"['cs.LG', 'cs.AI']",,http://arxiv.org/pdf/2503.13570v1
2503.13077v1,Towards Better Sample Efficiency in Multi-Agent Reinforcement Learning via Exploration,"Multi-agent reinforcement learning has shown promise in learning cooperative
behaviors in team-based environments. However, such methods often demand
extensive training time. For instance, the state-of-the-art method TiZero takes
40 days to train high-quality policies for a football environment. In this
paper, we hypothesize that better exploration mechanisms can improve the sample
efficiency of multi-agent methods. We propose two different approaches for
better exploration in TiZero: a self-supervised intrinsic reward and a random
network distillation bonus. Additionally, we introduce architectural
modifications to the original algorithm to enhance TiZero's computational
efficiency. We evaluate the sample efficiency of these approaches through
extensive experiments. Our results show that random network distillation
improves training sample efficiency by 18.8% compared to the original TiZero.
Furthermore, we evaluate the qualitative behavior of the models produced by
both variants against a heuristic AI, with the self-supervised reward
encouraging possession and random network distillation leading to a more
offensive performance. Our results highlights the applicability of our random
network distillation variant in practical settings. Lastly, due to the nature
of the proposed method, we acknowledge its use beyond football simulation,
especially in environments with strong multi-agent and strategic aspects.","['Amir Baghi', 'Jens Sjölund', 'Joakim Bergdahl', 'Linus Gisslén', 'Alessandro Sestini']",2025-03-17,"['cs.LG', 'cs.MA']","8 pages, 3 figures",http://arxiv.org/pdf/2503.13077v1
2503.13057v1,"MaskSDM with Shapley values to improve flexibility, robustness, and explainability in species distribution modeling","Species Distribution Models (SDMs) play a vital role in biodiversity
research, conservation planning, and ecological niche modeling by predicting
species distributions based on environmental conditions. The selection of
predictors is crucial, strongly impacting both model accuracy and how well the
predictions reflect ecological patterns. To ensure meaningful insights, input
variables must be carefully chosen to match the study objectives and the
ecological requirements of the target species. However, existing SDMs,
including both traditional and deep learning-based approaches, often lack key
capabilities for variable selection: (i) flexibility to choose relevant
predictors at inference without retraining; (ii) robustness to handle missing
predictor values without compromising accuracy; and (iii) explainability to
interpret and accurately quantify each predictor's contribution. To overcome
these limitations, we introduce MaskSDM, a novel deep learning-based SDM that
enables flexible predictor selection by employing a masked training strategy.
This approach allows the model to make predictions with arbitrary subsets of
input variables while remaining robust to missing data. It also provides a
clearer understanding of how adding or removing a given predictor affects model
performance and predictions. Additionally, MaskSDM leverages Shapley values for
precise predictor contribution assessments, improving upon traditional
approximations. We evaluate MaskSDM on the global sPlotOpen dataset, modeling
the distributions of 12,738 plant species. Our results show that MaskSDM
outperforms imputation-based methods and approximates models trained on
specific subsets of variables. These findings underscore MaskSDM's potential to
increase the applicability and adoption of SDMs, laying the groundwork for
developing foundation models in SDMs that can be readily applied to diverse
ecological applications.","['Robin Zbinden', 'Nina van Tiel', 'Gencer Sumbul', 'Chiara Vanalli', 'Benjamin Kellenberger', 'Devis Tuia']",2025-03-17,"['cs.LG', 'cs.CV']",,http://arxiv.org/pdf/2503.13057v1
2503.13056v1,Deep Hedging of Green PPAs in Electricity Markets,"In power markets, Green Power Purchase Agreements have become an important
contractual tool of the energy transition from fossil fuels to renewable
sources such as wind or solar radiation. Trading Green PPAs exposes agents to
price risks and weather risks. Also, developed electricity markets feature the
so-called cannibalisation effect : large infeeds induce low prices and vice
versa. As weather is a non-tradable entity the question arises how to hedge and
risk-manage in this highly incom-plete setting. We propose a ''deep hedging''
framework utilising machine learning methods to construct hedging strategies.
The resulting strategies outperform static and dynamic benchmark strategies
with respect to different risk measures.","['Richard Biegler-König', 'Daniel Oeltz']",2025-03-17,"['q-fin.CP', 'cs.LG', 'q-fin.RM']",,http://arxiv.org/pdf/2503.13056v1
2503.13051v1,Permutation Learning with Only N Parameters: From SoftSort to Self-Organizing Gaussians,"Sorting and permutation learning are key concepts in optimization and machine
learning, especially when organizing high-dimensional data into meaningful
spatial layouts. The Gumbel-Sinkhorn method, while effective, requires N*N
parameters to determine a full permutation matrix, making it computationally
expensive for large datasets. Low-rank matrix factorization approximations
reduce memory requirements to 2MN (with M << N), but they still struggle with
very large problems. SoftSort, by providing a continuous relaxation of the
argsort operator, allows differentiable 1D sorting, but it faces challenges
with multidimensional data and complex permutations. In this paper, we present
a novel method for learning permutations using only N parameters, which
dramatically reduces storage costs. Our approach builds on SoftSort, but
extends it by iteratively shuffling the N indices of the elements to be sorted
through a separable learning process. This modification significantly improves
sorting quality, especially for multidimensional data and complex optimization
criteria, and outperforms pure SoftSort. Our method offers improved memory
efficiency and scalability compared to existing approaches, while maintaining
high-quality permutation learning. Its dramatically reduced memory requirements
make it particularly well-suited for large-scale optimization tasks, such as
""Self-Organizing Gaussians"", where efficient and scalable permutation learning
is critical.","['Kai Uwe Barthel', 'Florian Barthel', 'Peter Eisert']",2025-03-17,"['cs.LG', 'cs.CV', 'stat.ML']",,http://arxiv.org/pdf/2503.13051v1
2503.13050v2,E-Values Expand the Scope of Conformal Prediction,"Conformal prediction is a powerful framework for distribution-free
uncertainty quantification. The standard approach to conformal prediction
relies on comparing the ranks of prediction scores: under exchangeability, the
rank of a future test point cannot be too extreme relative to a calibration
set. This rank-based method can be reformulated in terms of p-values. In this
paper, we explore an alternative approach based on e-values, known as conformal
e-prediction. E-values offer key advantages that cannot be achieved with
p-values, enabling new theoretical and practical capabilities. In particular,
we present three applications that leverage the unique strengths of e-values:
batch anytime-valid conformal prediction, fixed-size conformal sets with
data-dependent coverage, and conformal prediction under ambiguous ground truth.
Overall, these examples demonstrate that e-value-based constructions provide a
flexible expansion of the toolbox of conformal prediction.","['Etienne Gauthier', 'Francis Bach', 'Michael I. Jordan']",2025-03-17,"['stat.ML', 'cs.LG']",Code available at: https://github.com/GauthierE/evalues-expand-cp,http://arxiv.org/pdf/2503.13050v2
2503.13568v1,WMINet: A Wheel-Mounted Inertial Learning Approach For Mobile-Robot Positioning,"Autonomous mobile robots are widely used for navigation, transportation, and
inspection tasks indoors and outdoors. In practical situations of limited
satellite signals or poor lighting conditions, navigation depends only on
inertial sensors. In such cases, the navigation solution rapidly drifts due to
inertial measurement errors. In this work, we propose WMINet a wheel-mounted
inertial deep learning approach to estimate the mobile robot's position based
only on its inertial sensors. To that end, we merge two common practical
methods to reduce inertial drift: a wheel-mounted approach and driving the
mobile robot in periodic trajectories. Additionally, we enforce a wheelbase
constraint to further improve positioning performance. To evaluate our proposed
approach we recorded using the Rosbot-XL a wheel-mounted initial dataset
totaling 190 minutes, which is made publicly available. Our approach
demonstrated a 66\% improvement over state-of-the-art approaches. As a
consequence, our approach enables navigation in challenging environments and
bridges the pure inertial gap. This enables seamless robot navigation using
only inertial sensors for short periods.","['Gal Versano', 'Itzik Klein']",2025-03-17,"['cs.RO', 'cs.AI', 'cs.LG']",,http://arxiv.org/pdf/2503.13568v1
2503.13008v1,Knowledge Distillation: Enhancing Neural Network Compression with Integrated Gradients,"Efficient deployment of deep neural networks on resource-constrained devices
demands advanced compression techniques that preserve accuracy and
interoperability. This paper proposes a machine learning framework that
augments Knowledge Distillation (KD) with Integrated Gradients (IG), an
attribution method, to optimise the compression of convolutional neural
networks. We introduce a novel data augmentation strategy where IG maps,
precomputed from a teacher model, are overlaid onto training images to guide a
compact student model toward critical feature representations. This approach
leverages the teacher's decision-making insights, enhancing the student's
ability to replicate complex patterns with reduced parameters. Experiments on
CIFAR-10 demonstrate the efficacy of our method: a student model, compressed
4.1-fold from the MobileNet-V2 teacher, achieves 92.5% classification accuracy,
surpassing the baseline student's 91.4% and traditional KD approaches, while
reducing inference latency from 140 ms to 13 ms--a tenfold speedup. We perform
hyperparameter optimisation for efficient learning. Comprehensive ablation
studies dissect the contributions of KD and IG, revealing synergistic effects
that boost both performance and model explainability. Our method's emphasis on
feature-level guidance via IG distinguishes it from conventional KD, offering a
data-driven solution for mining transferable knowledge in neural architectures.
This work contributes to machine learning by providing a scalable,
interpretable compression technique, ideal for edge computing applications
where efficiency and transparency are paramount.","['David E. Hernandez', 'Jose Ramon Chang', 'Torbjörn E. M. Nordling']",2025-03-17,"['cs.LG', 'cs.CV', '68T05, 68T07', 'I.2.6; I.4.2; I.4.9']","15 pages, 3 figures, conference",http://arxiv.org/pdf/2503.13008v1
2503.13001v1,Linear-Size Neural Network Representation of Piecewise Affine Functions in $\mathbb{R}^2$,"It is shown that any continuous piecewise affine (CPA) function
$\mathbb{R}^2\to\mathbb{R}$ with $p$ pieces can be represented by a ReLU neural
network with two hidden layers and $O(p)$ neurons. Unlike prior work, which
focused on convex pieces, this analysis considers CPA functions with connected
but potentially non-convex pieces.",['Leo Zanotti'],2025-03-17,"['cs.LG', 'cs.NE', 'math.MG', 'stat.ML']",,http://arxiv.org/pdf/2503.13001v1
2503.12993v1,Robot Policy Transfer with Online Demonstrations: An Active Reinforcement Learning Approach,"Transfer Learning (TL) is a powerful tool that enables robots to transfer
learned policies across different environments, tasks, or embodiments. To
further facilitate this process, efforts have been made to combine it with
Learning from Demonstrations (LfD) for more flexible and efficient policy
transfer. However, these approaches are almost exclusively limited to offline
demonstrations collected before policy transfer starts, which may suffer from
the intrinsic issue of covariance shift brought by LfD and harm the performance
of policy transfer. Meanwhile, extensive work in the learning-from-scratch
setting has shown that online demonstrations can effectively alleviate
covariance shift and lead to better policy performance with improved sample
efficiency. This work combines these insights to introduce online
demonstrations into a policy transfer setting. We present Policy Transfer with
Online Demonstrations, an active LfD algorithm for policy transfer that can
optimize the timing and content of queries for online episodic expert
demonstrations under a limited demonstration budget. We evaluate our method in
eight robotic scenarios, involving policy transfer across diverse environment
characteristics, task objectives, and robotic embodiments, with the aim to
transfer a trained policy from a source task to a related but different target
task. The results show that our method significantly outperforms all baselines
in terms of average success rate and sample efficiency, compared to two
canonical LfD methods with offline demonstrations and one active LfD method
with online demonstrations. Additionally, we conduct preliminary sim-to-real
tests of the transferred policy on three transfer scenarios in the real-world
environment, demonstrating the policy effectiveness on a real robot
manipulator.","['Muhan Hou', 'Koen Hindriks', 'A. E. Eiben', 'Kim Baraka']",2025-03-17,"['cs.RO', 'cs.AI', 'cs.LG']",,http://arxiv.org/pdf/2503.12993v1
2503.12978v1,Enhancing Job Salary Prediction with Disentangled Composition Effect Modeling: A Neural Prototyping Approach,"In the era of the knowledge economy, understanding how job skills influence
salary is crucial for promoting recruitment with competitive salary systems and
aligned salary expectations. Despite efforts on salary prediction based on job
positions and talent demographics, there still lacks methods to effectively
discern the set-structured skills' intricate composition effect on job salary.
While recent advances in neural networks have significantly improved accurate
set-based quantitative modeling, their lack of explainability hinders obtaining
insights into the skills' composition effects. Indeed, model explanation for
set data is challenging due to the combinatorial nature, rich semantics, and
unique format. To this end, in this paper, we propose a novel intrinsically
explainable set-based neural prototyping approach, namely \textbf{LGDESetNet},
for explainable salary prediction that can reveal disentangled skill sets that
impact salary from both local and global perspectives. Specifically, we propose
a skill graph-enhanced disentangled discrete subset selection layer to identify
multi-faceted influential input subsets with varied semantics. Furthermore, we
propose a set-oriented prototype learning method to extract globally
influential prototypical sets. The resulting output is transparently derived
from the semantic interplay between these input subsets and global prototypes.
Extensive experiments on four real-world datasets demonstrate that our method
achieves superior performance than state-of-the-art baselines in salary
prediction while providing explainable insights into salary-influencing
patterns.","['Yang Ji', 'Ying Sun', 'Hengshu Zhu']",2025-03-17,['cs.LG'],,http://arxiv.org/pdf/2503.12978v1
2503.12966v1,Optimal Denoising in Score-Based Generative Models: The Role of Data Regularity,"Score-based generative models achieve state-of-the-art sampling performance
by denoising a distribution perturbed by Gaussian noise. In this paper, we
focus on a single deterministic denoising step, and compare the optimal
denoiser for the quadratic loss, we name ''full-denoising'', to the alternative
''half-denoising'' introduced by Hyv{\""a}rinen (2024). We show that looking at
the performances in term of distance between distribution tells a more nuanced
story, with different assumptions on the data leading to very different
conclusions. We prove that half-denoising is better than full-denoising for
regular enough densities, while full-denoising is better for singular densities
such as mixtures of Dirac measures or densities supported on a low-dimensional
subspace. In the latter case, we prove that full-denoising can alleviate the
curse of dimensionality under a linear manifold hypothesis.","['Eliot Beyler', 'Francis Bach']",2025-03-17,"['cs.LG', 'stat.ML']",,http://arxiv.org/pdf/2503.12966v1
2503.12964v1,Training Video Foundation Models with NVIDIA NeMo,"Video Foundation Models (VFMs) have recently been used to simulate the real
world to train physical AI systems and develop creative visual experiences.
However, there are significant challenges in training large-scale, high quality
VFMs that can generate high-quality videos. We present a scalable, open-source
VFM training pipeline with NVIDIA NeMo, providing accelerated video dataset
curation, multimodal data loading, and parallelized video diffusion model
training and inference. We also provide a comprehensive performance analysis
highlighting best practices for efficient VFM training and inference.","['Zeeshan Patel', 'Ethan He', 'Parth Mannan', 'Xiaowei Ren', 'Ryan Wolf', 'Niket Agarwal', 'Jacob Huffman', 'Zhuoyao Wang', 'Carl Wang', 'Jack Chang', 'Yan Bai', 'Tommy Huang', 'Linnan Wang', 'Sahil Jain', 'Shanmugam Ramasamy', 'Joseph Jennings', 'Ekaterina Sirazitdinova', 'Oleg Sudakov', 'Mingyuan Ma', 'Bobby Chen', 'Forrest Lin', 'Hao Wang', 'Vasanth Rao Naik Sabavat', 'Sriharsha Niverty', 'Rong Ou', 'Pallab Bhattacharya', 'David Page', 'Nima Tajbakhsh', 'Ashwath Aithal']",2025-03-17,"['cs.CV', 'cs.AI', 'cs.LG']",,http://arxiv.org/pdf/2503.12964v1
2503.13566v1,Classification of power quality events in the transmission grid: comparative evaluation of different machine learning models,"Automatic classification of electric power quality events with respect to
their root causes is critical for electrical grid management. In this paper, we
present comparative evaluation results of an extensive set of machine learning
models for the classification of power quality events, based on their root
causes. After extensive experiments using different machine learning libraries,
it is observed that the best performing learning models turn out to be Cubic
SVM and XGBoost. During error analysis, it is observed that the main source of
performance degradation for both models is the classification of ABC faults as
ABCG faults, or vice versa. Ultimately, the models achieving the best results
will be integrated into the event classification module of a large-scale power
quality and grid monitoring system for the Turkish electricity transmission
system.","['Umut Güvengir', 'Dilek Küçük', 'Serkan Buhan', 'Cuma Ali Mantaş', 'Murathan Yeniceli']",2025-03-17,"['eess.SP', 'cs.LG']",Presented at CIGRE SEERC 2023 Conference,http://arxiv.org/pdf/2503.13566v1
2503.12941v1,HiDe-LLaVA: Hierarchical Decoupling for Continual Instruction Tuning of Multimodal Large Language Model,"Instruction tuning is widely used to improve a pre-trained Multimodal Large
Language Model (MLLM) by training it on curated task-specific datasets,
enabling better comprehension of human instructions. However, it is infeasible
to collect all possible instruction datasets simultaneously in real-world
scenarios. Thus, enabling MLLM with continual instruction tuning is essential
for maintaining their adaptability. However, existing methods often trade off
memory efficiency for performance gains, significantly compromising overall
efficiency. In this paper, we propose a task-specific expansion and
task-general fusion framework based on the variations in Centered Kernel
Alignment (CKA) similarity across different model layers when trained on
diverse datasets. Furthermore, we analyze the information leakage present in
the existing benchmark and propose a new and more challenging benchmark to
rationally evaluate the performance of different methods. Comprehensive
experiments showcase a significant performance improvement of our method
compared to existing state-of-the-art methods. Our code will be public
available.","['Haiyang Guo', 'Fanhu Zeng', 'Ziwei Xiang', 'Fei Zhu', 'Da-Han Wang', 'Xu-Yao Zhang', 'Cheng-Lin Liu']",2025-03-17,"['cs.CL', 'cs.LG']",Preprint,http://arxiv.org/pdf/2503.12941v1
2503.12937v1,R1-VL: Learning to Reason with Multimodal Large Language Models via Step-wise Group Relative Policy Optimization,"Recent studies generally enhance MLLMs' reasoning capabilities via supervised
fine-tuning on high-quality chain-of-thought reasoning data, which often leads
models to merely imitate successful reasoning paths without understanding what
the wrong reasoning paths are. In this work, we aim to enhance the MLLMs'
reasoning ability beyond passively imitating positive reasoning paths. To this
end, we design Step-wise Group Relative Policy Optimization (StepGRPO), a new
online reinforcement learning framework that enables MLLMs to self-improve
reasoning ability via simple, effective and dense step-wise rewarding.
Specifically, StepGRPO introduces two novel rule-based reasoning rewards:
Step-wise Reasoning Accuracy Reward (StepRAR) and Step-wise Reasoning Validity
Reward (StepRVR). StepRAR rewards the reasoning paths that contain necessary
intermediate reasoning steps via a soft key-step matching technique, while
StepRAR rewards reasoning paths that follow a well-structured and logically
consistent reasoning process through a reasoning completeness and logic
evaluation strategy. With the proposed StepGRPO, we introduce R1-VL, a series
of MLLMs with outstanding capabilities in step-by-step reasoning. Extensive
experiments over 8 benchmarks demonstrate the superiority of our methods.","['Jingyi Zhang', 'Jiaxing Huang', 'Huanjin Yao', 'Shunyu Liu', 'Xikun Zhang', 'Shijian Lu', 'Dacheng Tao']",2025-03-17,"['cs.AI', 'cs.CL', 'cs.CV', 'cs.LG']",,http://arxiv.org/pdf/2503.12937v1
2503.12932v1,Efficient Action-Constrained Reinforcement Learning via Acceptance-Rejection Method and Augmented MDPs,"Action-constrained reinforcement learning (ACRL) is a generic framework for
learning control policies with zero action constraint violation, which is
required by various safety-critical and resource-constrained applications. The
existing ACRL methods can typically achieve favorable constraint satisfaction
but at the cost of either high computational burden incurred by the quadratic
programs (QP) or increased architectural complexity due to the use of
sophisticated generative models. In this paper, we propose a generic and
computationally efficient framework that can adapt a standard unconstrained RL
method to ACRL through two modifications: (i) To enforce the action
constraints, we leverage the classic acceptance-rejection method, where we
treat the unconstrained policy as the proposal distribution and derive a
modified policy with feasible actions. (ii) To improve the acceptance rate of
the proposal distribution, we construct an augmented two-objective Markov
decision process (MDP), which include additional self-loop state transitions
and a penalty signal for the rejected actions. This augmented MDP incentives
the learned policy to stay close to the feasible action sets. Through extensive
experiments in both robot control and resource allocation domains, we
demonstrate that the proposed framework enjoys faster training progress, better
constraint satisfaction, and a lower action inference time simultaneously than
the state-of-the-art ACRL methods. We have made the source code publicly
available to encourage further research in this direction.","['Wei Hung', 'Shao-Hua Sun', 'Ping-Chun Hsieh']",2025-03-17,"['cs.LG', 'I.2.6; I.5.1']","23 pages, 14 figures. Accepted at ICLR 2025",http://arxiv.org/pdf/2503.12932v1
2503.12930v1,Augmented Invertible Koopman Autoencoder for long-term time series forecasting,"Following the introduction of Dynamic Mode Decomposition and its numerous
extensions, many neural autoencoder-based implementations of the Koopman
operator have recently been proposed. This class of methods appears to be of
interest for modeling dynamical systems, either through direct long-term
prediction of the evolution of the state or as a powerful embedding for
downstream methods. In particular, a recent line of work has developed
invertible Koopman autoencoders (IKAEs), which provide an exact reconstruction
of the input state thanks to their analytically invertible encoder, based on
coupling layer normalizing flow models. We identify that the conservation of
the dimension imposed by the normalizing flows is a limitation for the IKAE
models, and thus we propose to augment the latent state with a second,
non-invertible encoder network. This results in our new model: the Augmented
Invertible Koopman AutoEncoder (AIKAE). We demonstrate the relevance of the
AIKAE through a series of long-term time series forecasting experiments, on
satellite image time series as well as on a benchmark involving predictions
based on a large lookback window of observations.","['Anthony Frion', 'Lucas Drumetz', 'Mauro Dalla Mura', 'Guillaume Tochon', 'Abdeldjalil Aïssa-El-Bey']",2025-03-17,"['cs.LG', 'stat.ML']",,http://arxiv.org/pdf/2503.12930v1
2503.13565v1,ML-SpecQD: Multi-Level Speculative Decoding with Quantized Drafts,"Speculative decoding (SD) has emerged as a method to accelerate LLM inference
without sacrificing any accuracy over the 16-bit model inference. In a typical
SD setup, the idea is to use a full-precision, small, fast model as ""draft"" to
generate the next few tokens and use the ""target"" large model to verify the
draft-generated tokens. The efficacy of this method heavily relies on the
acceptance ratio of the draft-generated tokens and the relative token
throughput of the draft versus the target model. Nevertheless, an efficient SD
pipeline requires pre-training and aligning the draft model to the target
model, making it impractical for LLM inference in a plug-and-play fashion. In
this work, we propose using MXFP4 models as drafts in a plug-and-play fashion
since the MXFP4 Weight-Only-Quantization (WOQ) merely direct-casts the BF16
target model weights to MXFP4. In practice, our plug-and-play solution gives
speedups up to 2x over the BF16 baseline. Then we pursue an opportunity for
further acceleration: the MXFP4 draft token generation itself can be
accelerated via speculative decoding by using yet another smaller draft. We
call our method ML-SpecQD: Multi-Level Speculative Decoding with Quantized
Drafts since it recursively applies speculation for accelerating the
draft-token generation. Combining Multi-Level Speculative Decoding with MXFP4
Quantized Drafts we outperform state-of-the-art speculative decoding, yielding
speedups up to 2.72x over the BF16 baseline.","['Evangelos Georganas', 'Dhiraj Kalamkar', 'Alexander Kozlov', 'Alexander Heinecke']",2025-03-17,"['cs.CL', 'cs.AI', 'cs.LG']",,http://arxiv.org/pdf/2503.13565v1
2503.12923v1,Lifelong Reinforcement Learning with Similarity-Driven Weighting by Large Models,"Lifelong Reinforcement Learning (LRL) holds significant potential for
addressing sequential tasks, but it still faces considerable challenges. A key
difficulty lies in effectively preventing catastrophic forgetting and
facilitating knowledge transfer while maintaining reliable decision-making
performance across subsequent tasks in dynamic environments. To tackle this, we
propose a novel framework, SDW (Similarity-Driven Weighting Framework), which
leverages large-language-model-generated dynamic functions to precisely control
the training process. The core of SDW lies in two functions pre-generated by
large models: the task similarity function and the weight computation function.
The task similarity function extracts multidimensional features from task
descriptions to quantify the similarities and differences between tasks in
terms of states, actions, and rewards. The weight computation function
dynamically generates critical training parameters based on the similarity
information, including the proportion of old task data stored in the Replay
Buffer and the strategy consistency weight in the loss function, enabling an
adaptive balance between learning new tasks and transferring knowledge from
previous tasks. By generating function code offline prior to training, rather
than relying on large-model inference during the training process, the SDW
framework reduces computational overhead while maintaining efficiency in
sequential task scenarios. Experimental results on Atari and MiniHack
sequential tasks demonstrate that SDW significantly outperforms existing
lifelong reinforcement learning methods.","['Zhiyi Huang', 'Xiaohan Shan', 'Jianmin Li']",2025-03-17,"['cs.LG', 'cs.SI']",,http://arxiv.org/pdf/2503.12923v1
2503.12919v1,COSMOS: Continuous Simplicial Neural Networks,"Simplicial complexes provide a powerful framework for modeling high-order
interactions in structured data, making them particularly suitable for
applications such as trajectory prediction and mesh processing. However,
existing simplicial neural networks (SNNs), whether convolutional or
attention-based, rely primarily on discrete filtering techniques, which can be
restrictive. In contrast, partial differential equations (PDEs) on simplicial
complexes offer a principled approach to capture continuous dynamics in such
structures. In this work, we introduce COntinuous SiMplicial neural netwOrkS
(COSMOS), a novel SNN architecture derived from PDEs on simplicial complexes.
We provide theoretical and experimental justifications of COSMOS's stability
under simplicial perturbations. Furthermore, we investigate the over-smoothing
phenomenon, a common issue in geometric deep learning, demonstrating that
COSMOS offers better control over this effect than discrete SNNs. Our
experiments on real-world datasets of ocean trajectory prediction and
regression on partial deformable shapes demonstrate that COSMOS achieves
competitive performance compared to state-of-the-art SNNs in complex and noisy
environments.","['Aref Einizade', 'Dorina Thanou', 'Fragkiskos D. Malliaros', 'Jhony H. Giraldo']",2025-03-17,['cs.LG'],"17 pages, 6 figures",http://arxiv.org/pdf/2503.12919v1
2503.12912v1,Pose as a Modality: A Psychology-Inspired Network for Personality Recognition with a New Multimodal Dataset,"In recent years, predicting Big Five personality traits from multimodal data
has received significant attention in artificial intelligence (AI). However,
existing computational models often fail to achieve satisfactory performance.
Psychological research has shown a strong correlation between pose and
personality traits, yet previous research has largely ignored pose data in
computational models. To address this gap, we develop a novel multimodal
dataset that incorporates full-body pose data. The dataset includes video
recordings of 287 participants completing a virtual interview with 36
questions, along with self-reported Big Five personality scores as labels. To
effectively utilize this multimodal data, we introduce the Psychology-Inspired
Network (PINet), which consists of three key modules: Multimodal Feature
Awareness (MFA), Multimodal Feature Interaction (MFI), and Psychology-Informed
Modality Correlation Loss (PIMC Loss). The MFA module leverages the Vision
Mamba Block to capture comprehensive visual features related to personality,
while the MFI module efficiently fuses the multimodal features. The PIMC Loss,
grounded in psychological theory, guides the model to emphasize different
modalities for different personality dimensions. Experimental results show that
the PINet outperforms several state-of-the-art baseline models. Furthermore,
the three modules of PINet contribute almost equally to the model's overall
performance. Incorporating pose data significantly enhances the model's
performance, with the pose modality ranking mid-level in importance among the
five modalities. These findings address the existing gap in personality-related
datasets that lack full-body pose data and provide a new approach for improving
the accuracy of personality prediction models, highlighting the importance of
integrating psychological insights into AI frameworks.","['Bin Tang', 'Keqi Pan', 'Miao Zheng', 'Ning Zhou', 'Jialu Sui', 'Dandan Zhu', 'Cheng-Long Deng', 'Shu-Guang Kuai']",2025-03-17,"['cs.CV', 'cs.LG']","9 pages, 6 figures, AAAI 2025 Oral",http://arxiv.org/pdf/2503.12912v1
2503.12902v1,Experiments with Optimal Model Trees,"Model trees provide an appealing way to perform interpretable machine
learning for both classification and regression problems. In contrast to
``classic'' decision trees with constant values in their leaves, model trees
can use linear combinations of predictor variables in their leaf nodes to form
predictions, which can help achieve higher accuracy and smaller trees. Typical
algorithms for learning model trees from training data work in a greedy
fashion, growing the tree in a top-down manner by recursively splitting the
data into smaller and smaller subsets. Crucially, the selected splits are only
locally optimal, potentially rendering the tree overly complex and less
accurate than a tree whose structure is globally optimal for the training data.
In this paper, we empirically investigate the effect of constructing globally
optimal model trees for classification and regression with linear support
vector machines at the leaf nodes. To this end, we present mixed-integer linear
programming formulations to learn optimal trees, compute such trees for a large
collection of benchmark data sets, and compare their performance against
greedily grown model trees in terms of interpretability and accuracy. We also
compare to classic optimal and greedily grown decision trees, random forests,
and support vector machines. Our results show that optimal model trees can
achieve competitive accuracy with very small trees. We also investigate the
effect on the accuracy of replacing axis-parallel splits with multivariate
ones, foregoing interpretability while potentially obtaining greater accuracy.","['Sabino Francesco Roselli', 'Eibe Frank']",2025-03-17,['cs.LG'],,http://arxiv.org/pdf/2503.12902v1
2503.12899v1,A Semantic-based Optimization Approach for Repairing LLMs: Case Study on Code Generation,"Language Models (LMs) are widely used in software engineering for code
generation, but they may produce code with errors. Rather than repairing the
generated code, an alternative way is to address the underlying failures of
models. LM repair offers a lightweight solution to this challenge: it requires
minimal data, reduces computational costs, and reduces the side effects. Unlike
retraining, LM repair focuses on applying tailored updates to targeted neurons,
making it ideal for scenarios with limited resources, high-performance demands,
or strict safety requirements. In this paper, we propose \ul{S}emantic
\ul{T}argeting for \ul{A}nalytical \ul{R}epair (\textsc{STAR}), a pioneering
and novel semantic-based optimization approach for repairing LLMs.
\textsc{STAR} realizes main operations in LM repair methods in an optimization
process, including locating ``buggy neurons'', solving ``neuron patches'', and
patching ``buggy neurons''. Correspondingly, it computes the deltas of weight
matrix as the prior information to guide optimization; and attributes the
targeted layers and neurons leveraging statistical insights. The neuron patches
are computed with a solid semantic-based analytical formula, which directly
bridges the changes to logits with the deltas of neurons, by steering latent
representations. Compared to the prior work of LM repair (\textsc{MINT}) and
optimization methods (\textsc{SGD}), \textsc{STAR} integrates their strengths
while mitigating their limitations. \textsc{STAR} supports solving multiple
failures together, significantly improving the usefulness. Evaluated on three
code generation tasks using popular code LMs, \textsc{STAR} demonstrates
superior effectiveness. Additionally, \textsc{STAR} exhibits better efficiency.
In terms of side effects, namely the balance between generalization and
specificity, \textsc{STAR} outperforms prior work by a significant margin.","['Jian Gu', 'Aldeida Aleti', 'Chunyang Chen', 'Hongyu Zhang']",2025-03-17,"['cs.SE', 'cs.CL', 'cs.LG']","12 pages, 6 figure, 6 tables, under peer-review",http://arxiv.org/pdf/2503.12899v1
2503.12897v1,Federated Continual Instruction Tuning,"A vast amount of instruction tuning data is crucial for the impressive
performance of Large Multimodal Models (LMMs), but the associated computational
costs and data collection demands during supervised fine-tuning make it
impractical for most researchers. Federated learning (FL) has the potential to
leverage all distributed data and training resources to reduce the overhead of
joint training. However, most existing methods assume a fixed number of tasks,
while in real-world scenarios, clients continuously encounter new knowledge and
often struggle to retain old tasks due to memory constraints. In this work, we
introduce the Federated Continual Instruction Tuning (FCIT) benchmark to model
this real-world challenge. Our benchmark includes two realistic scenarios,
encompassing four different settings and twelve carefully curated instruction
tuning datasets. To address the challenges posed by FCIT, we propose dynamic
knowledge organization to effectively integrate updates from different tasks
during training and subspace selective activation to allocate task-specific
output during inference. Extensive experimental results demonstrate that our
proposed method significantly enhances model performance across varying levels
of data heterogeneity and catastrophic forgetting. Our source code and dataset
will be made publicly available.","['Haiyang Guo', 'Fanhu Zeng', 'Fei Zhu', 'Wenzhuo Liu', 'Da-Han Wang', 'Jian Xu', 'Xu-Yao Zhang', 'Cheng-Lin Liu']",2025-03-17,"['cs.LG', 'cs.AI']",Preprint,http://arxiv.org/pdf/2503.12897v1
2503.12893v1,Edgeworth Expansion for Semi-hard Triplet Loss,"We develop a higher-order asymptotic analysis for the semi-hard triplet loss
using the Edgeworth expansion. It is known that this loss function enforces
that embeddings of similar samples are close while those of dissimilar samples
are separated by a specified margin. By refining the classical central limit
theorem, our approach quantifies the impact of the margin parameter and the
skewness of the underlying data distribution on the loss behavior. In
particular, we derive explicit Edgeworth expansions that reveal first-order
corrections in terms of the third cumulant, thereby characterizing non-Gaussian
effects present in the distribution of distance differences between
anchor-positive and anchor-negative pairs. Our findings provide detailed
insight into the sensitivity of the semi-hard triplet loss to its parameters
and offer guidance for choosing the margin to ensure training stability.",['Masanari Kimura'],2025-03-17,"['stat.ML', 'cs.LG']",,http://arxiv.org/pdf/2503.12893v1
2503.13562v1,Micro Text Classification Based on Balanced Positive-Unlabeled Learning,"In real-world text classification tasks, negative texts often contain a
minimal proportion of negative content, which is especially problematic in
areas like text quality control, legal risk screening, and sensitive
information interception. This challenge manifests at two levels: at the macro
level, distinguishing negative texts is difficult due to the high similarity
between coarse-grained positive and negative samples; at the micro level, the
issue stems from extreme class imbalance and a lack of fine-grained labels. To
address these challenges, we propose transforming the coarse-grained
positive-negative (PN) classification task into an imbalanced fine-grained
positive-unlabeled (PU) classification problem, supported by theoretical
analysis. We introduce a novel framework, Balanced Fine-Grained
Positive-Unlabeled (BFGPU) learning, which features a unique PU learning loss
function that optimizes macro-level performance amidst severe imbalance at the
micro level. The framework's performance is further boosted by rebalanced
pseudo-labeling and threshold adjustment. Extensive experiments on both public
and real-world datasets demonstrate the effectiveness of BFGPU, which
outperforms other methods, even in extreme scenarios where both macro and micro
levels are highly imbalanced.","['Lin-Han Jia', 'Lan-Zhe Guo', 'Zhi Zhou', 'Si-Ye Han', 'Zi-Wen Li', 'Yu-Feng Li']",2025-03-17,"['stat.ML', 'cs.AI', 'cs.LG']",,http://arxiv.org/pdf/2503.13562v1
2503.12883v1,Early Detection of Forest Calamities in Homogeneous Stands -- Deep Learning Applied to Bark-Beetle Outbreaks,"Climate change has increased the vulnerability of forests to insect-related
damage, resulting in widespread forest loss in Central Europe and highlighting
the need for effective, continuous monitoring systems. Remote sensing based
forest health monitoring, oftentimes, relies on supervised machine learning
algorithms that require labeled training data. Monitoring temporal patterns
through time series analysis offers a potential alternative for earlier
detection of disturbance but requires substantial storage resources. This study
investigates the potential of a Deep Learning algorithm based on a Long Short
Term Memory (LSTM) Autoencoder for the detection of anomalies in forest health
(e.g. bark beetle outbreaks), utilizing Sentinel-2 time series data. This
approach is an alternative to supervised machine learning methods, avoiding the
necessity for labeled training data. Furthermore, it is more memory-efficient
than other time series analysis approaches, as a robust model can be created
using only a 26-week-long time series as input. In this study, we monitored
pure stands of spruce in Thuringia, Germany, over a 7-year period from 2018 to
the end of 2024. Our best model achieved a detection accuracy of 87% on test
data and was able to detect 61% of all anomalies at a very early stage (more
than a month before visible signs of forest degradation). Compared to another
widely used time series break detection algorithm - BFAST (Breaks For Additive
Season and Trend), our approach consistently detected higher percentage of
anomalies at an earlier stage. These findings suggest that LSTM-based
Autoencoders could provide a promising, resource-efficient approach to forest
health monitoring, enabling more timely responses to emerging threats.","['Maximilian Kirsch', 'Jakob Wernicke', 'Pawan Datta', 'Christine Preisach']",2025-03-17,['cs.LG'],"24 pages, 18 figures, submitted to IEEE: Journal of Selected Topics
  in Applied Earth Observations and Remote Sensing",http://arxiv.org/pdf/2503.12883v1
2503.12882v1,DAPI: Domain Adaptive Toxicity Probe Vector Intervention for Fine-Grained Detoxification,"There have been attempts to utilize linear probe for detoxification, with
existing studies relying on a single toxicity probe vector to reduce toxicity.
However, toxicity can be fine-grained into various subcategories, making it
difficult to remove certain types of toxicity by using a single toxicity probe
vector. To address this limitation, we propose a category-specific toxicity
probe vector approach. First, we train multiple toxicity probe vectors for
different toxicity categories. During generation, we dynamically select the
most relevant toxicity probe vector based on the current context. Finally, the
selected vector is dynamically scaled and subtracted from model. Our method
successfully mitigated toxicity from categories that the single probe vector
approach failed to detoxify. Experiments demonstrate that our approach achieves
up to a 78.52% reduction in toxicity on the evaluation dataset, while fluency
remains nearly unchanged, with only a 0.052% drop compared to the unsteered
model.","['Cho Hyeonsu', 'Dooyoung Kim', 'Youngjoong Ko']",2025-03-17,"['cs.CL', 'cs.LG']","10 pages, 3 figures",http://arxiv.org/pdf/2503.12882v1
2503.12858v1,Harnessing Test-time Adaptation for NLU tasks Involving Dialects of English,"Test-time adaptation (TTA) is an excellent method which helps generalize
models across domains, tasks, and distributions without the use of labeled
datasets. Thus, TTA is very useful in natural language processing (NLP) in the
dialectal setting, since oftentimes, models are trained on Standard American
English (SAE), evaluated on Indian English or Nigerian English, of which
distribution differs significantly from the former. This is especially useful
since dialectal datasets are scarce. In this paper, we explore one of the most
famous TTA techniques, SHOT, in dialectal NLP. We finetune and evaluate SHOT on
different combinations of dialectal GLUE. Our findings show that SHOT is a
viable technique when labeled datasets are unavailable. We also theoretically
propose the concept of dialectal gap and show that it has a positive
correlation with the effectiveness of SHOT. We also find that in many cases,
finetuning on SAE yields higher performance than finetuning on dialectal data.
Our code is available at https://github.com/dukenguyenxyz/dialect-adaptation","['Duke Nguyen', 'Aditya Joshi', 'Flora Salim']",2025-03-17,"['cs.CL', 'cs.LG']",,http://arxiv.org/pdf/2503.12858v1
2503.12856v1,Island-Based Evolutionary Computation with Diverse Surrogates and Adaptive Knowledge Transfer for High-Dimensional Data-Driven Optimization,"In recent years, there has been a growing interest in data-driven
evolutionary algorithms (DDEAs) employing surrogate models to approximate the
objective functions with limited data. However, current DDEAs are primarily
designed for lower-dimensional problems and their performance drops
significantly when applied to large-scale optimization problems (LSOPs). To
address the challenge, this paper proposes an offline DDEA named DSKT-DDEA.
DSKT-DDEA leverages multiple islands that utilize different data to establish
diverse surrogate models, fostering diverse subpopulations and mitigating the
risk of premature convergence. In the intra-island optimization phase, a
semi-supervised learning method is devised to fine-tune the surrogates. It not
only facilitates data argumentation, but also incorporates the distribution
information gathered during the search process to align the surrogates with the
evolving local landscapes. Then, in the inter-island knowledge transfer phase,
the algorithm incorporates an adaptive strategy that periodically transfers
individual information and evaluates the transfer effectiveness in the new
environment, facilitating global optimization efficacy. Experimental results
demonstrate that our algorithm is competitive with state-of-the-art DDEAs on
problems with up to 1000 dimensions, while also exhibiting decent parallelism
and scalability. Our DSKT-DDEA is open-source and accessible at:
https://github.com/LabGong/DSKT-DDEA.","['Xian-Rong Zhang', 'Yue-Jiao Gong', 'Zhiguang Cao', 'Jun Zhang']",2025-03-17,"['cs.LG', 'cs.NE']",31 pages,http://arxiv.org/pdf/2503.12856v1
2503.12853v1,Adaptive Transformer Attention and Multi-Scale Fusion for Spine 3D Segmentation,"This study proposes a 3D semantic segmentation method for the spine based on
the improved SwinUNETR to improve segmentation accuracy and robustness. Aiming
at the complex anatomical structure of spinal images, this paper introduces a
multi-scale fusion mechanism to enhance the feature extraction capability by
using information of different scales, thereby improving the recognition
accuracy of the model for the target area. In addition, the introduction of the
adaptive attention mechanism enables the model to dynamically adjust the
attention to the key area, thereby optimizing the boundary segmentation effect.
The experimental results show that compared with 3D CNN, 3D U-Net, and 3D U-Net
+ Transformer, the model of this study has achieved significant improvements in
mIoU, mDice, and mAcc indicators, and has better segmentation performance. The
ablation experiment further verifies the effectiveness of the proposed improved
method, proving that multi-scale fusion and adaptive attention mechanism have a
positive effect on the segmentation task. Through the visualization analysis of
the inference results, the model can better restore the real anatomical
structure of the spinal image. Future research can further optimize the
Transformer structure and expand the data scale to improve the generalization
ability of the model. This study provides an efficient solution for the task of
medical image segmentation, which is of great significance to intelligent
medical image analysis.","['Yanlin Xiang', 'Qingyuan He', 'Ting Xu', 'Ran Hao', 'Jiacheng Hu', 'Hanchao Zhang']",2025-03-17,"['cs.CV', 'cs.LG']",,http://arxiv.org/pdf/2503.12853v1
2503.12822v1,An Optimization Framework for Differentially Private Sparse Fine-Tuning,"Differentially private stochastic gradient descent (DP-SGD) is broadly
considered to be the gold standard for training and fine-tuning neural networks
under differential privacy (DP). With the increasing availability of
high-quality pre-trained model checkpoints (e.g., vision and language models),
fine-tuning has become a popular strategy. However, despite recent progress in
understanding and applying DP-SGD for private transfer learning tasks,
significant challenges remain -- most notably, the performance gap between
models fine-tuned with DP-SGD and their non-private counterparts. Sparse
fine-tuning on private data has emerged as an alternative to full-model
fine-tuning; recent work has shown that privately fine-tuning only a small
subset of model weights and keeping the rest of the weights fixed can lead to
better performance. In this work, we propose a new approach for sparse
fine-tuning of neural networks under DP. Existing work on private sparse
finetuning often used fixed choice of trainable weights (e.g., updating only
the last layer), or relied on public model's weights to choose the subset of
weights to modify. Such choice of weights remains suboptimal. In contrast, we
explore an optimization-based approach, where our selection method makes use of
the private gradient information, while using off the shelf privacy accounting
techniques. Our numerical experiments on several computer vision models and
datasets show that our selection method leads to better prediction accuracy,
compared to full-model private fine-tuning or existing private sparse
fine-tuning approaches.","['Mehdi Makni', 'Kayhan Behdin', 'Gabriel Afriat', 'Zheng Xu', 'Sergei Vassilvitskii', 'Natalia Ponomareva', 'Hussein Hazimeh', 'Rahul Mazumder']",2025-03-17,"['cs.LG', 'stat.ML']",,http://arxiv.org/pdf/2503.12822v1
2503.12813v2,Epidemic Forecasting with a Hybrid Deep Learning Method Using CNN-LSTM With WOA-GWO Parameter Optimization: Global COVID-19 Case Study,"Effective epidemic modeling is essential for managing public health crises,
requiring robust methods to predict disease spread and optimize resource
allocation. This study introduces a novel deep learning framework that advances
time series forecasting for infectious diseases, with its application to COVID
19 data as a critical case study. Our hybrid approach integrates Convolutional
Neural Networks (CNNs) and Long Short Term Memory (LSTM) models to capture
spatial and temporal dynamics of disease transmission across diverse regions.
The CNN extracts spatial features from raw epidemiological data, while the LSTM
models temporal patterns, yielding precise and adaptable predictions. To
maximize performance, we employ a hybrid optimization strategy combining the
Whale Optimization Algorithm (WOA) and Gray Wolf Optimization (GWO) to fine
tune hyperparameters, such as learning rates, batch sizes, and training epochs
enhancing model efficiency and accuracy. Applied to COVID 19 case data from 24
countries across six continents, our method outperforms established benchmarks,
including ARIMA and standalone LSTM models, with statistically significant
gains in predictive accuracy (e.g., reduced RMSE). This framework demonstrates
its potential as a versatile method for forecasting epidemic trends, offering
insights for resource planning and decision making in both historical contexts,
like the COVID 19 pandemic, and future outbreaks.","['Mousa Alizadeh', 'Mohammad Hossein Samaei', 'Azam Seilsepour', 'Mohammad TH Beheshti']",2025-03-17,"['eess.IV', 'cs.LG']",,http://arxiv.org/pdf/2503.12813v2
2503.12811v1,A Multi-Power Law for Loss Curve Prediction Across Learning Rate Schedules,"Training large models is both resource-intensive and time-consuming, making
it crucial to understand the quantitative relationship between model
performance and hyperparameters. In this paper, we present an empirical law
that describes how the pretraining loss of large language models evolves under
different learning rate schedules, such as constant, cosine, and step decay
schedules. Our proposed law takes a multi-power form, combining a power law
based on the sum of learning rates and additional power laws to account for a
loss reduction effect induced by learning rate decay. We extensively validate
this law on various model sizes and architectures, and demonstrate that after
fitting on a few learning rate schedules, the law accurately predicts the loss
curves for unseen schedules of different shapes and horizons. Moreover, by
minimizing the predicted final pretraining loss across learning rate schedules,
we are able to find a schedule that outperforms the widely used cosine learning
rate schedule. Interestingly, this automatically discovered schedule bears some
resemblance to the recently proposed Warmup-Stable-Decay (WSD) schedule (Hu et
al, 2024) but achieves a slightly lower final loss. We believe these results
could offer valuable insights for understanding the dynamics of pretraining and
designing learning rate schedules to improve efficiency.","['Kairong Luo', 'Haodong Wen', 'Shengding Hu', 'Zhenbo Sun', 'Zhiyuan Liu', 'Maosong Sun', 'Kaifeng Lyu', 'Wenguang Chen']",2025-03-17,"['cs.LG', 'cs.AI', 'cs.CL', 'stat.ML']",,http://arxiv.org/pdf/2503.12811v1
2503.12808v2,"Estimating stationary mass, frequency by frequency","Suppose we observe a trajectory of length $n$ from an $\alpha$-mixing
stochastic process over a finite but potentially large state space. We consider
the problem of estimating the probability mass placed by the stationary
distribution of any such process on elements that occur with a certain
frequency in the observed sequence. We estimate this vector of probabilities in
total variation distance, showing universal consistency in $n$ and recovering
known results for i.i.d. sequences as special cases. Our proposed methodology
carefully combines the plug-in (or empirical) estimator with a
recently-proposed modification of the Good--Turing estimator called WingIt,
which was originally developed for Markovian sequences. En route to controlling
the error of our estimator, we develop new performance bounds on WingIt and the
plug-in estimator for $\alpha$-mixing stochastic processes. Importantly, the
extensively used method of Poissonization can no longer be applied in our non
i.i.d. setting, and so we develop complementary tools -- including
concentration inequalities for a natural self-normalized statistic of mixing
sequences -- that may prove independently useful in the design and analysis of
estimators for related problems.","['Milind Nakul', 'Vidya Muthukumar', 'Ashwin Pananjady']",2025-03-17,"['stat.ML', 'cs.IT', 'cs.LG', 'math.IT', 'math.PR', 'math.ST', 'stat.TH']",,http://arxiv.org/pdf/2503.12808v2
2503.12803v1,Leveraging Deep Neural Networks for Aspect-Based Sentiment Classification,"Aspect-based sentiment analysis seeks to determine sentiment with a high
level of detail. While graph convolutional networks (GCNs) are commonly used
for extracting sentiment features, their straightforward use in syntactic
feature extraction can lead to a loss of crucial information. This paper
presents a novel edge-enhanced GCN, called EEGCN, which improves performance by
preserving feature integrity as it processes syntactic graphs. We incorporate a
bidirectional long short-term memory (Bi-LSTM) network alongside a
self-attention-based transformer for effective text encoding, ensuring the
retention of long-range dependencies. A bidirectional GCN (Bi-GCN) with message
passing then captures the relationships between entities, while an
aspect-specific masking technique removes extraneous information. Extensive
evaluations and ablation studies on four benchmark datasets show that EEGCN
significantly enhances aspect-based sentiment analysis, overcoming issues with
syntactic feature extraction and advancing the field's methodologies.","['Chen Li', 'Debo Cheng', 'Yasuhiko Morimoto']",2025-03-17,"['cs.CL', 'cs.LG']",,http://arxiv.org/pdf/2503.12803v1
2503.12801v1,BLIA: Detect model memorization in binary classification model through passive Label Inference attack,"Model memorization has implications for both the generalization capacity of
machine learning models and the privacy of their training data. This paper
investigates label memorization in binary classification models through two
novel passive label inference attacks (BLIA). These attacks operate passively,
relying solely on the outputs of pre-trained models, such as confidence scores
and log-loss values, without interacting with or modifying the training
process. By intentionally flipping 50% of the labels in controlled subsets,
termed ""canaries,"" we evaluate the extent of label memorization under two
conditions: models trained without label differential privacy (Label-DP) and
those trained with randomized response-based Label-DP. Despite the application
of varying degrees of Label-DP, the proposed attacks consistently achieve
success rates exceeding 50%, surpassing the baseline of random guessing and
conclusively demonstrating that models memorize training labels, even when
these labels are deliberately uncorrelated with the features.","['Mohammad Wahiduzzaman Khan', 'Sheng Chen', 'Ilya Mironov', 'Leizhen Zhang', 'Rabib Noor']",2025-03-17,"['cs.LG', 'cs.CR']",,http://arxiv.org/pdf/2503.12801v1
2503.12796v1,A Reinforcement Learning-Driven Transformer GAN for Molecular Generation,"Generating molecules with desired chemical properties presents a critical
challenge in fields such as chemical synthesis and drug discovery. Recent
advancements in artificial intelligence (AI) and deep learning have
significantly contributed to data-driven molecular generation. However,
challenges persist due to the inherent sensitivity of simplified molecular
input line entry system (SMILES) representations and the difficulties in
applying generative adversarial networks (GANs) to discrete data. This study
introduces RL-MolGAN, a novel Transformer-based discrete GAN framework designed
to address these challenges. Unlike traditional Transformer architectures,
RL-MolGAN utilizes a first-decoder-then-encoder structure, facilitating the
generation of drug-like molecules from both $de~novo$ and scaffold-based
designs. In addition, RL-MolGAN integrates reinforcement learning (RL) and
Monte Carlo tree search (MCTS) techniques to enhance the stability of GAN
training and optimize the chemical properties of the generated molecules. To
further improve the model's performance, RL-MolWGAN, an extension of RL-MolGAN,
incorporates Wasserstein distance and mini-batch discrimination, which together
enhance the stability of the GAN. Experimental results on two widely used
molecular datasets, QM9 and ZINC, validate the effectiveness of our models in
generating high-quality molecular structures with diverse and desirable
chemical properties.","['Chen Li', 'Huidong Tang', 'Ye Zhu', 'Yoshihiro Yamanishi']",2025-03-17,"['cs.LG', 'cs.CL', 'physics.chem-ph']",,http://arxiv.org/pdf/2503.12796v1
2503.12793v2,Improving Generalization of Universal Adversarial Perturbation via Dynamic Maximin Optimization,"Deep neural networks (DNNs) are susceptible to universal adversarial
perturbations (UAPs). These perturbations are meticulously designed to fool the
target model universally across all sample classes. Unlike instance-specific
adversarial examples (AEs), generating UAPs is more complex because they must
be generalized across a wide range of data samples and models. Our research
reveals that existing universal attack methods, which optimize UAPs using DNNs
with static model parameter snapshots, do not fully leverage the potential of
DNNs to generate more effective UAPs. Rather than optimizing UAPs against
static DNN models with a fixed training set, we suggest using dynamic
model-data pairs to generate UAPs. In particular, we introduce a dynamic
maximin optimization strategy, aiming to optimize the UAP across a variety of
optimal model-data pairs. We term this approach DM-UAP. DM-UAP utilizes an
iterative max-min-min optimization framework that refines the model-data pairs,
coupled with a curriculum UAP learning algorithm to examine the combined space
of model parameters and data thoroughly. Comprehensive experiments on the
ImageNet dataset demonstrate that the proposed DM-UAP markedly enhances both
cross-sample universality and cross-model transferability of UAPs. Using only
500 samples for UAP generation, DM-UAP outperforms the state-of-the-art
approach with an average increase in fooling ratio of 12.108%.","['Yechao Zhang', 'Yingzhe Xu', 'Junyu Shi', 'Leo Yu Zhang', 'Shengshan Hu', 'Minghui Li', 'Yanjun Zhang']",2025-03-17,"['cs.LG', 'cs.CV']",Accepted in AAAI 2025,http://arxiv.org/pdf/2503.12793v2
2503.12784v1,Causal Feature Learning in the Social Sciences,"Variable selection poses a significant challenge in causal modeling,
particularly within the social sciences, where constructs often rely on
inter-related factors such as age, socioeconomic status, gender, and race.
Indeed, it has been argued that such attributes must be modeled as macro-level
abstractions of lower-level manipulable features, in order to preserve the
modularity assumption essential to causal inference. This paper accordingly
extends the theoretical framework of Causal Feature Learning (CFL).
Empirically, we apply the CFL algorithm to diverse social science datasets,
evaluating how CFL-derived macrostates compare with traditional microstates in
downstream modeling tasks.","['Jingzhou Huang', 'Jiuyao Lu', 'Alexander Williams Tolbert']",2025-03-17,"['stat.ME', 'cs.LG', 'stat.AP']",,http://arxiv.org/pdf/2503.12784v1
2503.12780v1,LangDA: Building Context-Awareness via Language for Domain Adaptive Semantic Segmentation,"Unsupervised domain adaptation for semantic segmentation (DASS) aims to
transfer knowledge from a label-rich source domain to a target domain with no
labels. Two key approaches in DASS are (1) vision-only approaches using masking
or multi-resolution crops, and (2) language-based approaches that use generic
class-wise prompts informed by target domain (e.g. ""a {snowy} photo of a
{class}""). However, the former is susceptible to noisy pseudo-labels that are
biased to the source domain. The latter does not fully capture the intricate
spatial relationships of objects -- key for dense prediction tasks. To this
end, we propose LangDA. LangDA addresses these challenges by, first, learning
contextual relationships between objects via VLM-generated scene descriptions
(e.g. ""a pedestrian is on the sidewalk, and the street is lined with
buildings.""). Second, LangDA aligns the entire image features with text
representation of this context-aware scene caption and learns generalized
representations via text. With this, LangDA sets the new state-of-the-art
across three DASS benchmarks, outperforming existing methods by 2.6%, 1.4% and
3.9%.","['Chang Liu', 'Bavesh Balaji', 'Saad Hossain', 'C Thomas', 'Kwei-Herng Lai', 'Raviteja Vemulapalli', 'Alexander Wong', 'Sirisha Rambhatla']",2025-03-17,"['cs.CV', 'cs.AI', 'cs.LG', 'eess.IV', 'stat.ML', '68Txx', 'I.2.1']",,http://arxiv.org/pdf/2503.12780v1
2503.12770v1,Asynchronous Predictive Counterfactual Regret Minimization$^+$ Algorithm in Solving Extensive-Form Games,"Counterfactual Regret Minimization (CFR) algorithms are widely used to
compute a Nash equilibrium (NE) in two-player zero-sum imperfect-information
extensive-form games (IIGs). Among them, Predictive CFR$^+$ (PCFR$^+$) is
particularly powerful, achieving an exceptionally fast empirical convergence
rate via the prediction in many games. However, the empirical convergence rate
of PCFR$^+$ would significantly degrade if the prediction is inaccurate,
leading to unstable performance on certain IIGs. To enhance the robustness of
PCFR$^+$, we propose a novel variant, Asynchronous PCFR$^+$ (APCFR$^+$), which
employs an adaptive asynchronization of step-sizes between the updates of
implicit and explicit accumulated counterfactual regrets to mitigate the impact
of the prediction inaccuracy on convergence. We present a theoretical analysis
demonstrating why APCFR$^+$ can enhance the robustness. Finally, we propose a
simplified version of APCFR$^+$ called Simple APCFR$^+$ (SAPCFR$^+$), which
uses a fixed asynchronization of step-sizes to simplify the implementation that
only needs a single-line modification of the original PCFR+. Interestingly,
SAPCFR$^+$ achieves a constant-factor lower theoretical regret bound than
PCFR$^+$ in the worst case. Experimental results demonstrate that (i) both
APCFR$^+$ and SAPCFR$^+$ outperform PCFR$^+$ in most of the tested games, as
well as (ii) SAPCFR$^+$ achieves a comparable empirical convergence rate with
APCFR$^+$.","['Linjian Meng', 'Youzhi Zhang', 'Zhenxing Ge', 'Tianpei Yang', 'Yang Gao']",2025-03-17,['cs.LG'],,http://arxiv.org/pdf/2503.12770v1
2503.12765v1,Stabilization Analysis and Mode Recognition of Kerosene Supersonic Combustion: A Deep Learning Approach Based on Res-CNN-beta-VAE,"The scramjet engine is a key propulsion system for hypersonic vehicles,
leveraging supersonic airflow to achieve high specific impulse, making it a
promising technology for aerospace applications. Understanding and controlling
the complex interactions between fuel injection, turbulent combustion, and
aerodynamic effects of compressible flows are crucial for ensuring stable
combustion in scramjet engines. However, identifying stable modes in scramjet
combustors is often challenging due to limited experimental measurement means
and extremely complex spatiotemporal evolution of supersonic turbulent
combustion. This work introduces an innovative deep learning framework that
combines dimensionality reduction via the Residual Convolutional Neural
Network-beta-Variational Autoencoder (Res-CNN-beta-VAE) model with unsupervised
clustering (K-means) to identify and analyze dynamical combustion modes in a
supersonic combustor. By mapping high-dimensional data of combustion snapshots
to a reduced three-dimensional latent space, the Res-CNN-beta-VAE model
captures the essential temporal and spatial features of flame behaviors and
enables the observation of transitions between combustion states. By analyzing
the standard deviation of latent variable trajectories, we introduce a novel
method for objectively distinguishing between dynamic transitions, which
provides a scalable and expert-independent alternative to traditional
classification methods. Besides, the unsupervised K-means clustering approach
effectively identifies the complex interplay between the cavity and the
jet-wake stabilization mechanisms, offering new insights into the system's
behavior across different gas-to-liquid mass flow ratios (GLRs).","['Weiming Xu', 'Tao Yang', 'Chang Liu', 'Kun Wu', 'Peng Zhang']",2025-03-17,"['physics.flu-dyn', 'cs.LG']","10 pages, 6 figures",http://arxiv.org/pdf/2503.12765v1
2503.12763v1,A Survey on Human Interaction Motion Generation,"Humans inhabit a world defined by interactions -- with other humans, objects,
and environments. These interactive movements not only convey our relationships
with our surroundings but also demonstrate how we perceive and communicate with
the real world. Therefore, replicating these interaction behaviors in digital
systems has emerged as an important topic for applications in robotics, virtual
reality, and animation. While recent advances in deep generative models and new
datasets have accelerated progress in this field, significant challenges remain
in modeling the intricate human dynamics and their interactions with entities
in the external world. In this survey, we present, for the first time, a
comprehensive overview of the literature in human interaction motion
generation. We begin by establishing foundational concepts essential for
understanding the research background. We then systematically review existing
solutions and datasets across three primary interaction tasks -- human-human,
human-object, and human-scene interactions -- followed by evaluation metrics.
Finally, we discuss open research directions and future opportunities.","['Kewei Sui', 'Anindita Ghosh', 'Inwoo Hwang', 'Jian Wang', 'Chuan Guo']",2025-03-17,"['cs.CV', 'cs.LG']","The repository listing relevant papers is accessible at:
  https://github.com/soraproducer/Awesome-Human-Interaction-Motion-Generation",http://arxiv.org/pdf/2503.12763v1
2503.13559v1,Dynamical Mode Recognition of Turbulent Flames in a Swirl-stabilized Annular Combustor by a Time-series Learning Approach,"Thermoacoustic instability in annular combustors, essential to aero engines
and modern gas turbines, can severely impair operational stability and
efficiency, accurately recognizing and understanding various combustion modes
is the prerequisite for understanding and controlling combustion instabilities.
However, the high-dimensional spatial-temporal dynamics of turbulent flames
typically pose considerable challenges to mode recognition. Based on the
bidirectional temporal and nonlinear dimensionality reduction models, this
study introduces a two-layer bidirectional long short-term memory variational
autoencoder, Bi-LSTM-VAE model, to effectively recognize dynamical modes in
annular combustion systems. Specifically, leveraging 16 pressure signals from a
swirl-stabilized annular combustor, the model maps complex dynamics into a
low-dimensional latent space while preserving temporal dependency and nonlinear
behavior features through the recurrent neural network structure. The results
show that the novel Bi-LSTM-VAE method enables a clear representation of
combustion states in two-dimensional state space. Analysis of latent variable
distributions reveals distinct patterns corresponding to a wide range of
equivalence ratios and premixed fuel and air mass flow rates, offering novel
insights into mode classification and transitions, highlighting this model's
potential for deciphering complex thermoacoustic phenomena.","['Tao Yang', 'Weiming Xu', 'Liangliang Xu', 'Peng Zhang']",2025-03-17,['cs.LG'],"5 pages, 3 figures",http://arxiv.org/pdf/2503.13559v1
2503.12760v1,SNPL: Simultaneous Policy Learning and Evaluation for Safe Multi-Objective Policy Improvement,"To design effective digital interventions, experimenters face the challenge
of learning decision policies that balance multiple objectives using offline
data. Often, they aim to develop policies that maximize goal outcomes, while
ensuring there are no undesirable changes in guardrail outcomes. To provide
credible recommendations, experimenters must not only identify policies that
satisfy the desired changes in goal and guardrail outcomes, but also offer
probabilistic guarantees about the changes these policies induce. In practice,
however, policy classes are often large, and digital experiments tend to
produce datasets with small effect sizes relative to noise. In this setting,
standard approaches such as data splitting or multiple testing often result in
unstable policy selection and/or insufficient statistical power. In this paper,
we provide safe noisy policy learning (SNPL), a novel approach that leverages
the concept of algorithmic stability to address these challenges. Our method
enables policy learning while simultaneously providing high-confidence
guarantees using the entire dataset, avoiding the need for data-splitting. We
present finite-sample and asymptotic versions of our algorithm that ensure the
recommended policy satisfies high-probability guarantees for avoiding guardrail
regressions and/or achieving goal outcome improvements. We test both variants
of our approach approach empirically on a real-world application of
personalizing SMS delivery. Our results on real-world data suggest that our
approach offers dramatic improvements in settings with large policy classes and
low signal-to-noise across both finite-sample and asymptotic safety guarantees,
offering up to 300\% improvements in detection rates and 150\% improvements in
policy gains at significantly smaller sample sizes.","['Brian Cho', 'Ana-Roxana Pop', 'Ariel Evince', 'Nathan Kallus']",2025-03-17,"['stat.ML', 'cs.LG', 'econ.EM']",,http://arxiv.org/pdf/2503.12760v1
2503.12755v1,Cohort-attention Evaluation Metric against Tied Data: Studying Performance of Classification Models in Cancer Detection,"Artificial intelligence (AI) has significantly improved medical screening
accuracy, particularly in cancer detection and risk assessment. However,
traditional classification metrics often fail to account for imbalanced data,
varying performance across cohorts, and patient-level inconsistencies, leading
to biased evaluations. We propose the Cohort-Attention Evaluation Metrics (CAT)
framework to address these challenges. CAT introduces patient-level assessment,
entropy-based distribution weighting, and cohort-weighted sensitivity and
specificity. Key metrics like CATSensitivity (CATSen), CATSpecificity (CATSpe),
and CATMean ensure balanced and fair evaluation across diverse populations.
This approach enhances predictive reliability, fairness, and interpretability,
providing a robust evaluation method for AI-driven medical screening models.","['Longfei Wei', 'Fang Sheng', 'Jianfei Zhang']",2025-03-17,"['cs.LG', 'cs.CE', 'stat.ML']",,http://arxiv.org/pdf/2503.12755v1
2503.13558v1,Survival Analysis with Machine Learning for Predicting Li-ion Battery Remaining Useful Life,"The accurate prediction of RUL for lithium-ion batteries is crucial for
enhancing the reliability and longevity of energy storage systems. Traditional
methods for RUL prediction often struggle with issues such as data sparsity,
varying battery chemistries, and the inability to capture complex degradation
patterns over time. In this study, we propose a survival analysis-based
framework combined with deep learning models to predict the RUL of lithium-ion
batteries. Specifically, we utilize five advanced models: the Cox-type models
(Cox, CoxPH, and CoxTime) and two machine-learning-based models (DeepHit and
MTLR). These models address the challenges of accurate RUL estimation by
transforming raw time-series battery data into survival data, including key
degradation indicators such as voltage, current, and internal resistance.
Advanced feature extraction techniques enhance the model's robustness in
diverse real-world scenarios, including varying charging conditions and battery
chemistries. Our models are tested using 10-fold cross-validation, ensuring
generalizability and minimizing overfitting. Experimental results show that our
survival-based framework significantly improves RUL prediction accuracy
compared to traditional methods, providing a reliable tool for battery
management and maintenance optimization. This study contributes to the
advancement of predictive maintenance in battery technology, offering valuable
insights for both researchers and industry practitioners aiming to enhance the
operational lifespan of lithium-ion batteries.","['Jingyuan Xue', 'Longfei Wei', 'Fang Sheng', 'Yuxin Gao', 'Jianfei Zhang']",2025-03-17,"['eess.SP', 'cs.AI', 'cs.LG']",,http://arxiv.org/pdf/2503.13558v1
2503.12753v1,SafeSlice: Enabling SLA-Compliant O-RAN Slicing via Safe Deep Reinforcement Learning,"Deep reinforcement learning (DRL)-based slicing policies have shown
significant success in simulated environments but face challenges in physical
systems such as open radio access networks (O-RANs) due to
simulation-to-reality gaps. These policies often lack safety guarantees to
ensure compliance with service level agreements (SLAs), such as the strict
latency requirements of immersive applications. As a result, a deployed DRL
slicing agent may make resource allocation (RA) decisions that degrade system
performance, particularly in previously unseen scenarios. Real-world immersive
applications require maintaining SLA constraints throughout deployment to
prevent risky DRL exploration. In this paper, we propose SafeSlice to address
both the cumulative (trajectory-wise) and instantaneous (state-wise) latency
constraints of O-RAN slices. We incorporate the cumulative constraints by
designing a sigmoid-based risk-sensitive reward function that reflects the
slices' latency requirements. Moreover, we build a supervised learning cost
model as part of a safety layer that projects the slicing agent's RA actions to
the nearest safe actions, fulfilling instantaneous constraints. We conduct an
exhaustive experiment that supports multiple services, including real virtual
reality (VR) gaming traffic, to investigate the performance of SafeSlice under
extreme and changing deployment conditions. SafeSlice achieves reductions of up
to 83.23% in average cumulative latency, 93.24% in instantaneous latency
violations, and 22.13% in resource consumption compared to the baselines. The
results also indicate SafeSlice's robustness to changing the threshold
configurations of latency constraints, a vital deployment scenario that will be
realized by the O-RAN paradigm to empower mobile network operators (MNOs).","['Ahmad M. Nagib', 'Hatem Abou-Zeid', 'Hossam S. Hassanein']",2025-03-17,"['cs.NI', 'cs.AI', 'cs.LG']","This article has been accepted for presentation in the IEEE
  International Conference on Machine Learning for Communication and Networking
  (ICMLCN) 2025",http://arxiv.org/pdf/2503.12753v1
2503.12744v1,Finite Samples for Shallow Neural Networks,"This paper investigates the ability of finite samples to identify two-layer
irreducible shallow networks with various nonlinear activation functions,
including rectified linear units (ReLU) and analytic functions such as the
logistic sigmoid and hyperbolic tangent. An ``irreducible"" network is one whose
function cannot be represented by another network with fewer neurons. For ReLU
activation functions, we first establish necessary and sufficient conditions
for determining the irreducibility of a network. Subsequently, we prove a
negative result: finite samples are insufficient for definitive identification
of any irreducible ReLU shallow network. Nevertheless, we demonstrate that for
a given irreducible network, one can construct a finite set of sampling points
that can distinguish it from other network with the same neuron count.
Conversely, for logistic sigmoid and hyperbolic tangent activation functions,
we provide a positive result. We construct finite samples that enable the
recovery of two-layer irreducible shallow analytic networks. To the best of our
knowledge, this is the first study to investigate the exact identification of
two-layer irreducible networks using finite sample function values. Our
findings provide insights into the comparative performance of networks with
different activation functions under limited sampling conditions.","['Yu Xia', 'Zhiqiang Xu']",2025-03-17,"['cs.LG', 'cs.IT', 'cs.NA', 'math.IT', 'math.NA']","25 pages, 1 figure",http://arxiv.org/pdf/2503.12744v1
2503.12738v1,Enhancing Circuit Trainability with Selective Gate Activation Strategy,"Hybrid quantum-classical computing relies heavily on Variational Quantum
Algorithms (VQAs) to tackle challenges in diverse fields like quantum chemistry
and machine learning. However, VQAs face a critical limitation: the balance
between circuit trainability and expressibility. Trainability, the ease of
optimizing circuit parameters for problem-solving, is often hampered by the
Barren Plateau, where gradients vanish and hinder optimization. On the other
hand, increasing expressibility, the ability to represent a wide range of
quantum states, often necessitates deeper circuits with more parameters, which
in turn exacerbates trainability issues. In this work, we investigate selective
gate activation strategies as a potential solution to these challenges within
the context of Variational Quantum Eigensolvers (VQEs). We evaluate three
different approaches: activating gates randomly without considering their type
or parameter magnitude, activating gates randomly but limited to a single gate
type, and activating gates based on the magnitude of their parameter values.
Experiment results reveal that the Magnitude-based strategy surpasses other
methods, achieving improved convergence.","['Jeihee Cho', 'Junyong Lee', 'Daniel Justice', 'Shiho Kim']",2025-03-17,"['quant-ph', 'cs.LG']","5 pages, 4 figures",http://arxiv.org/pdf/2503.12738v1
2503.12734v1,In-Context Linear Regression Demystified: Training Dynamics and Mechanistic Interpretability of Multi-Head Softmax Attention,"We study how multi-head softmax attention models are trained to perform
in-context learning on linear data. Through extensive empirical experiments and
rigorous theoretical analysis, we demystify the emergence of elegant attention
patterns: a diagonal and homogeneous pattern in the key-query (KQ) weights, and
a last-entry-only and zero-sum pattern in the output-value (OV) weights.
Remarkably, these patterns consistently appear from gradient-based training
starting from random initialization. Our analysis reveals that such emergent
structures enable multi-head attention to approximately implement a debiased
gradient descent predictor -- one that outperforms single-head attention and
nearly achieves Bayesian optimality up to proportional factor. Furthermore,
compared to linear transformers, the softmax attention readily generalizes to
sequences longer than those seen during training. We also extend our study to
scenarios with non-isotropic covariates and multi-task linear regression. In
the former, multi-head attention learns to implement a form of pre-conditioned
gradient descent. In the latter, we uncover an intriguing regime where the
interplay between head number and task number triggers a superposition
phenomenon that efficiently resolves multi-task in-context learning. Our
results reveal that in-context learning ability emerges from the trained
transformer as an aggregated effect of its architecture and the underlying data
distribution, paving the way for deeper understanding and broader applications
of in-context learning.","['Jianliang He', 'Xintian Pan', 'Siyu Chen', 'Zhuoran Yang']",2025-03-17,"['cs.LG', 'stat.ML']",,http://arxiv.org/pdf/2503.12734v1
2503.12733v2,A Linearized Alternating Direction Multiplier Method for Federated Matrix Completion Problems,"Matrix completion is fundamental for predicting missing data with a wide
range of applications in personalized healthcare, e-commerce, recommendation
systems, and social network analysis. Traditional matrix completion approaches
typically assume centralized data storage, which raises challenges in terms of
computational efficiency, scalability, and user privacy. In this paper, we
address the problem of federated matrix completion, focusing on scenarios where
user-specific data is distributed across multiple clients, and privacy
constraints are uncompromising. Federated learning provides a promising
framework to address these challenges by enabling collaborative learning across
distributed datasets without sharing raw data. We propose \texttt{FedMC-ADMM}
for solving federated matrix completion problems, a novel algorithmic framework
that combines the Alternating Direction Method of Multipliers with a randomized
block-coordinate strategy and alternating proximal gradient steps. Unlike
existing federated approaches, \texttt{FedMC-ADMM} effectively handles
multi-block nonconvex and nonsmooth optimization problems, allowing efficient
computation while preserving user privacy. We analyze the theoretical
properties of our algorithm, demonstrating subsequential convergence and
establishing a convergence rate of $\mathcal{O}(K^{-1/2})$, leading to a
communication complexity of $\mathcal{O}(\epsilon^{-2})$ for reaching an
$\epsilon$-stationary point. This work is the first to establish these
theoretical guarantees for federated matrix completion in the presence of
multi-block variables. To validate our approach, we conduct extensive
experiments on real-world datasets, including MovieLens 1M, 10M, and Netflix.
The results demonstrate that \texttt{FedMC-ADMM} outperforms existing methods
in terms of convergence speed and testing accuracy.","['Patrick Hytla', 'Tran T. A. Nghia', 'Duy Nhat Phan', 'Andrew Rice']",2025-03-17,['cs.LG'],"29 pages, 4 figures",http://arxiv.org/pdf/2503.12733v2
2503.13557v1,APF+: Boosting adaptive-potential function reinforcement learning methods with a W-shaped network for high-dimensional games,"Studies in reward shaping for reinforcement learning (RL) have flourished in
recent years due to its ability to speed up training. Our previous work
proposed an adaptive potential function (APF) and showed that APF can
accelerate the Q-learning with a Multi-layer Perceptron algorithm in the
low-dimensional domain. This paper proposes to extend APF with an encoder
(APF+) for RL state representation, allowing applying APF to the pixel-based
Atari games using a state-encoding method that projects high-dimensional game's
pixel frames to low-dimensional embeddings. We approach by designing the
state-representation encoder as a W-shaped network (W-Net), by using which we
are able to encode both the background as well as the moving entities in the
game frames. Specifically, the embeddings derived from the pre-trained W-Net
consist of two latent vectors: One represents the input state, and the other
represents the deviation of the input state's representation from itself. We
then incorporate W-Net into APF to train a downstream Dueling Deep Q-Network
(DDQN), obtain the APF-WNet-DDQN, and demonstrate its effectiveness in Atari
game-playing tasks. To evaluate the APF+W-Net module in such high-dimensional
tasks, we compare with two types of baseline methods: (i) the basic DDQN; and
(ii) two encoder-replaced APF-DDQN methods where we replace W-Net by (a) an
unsupervised state representation method called Spatiotemporal Deep Infomax
(ST-DIM) and (b) a ground truth state representation provided by the Atari
Annotated RAM Interface (ARI). The experiment results show that out of 20 Atari
games, APF-WNet-DDQN outperforms DDQN (14/20 games) and APF-STDIM-DDQN (13/20
games) significantly. In comparison against the APF-ARI-DDQN which employs
embeddings directly of the detailed game-internal state information, the
APF-WNet-DDQN achieves a comparable performance.","['Yifei Chen', 'Lambert Schomaker']",2025-03-17,"['cs.LG', 'cs.AI']",46 pages,http://arxiv.org/pdf/2503.13557v1
2503.12730v1,TinySQL: A Progressive Text-to-SQL Dataset for Mechanistic Interpretability Research,"Mechanistic interpretability research faces a gap between analyzing simple
circuits in toy tasks and discovering features in large models. To bridge this
gap, we propose text-to-SQL generation as an ideal task to study, as it
combines the formal structure of toy tasks with real-world complexity. We
introduce TinySQL, a synthetic dataset progressing from basic to advanced SQL
operations, and train models ranging from 33M to 1B parameters to establish a
comprehensive testbed for interpretability. We apply multiple complementary
interpretability techniques, including edge attribution patching and sparse
autoencoders, to identify minimal circuits and components supporting SQL
generation. Our analysis reveals both the potential and limitations of current
interpretability methods, showing how circuits can vary even across similar
queries. Lastly, we demonstrate how mechanistic interpretability can identify
flawed heuristics in models and improve synthetic dataset design. Our work
provides a comprehensive framework for evaluating and advancing
interpretability techniques while establishing clear boundaries for their
reliable application.","['Philip Quirke', 'Clement Neo', 'Abir Harrasse', 'Dhruv Nathawani', 'Amir Abdullah']",2025-03-17,"['cs.LG', 'cs.AI', 'cs.DB']","9 pages, 19 figures, 7 tables, 18 trained models",http://arxiv.org/pdf/2503.12730v1
2503.12688v1,Dynamic Angle Selection in X-Ray CT: A Reinforcement Learning Approach to Optimal Stopping,"In industrial X-ray Computed Tomography (CT), the need for rapid in-line
inspection is critical. Sparse-angle tomography plays a significant role in
this by reducing the required number of projections, thereby accelerating
processing and conserving resources. Most existing methods aim to balance
reconstruction quality and scanning time, typically relying on fixed scan
durations. Adaptive adjustment of the number of angles is essential; for
instance, more angles may be required for objects with complex geometries or
noisier projections. The concept of optimal stopping, which dynamically adjusts
this balance according to varying industrial needs, remains underutilized.
Building on our previous work, we integrate optimal stopping into sequential
Optimal Experimental Design (OED). We propose a novel method for computing the
policy gradient within the Actor-Critic framework, enabling the development of
adaptive policies for informative angle selection and scan termination.
Additionally, we investigated the gap between simulation and real-world
applications in the context of the developed learning-based method. Our trained
model, developed using synthetic data, demonstrates reliable performance when
applied to real-world data. This approach enhances the flexibility of CT
operations and expands the applicability of sparse-angle tomography in
industrial settings.",['Tianyuan Wang'],2025-03-16,"['cs.CV', 'cs.AI', 'cs.LG']",,http://arxiv.org/pdf/2503.12688v1
2503.12686v1,Can LLMs Formally Reason as Abstract Interpreters for Program Analysis?,"LLMs have demonstrated impressive capabilities in code generation and
comprehension, but their potential in being able to perform program analysis in
a formal, automatic manner remains under-explored. To that end, we
systematically investigate whether LLMs can reason about programs using a
program analysis framework called abstract interpretation. We prompt LLMs to
follow two different strategies, denoted as Compositional and Fixed Point
Equation, to formally reason in the style of abstract interpretation, which has
never been done before to the best of our knowledge. We validate our approach
using state-of-the-art LLMs on 22 challenging benchmark programs from the
Software Verification Competition (SV-COMP) 2019 dataset, widely used in
program analysis. Our results show that our strategies are able to elicit
abstract interpretation-based reasoning in the tested models, but LLMs are
susceptible to logical errors, especially while interpreting complex program
structures, as well as general hallucinations. This highlights key areas for
improvement in the formal reasoning capabilities of LLMs.","['Jacqueline L. Mitchell', 'Brian Hyeongseok Kim', 'Chenyu Zhou', 'Chao Wang']",2025-03-16,"['cs.LG', 'cs.PL', 'cs.SE']",,http://arxiv.org/pdf/2503.12686v1
2503.12683v1,Algebraic Adversarial Attacks on Explainability Models,"Classical adversarial attacks are phrased as a constrained optimisation
problem. Despite the efficacy of a constrained optimisation approach to
adversarial attacks, one cannot trace how an adversarial point was generated.
In this work, we propose an algebraic approach to adversarial attacks and study
the conditions under which one can generate adversarial examples for post-hoc
explainability models. Phrasing neural networks in the framework of geometric
deep learning, algebraic adversarial attacks are constructed through analysis
of the symmetry groups of neural networks. Algebraic adversarial examples
provide a mathematically tractable approach to adversarial examples. We
validate our approach of algebraic adversarial examples on two well-known and
one real-world dataset.","['Lachlan Simpson', 'Federico Costanza', 'Kyle Millar', 'Adriel Cheng', 'Cheng-Chew Lim', 'Hong Gunn Chew']",2025-03-16,"['cs.LG', 'math.GR']",,http://arxiv.org/pdf/2503.12683v1
2503.12679v1,Discovering uncertainty: Gaussian constitutive neural networks with correlated weights,"When characterizing materials, it can be important to not only predict their
mechanical properties, but also to estimate the probability distribution of
these properties across a set of samples. Constitutive neural networks allow
for the automated discovery of constitutive models that exactly satisfy
physical laws given experimental testing data, but are only capable of
predicting the mean stress response. Stochastic methods treat each weight as a
random variable and are capable of learning their probability distributions.
Bayesian constitutive neural networks combine both methods, but their weights
lack physical interpretability and we must sample each weight from a
probability distribution to train or evaluate the model. Here we introduce a
more interpretable network with fewer parameters, simpler training, and the
potential to discover correlated weights: Gaussian constitutive neural
networks. We demonstrate the performance of our new Gaussian network on biaxial
testing data, and discover a sparse and interpretable four-term model with
correlated weights. Importantly, the discovered distributions of material
parameters across a set of samples can serve as priors to discover better
constitutive models for new samples with limited data. We anticipate that
Gaussian constitutive neural networks are a natural first step towards
generative constitutive models informed by physical laws and parameter
uncertainty.","['Jeremy A. McCulloch', 'Ellen Kuhl']",2025-03-16,"['cs.CE', 'cs.LG']","10 pages, 5 figures, 1 table",http://arxiv.org/pdf/2503.12679v1
2503.12677v1,RL-TIME: Reinforcement Learning-based Task Replication in Multicore Embedded Systems,"Embedded systems power many modern applications and must often meet strict
reliability, real-time, thermal, and power requirements. Task replication can
improve reliability by duplicating a task's execution to handle transient and
permanent faults, but blindly applying replication often leads to excessive
overhead and higher temperatures. Existing design-time methods typically choose
the number of replicas based on worst-case conditions, which can waste
resources under normal operation. In this paper, we present RL-TIME, a
reinforcement learning-based approach that dynamically decides the number of
replicas according to actual system conditions. By considering both the
reliability target and a core-level Thermal Safe Power (TSP) constraint at
run-time, RL-TIME adapts the replication strategy to avoid unnecessary overhead
and overheating. Experimental results show that, compared to state-of-the-art
methods, RL-TIME reduces power consumption by 63%, increases schedulability by
53%, and respects TSP 72% more often.","['Roozbeh Siyadatzadeh', 'Mohsen Ansari', 'Muhammad Shafique', 'Alireza Ejlali']",2025-03-16,"['cs.LG', 'cs.SY', 'eess.SY']",,http://arxiv.org/pdf/2503.12677v1
2503.12668v1,ZO2: Scalable Zeroth-Order Fine-Tuning for Extremely Large Language Models with Limited GPU Memory,"Fine-tuning large pre-trained LLMs generally demands extensive GPU memory.
Traditional first-order optimizers like SGD encounter substantial difficulties
due to increased memory requirements from storing activations and gradients
during both the forward and backward phases as the model size expands.
Alternatively, zeroth-order (ZO) techniques can compute gradients using just
forward operations, eliminating the need to store activations. Furthermore, by
leveraging CPU capabilities, it's feasible to enhance both the memory and
processing power available to a single GPU. We propose a novel framework, ZO2
(Zeroth-Order Offloading), for efficient zeroth-order fine-tuning of LLMs with
only limited GPU memory. Our framework dynamically shifts model parameters
between the CPU and GPU as required, optimizing computation flow and maximizing
GPU usage by minimizing downtime. This integration of parameter adjustments
with ZO's double forward operations reduces unnecessary data movement,
enhancing the fine-tuning efficacy. Additionally, our framework supports an
innovative low-bit precision approach in AMP mode to streamline data exchanges
between the CPU and GPU. Employing this approach allows us to fine-tune
extraordinarily large models, such as the OPT-175B with more than 175 billion
parameters, on a mere 18GB GPU--achievements beyond the reach of traditional
methods. Moreover, our framework achieves these results with almost no
additional time overhead and absolutely no accuracy loss compared to standard
zeroth-order methods. ZO2's code has been open-sourced in
https://github.com/liangyuwang/zo2.","['Liangyu Wang', 'Jie Ren', 'Hang Xu', 'Junxiao Wang', 'Huanyi Xie', 'David E. Keyes', 'Di Wang']",2025-03-16,"['cs.LG', 'cs.PF']","14 pages, 7 figures",http://arxiv.org/pdf/2503.12668v1
2503.12663v1,Logic-RAG: Augmenting Large Multimodal Models with Visual-Spatial Knowledge for Road Scene Understanding,"Large multimodal models (LMMs) are increasingly integrated into autonomous
driving systems for user interaction. However, their limitations in
fine-grained spatial reasoning pose challenges for system interpretability and
user trust. We introduce Logic-RAG, a novel Retrieval-Augmented Generation
(RAG) framework that improves LMMs' spatial understanding in driving scenarios.
Logic-RAG constructs a dynamic knowledge base (KB) about object-object
relationships in first-order logic (FOL) using a perception module, a
query-to-logic embedder, and a logical inference engine. We evaluated Logic-RAG
on visual-spatial queries using both synthetic and real-world driving videos.
When using popular LMMs (GPT-4V, Claude 3.5) as proxies for an autonomous
driving system, these models achieved only 55% accuracy on synthetic driving
scenes and under 75% on real-world driving scenes. Augmenting them with
Logic-RAG increased their accuracies to over 80% and 90%, respectively. An
ablation study showed that even without logical inference, the fact-based
context constructed by Logic-RAG alone improved accuracy by 15%. Logic-RAG is
extensible: it allows seamless replacement of individual components with
improved versions and enables domain experts to compose new knowledge in both
FOL and natural language. In sum, Logic-RAG addresses critical spatial
reasoning deficiencies in LMMs for autonomous driving applications. Code and
data are available at https://github.com/Imran2205/LogicRAG.","['Imran Kabir', 'Md Alimoor Reza', 'Syed Billah']",2025-03-16,"['cs.CV', 'cs.CL', 'cs.LG', 'cs.RO']",,http://arxiv.org/pdf/2503.12663v1
2503.12662v1,TuneNSearch: a hybrid transfer learning and local search approach for solving vehicle routing problems,"This paper introduces TuneNSearch, a hybrid transfer learning and local
search approach for addressing different variants of vehicle routing problems
(VRP). Recently, multi-task learning has gained much attention for solving VRP
variants. However, this adaptability often compromises the performance of the
models. To address this challenge, we first pre-train a reinforcement learning
model on the multi-depot VRP, followed by a short fine-tuning phase to adapt it
to different variants. By leveraging the complexity of the multi-depot VRP, the
pre-trained model learns richer node representations and gains more
transferable knowledge compared to models trained on simpler routing problems,
such as the traveling salesman problem. TuneNSearch employs, in the first
stage, a Transformer-based architecture, augmented with a residual edge-graph
attention network to capture the impact of edge distances and residual
connections between layers. This architecture allows for a more precise capture
of graph-structured data, improving the encoding of VRP's features. After
inference, our model is also coupled with a second stage composed of a local
search algorithm, which yields substantial performance gains with minimal
computational overhead added. Results show that TuneNSearch outperforms many
existing state-of-the-art models trained for each VRP variant, requiring only
one-fifth of the training epochs. Our approach demonstrates strong
generalization, achieving high performance across different tasks,
distributions and problem sizes, thus addressing a long-standing gap in the
literature.","['Arthur Corrêa', 'Cristóvão Silva', 'Liming Xu', 'Alexandra Brintrup', 'Samuel Moniz']",2025-03-16,['cs.LG'],,http://arxiv.org/pdf/2503.12662v1
2503.12649v1,FW-Merging: Scaling Model Merging with Frank-Wolfe Optimization,"Model merging has emerged as a promising approach for multi-task learning
(MTL), offering a data-efficient alternative to conventional fine-tuning.
However, with the rapid development of the open-source AI ecosystem and the
increasing availability of fine-tuned foundation models, existing model merging
methods face two key limitations: (i) They are primarily designed for in-house
fine-tuned models, making them less adaptable to diverse model sources with
partially unknown model and task information, (ii) They struggle to scale
effectively when merging numerous model checkpoints. To address these
challenges, we formulate model merging as a constrained optimization problem
and introduce a novel approach: Frank-Wolfe Merging (FW-Merging). Inspired by
Frank-Wolfe optimization, our approach iteratively selects the most relevant
model in the pool to minimize a linear approximation of the objective function
and then executes a local merging similar to the Frank-Wolfe update. The
objective function is designed to capture the desired behavior of the
target-merged model, while the fine-tuned candidate models define the
constraint set. More importantly, FW-Merging serves as an orthogonal technique
for existing merging methods, seamlessly integrating with them to further
enhance accuracy performance. Our experiments show that FW-Merging scales
across diverse model sources, remaining stable with 16 irrelevant models and
improving by 15.3% with 16 relevant models on 20 CV tasks, while maintaining
constant memory overhead, unlike the linear overhead of data-informed merging
methods. Compared with the state-of-the-art approaches, FW-Merging surpasses
the data-free merging method by 32.8% and outperforms the data-informed
Adamerging by 8.39% when merging 20 ViT models.","['Hao Mark Chen', 'Shell Xu Hu', 'Wayne Luk', 'Timothy Hospedales', 'Hongxiang Fan']",2025-03-16,"['cs.LG', 'cs.AI']",,http://arxiv.org/pdf/2503.12649v1
2503.12648v1,Realized Volatility Forecasting for New Issues and Spin-Offs using Multi-Source Transfer Learning,"Forecasting the volatility of financial assets is essential for various
financial applications. This paper addresses the challenging task of
forecasting the volatility of financial assets with limited historical data,
such as new issues or spin-offs, by proposing a multi-source transfer learning
approach. Specifically, we exploit complementary source data of assets with a
substantial historical data record by selecting source time series instances
that are most similar to the limited target data of the new issue/spin-off.
Based on these instances and the target data, we estimate linear and non-linear
realized volatility models and compare their forecasting performance to
forecasts of models trained exclusively on the target data, and models trained
on the entire source and target data. The results show that our transfer
learning approach outperforms the alternative models and that the integration
of complementary data is also beneficial immediately after the initial trading
day of the new issue/spin-off.","['Andreas Teller', 'Uta Pigorsch', 'Christian Pigorsch']",2025-03-16,"['cs.LG', 'q-fin.CP']",Submitted to the International Journal of Forecasting,http://arxiv.org/pdf/2503.12648v1
2503.12645v1,Understanding Gradient Orthogonalization for Deep Learning via Non-Euclidean Trust-Region Optimization,"Optimization with matrix gradient orthogonalization has recently demonstrated
impressive results in the training of deep neural networks (Jordan et al.,
2024; Liu et al., 2025). In this paper, we provide a theoretical analysis of
this approach. In particular, we show that the orthogonalized gradient method
can be seen as a first-order trust-region optimization method, where the
trust-region is defined in terms of the matrix spectral norm. Motivated by this
observation, we provide the first theoretical analysis of the stochastic
non-Euclidean trust-region gradient method with momentum, which recovers the
Muon optimizer (Jordan et al., 2024) as a special case. In addition, we
establish the convergence of the normalized SGD with momentum (Cutkosky and
Mehta, 2020) in the constrained and composite setting, show that its iteration
complexity of finding an $\varepsilon$-accurate solution can be improved from
$\mathcal{O}(\varepsilon^{-3.5})$ to $\mathcal{O}(\varepsilon^{-3})$ under the
star-convexity assumption, and obtain similar results for the Muon algorithm.
Finally, our theoretical findings provide an explanation for the practical
superiority of Muon compared to the Orthogonal-SGDM algorithm of Tuddenham et
al. (2022).",['Dmitry Kovalev'],2025-03-16,"['cs.LG', 'math.OC', 'stat.ML']",,http://arxiv.org/pdf/2503.12645v1
2503.12635v1,Hybrid Learners Do Not Forget: A Brain-Inspired Neuro-Symbolic Approach to Continual Learning,"Continual learning is crucial for creating AI agents that can learn and
improve themselves autonomously. A primary challenge in continual learning is
to learn new tasks without losing previously learned knowledge. Current
continual learning methods primarily focus on enabling a neural network with
mechanisms that mitigate forgetting effects. Inspired by the two distinct
systems in the human brain, System 1 and System 2, we propose a Neuro-Symbolic
Brain-Inspired Continual Learning (NeSyBiCL) framework that incorporates two
subsystems to solve continual learning: A neural network model responsible for
quickly adapting to the most recent task, together with a symbolic reasoner
responsible for retaining previously acquired knowledge from previous tasks.
Moreover, we design an integration mechanism between these components to
facilitate knowledge transfer from the symbolic reasoner to the neural network.
We also introduce two compositional continual learning benchmarks and
demonstrate that NeSyBiCL is effective and leads to superior performance
compared to continual learning methods that merely rely on neural architectures
to address forgetting.","['Amin Banayeeanzade', 'Mohammad Rostami']",2025-03-16,"['cs.LG', 'cs.AI']",,http://arxiv.org/pdf/2503.12635v1
2503.12633v1,Fast filtering of non-Gaussian models using Amortized Optimal Transport Maps,"In this paper, we present the amortized optimal transport filter (A-OTF)
designed to mitigate the computational burden associated with the real-time
training of optimal transport filters (OTFs). OTFs can perform accurate
non-Gaussian Bayesian updates in the filtering procedure, but they require
training at every time step, which makes them expensive. The proposed A-OTF
framework exploits the similarity between OTF maps during an initial/offline
training stage in order to reduce the cost of inference during online
calculations. More precisely, we use clustering algorithms to select relevant
subsets of pre-trained maps whose weighted average is used to compute the A-OTF
model akin to a mixture of experts. A series of numerical experiments validate
that A-OTF achieves substantial computational savings during online inference
while preserving the inherent flexibility and accuracy of OTF.","['Mohammad Al-Jarrah', 'Bamdad Hosseini', 'Amirhossein Taghvaei']",2025-03-16,"['math.OC', 'cs.LG']","6 pages, 4 figures",http://arxiv.org/pdf/2503.12633v1
2503.12623v1,MAVEN: Multi-modal Attention for Valence-Arousal Emotion Network,"This paper introduces MAVEN (Multi-modal Attention for Valence-Arousal
Emotion Network), a novel architecture for dynamic emotion recognition through
dimensional modeling of affect. The model uniquely integrates visual, audio,
and textual modalities via a bi-directional cross-modal attention mechanism
with six distinct attention pathways, enabling comprehensive interactions
between all modality pairs. Our proposed approach employs modality-specific
encoders to extract rich feature representations from synchronized video
frames, audio segments, and transcripts. The architecture's novelty lies in its
cross-modal enhancement strategy, where each modality representation is refined
through weighted attention from other modalities, followed by self-attention
refinement through modality-specific encoders. Rather than directly predicting
valence-arousal values, MAVEN predicts emotions in a polar coordinate form,
aligning with psychological models of the emotion circumplex. Experimental
evaluation on the Aff-Wild2 dataset demonstrates the effectiveness of our
approach, with performance measured using Concordance Correlation Coefficient
(CCC). The multi-stage architecture demonstrates superior ability to capture
the complex, nuanced nature of emotional expressions in conversational videos,
advancing the state-of-the-art (SOTA) in continuous emotion recognition
in-the-wild. Code can be found at:
https://github.com/Vrushank-Ahire/MAVEN_8th_ABAW.","['Vrushank Ahire', 'Kunal Shah', 'Mudasir Nazir Khan', 'Nikhil Pakhale', 'Lownish Rai Sookha', 'M. A. Ganaie', 'Abhinav Dhall']",2025-03-16,"['cs.LG', 'cs.AI', 'cs.CV', 'cs.MM']",,http://arxiv.org/pdf/2503.12623v1
2503.12622v1,Real-Time Cell Sorting with Scalable In Situ FPGA-Accelerated Deep Learning,"Precise cell classification is essential in biomedical diagnostics and
therapeutic monitoring, particularly for identifying diverse cell types
involved in various diseases. Traditional cell classification methods such as
flow cytometry depend on molecular labeling which is often costly,
time-intensive, and can alter cell integrity. To overcome these limitations, we
present a label-free machine learning framework for cell classification,
designed for real-time sorting applications using bright-field microscopy
images. This approach leverages a teacher-student model architecture enhanced
by knowledge distillation, achieving high efficiency and scalability across
different cell types. Demonstrated through a use case of classifying lymphocyte
subsets, our framework accurately classifies T4, T8, and B cell types with a
dataset of 80,000 preprocessed images, accessible via an open-source Python
package for easy adaptation. Our teacher model attained 98\% accuracy in
differentiating T4 cells from B cells and 93\% accuracy in zero-shot
classification between T8 and B cells. Remarkably, our student model operates
with only 0.02\% of the teacher model's parameters, enabling field-programmable
gate array (FPGA) deployment. Our FPGA-accelerated student model achieves an
ultra-low inference latency of just 14.5~$\mu$s and a complete cell
detection-to-sorting trigger time of 24.7~$\mu$s, delivering 12x and 40x
improvements over the previous state-of-the-art real-time cell analysis
algorithm in inference and total latency, respectively, while preserving
accuracy comparable to the teacher model. This framework provides a scalable,
cost-effective solution for lymphocyte classification, as well as a new SOTA
real-time cell sorting implementation for rapid identification of subsets using
in situ deep learning on off-the-shelf computing hardware.","['Khayrul Islam', 'Ryan F. Forelli', 'Jianzhong Han', 'Deven Bhadane', 'Jian Huang', 'Joshua C. Agar', 'Nhan Tran', 'Seda Ogrenci', 'Yaling Liu']",2025-03-16,['cs.LG'],,http://arxiv.org/pdf/2503.12622v1
2503.12617v1,Scaling Semantic Categories: Investigating the Impact on Vision Transformer Labeling Performance,"This study explores the impact of scaling semantic categories on the image
classification performance of vision transformers (ViTs). In this specific
case, the CLIP server provided by Jina AI is used for experimentation. The
research hypothesizes that as the number of ground truth and artificially
introduced semantically equivalent categories increases, the labeling accuracy
of ViTs improves until a theoretical maximum or limit is reached. A wide
variety of image datasets were chosen to test this hypothesis. These datasets
were processed through a custom function in Python designed to evaluate the
model's accuracy, with adjustments being made to account for format differences
between datasets. By exponentially introducing new redundant categories, the
experiment assessed accuracy trends until they plateaued, decreased, or
fluctuated inconsistently. The findings show that while semantic scaling
initially increases model performance, the benefits diminish or reverse after
surpassing a critical threshold, providing insight into the limitations and
possible optimization of category labeling strategies for ViTs.","['Anthony Lamelas', 'Harrison Muchnic']",2025-03-16,"['cs.CV', 'cs.AI', 'cs.LG']","4 pages, 7 figures, submitted to CVPR (feedback pending)",http://arxiv.org/pdf/2503.12617v1
2503.12615v1,LATINO-PRO: LAtent consisTency INverse sOlver with PRompt Optimization,"Text-to-image latent diffusion models (LDMs) have recently emerged as
powerful generative models with great potential for solving inverse problems in
imaging. However, leveraging such models in a Plug & Play (PnP), zero-shot
manner remains challenging because it requires identifying a suitable text
prompt for the unknown image of interest. Also, existing text-to-image PnP
approaches are highly computationally expensive. We herein address these
challenges by proposing a novel PnP inference paradigm specifically designed
for embedding generative models within stochastic inverse solvers, with special
attention to Latent Consistency Models (LCMs), which distill LDMs into fast
generators. We leverage our framework to propose LAtent consisTency INverse
sOlver (LATINO), the first zero-shot PnP framework to solve inverse problems
with priors encoded by LCMs. Our conditioning mechanism avoids automatic
differentiation and reaches SOTA quality in as little as 8 neural function
evaluations. As a result, LATINO delivers remarkably accurate solutions and is
significantly more memory and computationally efficient than previous
approaches. We then embed LATINO within an empirical Bayesian framework that
automatically calibrates the text prompt from the observed measurements by
marginal maximum likelihood estimation. Extensive experiments show that prompt
self-calibration greatly improves estimation, allowing LATINO with PRompt
Optimization to define new SOTAs in image reconstruction quality and
computational efficiency.","['Alessio Spagnoletti', 'Jean Prost', 'Andrés Almansa', 'Nicolas Papadakis', 'Marcelo Pereyra']",2025-03-16,"['cs.CV', 'cs.LG']","27 pages, 20 figures",http://arxiv.org/pdf/2503.12615v1
2503.12602v1,SynLlama: Generating Synthesizable Molecules and Their Analogs with Large Language Models,"Generative machine learning models for small molecule drug discovery have
shown immense promise, but many molecules generated by this approach are too
difficult to synthesize to be worth further investigation or further
development. We present a novel approach by fine-tuning Meta's Llama3 large
language models (LLMs) to create SynLlama, which generates full synthetic
pathways made of commonly accessible Enamine building blocks and robust organic
reaction templates. SynLlama explores a large synthesizable space using
significantly less data compared to other state-of-the-art methods, and offers
strong performance in bottom-up synthesis, synthesizable analog generation, and
hit expansion, offering medicinal chemists a valuable tool for drug discovery
developments. We find that SynLlama can effectively generalize to unseen yet
purchasable building blocks, meaning that its reconstruction capabilities
extend to a broader synthesizable chemical space than the training data.","['Kunyang Sun', 'Dorian Bagni', 'Joseph M. Cavanagh', 'Yingze Wang', 'Jacob M. Sawyer', 'Andrew Gritsevskiy', 'Teresa Head-Gordon']",2025-03-16,"['cs.LG', 'physics.bio-ph']",,http://arxiv.org/pdf/2503.12602v1
2503.12600v1,GraphEval: A Lightweight Graph-Based LLM Framework for Idea Evaluation,"The powerful capabilities of Large Language Models (LLMs) have led to their
growing use in evaluating human-generated content, particularly in evaluating
research ideas within academic settings. Existing solutions primarily rely on
prompt-based LLM methods or fine-tuned lightweight language models for idea
evaluation. However, these methods are often unstable and struggle to
comprehend the complex semantic information embedded in the ideas, impeding
their ability to perform high-quality evaluations. To address the above
challenges, we propose GraphEval, a lightweight graph-based LLM framework for
idea evaluation. Our insight is that a complex idea can be broken down into
comprehensible viewpoint nodes using prompts from small LLMs. These viewpoint
nodes can then be linked together through edges created from LLM-based relation
extraction and/or BERT similarity scores. The created viewpoint-graph can be
used to conveniently propagate scores across view-nodes to improve the
robustness of the idea evaluations. In particular, we propose two lightweight
graph-based methods for idea evaluation: (1) GraphEval-LP: a training-free
label propagation algorithm that propagates evaluation scores from known
view-nodes to unknown nodes; (2) GraphEval-GNN: a Graph Neural Networks (GNN)
that is trained to predict the evaluation scores given the observed graph with
minimal computation resources. Moreover, to overcome LLM's limitation in
objectively assessing the novelty of ideas, we further propose a novelty
detection model to GraphEval-GNN to enhance its capability in judging idea
novelty. Experiments on two datasets show GraphEval improves F1 scores by at
least 14% with low computation and API costs. Additionally, GraphEval can
effectively detect plagiarized ideas.","['Tao Feng', 'Yihang Sun', 'Jiaxuan You']",2025-03-16,['cs.LG'],,http://arxiv.org/pdf/2503.12600v1
2503.12593v1,Fourier-Based 3D Multistage Transformer for Aberration Correction in Multicellular Specimens,"High-resolution tissue imaging is often compromised by sample-induced optical
aberrations that degrade resolution and contrast. While wavefront sensor-based
adaptive optics (AO) can measure these aberrations, such hardware solutions are
typically complex, expensive to implement, and slow when serially mapping
spatially varying aberrations across large fields of view. Here, we introduce
AOViFT (Adaptive Optical Vision Fourier Transformer) -- a machine
learning-based aberration sensing framework built around a 3D multistage Vision
Transformer that operates on Fourier domain embeddings. AOViFT infers
aberrations and restores diffraction-limited performance in puncta-labeled
specimens with substantially reduced computational cost, training time, and
memory footprint compared to conventional architectures or real-space networks.
We validated AOViFT on live gene-edited zebrafish embryos, demonstrating its
ability to correct spatially varying aberrations using either a deformable
mirror or post-acquisition deconvolution. By eliminating the need for the guide
star and wavefront sensing hardware and simplifying the experimental workflow,
AOViFT lowers technical barriers for high-resolution volumetric microscopy
across diverse biological samples.","['Thayer Alshaabi', 'Daniel E. Milkie', 'Gaoxiang Liu', 'Cyna Shirazinejad', 'Jason L. Hong', 'Kemal Achour', 'Frederik Görlitz', 'Ana Milunovic-Jevtic', 'Cat Simmons', 'Ibrahim S. Abuzahriyeh', 'Erin Hong', 'Samara Erin Williams', 'Nathanael Harrison', 'Evan Huang', 'Eun Seok Bae', 'Alison N. Killilea', 'David G. Drubin', 'Ian A. Swinburne', 'Srigokul Upadhyayula', 'Eric Betzig']",2025-03-16,"['eess.IV', 'cs.AI', 'cs.LG', 'physics.bio-ph', 'q-bio.QM']","52 pages, 6 figures, 23 si figures, 8 si tables",http://arxiv.org/pdf/2503.12593v1
2503.12592v1,MoECollab: Democratizing LLM Development Through Collaborative Mixture of Experts,"Large Language Model (LLM) development has become increasingly centralized,
limiting participation to well-resourced organizations. This paper introduces
MoECollab, a novel framework leveraging Mixture of Experts (MoE) architecture
to enable distributed, collaborative LLM development. By decomposing monolithic
models into specialized expert modules coordinated by a trainable gating
network, our framework allows diverse contributors to participate regardless of
computational resources. We provide a complete technical implementation with
mathematical foundations for expert dynamics, gating mechanisms, and
integration strategies. Experiments on multiple datasets demonstrate that our
approach achieves accuracy improvements of 3-7% over baseline models while
reducing computational requirements by 34%. Expert specialization yields
significant domain-specific gains, with improvements from 51% to 88% F1 score
in general classification and from 23% to 44% accuracy in news categorization.
We formalize the routing entropy optimization problem and demonstrate how
proper regularization techniques lead to 14% higher expert utilization rates.
These results validate MoECollab as an effective approach for democratizing LLM
development through architecturally-supported collaboration.",['Harshit'],2025-03-16,"['cs.LG', 'cs.AI', 'cs.CL']",,http://arxiv.org/pdf/2503.12592v1
2503.12579v1,Focusing Robot Open-Ended Reinforcement Learning Through Users' Purposes,"Open-Ended Learning (OEL) autonomous robots can acquire new skills and
knowledge through direct interaction with their environment, relying on
mechanisms such as intrinsic motivations and self-generated goals to guide
learning processes. OEL robots are highly relevant for applications as they can
autonomously leverage acquired knowledge to perform tasks beneficial to human
users in unstructured environments, addressing challenges unforeseen at design
time. However, OEL robots face a significant limitation: their openness may
lead them to waste time learning information that is irrelevant to tasks
desired by specific users. Here, we propose a solution called `Purpose-Directed
Open-Ended Learning' (POEL), based on the novel concept of `purpose' introduced
in previous work. A purpose specifies what users want the robot to achieve. The
key insight of this work is that purpose can focus OEL on learning
self-generated classes of tasks that, while unknown during autonomous learning
(as typical in OEL), involve objects relevant to the purpose. This concept is
operationalised in a novel robot architecture capable of receiving a human
purpose through speech-to-text, analysing the scene to identify objects, and
using a Large Language Model to reason about which objects are
purpose-relevant. These objects are then used to bias OEL exploration towards
their spatial proximity and to self-generate rewards that favour interactions
with them. The solution is tested in a simulated scenario where a
camera-arm-gripper robot interacts freely with purpose-related and distractor
objects. For the first time, the results demonstrate the potential advantages
of purpose-focused OEL over state-of-the-art OEL methods, enabling robots to
handle unstructured environments while steering their learning toward knowledge
acquisition relevant to users.","['Emilio Cartoni', 'Gianluca Cioccolini', 'Gianluca Baldassarre']",2025-03-16,"['cs.RO', 'cs.LG']","4 pages, 2 figures, accepted at RLDM 2025",http://arxiv.org/pdf/2503.12579v1
2503.12572v1,Deblur Gaussian Splatting SLAM,"We present Deblur-SLAM, a robust RGB SLAM pipeline designed to recover sharp
reconstructions from motion-blurred inputs. The proposed method bridges the
strengths of both frame-to-frame and frame-to-model approaches to model
sub-frame camera trajectories that lead to high-fidelity reconstructions in
motion-blurred settings. Moreover, our pipeline incorporates techniques such as
online loop closure and global bundle adjustment to achieve a dense and precise
global trajectory. We model the physical image formation process of
motion-blurred images and minimize the error between the observed blurry images
and rendered blurry images obtained by averaging sharp virtual sub-frame
images. Additionally, by utilizing a monocular depth estimator alongside the
online deformation of Gaussians, we ensure precise mapping and enhanced image
deblurring. The proposed SLAM pipeline integrates all these components to
improve the results. We achieve state-of-the-art results for sharp map
estimation and sub-frame trajectory recovery both on synthetic and real-world
blurry input data.","['Francesco Girlanda', 'Denys Rozumnyi', 'Marc Pollefeys', 'Martin R. Oswald']",2025-03-16,"['cs.CV', 'cs.AI', 'cs.LG']",,http://arxiv.org/pdf/2503.12572v1
2503.12563v1,Diffusion on Graph: Augmentation of Graph Structure for Node Classification,"Graph diffusion models have recently been proposed to synthesize entire
graphs, such as molecule graphs. Although existing methods have shown great
performance in generating entire graphs for graph-level learning tasks, no
graph diffusion models have been developed to generate synthetic graph
structures, that is, synthetic nodes and associated edges within a given graph,
for node-level learning tasks. Inspired by the research in the computer vision
literature using synthetic data for enhanced performance, we propose Diffusion
on Graph (DoG), which generates synthetic graph structures to boost the
performance of GNNs. The synthetic graph structures generated by DoG are
combined with the original graph to form an augmented graph for the training of
node-level learning tasks, such as node classification and graph contrastive
learning (GCL). To improve the efficiency of the generation process, a Bi-Level
Neighbor Map Decoder (BLND) is introduced in DoG. To mitigate the adverse
effect of the noise introduced by the synthetic graph structures, a low-rank
regularization method is proposed for the training of graph neural networks
(GNNs) on the augmented graphs. Extensive experiments on various graph datasets
for semi-supervised node classification and graph contrastive learning have
been conducted to demonstrate the effectiveness of DoG with low-rank
regularization. The code of DoG is available at
https://github.com/Statistical-Deep-Learning/DoG.","['Yancheng Wang', 'Changyu Liu', 'Yingzhen Yang']",2025-03-16,['cs.LG'],Published in Transactions on Machine Learning Research (TMLR) 2025,http://arxiv.org/pdf/2503.12563v1
